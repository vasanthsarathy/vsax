{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"VSAX: Vector Symbolic Algebra for JAX","text":"<p>VSAX is a GPU-accelerated, JAX-native Python library for Vector Symbolic Architectures (VSAs). It provides composable symbolic representations using hypervectors, algebraic operations for binding and bundling, and encoding strategies for symbolic and structured data.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83d\ude80 Three VSA Models: FHRR, MAP, and Binary implementations \u2705</li> <li>\u26a1 GPU-Accelerated: Built on JAX for high-performance computation</li> <li>\ud83e\udde9 Modular Architecture: Clean separation between representations and operations</li> <li>\ud83e\uddec Complete Representations: Complex, Real, and Binary hypervectors \u2705</li> <li>\u2699\ufe0f Full Operation Sets: FFT-based FHRR, MAP, and XOR/majority Binary ops \u2705</li> <li>\ud83c\udfb2 Random Sampling: Sampling utilities for all representation types \u2705</li> <li>\ud83d\udcaf Type-Safe: Full type annotations with mypy support</li> <li>\u2705 Well-Tested: 339 tests with 96% coverage</li> <li>\ud83d\udd0d Similarity Metrics: Cosine, dot, and Hamming similarity</li> <li>\u26a1 Batch Operations: GPU-accelerated vmap operations</li> <li>\ud83d\udcbe I/O &amp; Persistence: Save/load basis vectors to JSON</li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#from-pypi-recommended","title":"From PyPI (Recommended)","text":"<pre><code>pip install vsax\n</code></pre>"},{"location":"#from-source","title":"From Source","text":"<pre><code>git clone https://github.com/yourusername/vsax.git\ncd vsax\n\n# Using uv (recommended)\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e \".[dev]\"\n\n# Or using pip\npip install -e \".[dev]\"\n</code></pre>"},{"location":"#quick-example","title":"Quick Example","text":""},{"location":"#simple-api-v050","title":"Simple API (v0.5.0)","text":"<pre><code>from vsax import create_fhrr_model, VSAMemory, DictEncoder\nfrom vsax.similarity import cosine_similarity\nfrom vsax.utils import vmap_bind\nimport jax.numpy as jnp\n\n# Create model with factory function\nmodel = create_fhrr_model(dim=512)\n\n# Create memory for symbols\nmemory = VSAMemory(model)\nmemory.add_many([\"dog\", \"cat\", \"animal\", \"run\", \"jump\"])\n\n# Access and manipulate symbols\ndog = memory[\"dog\"]\nanimal = memory[\"animal\"]\n\n# Bind two concepts (circular convolution)\ndog_is_animal = model.opset.bind(dog.vec, animal.vec)\n\n# Bundle multiple concepts (sum and normalize)\npets = model.opset.bundle(memory[\"dog\"].vec, memory[\"cat\"].vec)\n\n# NEW: Similarity search\nsimilarity = cosine_similarity(memory[\"dog\"], memory[\"cat\"])\nprint(f\"Dog-Cat similarity: {similarity:.3f}\")\n\n# NEW: Batch operations (GPU-accelerated)\nnouns = jnp.stack([memory[\"dog\"].vec, memory[\"cat\"].vec])\nverbs = jnp.stack([memory[\"run\"].vec, memory[\"jump\"].vec])\nactions = vmap_bind(model.opset, nouns, verbs)  # Parallel binding!\n\n# NEW: Encoders\nencoder = DictEncoder(model, memory)\nsentence = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})\n</code></pre>"},{"location":"#map-model-real-hypervectors","title":"MAP Model (Real Hypervectors)","text":"<pre><code>from vsax import RealHypervector, MAPOperations, sample_random\n\nmodel = VSAModel(\n    dim=512,\n    rep_cls=RealHypervector,\n    opset=MAPOperations(),\n    sampler=sample_random\n)\n\n# Element-wise multiplication for binding\n# Element-wise mean for bundling\n</code></pre>"},{"location":"#binary-model-bipolar-hypervectors","title":"Binary Model (Bipolar Hypervectors)","text":"<pre><code>from vsax import BinaryHypervector, BinaryOperations, sample_binary_random\n\nmodel = VSAModel(\n    dim=512,\n    rep_cls=BinaryHypervector,\n    opset=BinaryOperations(),\n    sampler=sample_binary_random\n)\n\n# XOR binding (exact unbinding)\n# Majority voting for bundling\n</code></pre>"},{"location":"#development-status","title":"Development Status","text":"<p>Current: Iteration 6 Complete \u2705</p>"},{"location":"#completed","title":"Completed","text":"<p>Iteration 1 (v0.1.0): Foundation &amp; Infrastructure \u2705 - \u2705 Core abstract classes (AbstractHypervector, AbstractOpSet) - \u2705 VSAModel dataclass - \u2705 Package structure - \u2705 Testing infrastructure (pytest, coverage) - \u2705 CI/CD pipeline (GitHub Actions) - \u2705 Documentation site (MkDocs)</p> <p>Iteration 2 (v0.2.0): Core Algebras \u2705 - \u2705 All 3 representations (Complex, Real, Binary) - \u2705 All 3 operation sets (FHRR, MAP, Binary) - \u2705 Sampling utilities - \u2705 175 comprehensive tests with 96% coverage - \u2705 Full integration tests</p> <p>Iteration 3 (v0.3.0): Models &amp; Memory \u2705 - \u2705 VSAMemory for symbol storage - \u2705 Factory functions for easy model creation - \u2705 Integration utilities - \u2705 230 tests with 89% coverage</p> <p>Iteration 4 (v0.4.0): First Usable Release \u2705 - \u2705 5 Core Encoders (Scalar, Sequence, Set, Dict, Graph) - \u2705 AbstractEncoder base class - \u2705 Complete working examples for all 3 models - \u2705 Custom encoder examples - \u2705 280+ tests with 92%+ coverage</p> <p>Iteration 5 (v0.5.0): Similarity Metrics &amp; Utilities \u2705 - \u2705 Cosine, dot, and Hamming similarity functions - \u2705 Batch operations with JAX vmap (vmap_bind, vmap_bundle, vmap_similarity) - \u2705 Visualization utilities (pretty_repr, format_similarity_results) - \u2705 GPU-accelerated similarity search - \u2705 319 tests with 95%+ coverage</p> <p>Iteration 6 (v0.6.0): I/O &amp; Persistence \u2705 - \u2705 save_basis() and load_basis() functions - \u2705 JSON serialization for all 3 models - \u2705 Round-trip vector preservation - \u2705 Dimension and type validation - \u2705 339 tests with 96% coverage</p>"},{"location":"#coming-next","title":"Coming Next","text":"<p>Iteration 7 (v1.0.0): Full Documentation &amp; Production Release - Complete API documentation - Tutorial notebooks - Production-ready v1.0.0 release</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Getting Started - Installation and first steps</li> <li>Tutorials - Interactive Jupyter notebooks with real datasets \u2728 NEW</li> <li>MNIST Classification - Image classification with VSA</li> <li>Knowledge Graph Reasoning (coming soon)</li> <li>User Guide - Detailed guides for all components</li> <li>Examples - Working examples for all three models</li> <li>API Reference - Complete API documentation</li> <li>Design Specification - Technical design details</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions! Please see CONTRIBUTING.md for guidelines.</p>"},{"location":"#license","title":"License","text":"<p>VSAX is released under the MIT License. See LICENSE for details.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use VSAX in your research, please cite:</p> <pre><code>@software{vsax2025,\n  title = {VSAX: Vector Symbolic Algebra for JAX},\n  author = {Sarathy, Vasanth},\n  year = {2025},\n  version = {0.7.2},\n  url = {https://github.com/vasanthsarathy/vsax}\n}\n</code></pre>"},{"location":"comparison/","title":"VSAX vs Other HDC/VSA Libraries","text":"<p>This document explains VSAX's design philosophy and how it compares to other open-source hyperdimensional computing libraries.</p>"},{"location":"comparison/#tldr-when-to-use-vsax","title":"TL;DR - When to Use VSAX","text":"<p>Choose VSAX if you want: - \u2705 JAX-native functional programming with automatic GPU acceleration - \u2705 Clean separation between representations and operations - \u2705 Composable, modular architecture for research and prototyping - \u2705 Strong theoretical grounding (implements canonical VSA models) - \u2705 Type-safe, well-documented API with 94% test coverage - \u2705 Resonator networks for factorization - \u2705 Seamless integration with JAX ecosystem (jit, vmap, grad)</p> <p>Choose alternatives if you need: - \u274c PyTorch integration \u2192 torchhd - \u274c Production ML classifiers with 150+ datasets \u2192 torchhd - \u274c Biomedical/medical informatics focus \u2192 hdlib - \u274c Advanced boolean operations and circuit compilation \u2192 PyBHV - \u274c Custom CUDA kernels \u2192 hdtorch</p>"},{"location":"comparison/#vsaxs-design-philosophy","title":"VSAX's Design Philosophy","text":"<p>VSAX is built on three core principles:</p>"},{"location":"comparison/#1-jax-native-functional-programming","title":"1. JAX-Native Functional Programming","text":"<p>Unlike PyTorch-based libraries (torchhd, hdtorch), VSAX is built entirely on JAX:</p> <pre><code># JAX provides automatic differentiation, JIT compilation, and vectorization\nfrom jax import jit, vmap, grad\nimport jax.numpy as jnp\n\n# VSAX operations are pure functions\nresult = model.opset.bind(a, b)  # Functional, composable\n\n# Automatic GPU acceleration - no explicit device management\n@jit\ndef fast_encoding(vectors):\n    return vmap(model.opset.bundle)(vectors)\n</code></pre> <p>Why JAX? - Functional purity: No hidden state, easier to reason about - Automatic transformations: <code>jit</code>, <code>vmap</code>, <code>grad</code> work out of the box - Research-friendly: Designed for ML research at Google/DeepMind - NumPy-like API: Familiar interface, minimal learning curve</p>"},{"location":"comparison/#2-modular-architecture","title":"2. Modular Architecture","text":"<p>VSAX cleanly separates concerns:</p> <pre><code># Representations (data)\nComplexHypervector, RealHypervector, BinaryHypervector\n\n# Operations (algorithms)\nFHRROperations, MAPOperations, BinaryOperations\n\n# Model (composition)\nVSAModel(dim, rep_cls, opset, sampler)\n</code></pre> <p>This is different from torchhd's integrated approach where models are classes with built-in operations.</p> <p>Benefit: Mix and match components: - Try different operations with the same representation - Swap representations without changing code - Easy to add new VSA models</p>"},{"location":"comparison/#3-simplicity-and-clarity","title":"3. Simplicity and Clarity","text":"<p>VSAX prioritizes understanding over features:</p> <ul> <li>3 canonical VSA models (FHRR, MAP, Binary) implemented correctly</li> <li>Clear abstractions: Every operation has a mathematical meaning</li> <li>Comprehensive tutorials: Learn VSA concepts, not just API calls</li> <li>Theory-first: Based on foundational papers (Plate, Gayler, Kanerva)</li> </ul>"},{"location":"comparison/#feature-comparison","title":"Feature Comparison","text":""},{"location":"comparison/#supported-vsa-models","title":"Supported VSA Models","text":"Library FHRR MAP Binary HRR Others VSAX \u2705 \u2705 \u2705 \u274c - torchhd \u2705 \u2705 \u2705 (BSC) \u2705 B-SBC, CGR, MCR, VTB hdlib \u2753 \u2753 \u2753 \u2753 General VSA PyBHV \u274c \u274c \u2705 \u274c Boolean only hdtorch \u2753 \u2753 \u2705 \u2753 Focus on CUDA ops <p>VSAX focuses on quality over quantity: 3 well-implemented models vs 8+ models with varying documentation.</p>"},{"location":"comparison/#core-operations","title":"Core Operations","text":"Feature VSAX torchhd hdlib PyBHV hdtorch Binding \u2705 \u2705 \u2705 \u2705 (XOR) \u2705 Bundling \u2705 \u2705 \u2705 \u2705 (Majority) \u2705 Permutation \u2705 \u2705 \u2705 \u2705 \u2705 Similarity \u2705 \u2705 \u2705 \u2705 \u2705 Resonator Networks \u2705 \u274c \u274c \u274c \u274c Memory/Cleanup \u2705 \u2705 \u2705 \u274c \u274c <p>VSAX unique feature: Full implementation of resonator networks for factorization (from Frady et al. 2020).</p>"},{"location":"comparison/#encoders","title":"Encoders","text":"Feature VSAX torchhd hdlib PyBHV hdtorch Scalar \u2705 \u2705 (Level, Thermometer) \u2705 \u274c \u2705 Sequence \u2705 \u2705 \u2705 \u274c \u2705 Set \u2705 \u2705 (Multiset) \u2705 \u274c \u274c Dict/Record \u2705 \u274c \u274c \u274c \u274c Graph \u2705 \u2705 \u2705 \u2705 \u274c Tree \u274c \u2705 \u274c \u274c \u274c FSA \u274c \u2705 \u274c \u274c \u274c <p>VSAX strength: Clean, extensible encoder API with <code>AbstractEncoder</code> base class.</p>"},{"location":"comparison/#machine-learning","title":"Machine Learning","text":"Feature VSAX torchhd hdlib PyBHV hdtorch Classification \u274c \u2705 (9+ types) \u2705 \u2705 \u2705 (Basic) Built-in Datasets \u274c \u2705 (150+) \u2705 (Some) \u274c \u274c Online Learning \u274c \u2705 (OnlineHD) \u274c \u274c \u274c Neural Integration \u274c \u2705 (NeuralHD) \u274c \u274c \u274c Regression \u274c \u274c \u2705 \u274c \u274c Clustering \u274c \u274c \u2705 \u274c \u274c <p>Biggest VSAX gap: No built-in classifiers or ML workflows (yet).</p> <p>torchhd is the clear winner for production ML applications.</p>"},{"location":"comparison/#performance-hardware","title":"Performance &amp; Hardware","text":"Feature VSAX torchhd hdlib PyBHV hdtorch GPU Support \u2705 (JAX auto) \u2705 (PyTorch) \u274c \u2705 (PyTorch backend) \u2705 (Custom CUDA) CPU Fallback \u2705 \u2705 \u2705 \u2705 \u274c Batch Operations \u2705 (vmap) \u2705 \u2705 \u2705 \u2705 JIT Compilation \u2705 (JAX) \u2705 (TorchScript) \u274c \u274c \u2705 Custom Kernels \u274c \u274c \u274c \u2705 (C++) \u2705 (CUDA) <p>VSAX uses JAX's automatic GPU dispatch - no manual device management.</p>"},{"location":"comparison/#developer-experience","title":"Developer Experience","text":"Feature VSAX torchhd hdlib PyBHV hdtorch Type Hints \u2705 (Full) \u2705 \u2753 \u274c \u2753 Test Coverage 94% \u2753 \u2753 \u2753 \u2753 Documentation \u2705 \u2705 \u2705 (Wiki) \u2705 \u2705 Tutorials \u2705 (3 deep) \u2705 \u2705 \u2705 (Examples) \u2705 Examples \u2705 \u2705 \u2705 \u2705 (Many) \u2705 <p>VSAX prioritizes code quality: Type-safe, well-tested, thoroughly documented.</p>"},{"location":"comparison/#detailed-library-comparison","title":"Detailed Library Comparison","text":""},{"location":"comparison/#torchhd-the-production-ml-library","title":"torchhd: The Production ML Library","text":"<p>Best for: Machine learning applications, classification tasks, production deployment</p> <p>Strengths: - Comprehensive: 8 VSA models, 9+ classifiers, 150+ datasets - Production-ready: Battle-tested with active community (346 stars) - PyTorch integration: Seamless with existing PyTorch workflows - Rich structures: Graph, Tree, FSA, HashTable implementations - Well-documented: Extensive tutorials and examples</p> <p>Weaknesses: - Complexity: Large API surface, steeper learning curve - PyTorch-coupled: Hard to use without PyTorch knowledge - Less modular: Models are monolithic classes</p> <p>When to choose over VSAX: - You need production ML classifiers - You're already using PyTorch - You want ready-made datasets - You need advanced structures (Tree, FSA)</p>"},{"location":"comparison/#hdlib-the-biomedical-specialist","title":"hdlib: The Biomedical Specialist","text":"<p>Best for: Biomedical applications, bioinformatics, medical informatics</p> <p>Strengths: - Domain focus: Proven in cancer classification, metagenomics - Versatile: Classification, regression, clustering, feature selection - Academic backing: Peer-reviewed publications - Easy install: PyPI and conda-forge</p> <p>Weaknesses: - Less clear: VSA model support not well documented - No GPU: CPU-only implementation - Older codebase: Less active maintenance</p> <p>When to choose over VSAX: - You're working in bioinformatics/medical AI - You need regression or clustering - You want proven biomedical applications</p>"},{"location":"comparison/#pybhv-the-boolean-specialist","title":"PyBHV: The Boolean Specialist","text":"<p>Best for: Boolean operations, symbolic reasoning, theoretical research</p> <p>Strengths: - Research framework: Expression simplification, circuit compilation - Multiple backends: Python, C++, NumPy, PyTorch with bit-packing - Rich metrics: Comprehensive distance and similarity measures - Symbolic computing: Law-based testing and optimization - Memory efficient: 8x compression with bit-packing</p> <p>Weaknesses: - Boolean only: No support for real or complex hypervectors - Narrow focus: Limited to binary VSA - Complex API: Many abstraction levels</p> <p>When to choose over VSAX: - You only need boolean/binary hypervectors - You want circuit compilation or logic synthesis - You need bit-level optimization - You're doing theoretical VSA research</p>"},{"location":"comparison/#hdtorch-the-cuda-accelerator","title":"hdtorch: The CUDA Accelerator","text":"<p>Best for: Custom GPU kernels, maximum performance</p> <p>Strengths: - Custom CUDA: Hand-optimized GPU kernels - Performance: Fastest for supported operations - Educational: Clear tutorials on CUDA implementation</p> <p>Weaknesses: - Limited scope: Fewer features than torchhd or VSAX - CUDA required: No CPU fallback - Less mature: Smaller community</p> <p>When to choose over VSAX: - You need maximum GPU performance - You want to learn CUDA kernel programming - You're willing to trade features for speed</p>"},{"location":"comparison/#what-makes-vsax-unique","title":"What Makes VSAX Unique?","text":""},{"location":"comparison/#1-jax-first-design","title":"1. JAX-First Design","text":"<p>VSAX is the only JAX-native VSA library:</p> <pre><code># Automatic GPU acceleration\nmodel = create_fhrr_model(dim=512)  # Works on GPU if available\n\n# JIT compilation for speed\n@jit\ndef encode_batch(items):\n    return vmap(encoder.encode)(items)\n\n# Automatic differentiation (future: differentiable VSA)\ngradient = grad(lambda x: similarity(x, target))\n</code></pre> <p>Why this matters: - JAX is the future of ML research (used by Google, DeepMind) - Functional programming = easier reasoning - Better for research and prototyping</p>"},{"location":"comparison/#2-clean-theoretical-foundation","title":"2. Clean Theoretical Foundation","text":"<p>VSAX implements the canonical VSA models from foundational papers:</p> <ul> <li>FHRR: Plate (1995) - Complex-valued circular convolution</li> <li>MAP: Gayler (1998) - Multiply-Add-Permute</li> <li>Binary: Kanerva (1996) - Binary Spatter Codes</li> </ul> <p>Each implementation is mathematically correct and well-documented.</p>"},{"location":"comparison/#3-resonator-networks","title":"3. Resonator Networks","text":"<p>VSAX is the only library with full resonator support:</p> <pre><code># Factorize compositional structures\nresonator = Resonator(model, codebooks=[subjects, relations, objects])\nfactors = resonator.factorize(composite_vector)\n# ['dog', 'isA', 'mammal']\n</code></pre> <p>Based on Frady et al. (2020), resonators enable: - Decoding compositional structures - Iterative refinement with convergence - Multi-factor factorization</p>"},{"location":"comparison/#4-tutorial-driven-documentation","title":"4. Tutorial-Driven Documentation","text":"<p>VSAX teaches VSA concepts, not just API:</p> <ol> <li>MNIST Classification: Learn encoding and prototypes</li> <li>Knowledge Graphs: Understand binding and bundling</li> <li>Kanerva's Analogies: Master mappings and transformations</li> </ol> <p>Each tutorial implements foundational papers with full code.</p>"},{"location":"comparison/#5-research-friendly-architecture","title":"5. Research-Friendly Architecture","text":"<p>VSAX makes it easy to experiment:</p> <pre><code># Try different operations with same representation\nmodel1 = VSAModel(dim=512, rep_cls=ComplexHypervector,\n                  opset=FHRROperations(), sampler=sample_complex_random)\n\nmodel2 = VSAModel(dim=512, rep_cls=ComplexHypervector,\n                  opset=MAPOperations(), sampler=sample_complex_random)\n\n# Same API, different algebra!\n</code></pre>"},{"location":"comparison/#what-vsax-doesnt-yet-do","title":"What VSAX Doesn't (Yet) Do","text":"<p>We're honest about gaps:</p>"},{"location":"comparison/#machine-learning-classifiers","title":"\u274c Machine Learning Classifiers","text":"<p>Missing: - No built-in classifiers (Centroid, AdaptHD, OnlineHD, etc.) - No datasets - No training loops</p> <p>Workaround: Build your own with VSAX primitives: <pre><code># Manual centroid classifier\nprototypes = {label: bundle(class_examples) for label, class_examples in data}\nprediction = max(prototypes, key=lambda l: similarity(query, prototypes[l]))\n</code></pre></p> <p>Future: v1.0+ will add classifiers</p>"},{"location":"comparison/#advanced-structures","title":"\u274c Advanced Structures","text":"<p>Missing: - Tree encoders - Finite State Automata - HashTable structures</p> <p>Workaround: Use GraphEncoder as building block</p> <p>Future: May add in v1.x based on demand</p>"},{"location":"comparison/#additional-vsa-models","title":"\u274c Additional VSA Models","text":"<p>Missing: - HRR (original Plate model without FFT) - BSC variants (Sparse Block Codes) - CGR, MCR, VTB from recent research</p> <p>Reason: We prioritize depth (correct implementation, documentation, tests) over breadth</p> <p>Future: May add models with strong theoretical foundation</p>"},{"location":"comparison/#production-optimization","title":"\u274c Production Optimization","text":"<p>Missing: - Custom CUDA kernels (like hdtorch) - Bit-packing (like PyBHV) - Quantization/compression</p> <p>Reason: JAX provides good-enough performance for research</p> <p>Future: Optimization in later versions if needed</p>"},{"location":"comparison/#choosing-the-right-library","title":"Choosing the Right Library","text":""},{"location":"comparison/#use-vsax-if-you","title":"Use VSAX if you:","text":"<ul> <li>\ud83c\udf93 Want to learn VSA deeply with tutorial-driven examples</li> <li>\ud83d\udd2c Are doing research and need flexibility</li> <li>\ud83e\uddee Prefer functional programming and JAX</li> <li>\ud83d\udcd0 Value theoretical correctness over feature count</li> <li>\ud83e\udde9 Need compositional operations (resonators, mappings)</li> <li>\ud83d\udcbb Want type-safe, well-tested code</li> </ul>"},{"location":"comparison/#use-torchhd-if-you","title":"Use torchhd if you:","text":"<ul> <li>\ud83c\udfed Need production ML with classifiers and datasets</li> <li>\ud83d\udd25 Are already using PyTorch</li> <li>\ud83d\udcca Want many VSA models to experiment with</li> <li>\ud83d\ude80 Need battle-tested software (350+ stars)</li> <li>\ud83c\udfaf Are building classification systems</li> </ul>"},{"location":"comparison/#use-hdlib-if-you","title":"Use hdlib if you:","text":"<ul> <li>\ud83e\uddec Work in bioinformatics or medical AI</li> <li>\ud83d\udcc8 Need regression or clustering</li> <li>\ud83d\udcda Want proven biomedical applications</li> <li>\ud83d\udc0d Prefer simple Python without GPU</li> </ul>"},{"location":"comparison/#use-pybhv-if-you","title":"Use PyBHV if you:","text":"<ul> <li>\ud83d\udd32 Only need boolean hypervectors</li> <li>\u26a1 Want bit-level optimization</li> <li>\ud83e\udde0 Are doing symbolic reasoning research</li> <li>\ud83d\udd27 Need circuit compilation</li> </ul>"},{"location":"comparison/#use-hdtorch-if-you","title":"Use hdtorch if you:","text":"<ul> <li>\u2699\ufe0f Need custom CUDA kernels</li> <li>\ud83c\udfce\ufe0f Want maximum GPU performance</li> <li>\ud83c\udf93 Want to learn CUDA programming</li> </ul>"},{"location":"comparison/#vsax-roadmap-closing-the-gaps","title":"VSAX Roadmap: Closing the Gaps","text":""},{"location":"comparison/#v100-future","title":"v1.0.0 (Future)","text":"<ul> <li>\u2705 Basic classifiers (Centroid, kNN)</li> <li>\u2705 Common datasets (MNIST, CIFAR-10)</li> <li>\u2705 Training utilities</li> </ul>"},{"location":"comparison/#v110-future","title":"v1.1.0 (Future)","text":"<ul> <li>\u2705 Tree and FSA encoders</li> <li>\u2705 Additional VSA models (HRR, BSC variants)</li> </ul>"},{"location":"comparison/#v200-future","title":"v2.0.0 (Future)","text":"<ul> <li>\u2705 Advanced classifiers (OnlineHD, AdaptHD)</li> <li>\u2705 Performance optimizations</li> <li>\u2705 Production tooling</li> </ul> <p>Guiding principle: Maintain simplicity and theoretical clarity while adding practical features.</p>"},{"location":"comparison/#contributing-to-vsax","title":"Contributing to VSAX","text":"<p>We welcome contributions! Priority areas:</p> <ol> <li>Classifiers: Implement standard HDC classifiers</li> <li>Datasets: Add benchmark datasets with encoders</li> <li>Examples: More domain applications (NLP, robotics, etc.)</li> <li>VSA Models: Add models with theoretical grounding</li> <li>Performance: Optimize hot paths while keeping API clean</li> </ol> <p>See CONTRIBUTING.md for guidelines.</p>"},{"location":"comparison/#conclusion","title":"Conclusion","text":"<p>VSAX is a research-oriented, JAX-native VSA library that prioritizes: - \u2728 Clarity over completeness - \ud83e\uddee Theory over features - \ud83d\udd2c Research over production</p> <p>If you need production ML \u2192 choose torchhd If you need biomedical apps \u2192 choose hdlib If you need boolean operations \u2192 choose PyBHV If you need custom CUDA \u2192 choose hdtorch</p> <p>If you want to understand VSA deeply and build novel approaches \u2192 choose VSAX \u2728</p>"},{"location":"comparison/#references","title":"References","text":"<ul> <li>torchhd: https://github.com/hyperdimensional-computing/torchhd</li> <li>hdlib: https://github.com/cumbof/hdlib</li> <li>PyBHV: https://github.com/Adam-Vandervorst/PyBHV</li> <li>hdtorch: https://hdtorch.readthedocs.io/en/latest/</li> </ul> <p>Last updated: 2025-01-16</p>"},{"location":"design-spec/","title":"Technical Specification: VSAX - Vector Symbolic Algebra Library","text":""},{"location":"design-spec/#overview","title":"Overview","text":"<p>VSAX is a GPU-accelerated, JAX-native Python library for vector symbolic architectures (VSAs). It provides composable symbolic representations using hypervectors, algebraic operations for binding and bundling, and encoding strategies for symbolic and structured data. The library is designed to be modular, efficient, and extensible.</p>"},{"location":"design-spec/#core-objectives","title":"Core Objectives","text":"<ul> <li>Enable definition of VSA models combining representations (e.g., complex, real, binary) with algebraic operation sets (e.g., FHRR, MAP).</li> <li>Support encoding of symbolic data (scalars, dictionaries, graphs) using model-defined operations.</li> <li>Maintain a persistent, accessible store of basis hypervectors.</li> <li>Be fully compatible with JAX for high-performance, differentiable, GPU/TPU computation.</li> <li>Provide a clean API and separation of concerns.</li> <li>Be as usable and expressive as NumPy or PyTorch for symbolic computation.</li> </ul>"},{"location":"design-spec/#architecture","title":"Architecture","text":""},{"location":"design-spec/#1-vsamodel","title":"1. VSAModel","text":"<ul> <li><code>dim: int</code> \u2014 dimensionality of all hypervectors</li> <li><code>rep_cls: Type[AbstractHypervector]</code> \u2014 the representation class (e.g. ComplexHypervector)</li> <li><code>opset: AbstractOpSet</code> \u2014 operation strategies (bind, bundle, inverse)</li> <li><code>sampler: Callable[[int, int], jnp.ndarray]</code> \u2014 function for sampling raw vectors</li> </ul> <p>\u27a1\ufe0f Immutable dataclass container for algebra definition. No ops. Used by encoders and memory.</p>"},{"location":"design-spec/#2-vsamemory","title":"2. VSAMemory","text":"<ul> <li>Stores named hypervectors (basis symbols)</li> <li>Uses <code>VSAModel</code> to sample and wrap vectors</li> <li>Supports dictionary-style access:</li> <li><code>memory.add(\"apple\")</code></li> <li><code>memory[\"apple\"]</code></li> <li>Methods:</li> <li><code>add(name: str)</code></li> <li><code>add_many(names: list[str])</code></li> <li><code>get(name: str)</code> \u2192 returns representation-wrapped vector</li> </ul> <p>\u27a1\ufe0f Symbol table + runtime memory for symbolic concepts.</p>"},{"location":"design-spec/#3-abstracthypervector","title":"3. AbstractHypervector","text":"<ul> <li>Base class for representations</li> <li>Wraps a single <code>jnp.ndarray</code> with:</li> <li><code>.vec</code>: the underlying vector</li> <li><code>.normalize()</code></li> <li><code>.to_numpy()</code></li> <li><code>.shape</code>, <code>.dtype</code> proxies</li> <li>Future: implement <code>__jax_array__</code> and <code>__array__</code> for seamless ops</li> </ul> <p>\u27a1\ufe0f Allows clean vector math and JAX compatibility.</p>"},{"location":"design-spec/#4-abstractopset","title":"4. AbstractOpSet","text":"<p>Defines symbolic operations over <code>jnp.ndarray</code>s: - <code>bind(a, b)</code> - <code>bundle(*args)</code> - <code>inverse(a)</code> - <code>permute(a, shift)</code> (optional)</p> <p>\u27a1\ufe0f Stateless, pure functional interface for algebra.</p>"},{"location":"design-spec/#5-encoders","title":"5. Encoders","text":"<p>Classes that convert structured data into hypervectors:</p>"},{"location":"design-spec/#scalarencoder","title":"ScalarEncoder","text":"<ul> <li>Input: <code>name: str</code>, <code>value: float</code></li> <li>Output: powered basis vector (e.g. <code>basis_vec ** value</code>)</li> </ul>"},{"location":"design-spec/#dictencoder","title":"DictEncoder","text":"<ul> <li>Input: <code>{role: filler}</code></li> <li>Output: bundled binding of role-filler pairs</li> </ul> <p>\u27a1\ufe0f Each encoder accepts a model and memory. Add <code>.fit()</code>, <code>.encode()</code> for consistency.</p>"},{"location":"design-spec/#6-similarity-metrics","title":"6. Similarity Metrics","text":"<p>Located in <code>vsax/similarity/</code> - <code>cosine_similarity(a, b)</code> - <code>dot_similarity(a, b)</code> - <code>hamming_similarity(a, b)</code></p> <p>\u27a1\ufe0f Independent of model. Uses <code>.vec</code> or coerces inputs.</p>"},{"location":"design-spec/#7-io","title":"7. I/O","text":""},{"location":"design-spec/#save_basismemory-path","title":"<code>save_basis(memory, path)</code>","text":"<ul> <li>JSON serialization of named basis vectors</li> </ul>"},{"location":"design-spec/#load_basismemory-path","title":"<code>load_basis(memory, path)</code>","text":"<ul> <li>Load into a memory from disk using the model's <code>rep_cls</code></li> </ul> <p>\u27a1\ufe0f Reuse persistent symbolic spaces across sessions.</p>"},{"location":"design-spec/#8-resonator-networks","title":"8. Resonator Networks","text":""},{"location":"design-spec/#cleanupmemory","title":"<code>CleanupMemory</code>","text":"<ul> <li>Codebook projection for nearest vector retrieval</li> <li>Input: query vector</li> <li>Output: closest symbol from codebook or None if below threshold</li> </ul>"},{"location":"design-spec/#resonator","title":"<code>Resonator</code>","text":"<ul> <li>Iterative factorization of VSA composites</li> <li>Decomposes <code>s = a \u2299 b \u2299 c</code> into factors from known codebooks</li> <li>Superposition initialization (Frady et al. 2020)</li> <li>Supports 2-3 factor composites</li> <li>Works with all 3 VSA models</li> </ul> <p>\u27a1\ufe0f Enables decoding of complex VSA data structures.</p>"},{"location":"design-spec/#9-vector-utilities","title":"9. Vector Utilities","text":"<ul> <li><code>vsax.utils.coerce_vec()</code> \u2014 ensure input is <code>jnp.ndarray</code></li> <li><code>vsax.utils.vmap_bind()</code> \u2014 batch version of bind</li> <li><code>vsax.utils.vmap_bundle()</code> \u2014 batch version of bundle</li> <li><code>vsax.utils.pretty_repr()</code> \u2014 printing shape/type of vectors</li> </ul> <p>\u27a1\ufe0f Improves usability and debugging.</p>"},{"location":"design-spec/#representations","title":"Representations","text":"<p>Located in <code>vsax/representations/</code> - <code>ComplexHypervector</code> \u2014 phase-based encoding, useful for FHRR - <code>BinaryHypervector</code> \u2014 elementwise \u00b11 or 0/1 vectors - <code>RealHypervector</code> \u2014 continuous valued vectors</p> <p>Each wraps a <code>jnp.ndarray</code> and conforms to <code>AbstractHypervector</code>.</p>"},{"location":"design-spec/#operation-sets","title":"Operation Sets","text":"<p>Located in <code>vsax/ops/</code> - <code>FHRROperations</code> \u2014 FFT-based circular convolution - <code>MAPOperations</code> \u2014 elementwise multiplication and mean - <code>BinaryOperations</code> \u2014 XOR, majority</p> <p>\u27a1\ufe0f Functional, stateless ops working directly on <code>jnp.ndarray</code>s.</p>"},{"location":"design-spec/#sampling","title":"Sampling","text":"<p>Located in <code>vsax/sampling/</code> - <code>sample_random(dim, n)</code> \u2014 random normal - <code>sample_circular(dim, n)</code> \u2014 structured circular sampling</p> <p>\u27a1\ufe0f Used by <code>VSAModel</code> for basis vector generation.</p>"},{"location":"design-spec/#test-coverage","title":"Test Coverage","text":"<p>Located in <code>tests/</code> - <code>test_model_memory_init()</code> - <code>test_scalar_encoding()</code> - <code>test_dict_encoding()</code> - <code>test_similarity_metrics()</code> - <code>test_save_load()</code> - <code>test_vector_ops()</code> - <code>test_batch_encoding()</code> (planned)</p> <p>\u27a1\ufe0f Validates representation correctness and symbolic consistency.</p>"},{"location":"design-spec/#usage-examples","title":"Usage Examples","text":""},{"location":"design-spec/#example-1-basic-symbolic-binding","title":"Example 1: Basic symbolic binding","text":"<pre><code>a = memory[\"apple\"]\nb = memory[\"fruit\"]\nencoded = model.opset.bind(a.vec, b.vec)\n</code></pre>"},{"location":"design-spec/#example-2-scalar-encoding","title":"Example 2: Scalar Encoding","text":"<pre><code>encoder = ScalarEncoder(model, memory)\nmemory.add(\"temperature\")\nvec = encoder.encode(\"temperature\", 23.5)\n</code></pre>"},{"location":"design-spec/#example-3-dictionary-encoding-role-filler","title":"Example 3: Dictionary Encoding (role-filler)","text":"<pre><code>encoder = DictEncoder(model, memory)\nmemory.add_many([\"subject\", \"predicate\", \"object\", \"dog\", \"is_a\", \"animal\"])\nvec = encoder.encode({\"subject\": \"dog\", \"predicate\": \"is_a\", \"object\": \"animal\"})\n</code></pre>"},{"location":"design-spec/#example-4-similarity","title":"Example 4: Similarity","text":"<pre><code>similarity = cosine_similarity(vec, memory[\"dog\"])\n</code></pre>"},{"location":"design-spec/#example-5-save-and-load-basis","title":"Example 5: Save and Load Basis","text":"<pre><code>save_basis(memory, \"./basis.json\")\nnew_memory = VSAMemory(model)\nload_basis(new_memory, \"./basis.json\")\n</code></pre>"},{"location":"design-spec/#example-6-batch-operations","title":"Example 6: Batch Operations","text":"<pre><code>from vsax.utils.batch import vmap_bind\nX = jnp.stack([a.vec, b.vec, c.vec])\nY = jnp.stack([x.vec, y.vec, z.vec])\nbatch_result = vmap_bind(model.opset, X, Y)\n</code></pre>"},{"location":"design-spec/#example-7-resonator-networks","title":"Example 7: Resonator Networks","text":"<pre><code>from vsax import CleanupMemory, Resonator\n\n# Create codebooks\nletters = CleanupMemory([\"alpha\", \"beta\"], memory)\nnumbers = CleanupMemory([\"one\", \"two\"], memory)\n\n# Create resonator\nresonator = Resonator([letters, numbers], model.opset)\n\n# Factorize composite\ncomposite = model.opset.bind(memory[\"alpha\"].vec, memory[\"one\"].vec)\nfactors = resonator.factorize(composite)  # [\"alpha\", \"one\"]\n</code></pre>"},{"location":"design-spec/#example-8-access-vec-automatically","title":"Example 8: Access .vec automatically","text":"<pre><code># Future sugar\nbind(a, b)  # Automatically unwraps .vec if needed\n</code></pre>"},{"location":"design-spec/#extensibility-plan","title":"Extensibility Plan","text":""},{"location":"design-spec/#completed","title":"Completed \u2705","text":"<ul> <li>\u2705 <code>GraphEncoder</code>, <code>SequenceEncoder</code>, <code>SetEncoder</code>, <code>DictEncoder</code>, <code>ScalarEncoder</code></li> <li>\u2705 Dictionary-style access to <code>VSAMemory</code></li> <li>\u2705 <code>vmap</code>/<code>jit</code>-friendly versions of bind/bundle</li> <li>\u2705 Save/load basis vectors (I/O)</li> <li>\u2705 Resonator networks for factorization</li> <li>\u2705 Similarity metrics (cosine, dot, Hamming)</li> <li>\u2705 Batch operations (vmap_bind, vmap_bundle, vmap_similarity)</li> </ul>"},{"location":"design-spec/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Add <code>TreeEncoder</code> for hierarchical structures</li> <li>Add <code>QuaternionHypervector</code>, <code>FourierHypervector</code></li> <li>Add coercion logic to auto-handle <code>.vec</code></li> <li>Implement <code>__jax_array__</code> on representations for seamless ops</li> <li>Streamlit UI for interactive symbolic exploration</li> <li>CLI tools for inspecting memory</li> <li>Registries for custom representations and opsets</li> <li>Multi-factor resonator support (4+ factors)</li> </ul>"},{"location":"design-spec/#summary","title":"Summary","text":"<p>VSAX (v0.7.1) provides a principled, modular, and efficient system for symbolic reasoning with hypervectors. It is built for researchers and developers interested in neurosymbolic AI, cognitive modeling, and high-performance semantic encoding systems.</p> <p>Key Features: - Three complete VSA models (FHRR, MAP, Binary) - Five core encoders for structured data - Resonator networks for factorization and decoding - Similarity metrics and batch operations - I/O persistence for basis vectors - GPU acceleration via JAX</p> <p>Usability is prioritized with a clean, NumPy-style API, factory functions, batch operations, and JAX-native performance \u2014 enabling symbolic algebra at scale.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<p>VSAX requires Python 3.9 or later.</p>"},{"location":"getting-started/#from-pypi-recommended","title":"From PyPI (Recommended)","text":"<pre><code>pip install vsax\n</code></pre>"},{"location":"getting-started/#from-source","title":"From Source","text":""},{"location":"getting-started/#using-uv-recommended","title":"Using uv (Recommended)","text":"<p>uv is a fast Python package installer and resolver created by Astral (the makers of ruff). It's significantly faster than pip and handles virtual environments seamlessly.</p> <p>Install uv:</p> <pre><code># Unix/macOS\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre> <p>Install VSAX:</p> <pre><code>git clone https://github.com/vasanthsarathy/vsax.git\ncd vsax\n\n# Create virtual environment and install\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e .\n</code></pre>"},{"location":"getting-started/#using-pip","title":"Using pip","text":"<pre><code>git clone https://github.com/vasanthsarathy/vsax.git\ncd vsax\n\n# Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install package\npip install -e .\n</code></pre>"},{"location":"getting-started/#development-installation","title":"Development Installation","text":"<p>To install with development dependencies:</p> <p>Using uv: <pre><code>uv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e \".[dev,docs]\"\n</code></pre></p> <p>Using pip: <pre><code>python -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\npip install -e \".[dev,docs]\"\n</code></pre></p>"},{"location":"getting-started/#verifying-installation","title":"Verifying Installation","text":"<pre><code># Check that vsax is installed\npython -c \"import vsax; print(vsax.__version__)\"\n\n# Run tests\npytest\n</code></pre>"},{"location":"getting-started/#basic-usage","title":"Basic Usage","text":"<p>VSAX supports three VSA models:</p> <ol> <li>FHRR - Fourier Holographic Reduced Representation (complex hypervectors)</li> <li>MAP - Multiply-Add-Permute (real hypervectors)</li> <li>Binary VSA - Binary hypervectors with XOR binding</li> </ol>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":"<pre><code>from vsax import create_fhrr_model, VSAMemory, DictEncoder\nfrom vsax.similarity import cosine_similarity\n\n# Create model with factory function\nmodel = create_fhrr_model(dim=512)\n\n# Create memory for symbols\nmemory = VSAMemory(model)\nmemory.add_many([\"dog\", \"cat\", \"run\", \"jump\"])\n\n# Encode structured data\nencoder = DictEncoder(model, memory)\nsentence = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})\n\n# Similarity search\nsimilarity = cosine_similarity(memory[\"dog\"], memory[\"cat\"])\nprint(f\"Similarity: {similarity:.3f}\")\n</code></pre>"},{"location":"getting-started/#advanced-features","title":"Advanced Features","text":"<p>Resonator Networks (v0.7.0+) - Factorize composite hypervectors:</p> <pre><code>from vsax import CleanupMemory, Resonator\n\n# Create codebooks\nletters = CleanupMemory([\"alpha\", \"beta\"], memory)\nnumbers = CleanupMemory([\"one\", \"two\"], memory)\n\n# Create resonator\nresonator = Resonator([letters, numbers], model.opset)\n\n# Factorize composite\ncomposite = model.opset.bind(memory[\"alpha\"].vec, memory[\"one\"].vec)\nfactors = resonator.factorize(composite)  # [\"alpha\", \"one\"]\n</code></pre> <p>I/O &amp; Persistence (v0.6.0+) - Save and load basis vectors:</p> <pre><code>from vsax import save_basis, load_basis\n\n# Save basis to JSON\nsave_basis(memory, \"my_basis.json\")\n\n# Load basis from JSON\nnew_memory = VSAMemory(model)\nload_basis(new_memory, \"my_basis.json\")\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the API Reference</li> <li>Check out example notebooks</li> <li>Read the design specification</li> <li>See the User Guide for detailed tutorials</li> <li>Learn about Resonator Networks</li> <li>Understand Persistence</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for VSAX v0.7.1.</p>"},{"location":"api/#core-components","title":"Core Components","text":"<ul> <li>Base Classes - Abstract interfaces (AbstractHypervector, AbstractOpSet)</li> <li>VSAModel - Immutable model container</li> </ul>"},{"location":"api/#representations","title":"Representations","text":"<ul> <li>ComplexHypervector - Complex-valued phase-based representation</li> <li>RealHypervector - Real-valued continuous representation</li> <li>BinaryHypervector - Binary/bipolar discrete representation</li> </ul>"},{"location":"api/#operations","title":"Operations","text":"<ul> <li>FHRROperations - FFT-based circular convolution</li> <li>MAPOperations - Element-wise multiply and mean</li> <li>BinaryOperations - XOR and majority voting</li> </ul>"},{"location":"api/#sampling","title":"Sampling","text":"<ul> <li>Sampling Functions - Random vector generation</li> </ul>"},{"location":"api/#memory-utilities","title":"Memory &amp; Utilities","text":"<ul> <li>VSAMemory - Symbol table and basis management</li> <li>Factory Functions - Easy model creation</li> </ul>"},{"location":"api/#encoders","title":"Encoders","text":"<ul> <li>ScalarEncoder - Encode numeric values</li> <li>SequenceEncoder - Encode ordered sequences</li> <li>SetEncoder - Encode unordered collections</li> <li>DictEncoder - Encode key-value pairs</li> <li>GraphEncoder - Encode graph structures</li> <li>AbstractEncoder - Base class for custom encoders</li> </ul>"},{"location":"api/#similarity","title":"Similarity","text":"<ul> <li>Similarity Functions - Cosine, dot, Hamming similarity</li> </ul>"},{"location":"api/#resonator-networks","title":"Resonator Networks","text":"<ul> <li>CleanupMemory &amp; Resonator - Codebook projection and iterative factorization</li> </ul>"},{"location":"api/#io-persistence","title":"I/O &amp; Persistence","text":"<ul> <li>Save/Load Functions - JSON serialization for basis vectors</li> </ul>"},{"location":"api/#utilities","title":"Utilities","text":"<ul> <li>Batch Operations - vmap_bind, vmap_bundle, vmap_similarity</li> <li>Visualization - pretty_repr, format_similarity_results</li> </ul>"},{"location":"api/#quick-links","title":"Quick Links","text":"<ul> <li>Getting Started</li> <li>User Guide</li> <li>Examples</li> </ul>"},{"location":"api/sampling/","title":"Sampling Functions","text":"<p>Functions for generating random basis hypervectors.</p>"},{"location":"api/sampling/#sample_random","title":"sample_random","text":""},{"location":"api/sampling/#vsax.sampling.sample_random","title":"<code>vsax.sampling.sample_random(dim, n, key=None)</code>","text":"<p>Sample n random real-valued vectors from normal distribution.</p> <p>Generates random vectors with elements drawn from a standard normal distribution N(0, 1). These are suitable for use with MAP operations.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimensionality of each vector.</p> required <code>n</code> <code>int</code> <p>Number of vectors to sample.</p> required <code>key</code> <code>Optional[PRNGKey]</code> <p>JAX random key. If None, uses PRNGKey(0).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>JAX array of shape (n, dim) containing sampled vectors.</p> Example <p>import jax key = jax.random.PRNGKey(42) vectors = sample_random(512, 10, key) assert vectors.shape == (10, 512) assert not jnp.iscomplexobj(vectors)</p> Source code in <code>vsax/sampling/random.py</code> <pre><code>def sample_random(\n    dim: int, n: int, key: Optional[jax.random.PRNGKey] = None\n) -&gt; jnp.ndarray:\n    \"\"\"Sample n random real-valued vectors from normal distribution.\n\n    Generates random vectors with elements drawn from a standard normal\n    distribution N(0, 1). These are suitable for use with MAP operations.\n\n    Args:\n        dim: Dimensionality of each vector.\n        n: Number of vectors to sample.\n        key: JAX random key. If None, uses PRNGKey(0).\n\n    Returns:\n        JAX array of shape (n, dim) containing sampled vectors.\n\n    Example:\n        &gt;&gt;&gt; import jax\n        &gt;&gt;&gt; key = jax.random.PRNGKey(42)\n        &gt;&gt;&gt; vectors = sample_random(512, 10, key)\n        &gt;&gt;&gt; assert vectors.shape == (10, 512)\n        &gt;&gt;&gt; assert not jnp.iscomplexobj(vectors)\n    \"\"\"\n    if key is None:\n        key = jax.random.PRNGKey(0)\n\n    return jax.random.normal(key, shape=(n, dim))\n</code></pre>"},{"location":"api/sampling/#sample_complex_random","title":"sample_complex_random","text":""},{"location":"api/sampling/#vsax.sampling.sample_complex_random","title":"<code>vsax.sampling.sample_complex_random(dim, n, key=None)</code>","text":"<p>Sample n random complex-valued vectors with random phases.</p> <p>Generates unit-magnitude complex vectors with uniformly random phases in [0, 2\u03c0). These are suitable for use with FHRR operations.</p> <p>The vectors have the form: exp(i * \u03b8) where \u03b8 ~ Uniform(0, 2\u03c0).</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimensionality of each vector.</p> required <code>n</code> <code>int</code> <p>Number of vectors to sample.</p> required <code>key</code> <code>Optional[PRNGKey]</code> <p>JAX random key. If None, uses PRNGKey(0).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>JAX array of shape (n, dim) containing complex unit-magnitude vectors.</p> Example <p>import jax key = jax.random.PRNGKey(42) vectors = sample_complex_random(512, 10, key) assert vectors.shape == (10, 512) assert jnp.iscomplexobj(vectors)</p> Source code in <code>vsax/sampling/random.py</code> <pre><code>def sample_complex_random(\n    dim: int, n: int, key: Optional[jax.random.PRNGKey] = None\n) -&gt; jnp.ndarray:\n    \"\"\"Sample n random complex-valued vectors with random phases.\n\n    Generates unit-magnitude complex vectors with uniformly random phases\n    in [0, 2\u03c0). These are suitable for use with FHRR operations.\n\n    The vectors have the form: exp(i * \u03b8) where \u03b8 ~ Uniform(0, 2\u03c0).\n\n    Args:\n        dim: Dimensionality of each vector.\n        n: Number of vectors to sample.\n        key: JAX random key. If None, uses PRNGKey(0).\n\n    Returns:\n        JAX array of shape (n, dim) containing complex unit-magnitude vectors.\n\n    Example:\n        &gt;&gt;&gt; import jax\n        &gt;&gt;&gt; key = jax.random.PRNGKey(42)\n        &gt;&gt;&gt; vectors = sample_complex_random(512, 10, key)\n        &gt;&gt;&gt; assert vectors.shape == (10, 512)\n        &gt;&gt;&gt; assert jnp.iscomplexobj(vectors)\n        &gt;&gt;&gt; # All magnitudes should be 1.0\n        &gt;&gt;&gt; assert jnp.allclose(jnp.abs(vectors), 1.0)\n    \"\"\"\n    if key is None:\n        key = jax.random.PRNGKey(0)\n\n    # Sample random phases uniformly in [0, 2\u03c0)\n    phases = jax.random.uniform(key, shape=(n, dim), minval=0, maxval=2 * jnp.pi)\n\n    # Convert to complex unit vectors\n    return jnp.exp(1j * phases)\n</code></pre>"},{"location":"api/sampling/#vsax.sampling.sample_complex_random--all-magnitudes-should-be-10","title":"All magnitudes should be 1.0","text":"<p>assert jnp.allclose(jnp.abs(vectors), 1.0)</p>"},{"location":"api/sampling/#sample_binary_random","title":"sample_binary_random","text":""},{"location":"api/sampling/#vsax.sampling.sample_binary_random","title":"<code>vsax.sampling.sample_binary_random(dim, n, key=None, bipolar=True)</code>","text":"<p>Sample n random binary vectors.</p> <p>Generates random binary vectors with values uniformly sampled from: - Bipolar mode: {-1, +1} - Binary mode: {0, 1}</p> <p>These are suitable for use with Binary VSA operations.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimensionality of each vector.</p> required <code>n</code> <code>int</code> <p>Number of vectors to sample.</p> required <code>key</code> <code>Optional[PRNGKey]</code> <p>JAX random key. If None, uses PRNGKey(0).</p> <code>None</code> <code>bipolar</code> <code>bool</code> <p>If True, sample from {-1, +1}. If False, sample from {0, 1}.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>JAX array of shape (n, dim) containing binary values.</p> Example <p>import jax key = jax.random.PRNGKey(42)</p> Source code in <code>vsax/sampling/random.py</code> <pre><code>def sample_binary_random(\n    dim: int, n: int, key: Optional[jax.random.PRNGKey] = None, bipolar: bool = True\n) -&gt; jnp.ndarray:\n    \"\"\"Sample n random binary vectors.\n\n    Generates random binary vectors with values uniformly sampled from:\n    - Bipolar mode: {-1, +1}\n    - Binary mode: {0, 1}\n\n    These are suitable for use with Binary VSA operations.\n\n    Args:\n        dim: Dimensionality of each vector.\n        n: Number of vectors to sample.\n        key: JAX random key. If None, uses PRNGKey(0).\n        bipolar: If True, sample from {-1, +1}. If False, sample from {0, 1}.\n\n    Returns:\n        JAX array of shape (n, dim) containing binary values.\n\n    Example:\n        &gt;&gt;&gt; import jax\n        &gt;&gt;&gt; key = jax.random.PRNGKey(42)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Bipolar sampling\n        &gt;&gt;&gt; bipolar_vecs = sample_binary_random(512, 10, key, bipolar=True)\n        &gt;&gt;&gt; assert bipolar_vecs.shape == (10, 512)\n        &gt;&gt;&gt; assert jnp.all(jnp.isin(bipolar_vecs, jnp.array([-1, 1])))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Binary sampling\n        &gt;&gt;&gt; binary_vecs = sample_binary_random(512, 10, key, bipolar=False)\n        &gt;&gt;&gt; assert jnp.all(jnp.isin(binary_vecs, jnp.array([0, 1])))\n    \"\"\"\n    if key is None:\n        key = jax.random.PRNGKey(0)\n\n    if bipolar:\n        # Sample from {-1, +1}\n        return jax.random.choice(key, jnp.array([-1, 1]), shape=(n, dim))\n    else:\n        # Sample from {0, 1}\n        return jax.random.choice(key, jnp.array([0, 1]), shape=(n, dim))\n</code></pre>"},{"location":"api/sampling/#vsax.sampling.sample_binary_random--bipolar-sampling","title":"Bipolar sampling","text":"<p>bipolar_vecs = sample_binary_random(512, 10, key, bipolar=True) assert bipolar_vecs.shape == (10, 512) assert jnp.all(jnp.isin(bipolar_vecs, jnp.array([-1, 1])))</p>"},{"location":"api/sampling/#vsax.sampling.sample_binary_random--binary-sampling","title":"Binary sampling","text":"<p>binary_vecs = sample_binary_random(512, 10, key, bipolar=False) assert jnp.all(jnp.isin(binary_vecs, jnp.array([0, 1])))</p>"},{"location":"api/core/base/","title":"Base Classes","text":"<p>Core abstract classes that define the VSA interface.</p>"},{"location":"api/core/base/#abstracthypervector","title":"AbstractHypervector","text":""},{"location":"api/core/base/#vsax.core.base.AbstractHypervector","title":"<code>vsax.core.base.AbstractHypervector</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for all hypervector representations.</p> <p>Wraps a JAX array and provides common operations for hypervectors. All concrete implementations must inherit from this class.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>The underlying JAX array representing the hypervector.</p> required Source code in <code>vsax/core/base.py</code> <pre><code>class AbstractHypervector(ABC):\n    \"\"\"Base class for all hypervector representations.\n\n    Wraps a JAX array and provides common operations for hypervectors.\n    All concrete implementations must inherit from this class.\n\n    Args:\n        vec: The underlying JAX array representing the hypervector.\n    \"\"\"\n\n    def __init__(self, vec: jnp.ndarray) -&gt; None:\n        \"\"\"Initialize hypervector with underlying array.\n\n        Args:\n            vec: JAX array representing the hypervector.\n        \"\"\"\n        self._vec = vec\n\n    @property\n    def vec(self) -&gt; jnp.ndarray:\n        \"\"\"Return the underlying JAX array.\n\n        Returns:\n            The JAX array wrapped by this hypervector.\n        \"\"\"\n        return self._vec\n\n    @property\n    def shape(self) -&gt; tuple[int, ...]:\n        \"\"\"Return the shape of the hypervector.\n\n        Returns:\n            Tuple representing the shape of the underlying array.\n        \"\"\"\n        return cast(tuple[int, ...], self._vec.shape)\n\n    @property\n    def dtype(self) -&gt; jnp.dtype:\n        \"\"\"Return the data type of the hypervector.\n\n        Returns:\n            JAX dtype of the underlying array.\n        \"\"\"\n        return self._vec.dtype\n\n    @abstractmethod\n    def normalize(self) -&gt; \"AbstractHypervector\":\n        \"\"\"Normalize the hypervector.\n\n        The normalization method depends on the representation type.\n        For example, complex vectors normalize to unit magnitude (phase-only),\n        while real vectors use L2 normalization.\n\n        Returns:\n            Normalized hypervector of the same type.\n        \"\"\"\n        pass\n\n    def to_numpy(self) -&gt; np.ndarray:\n        \"\"\"Convert the hypervector to a NumPy array.\n\n        Returns:\n            NumPy array representation of the hypervector.\n        \"\"\"\n        return np.array(self._vec)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return string representation of the hypervector.\n\n        Returns:\n            String showing class name, shape, and dtype.\n        \"\"\"\n        return f\"{self.__class__.__name__}(shape={self.shape}, dtype={self.dtype})\"\n</code></pre>"},{"location":"api/core/base/#vsax.core.base.AbstractHypervector-attributes","title":"Attributes","text":""},{"location":"api/core/base/#vsax.core.base.AbstractHypervector.vec","title":"<code>vec</code>  <code>property</code>","text":"<p>Return the underlying JAX array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The JAX array wrapped by this hypervector.</p>"},{"location":"api/core/base/#vsax.core.base.AbstractHypervector.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Return the shape of the hypervector.</p> <p>Returns:</p> Type Description <code>tuple[int, ...]</code> <p>Tuple representing the shape of the underlying array.</p>"},{"location":"api/core/base/#vsax.core.base.AbstractHypervector.dtype","title":"<code>dtype</code>  <code>property</code>","text":"<p>Return the data type of the hypervector.</p> <p>Returns:</p> Type Description <code>dtype</code> <p>JAX dtype of the underlying array.</p>"},{"location":"api/core/base/#vsax.core.base.AbstractHypervector-functions","title":"Functions","text":""},{"location":"api/core/base/#vsax.core.base.AbstractHypervector.normalize","title":"<code>normalize()</code>  <code>abstractmethod</code>","text":"<p>Normalize the hypervector.</p> <p>The normalization method depends on the representation type. For example, complex vectors normalize to unit magnitude (phase-only), while real vectors use L2 normalization.</p> <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>Normalized hypervector of the same type.</p> Source code in <code>vsax/core/base.py</code> <pre><code>@abstractmethod\ndef normalize(self) -&gt; \"AbstractHypervector\":\n    \"\"\"Normalize the hypervector.\n\n    The normalization method depends on the representation type.\n    For example, complex vectors normalize to unit magnitude (phase-only),\n    while real vectors use L2 normalization.\n\n    Returns:\n        Normalized hypervector of the same type.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base/#vsax.core.base.AbstractHypervector.to_numpy","title":"<code>to_numpy()</code>","text":"<p>Convert the hypervector to a NumPy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>NumPy array representation of the hypervector.</p> Source code in <code>vsax/core/base.py</code> <pre><code>def to_numpy(self) -&gt; np.ndarray:\n    \"\"\"Convert the hypervector to a NumPy array.\n\n    Returns:\n        NumPy array representation of the hypervector.\n    \"\"\"\n    return np.array(self._vec)\n</code></pre>"},{"location":"api/core/base/#abstractopset","title":"AbstractOpSet","text":""},{"location":"api/core/base/#vsax.core.base.AbstractOpSet","title":"<code>vsax.core.base.AbstractOpSet</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for VSA operation sets.</p> <p>Defines the symbolic algebra operations for binding and bundling hypervectors. All operations work directly on JAX arrays, not on AbstractHypervector instances.</p> <p>Concrete implementations (FHRR, MAP, Binary) must implement all abstract methods.</p> Source code in <code>vsax/core/base.py</code> <pre><code>class AbstractOpSet(ABC):\n    \"\"\"Base class for VSA operation sets.\n\n    Defines the symbolic algebra operations for binding and bundling hypervectors.\n    All operations work directly on JAX arrays, not on AbstractHypervector instances.\n\n    Concrete implementations (FHRR, MAP, Binary) must implement all abstract methods.\n    \"\"\"\n\n    @abstractmethod\n    def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bind two hypervectors together.\n\n        Binding creates a composite representation that is dissimilar to both inputs\n        but can be unbound using the inverse operation. The specific binding operation\n        depends on the algebra (e.g., circular convolution for FHRR, elementwise\n        multiplication for MAP).\n\n        Args:\n            a: First hypervector as JAX array.\n            b: Second hypervector as JAX array.\n\n        Returns:\n            Bound hypervector as JAX array.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bundle multiple hypervectors into a single representation.\n\n        Bundling creates a superposition that is similar to all inputs.\n        The bundled vector can be queried to retrieve the constituent vectors.\n\n        Args:\n            *vecs: Variable number of hypervectors as JAX arrays.\n\n        Returns:\n            Bundled hypervector as JAX array.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Compute the inverse of a hypervector.\n\n        The inverse is used to unbind: if c = bind(a, b), then\n        unbind(c, b) = bind(c, inverse(b)) \u2248 a.\n\n        Args:\n            a: Hypervector as JAX array.\n\n        Returns:\n            Inverse hypervector as JAX array.\n        \"\"\"\n        pass\n\n    def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n        \"\"\"Permute a hypervector by circular shift.\n\n        This is an optional operation. The default implementation performs\n        a circular shift, but concrete classes may override with different\n        permutation strategies.\n\n        Args:\n            a: Hypervector as JAX array.\n            shift: Number of positions to shift (positive = right, negative = left).\n\n        Returns:\n            Permuted hypervector as JAX array.\n        \"\"\"\n        return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/core/base/#vsax.core.base.AbstractOpSet-functions","title":"Functions","text":""},{"location":"api/core/base/#vsax.core.base.AbstractOpSet.bind","title":"<code>bind(a, b)</code>  <code>abstractmethod</code>","text":"<p>Bind two hypervectors together.</p> <p>Binding creates a composite representation that is dissimilar to both inputs but can be unbound using the inverse operation. The specific binding operation depends on the algebra (e.g., circular convolution for FHRR, elementwise multiplication for MAP).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>First hypervector as JAX array.</p> required <code>b</code> <code>ndarray</code> <p>Second hypervector as JAX array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Bound hypervector as JAX array.</p> Source code in <code>vsax/core/base.py</code> <pre><code>@abstractmethod\ndef bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bind two hypervectors together.\n\n    Binding creates a composite representation that is dissimilar to both inputs\n    but can be unbound using the inverse operation. The specific binding operation\n    depends on the algebra (e.g., circular convolution for FHRR, elementwise\n    multiplication for MAP).\n\n    Args:\n        a: First hypervector as JAX array.\n        b: Second hypervector as JAX array.\n\n    Returns:\n        Bound hypervector as JAX array.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base/#vsax.core.base.AbstractOpSet.bundle","title":"<code>bundle(*vecs)</code>  <code>abstractmethod</code>","text":"<p>Bundle multiple hypervectors into a single representation.</p> <p>Bundling creates a superposition that is similar to all inputs. The bundled vector can be queried to retrieve the constituent vectors.</p> <p>Parameters:</p> Name Type Description Default <code>*vecs</code> <code>ndarray</code> <p>Variable number of hypervectors as JAX arrays.</p> <code>()</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Bundled hypervector as JAX array.</p> Source code in <code>vsax/core/base.py</code> <pre><code>@abstractmethod\ndef bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bundle multiple hypervectors into a single representation.\n\n    Bundling creates a superposition that is similar to all inputs.\n    The bundled vector can be queried to retrieve the constituent vectors.\n\n    Args:\n        *vecs: Variable number of hypervectors as JAX arrays.\n\n    Returns:\n        Bundled hypervector as JAX array.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base/#vsax.core.base.AbstractOpSet.inverse","title":"<code>inverse(a)</code>  <code>abstractmethod</code>","text":"<p>Compute the inverse of a hypervector.</p> <p>The inverse is used to unbind: if c = bind(a, b), then unbind(c, b) = bind(c, inverse(b)) \u2248 a.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Inverse hypervector as JAX array.</p> Source code in <code>vsax/core/base.py</code> <pre><code>@abstractmethod\ndef inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Compute the inverse of a hypervector.\n\n    The inverse is used to unbind: if c = bind(a, b), then\n    unbind(c, b) = bind(c, inverse(b)) \u2248 a.\n\n    Args:\n        a: Hypervector as JAX array.\n\n    Returns:\n        Inverse hypervector as JAX array.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base/#vsax.core.base.AbstractOpSet.permute","title":"<code>permute(a, shift)</code>","text":"<p>Permute a hypervector by circular shift.</p> <p>This is an optional operation. The default implementation performs a circular shift, but concrete classes may override with different permutation strategies.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array.</p> required <code>shift</code> <code>int</code> <p>Number of positions to shift (positive = right, negative = left).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Permuted hypervector as JAX array.</p> Source code in <code>vsax/core/base.py</code> <pre><code>def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n    \"\"\"Permute a hypervector by circular shift.\n\n    This is an optional operation. The default implementation performs\n    a circular shift, but concrete classes may override with different\n    permutation strategies.\n\n    Args:\n        a: Hypervector as JAX array.\n        shift: Number of positions to shift (positive = right, negative = left).\n\n    Returns:\n        Permuted hypervector as JAX array.\n    \"\"\"\n    return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/core/factory/","title":"Factory Functions","text":"<p>Convenient factory functions for creating VSA models with sensible defaults.</p> <p>These functions provide a simple, one-line way to create fully configured VSA models for each of the three supported algebras: FHRR, MAP, and Binary.</p>"},{"location":"api/core/factory/#create_fhrr_model","title":"create_fhrr_model","text":""},{"location":"api/core/factory/#vsax.core.factory.create_fhrr_model","title":"<code>vsax.core.factory.create_fhrr_model(dim=512, key=None)</code>","text":"<p>Create a FHRR model (Complex hypervectors with FFT-based operations).</p> <p>FHRR (Fourier Holographic Reduced Representation) uses complex-valued hypervectors with circular convolution for binding. It provides exact unbinding via complex conjugation.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimensionality of hypervectors. Default: 512.</p> <code>512</code> <code>key</code> <code>Optional[Array]</code> <p>Optional JAX PRNG key for reproducible sampling. Not used in model creation but can be passed to VSAMemory.</p> <code>None</code> <p>Returns:</p> Type Description <code>VSAModel</code> <p>VSAModel configured for FHRR operations.</p> Example <p>from vsax import create_fhrr_model, VSAMemory model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add(\"symbol\")</p> Source code in <code>vsax/core/factory.py</code> <pre><code>def create_fhrr_model(dim: int = 512, key: Optional[jax.Array] = None) -&gt; VSAModel:\n    \"\"\"Create a FHRR model (Complex hypervectors with FFT-based operations).\n\n    FHRR (Fourier Holographic Reduced Representation) uses complex-valued\n    hypervectors with circular convolution for binding. It provides exact\n    unbinding via complex conjugation.\n\n    Args:\n        dim: Dimensionality of hypervectors. Default: 512.\n        key: Optional JAX PRNG key for reproducible sampling. Not used in\n            model creation but can be passed to VSAMemory.\n\n    Returns:\n        VSAModel configured for FHRR operations.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"symbol\")\n    \"\"\"\n    return VSAModel(\n        dim=dim,\n        rep_cls=ComplexHypervector,\n        opset=FHRROperations(),\n        sampler=sample_complex_random,\n    )\n</code></pre>"},{"location":"api/core/factory/#create_map_model","title":"create_map_model","text":""},{"location":"api/core/factory/#vsax.core.factory.create_map_model","title":"<code>vsax.core.factory.create_map_model(dim=512, key=None)</code>","text":"<p>Create a MAP model (Real hypervectors with element-wise operations).</p> <p>MAP (Multiply-Add-Permute) uses real-valued hypervectors with element-wise multiplication for binding and averaging for bundling. It provides approximate unbinding.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimensionality of hypervectors. Default: 512.</p> <code>512</code> <code>key</code> <code>Optional[Array]</code> <p>Optional JAX PRNG key for reproducible sampling. Not used in model creation but can be passed to VSAMemory.</p> <code>None</code> <p>Returns:</p> Type Description <code>VSAModel</code> <p>VSAModel configured for MAP operations.</p> Example <p>from vsax import create_map_model, VSAMemory model = create_map_model(dim=1024) memory = VSAMemory(model) memory.add_many([\"red\", \"green\", \"blue\"])</p> Source code in <code>vsax/core/factory.py</code> <pre><code>def create_map_model(dim: int = 512, key: Optional[jax.Array] = None) -&gt; VSAModel:\n    \"\"\"Create a MAP model (Real hypervectors with element-wise operations).\n\n    MAP (Multiply-Add-Permute) uses real-valued hypervectors with\n    element-wise multiplication for binding and averaging for bundling.\n    It provides approximate unbinding.\n\n    Args:\n        dim: Dimensionality of hypervectors. Default: 512.\n        key: Optional JAX PRNG key for reproducible sampling. Not used in\n            model creation but can be passed to VSAMemory.\n\n    Returns:\n        VSAModel configured for MAP operations.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_map_model, VSAMemory\n        &gt;&gt;&gt; model = create_map_model(dim=1024)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"red\", \"green\", \"blue\"])\n    \"\"\"\n    return VSAModel(\n        dim=dim,\n        rep_cls=RealHypervector,\n        opset=MAPOperations(),\n        sampler=sample_random,\n    )\n</code></pre>"},{"location":"api/core/factory/#create_binary_model","title":"create_binary_model","text":""},{"location":"api/core/factory/#vsax.core.factory.create_binary_model","title":"<code>vsax.core.factory.create_binary_model(dim=10000, bipolar=True, key=None)</code>","text":"<p>Create a Binary model (Binary hypervectors with XOR/majority operations).</p> <p>Binary VSA uses discrete {-1, +1} (bipolar) or {0, 1} (binary) hypervectors with XOR for binding and majority voting for bundling. It provides exact unbinding (self-inverse property).</p> <p>Note: Binary models typically require higher dimensionality (10000+) for good performance due to discrete representation.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimensionality of hypervectors. Default: 10000 (higher than continuous models due to discrete representation).</p> <code>10000</code> <code>bipolar</code> <code>bool</code> <p>If True, use {-1, +1} representation. If False, use {0, 1}. Default: True (bipolar is more common).</p> <code>True</code> <code>key</code> <code>Optional[Array]</code> <p>Optional JAX PRNG key for reproducible sampling. Not used in model creation but can be passed to VSAMemory.</p> <code>None</code> <p>Returns:</p> Type Description <code>VSAModel</code> <p>VSAModel configured for Binary operations.</p> Example <p>from vsax import create_binary_model, VSAMemory model = create_binary_model(dim=10000, bipolar=True) memory = VSAMemory(model) memory.add(\"concept\")</p> Source code in <code>vsax/core/factory.py</code> <pre><code>def create_binary_model(\n    dim: int = 10000, bipolar: bool = True, key: Optional[jax.Array] = None\n) -&gt; VSAModel:\n    \"\"\"Create a Binary model (Binary hypervectors with XOR/majority operations).\n\n    Binary VSA uses discrete {-1, +1} (bipolar) or {0, 1} (binary) hypervectors\n    with XOR for binding and majority voting for bundling. It provides exact\n    unbinding (self-inverse property).\n\n    Note: Binary models typically require higher dimensionality (10000+) for\n    good performance due to discrete representation.\n\n    Args:\n        dim: Dimensionality of hypervectors. Default: 10000 (higher than\n            continuous models due to discrete representation).\n        bipolar: If True, use {-1, +1} representation. If False, use {0, 1}.\n            Default: True (bipolar is more common).\n        key: Optional JAX PRNG key for reproducible sampling. Not used in\n            model creation but can be passed to VSAMemory.\n\n    Returns:\n        VSAModel configured for Binary operations.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_binary_model, VSAMemory\n        &gt;&gt;&gt; model = create_binary_model(dim=10000, bipolar=True)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"concept\")\n    \"\"\"\n\n    # Create a wrapper sampler that passes bipolar parameter\n    def binary_sampler(dim: int, n: int, key: jax.Array) -&gt; jax.Array:\n        \"\"\"Wrapper sampler that includes bipolar parameter.\"\"\"\n        return sample_binary_random(dim=dim, n=n, key=key, bipolar=bipolar)\n\n    return VSAModel(\n        dim=dim,\n        rep_cls=BinaryHypervector,\n        opset=BinaryOperations(),\n        sampler=binary_sampler,\n    )\n</code></pre>"},{"location":"api/core/memory/","title":"VSAMemory","text":"<p>Dictionary-style symbol table for managing named hypervectors.</p> <p>VSAMemory provides a convenient interface for creating, storing, and accessing hypervectors associated with symbolic names. It automatically handles vector sampling and wrapping using the model's configuration.</p>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory","title":"<code>vsax.core.memory.VSAMemory</code>","text":"<p>Symbol table for storing and managing named basis vectors.</p> <p>VSAMemory provides a dictionary-style interface for creating, storing, and retrieving named hypervectors. Each symbol is associated with a randomly sampled hypervector from the model's sampling distribution.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>VSAModel</code> <p>VSAModel instance defining the representation and operations.</p> required <code>key</code> <code>Optional[Array]</code> <p>Optional JAX PRNG key for reproducible sampling. If None, uses a default key.</p> <code>None</code> Example <p>from vsax import create_fhrr_model, VSAMemory model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add(\"dog\") memory.add_many([\"cat\", \"bird\"]) dog = memory[\"dog\"] assert \"cat\" in memory print(memory.keys()) ['dog', 'cat', 'bird']</p> Source code in <code>vsax/core/memory.py</code> <pre><code>class VSAMemory:\n    \"\"\"Symbol table for storing and managing named basis vectors.\n\n    VSAMemory provides a dictionary-style interface for creating, storing, and\n    retrieving named hypervectors. Each symbol is associated with a randomly\n    sampled hypervector from the model's sampling distribution.\n\n    Args:\n        model: VSAModel instance defining the representation and operations.\n        key: Optional JAX PRNG key for reproducible sampling. If None, uses a\n            default key.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"dog\")\n        &gt;&gt;&gt; memory.add_many([\"cat\", \"bird\"])\n        &gt;&gt;&gt; dog = memory[\"dog\"]\n        &gt;&gt;&gt; assert \"cat\" in memory\n        &gt;&gt;&gt; print(memory.keys())\n        ['dog', 'cat', 'bird']\n    \"\"\"\n\n    def __init__(self, model: VSAModel, key: Optional[jax.Array] = None) -&gt; None:\n        \"\"\"Initialize VSAMemory with a model.\n\n        Args:\n            model: VSAModel instance defining the VSA algebra.\n            key: Optional JAX PRNG key for reproducible sampling.\n        \"\"\"\n        self._model = model\n        self._symbols: dict[str, AbstractHypervector] = {}\n        self._key = key if key is not None else jax.random.PRNGKey(0)\n        self._counter = 0\n\n    @property\n    def model(self) -&gt; VSAModel:\n        \"\"\"Get the underlying VSAModel.\"\"\"\n        return self._model\n\n    def add(self, name: str) -&gt; AbstractHypervector:\n        \"\"\"Add a new symbol to memory with a randomly sampled hypervector.\n\n        If the symbol already exists, returns the existing hypervector without\n        resampling.\n\n        Args:\n            name: Name of the symbol to add.\n\n        Returns:\n            The hypervector associated with the symbol.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; dog = memory.add(\"dog\")\n            &gt;&gt;&gt; assert \"dog\" in memory\n        \"\"\"\n        if name in self._symbols:\n            return self._symbols[name]\n\n        # Split key for this sample\n        self._key, subkey = jax.random.split(self._key)\n\n        # Sample a new vector\n        vec = self._model.sampler(self._model.dim, 1, subkey)[0]\n\n        # Wrap in representation\n        hv = self._model.rep_cls(vec)\n\n        # Store and return\n        self._symbols[name] = hv\n        self._counter += 1\n        return hv\n\n    def add_many(self, names: Iterable[str]) -&gt; list[AbstractHypervector]:\n        \"\"\"Add multiple symbols to memory.\n\n        Args:\n            names: Iterable of symbol names to add.\n\n        Returns:\n            List of hypervectors corresponding to the added symbols.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; colors = memory.add_many([\"red\", \"green\", \"blue\"])\n            &gt;&gt;&gt; assert len(colors) == 3\n        \"\"\"\n        return [self.add(name) for name in names]\n\n    def get(self, name: str) -&gt; AbstractHypervector:\n        \"\"\"Get a hypervector by name.\n\n        Args:\n            name: Name of the symbol to retrieve.\n\n        Returns:\n            The hypervector associated with the symbol.\n\n        Raises:\n            KeyError: If the symbol does not exist in memory.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; memory.add(\"dog\")\n            &gt;&gt;&gt; dog = memory.get(\"dog\")\n        \"\"\"\n        return self._symbols[name]\n\n    def __getitem__(self, name: str) -&gt; AbstractHypervector:\n        \"\"\"Get a hypervector by name using dictionary syntax.\n\n        Args:\n            name: Name of the symbol to retrieve.\n\n        Returns:\n            The hypervector associated with the symbol.\n\n        Raises:\n            KeyError: If the symbol does not exist in memory.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; memory.add(\"dog\")\n            &gt;&gt;&gt; dog = memory[\"dog\"]\n        \"\"\"\n        return self.get(name)\n\n    def __contains__(self, name: str) -&gt; bool:\n        \"\"\"Check if a symbol exists in memory.\n\n        Args:\n            name: Name of the symbol to check.\n\n        Returns:\n            True if the symbol exists, False otherwise.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; memory.add(\"dog\")\n            &gt;&gt;&gt; assert \"dog\" in memory\n            &gt;&gt;&gt; assert \"cat\" not in memory\n        \"\"\"\n        return name in self._symbols\n\n    def keys(self) -&gt; list[str]:\n        \"\"\"Get all symbol names in memory.\n\n        Returns:\n            List of symbol names.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; memory.add_many([\"a\", \"b\", \"c\"])\n            &gt;&gt;&gt; assert memory.keys() == [\"a\", \"b\", \"c\"]\n        \"\"\"\n        return list(self._symbols.keys())\n\n    def __len__(self) -&gt; int:\n        \"\"\"Get the number of symbols in memory.\n\n        Returns:\n            Number of stored symbols.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; memory.add_many([\"a\", \"b\", \"c\"])\n            &gt;&gt;&gt; assert len(memory) == 3\n        \"\"\"\n        return len(self._symbols)\n\n    def clear(self) -&gt; None:\n        \"\"\"Remove all symbols from memory.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; memory.add_many([\"a\", \"b\", \"c\"])\n            &gt;&gt;&gt; memory.clear()\n            &gt;&gt;&gt; assert len(memory) == 0\n        \"\"\"\n        self._symbols.clear()\n        self._counter = 0\n\n    def __repr__(self) -&gt; str:\n        \"\"\"String representation of VSAMemory.\"\"\"\n        return f\"VSAMemory(model={self._model.rep_cls.__name__}, symbols={len(self._symbols)})\"\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory-attributes","title":"Attributes","text":""},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.model","title":"<code>model</code>  <code>property</code>","text":"<p>Get the underlying VSAModel.</p>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory-functions","title":"Functions","text":""},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.__init__","title":"<code>__init__(model, key=None)</code>","text":"<p>Initialize VSAMemory with a model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>VSAModel</code> <p>VSAModel instance defining the VSA algebra.</p> required <code>key</code> <code>Optional[Array]</code> <p>Optional JAX PRNG key for reproducible sampling.</p> <code>None</code> Source code in <code>vsax/core/memory.py</code> <pre><code>def __init__(self, model: VSAModel, key: Optional[jax.Array] = None) -&gt; None:\n    \"\"\"Initialize VSAMemory with a model.\n\n    Args:\n        model: VSAModel instance defining the VSA algebra.\n        key: Optional JAX PRNG key for reproducible sampling.\n    \"\"\"\n    self._model = model\n    self._symbols: dict[str, AbstractHypervector] = {}\n    self._key = key if key is not None else jax.random.PRNGKey(0)\n    self._counter = 0\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.add","title":"<code>add(name)</code>","text":"<p>Add a new symbol to memory with a randomly sampled hypervector.</p> <p>If the symbol already exists, returns the existing hypervector without resampling.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the symbol to add.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The hypervector associated with the symbol.</p> Example <p>memory = VSAMemory(model) dog = memory.add(\"dog\") assert \"dog\" in memory</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def add(self, name: str) -&gt; AbstractHypervector:\n    \"\"\"Add a new symbol to memory with a randomly sampled hypervector.\n\n    If the symbol already exists, returns the existing hypervector without\n    resampling.\n\n    Args:\n        name: Name of the symbol to add.\n\n    Returns:\n        The hypervector associated with the symbol.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; dog = memory.add(\"dog\")\n        &gt;&gt;&gt; assert \"dog\" in memory\n    \"\"\"\n    if name in self._symbols:\n        return self._symbols[name]\n\n    # Split key for this sample\n    self._key, subkey = jax.random.split(self._key)\n\n    # Sample a new vector\n    vec = self._model.sampler(self._model.dim, 1, subkey)[0]\n\n    # Wrap in representation\n    hv = self._model.rep_cls(vec)\n\n    # Store and return\n    self._symbols[name] = hv\n    self._counter += 1\n    return hv\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.add_many","title":"<code>add_many(names)</code>","text":"<p>Add multiple symbols to memory.</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>Iterable[str]</code> <p>Iterable of symbol names to add.</p> required <p>Returns:</p> Type Description <code>list[AbstractHypervector]</code> <p>List of hypervectors corresponding to the added symbols.</p> Example <p>memory = VSAMemory(model) colors = memory.add_many([\"red\", \"green\", \"blue\"]) assert len(colors) == 3</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def add_many(self, names: Iterable[str]) -&gt; list[AbstractHypervector]:\n    \"\"\"Add multiple symbols to memory.\n\n    Args:\n        names: Iterable of symbol names to add.\n\n    Returns:\n        List of hypervectors corresponding to the added symbols.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; colors = memory.add_many([\"red\", \"green\", \"blue\"])\n        &gt;&gt;&gt; assert len(colors) == 3\n    \"\"\"\n    return [self.add(name) for name in names]\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.get","title":"<code>get(name)</code>","text":"<p>Get a hypervector by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the symbol to retrieve.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The hypervector associated with the symbol.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the symbol does not exist in memory.</p> Example <p>memory = VSAMemory(model) memory.add(\"dog\") dog = memory.get(\"dog\")</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def get(self, name: str) -&gt; AbstractHypervector:\n    \"\"\"Get a hypervector by name.\n\n    Args:\n        name: Name of the symbol to retrieve.\n\n    Returns:\n        The hypervector associated with the symbol.\n\n    Raises:\n        KeyError: If the symbol does not exist in memory.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"dog\")\n        &gt;&gt;&gt; dog = memory.get(\"dog\")\n    \"\"\"\n    return self._symbols[name]\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.__getitem__","title":"<code>__getitem__(name)</code>","text":"<p>Get a hypervector by name using dictionary syntax.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the symbol to retrieve.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The hypervector associated with the symbol.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the symbol does not exist in memory.</p> Example <p>memory = VSAMemory(model) memory.add(\"dog\") dog = memory[\"dog\"]</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def __getitem__(self, name: str) -&gt; AbstractHypervector:\n    \"\"\"Get a hypervector by name using dictionary syntax.\n\n    Args:\n        name: Name of the symbol to retrieve.\n\n    Returns:\n        The hypervector associated with the symbol.\n\n    Raises:\n        KeyError: If the symbol does not exist in memory.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"dog\")\n        &gt;&gt;&gt; dog = memory[\"dog\"]\n    \"\"\"\n    return self.get(name)\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.__contains__","title":"<code>__contains__(name)</code>","text":"<p>Check if a symbol exists in memory.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the symbol to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the symbol exists, False otherwise.</p> Example <p>memory = VSAMemory(model) memory.add(\"dog\") assert \"dog\" in memory assert \"cat\" not in memory</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def __contains__(self, name: str) -&gt; bool:\n    \"\"\"Check if a symbol exists in memory.\n\n    Args:\n        name: Name of the symbol to check.\n\n    Returns:\n        True if the symbol exists, False otherwise.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"dog\")\n        &gt;&gt;&gt; assert \"dog\" in memory\n        &gt;&gt;&gt; assert \"cat\" not in memory\n    \"\"\"\n    return name in self._symbols\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.keys","title":"<code>keys()</code>","text":"<p>Get all symbol names in memory.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of symbol names.</p> Example <p>memory = VSAMemory(model) memory.add_many([\"a\", \"b\", \"c\"]) assert memory.keys() == [\"a\", \"b\", \"c\"]</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def keys(self) -&gt; list[str]:\n    \"\"\"Get all symbol names in memory.\n\n    Returns:\n        List of symbol names.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"a\", \"b\", \"c\"])\n        &gt;&gt;&gt; assert memory.keys() == [\"a\", \"b\", \"c\"]\n    \"\"\"\n    return list(self._symbols.keys())\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.__len__","title":"<code>__len__()</code>","text":"<p>Get the number of symbols in memory.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of stored symbols.</p> Example <p>memory = VSAMemory(model) memory.add_many([\"a\", \"b\", \"c\"]) assert len(memory) == 3</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Get the number of symbols in memory.\n\n    Returns:\n        Number of stored symbols.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"a\", \"b\", \"c\"])\n        &gt;&gt;&gt; assert len(memory) == 3\n    \"\"\"\n    return len(self._symbols)\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.clear","title":"<code>clear()</code>","text":"<p>Remove all symbols from memory.</p> Example <p>memory = VSAMemory(model) memory.add_many([\"a\", \"b\", \"c\"]) memory.clear() assert len(memory) == 0</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Remove all symbols from memory.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"a\", \"b\", \"c\"])\n        &gt;&gt;&gt; memory.clear()\n        &gt;&gt;&gt; assert len(memory) == 0\n    \"\"\"\n    self._symbols.clear()\n    self._counter = 0\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of VSAMemory.</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"String representation of VSAMemory.\"\"\"\n    return f\"VSAMemory(model={self._model.rep_cls.__name__}, symbols={len(self._symbols)})\"\n</code></pre>"},{"location":"api/core/model/","title":"VSAModel","text":"<p>The immutable container that defines a complete VSA algebra.</p>"},{"location":"api/core/model/#vsax.core.model.VSAModel","title":"<code>vsax.core.model.VSAModel</code>  <code>dataclass</code>","text":"<p>Immutable container defining a complete VSA algebra.</p> <p>VSAModel combines a representation type, operation set, and sampling function to define a complete VSA system. It does not perform operations itself, but serves as a configuration object used by VSAMemory and encoders.</p> <p>Attributes:</p> Name Type Description <code>dim</code> <code>int</code> <p>Dimensionality of all hypervectors in this model.</p> <code>rep_cls</code> <code>type[AbstractHypervector]</code> <p>The hypervector representation class (e.g., ComplexHypervector).</p> <code>opset</code> <code>AbstractOpSet</code> <p>The operation set instance defining bind/bundle/inverse operations.</p> <code>sampler</code> <code>Callable[[int, int, PRNGKey], ndarray]</code> <p>Function to sample random vectors with signature      (dim: int, n: int, key: PRNGKey) -&gt; jnp.ndarray.</p> Example <p>from vsax.representations import ComplexHypervector from vsax.ops import FHRROperations from vsax.sampling import sample_complex_random model = VSAModel( ...     dim=512, ...     rep_cls=ComplexHypervector, ...     opset=FHRROperations(), ...     sampler=sample_complex_random ... )</p> Source code in <code>vsax/core/model.py</code> <pre><code>@dataclass(frozen=True)\nclass VSAModel:\n    \"\"\"Immutable container defining a complete VSA algebra.\n\n    VSAModel combines a representation type, operation set, and sampling function\n    to define a complete VSA system. It does not perform operations itself, but\n    serves as a configuration object used by VSAMemory and encoders.\n\n    Attributes:\n        dim: Dimensionality of all hypervectors in this model.\n        rep_cls: The hypervector representation class (e.g., ComplexHypervector).\n        opset: The operation set instance defining bind/bundle/inverse operations.\n        sampler: Function to sample random vectors with signature\n                 (dim: int, n: int, key: PRNGKey) -&gt; jnp.ndarray.\n\n    Example:\n        &gt;&gt;&gt; from vsax.representations import ComplexHypervector\n        &gt;&gt;&gt; from vsax.ops import FHRROperations\n        &gt;&gt;&gt; from vsax.sampling import sample_complex_random\n        &gt;&gt;&gt; model = VSAModel(\n        ...     dim=512,\n        ...     rep_cls=ComplexHypervector,\n        ...     opset=FHRROperations(),\n        ...     sampler=sample_complex_random\n        ... )\n    \"\"\"\n\n    dim: int\n    rep_cls: type[AbstractHypervector]\n    opset: AbstractOpSet\n    sampler: Callable[[int, int, jax.random.PRNGKey], jnp.ndarray]\n\n    def __post_init__(self) -&gt; None:\n        \"\"\"Validate model parameters.\n\n        Raises:\n            ValueError: If dim is not positive.\n        \"\"\"\n        if self.dim &lt;= 0:\n            raise ValueError(f\"dim must be positive, got {self.dim}\")\n</code></pre>"},{"location":"api/core/model/#vsax.core.model.VSAModel-functions","title":"Functions","text":""},{"location":"api/core/model/#vsax.core.model.VSAModel.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Validate model parameters.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If dim is not positive.</p> Source code in <code>vsax/core/model.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Validate model parameters.\n\n    Raises:\n        ValueError: If dim is not positive.\n    \"\"\"\n    if self.dim &lt;= 0:\n        raise ValueError(f\"dim must be positive, got {self.dim}\")\n</code></pre>"},{"location":"api/encoders/","title":"Encoders API","text":"<p>VSAX encoders convert structured data into hypervector representations.</p>"},{"location":"api/encoders/#base-classes","title":"Base Classes","text":""},{"location":"api/encoders/#vsax.encoders.AbstractEncoder","title":"<code>vsax.encoders.AbstractEncoder</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for encoding structured data into hypervectors.</p> <p>All encoders must implement the <code>encode()</code> method. Encoders can optionally implement <code>fit()</code> for learned encodings and <code>decode()</code> for reconstruction.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The VSAModel instance defining the VSA algebra.</p> <code>memory</code> <p>The VSAMemory instance for accessing basis hypervectors.</p> Example <p>class MyEncoder(AbstractEncoder): ...     def encode(self, data): ...         # Custom encoding logic ...         return self.memory[\"basis\"] encoder = MyEncoder(model, memory) hv = encoder.encode(some_data)</p> Source code in <code>vsax/encoders/base.py</code> <pre><code>class AbstractEncoder(ABC):\n    \"\"\"Abstract base class for encoding structured data into hypervectors.\n\n    All encoders must implement the `encode()` method. Encoders can optionally\n    implement `fit()` for learned encodings and `decode()` for reconstruction.\n\n    Attributes:\n        model: The VSAModel instance defining the VSA algebra.\n        memory: The VSAMemory instance for accessing basis hypervectors.\n\n    Example:\n        &gt;&gt;&gt; class MyEncoder(AbstractEncoder):\n        ...     def encode(self, data):\n        ...         # Custom encoding logic\n        ...         return self.memory[\"basis\"]\n        &gt;&gt;&gt; encoder = MyEncoder(model, memory)\n        &gt;&gt;&gt; hv = encoder.encode(some_data)\n    \"\"\"\n\n    def __init__(self, model: VSAModel, memory: VSAMemory) -&gt; None:\n        \"\"\"Initialize the encoder.\n\n        Args:\n            model: The VSAModel instance.\n            memory: The VSAMemory instance with basis symbols.\n        \"\"\"\n        self.model = model\n        self.memory = memory\n\n    @abstractmethod\n    def encode(self, *args: Any, **kwargs: Any) -&gt; AbstractHypervector:\n        \"\"\"Encode data into a hypervector.\n\n        Args:\n            *args: Positional arguments (encoder-specific).\n            **kwargs: Keyword arguments (encoder-specific).\n\n        Returns:\n            The encoded hypervector.\n\n        Raises:\n            NotImplementedError: This is an abstract method.\n\n        Note:\n            Different encoders may have different signatures. See specific\n            encoder documentation for details.\n        \"\"\"\n        pass\n\n    def fit(self, data: Any) -&gt; None:\n        \"\"\"Optionally fit encoder parameters to data.\n\n        This method is optional and can be used for learned encodings.\n        By default, it does nothing.\n\n        Args:\n            data: The training data.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/encoders/#vsax.encoders.AbstractEncoder-functions","title":"Functions","text":""},{"location":"api/encoders/#vsax.encoders.AbstractEncoder.__init__","title":"<code>__init__(model, memory)</code>","text":"<p>Initialize the encoder.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>VSAModel</code> <p>The VSAModel instance.</p> required <code>memory</code> <code>VSAMemory</code> <p>The VSAMemory instance with basis symbols.</p> required Source code in <code>vsax/encoders/base.py</code> <pre><code>def __init__(self, model: VSAModel, memory: VSAMemory) -&gt; None:\n    \"\"\"Initialize the encoder.\n\n    Args:\n        model: The VSAModel instance.\n        memory: The VSAMemory instance with basis symbols.\n    \"\"\"\n    self.model = model\n    self.memory = memory\n</code></pre>"},{"location":"api/encoders/#vsax.encoders.AbstractEncoder.encode","title":"<code>encode(*args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Encode data into a hypervector.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>Positional arguments (encoder-specific).</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments (encoder-specific).</p> <code>{}</code> <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The encoded hypervector.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This is an abstract method.</p> Note <p>Different encoders may have different signatures. See specific encoder documentation for details.</p> Source code in <code>vsax/encoders/base.py</code> <pre><code>@abstractmethod\ndef encode(self, *args: Any, **kwargs: Any) -&gt; AbstractHypervector:\n    \"\"\"Encode data into a hypervector.\n\n    Args:\n        *args: Positional arguments (encoder-specific).\n        **kwargs: Keyword arguments (encoder-specific).\n\n    Returns:\n        The encoded hypervector.\n\n    Raises:\n        NotImplementedError: This is an abstract method.\n\n    Note:\n        Different encoders may have different signatures. See specific\n        encoder documentation for details.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/encoders/#vsax.encoders.AbstractEncoder.fit","title":"<code>fit(data)</code>","text":"<p>Optionally fit encoder parameters to data.</p> <p>This method is optional and can be used for learned encodings. By default, it does nothing.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The training data.</p> required Source code in <code>vsax/encoders/base.py</code> <pre><code>def fit(self, data: Any) -&gt; None:\n    \"\"\"Optionally fit encoder parameters to data.\n\n    This method is optional and can be used for learned encodings.\n    By default, it does nothing.\n\n    Args:\n        data: The training data.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/encoders/#core-encoders","title":"Core Encoders","text":"<ul> <li>ScalarEncoder - Numeric values</li> <li>SequenceEncoder - Ordered sequences</li> <li>SetEncoder - Unordered collections</li> <li>DictEncoder - Key-value pairs</li> <li>GraphEncoder - Graph structures</li> </ul>"},{"location":"api/encoders/dict/","title":"DictEncoder","text":"<p>Encoder for dictionaries using role-filler binding.</p>"},{"location":"api/encoders/dict/#vsax.encoders.DictEncoder","title":"<code>vsax.encoders.DictEncoder</code>","text":"<p>               Bases: <code>AbstractEncoder</code></p> <p>Encoder for dictionaries using role-filler binding.</p> <p>Encodes dictionaries by binding each key (role) with its value (filler), then bundling all key-value pairs together.</p> <p>Both keys and values must be symbols that exist in memory.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The VSAModel instance defining the VSA algebra.</p> <code>memory</code> <p>The VSAMemory instance for accessing basis hypervectors.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.encoders import DictEncoder model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"subject\", \"action\", \"dog\", \"run\"]) encoder = DictEncoder(model, memory) sentence_hv = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})</p> Source code in <code>vsax/encoders/dict.py</code> <pre><code>class DictEncoder(AbstractEncoder):\n    \"\"\"Encoder for dictionaries using role-filler binding.\n\n    Encodes dictionaries by binding each key (role) with its value (filler),\n    then bundling all key-value pairs together.\n\n    Both keys and values must be symbols that exist in memory.\n\n    Attributes:\n        model: The VSAModel instance defining the VSA algebra.\n        memory: The VSAMemory instance for accessing basis hypervectors.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; from vsax.encoders import DictEncoder\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"subject\", \"action\", \"dog\", \"run\"])\n        &gt;&gt;&gt; encoder = DictEncoder(model, memory)\n        &gt;&gt;&gt; sentence_hv = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})\n    \"\"\"\n\n    def encode(self, mapping: dict[str, str]) -&gt; AbstractHypervector:\n        \"\"\"Encode a dictionary of key-value pairs.\n\n        Args:\n            mapping: A dictionary mapping role names to filler names.\n                     Both keys and values must be symbols in memory.\n\n        Returns:\n            The encoded hypervector representing the dictionary.\n\n        Raises:\n            KeyError: If any key or value is not in memory.\n            ValueError: If the dictionary is empty.\n\n        Example:\n            &gt;&gt;&gt; encoder = DictEncoder(model, memory)\n            &gt;&gt;&gt; dict_hv = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})\n        \"\"\"\n        if len(mapping) == 0:\n            raise ValueError(\"Cannot encode empty dictionary\")\n\n        # Bind each key with its value and collect results\n        bound_pairs = []\n        for key, value in mapping.items():\n            key_hv = self.memory[key]\n            value_hv = self.memory[value]\n\n            # Bind key (role) with value (filler)\n            bound = self.model.opset.bind(key_hv.vec, value_hv.vec)\n            bound_pairs.append(bound)\n\n        # Bundle all key-value pairs\n        result = self.model.opset.bundle(*bound_pairs)\n\n        return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/dict/#vsax.encoders.DictEncoder-functions","title":"Functions","text":""},{"location":"api/encoders/dict/#vsax.encoders.DictEncoder.encode","title":"<code>encode(mapping)</code>","text":"<p>Encode a dictionary of key-value pairs.</p> <p>Parameters:</p> Name Type Description Default <code>mapping</code> <code>dict[str, str]</code> <p>A dictionary mapping role names to filler names.      Both keys and values must be symbols in memory.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The encoded hypervector representing the dictionary.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If any key or value is not in memory.</p> <code>ValueError</code> <p>If the dictionary is empty.</p> Example <p>encoder = DictEncoder(model, memory) dict_hv = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})</p> Source code in <code>vsax/encoders/dict.py</code> <pre><code>def encode(self, mapping: dict[str, str]) -&gt; AbstractHypervector:\n    \"\"\"Encode a dictionary of key-value pairs.\n\n    Args:\n        mapping: A dictionary mapping role names to filler names.\n                 Both keys and values must be symbols in memory.\n\n    Returns:\n        The encoded hypervector representing the dictionary.\n\n    Raises:\n        KeyError: If any key or value is not in memory.\n        ValueError: If the dictionary is empty.\n\n    Example:\n        &gt;&gt;&gt; encoder = DictEncoder(model, memory)\n        &gt;&gt;&gt; dict_hv = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})\n    \"\"\"\n    if len(mapping) == 0:\n        raise ValueError(\"Cannot encode empty dictionary\")\n\n    # Bind each key with its value and collect results\n    bound_pairs = []\n    for key, value in mapping.items():\n        key_hv = self.memory[key]\n        value_hv = self.memory[value]\n\n        # Bind key (role) with value (filler)\n        bound = self.model.opset.bind(key_hv.vec, value_hv.vec)\n        bound_pairs.append(bound)\n\n    # Bundle all key-value pairs\n    result = self.model.opset.bundle(*bound_pairs)\n\n    return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/graph/","title":"GraphEncoder","text":"<p>Encoder for graph structures using edge binding.</p>"},{"location":"api/encoders/graph/#vsax.encoders.GraphEncoder","title":"<code>vsax.encoders.GraphEncoder</code>","text":"<p>               Bases: <code>AbstractEncoder</code></p> <p>Encoder for graph structures using edge binding.</p> <p>Encodes graphs by representing each edge as a binding of source, relation, and target, then bundling all edges together.</p> <p>Graphs are represented as edge lists: [(source, relation, target), ...]</p> <p>All node and relation names must be symbols that exist in memory.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The VSAModel instance defining the VSA algebra.</p> <code>memory</code> <p>The VSAMemory instance for accessing basis hypervectors.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.encoders import GraphEncoder model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"Alice\", \"Bob\", \"knows\", \"likes\"]) encoder = GraphEncoder(model, memory)</p> Source code in <code>vsax/encoders/graph.py</code> <pre><code>class GraphEncoder(AbstractEncoder):\n    \"\"\"Encoder for graph structures using edge binding.\n\n    Encodes graphs by representing each edge as a binding of source, relation,\n    and target, then bundling all edges together.\n\n    Graphs are represented as edge lists: [(source, relation, target), ...]\n\n    All node and relation names must be symbols that exist in memory.\n\n    Attributes:\n        model: The VSAModel instance defining the VSA algebra.\n        memory: The VSAMemory instance for accessing basis hypervectors.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; from vsax.encoders import GraphEncoder\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"Alice\", \"Bob\", \"knows\", \"likes\"])\n        &gt;&gt;&gt; encoder = GraphEncoder(model, memory)\n        &gt;&gt;&gt; # Alice knows Bob, Alice likes Bob\n        &gt;&gt;&gt; graph_hv = encoder.encode([\n        ...     (\"Alice\", \"knows\", \"Bob\"),\n        ...     (\"Alice\", \"likes\", \"Bob\")\n        ... ])\n    \"\"\"\n\n    def encode(\n        self, edges: list[tuple[str, str, str]]\n    ) -&gt; AbstractHypervector:\n        \"\"\"Encode a graph as a list of edges.\n\n        Args:\n            edges: List of (source, relation, target) tuples.\n                   All names must be symbols in memory.\n\n        Returns:\n            The encoded hypervector representing the graph.\n\n        Raises:\n            KeyError: If any node or relation is not in memory.\n            ValueError: If the edge list is empty.\n\n        Example:\n            &gt;&gt;&gt; encoder = GraphEncoder(model, memory)\n            &gt;&gt;&gt; graph_hv = encoder.encode([\n            ...     (\"Alice\", \"knows\", \"Bob\"),\n            ...     (\"Bob\", \"likes\", \"Alice\")\n            ... ])\n        \"\"\"\n        if len(edges) == 0:\n            raise ValueError(\"Cannot encode empty graph (no edges)\")\n\n        # Encode each edge and collect results\n        edge_encodings = []\n        for source, relation, target in edges:\n            source_hv = self.memory[source]\n            relation_hv = self.memory[relation]\n            target_hv = self.memory[target]\n\n            # Encode edge as bind(source, bind(relation, target))\n            rel_target = self.model.opset.bind(relation_hv.vec, target_hv.vec)\n            edge_encoding = self.model.opset.bind(source_hv.vec, rel_target)\n            edge_encodings.append(edge_encoding)\n\n        # Bundle all edges together\n        result = self.model.opset.bundle(*edge_encodings)\n\n        return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/graph/#vsax.encoders.GraphEncoder--alice-knows-bob-alice-likes-bob","title":"Alice knows Bob, Alice likes Bob","text":"<p>graph_hv = encoder.encode([ ...     (\"Alice\", \"knows\", \"Bob\"), ...     (\"Alice\", \"likes\", \"Bob\") ... ])</p>"},{"location":"api/encoders/graph/#vsax.encoders.GraphEncoder-functions","title":"Functions","text":""},{"location":"api/encoders/graph/#vsax.encoders.GraphEncoder.encode","title":"<code>encode(edges)</code>","text":"<p>Encode a graph as a list of edges.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <code>list[tuple[str, str, str]]</code> <p>List of (source, relation, target) tuples.    All names must be symbols in memory.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The encoded hypervector representing the graph.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If any node or relation is not in memory.</p> <code>ValueError</code> <p>If the edge list is empty.</p> Example <p>encoder = GraphEncoder(model, memory) graph_hv = encoder.encode([ ...     (\"Alice\", \"knows\", \"Bob\"), ...     (\"Bob\", \"likes\", \"Alice\") ... ])</p> Source code in <code>vsax/encoders/graph.py</code> <pre><code>def encode(\n    self, edges: list[tuple[str, str, str]]\n) -&gt; AbstractHypervector:\n    \"\"\"Encode a graph as a list of edges.\n\n    Args:\n        edges: List of (source, relation, target) tuples.\n               All names must be symbols in memory.\n\n    Returns:\n        The encoded hypervector representing the graph.\n\n    Raises:\n        KeyError: If any node or relation is not in memory.\n        ValueError: If the edge list is empty.\n\n    Example:\n        &gt;&gt;&gt; encoder = GraphEncoder(model, memory)\n        &gt;&gt;&gt; graph_hv = encoder.encode([\n        ...     (\"Alice\", \"knows\", \"Bob\"),\n        ...     (\"Bob\", \"likes\", \"Alice\")\n        ... ])\n    \"\"\"\n    if len(edges) == 0:\n        raise ValueError(\"Cannot encode empty graph (no edges)\")\n\n    # Encode each edge and collect results\n    edge_encodings = []\n    for source, relation, target in edges:\n        source_hv = self.memory[source]\n        relation_hv = self.memory[relation]\n        target_hv = self.memory[target]\n\n        # Encode edge as bind(source, bind(relation, target))\n        rel_target = self.model.opset.bind(relation_hv.vec, target_hv.vec)\n        edge_encoding = self.model.opset.bind(source_hv.vec, rel_target)\n        edge_encodings.append(edge_encoding)\n\n    # Bundle all edges together\n    result = self.model.opset.bundle(*edge_encodings)\n\n    return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/scalar/","title":"ScalarEncoder","text":"<p>Encoder for numeric scalar values using power encoding.</p>"},{"location":"api/encoders/scalar/#vsax.encoders.ScalarEncoder","title":"<code>vsax.encoders.ScalarEncoder</code>","text":"<p>               Bases: <code>AbstractEncoder</code></p> <p>Encoder for numeric scalar values using power encoding.</p> <p>For complex hypervectors (FHRR), encodes values by raising the basis hypervector to the power of the value, which rotates the phase.</p> <p>For real and binary hypervectors, encodes by iterated binding of the basis vector with itself.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The VSAModel instance defining the VSA algebra.</p> <code>memory</code> <p>The VSAMemory instance for accessing basis hypervectors.</p> <code>min_val</code> <p>Minimum value for the encoding range (optional).</p> <code>max_val</code> <p>Maximum value for the encoding range (optional).</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.encoders import ScalarEncoder model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add(\"temperature\") encoder = ScalarEncoder(model, memory) temp_hv = encoder.encode(\"temperature\", 23.5)</p> Source code in <code>vsax/encoders/scalar.py</code> <pre><code>class ScalarEncoder(AbstractEncoder):\n    \"\"\"Encoder for numeric scalar values using power encoding.\n\n    For complex hypervectors (FHRR), encodes values by raising the basis\n    hypervector to the power of the value, which rotates the phase.\n\n    For real and binary hypervectors, encodes by iterated binding of the\n    basis vector with itself.\n\n    Attributes:\n        model: The VSAModel instance defining the VSA algebra.\n        memory: The VSAMemory instance for accessing basis hypervectors.\n        min_val: Minimum value for the encoding range (optional).\n        max_val: Maximum value for the encoding range (optional).\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; from vsax.encoders import ScalarEncoder\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"temperature\")\n        &gt;&gt;&gt; encoder = ScalarEncoder(model, memory)\n        &gt;&gt;&gt; temp_hv = encoder.encode(\"temperature\", 23.5)\n    \"\"\"\n\n    def __init__(\n        self,\n        model: VSAModel,\n        memory: VSAMemory,\n        min_val: Optional[float] = None,\n        max_val: Optional[float] = None,\n    ) -&gt; None:\n        \"\"\"Initialize the ScalarEncoder.\n\n        Args:\n            model: The VSAModel instance.\n            memory: The VSAMemory instance with basis symbols.\n            min_val: Minimum value for normalization (optional).\n            max_val: Maximum value for normalization (optional).\n        \"\"\"\n        super().__init__(model, memory)\n        self.min_val = min_val\n        self.max_val = max_val\n\n    def encode(self, symbol_name: str, value: float) -&gt; AbstractHypervector:\n        \"\"\"Encode a scalar value.\n\n        Args:\n            symbol_name: Name of the basis symbol in memory to use.\n            value: The numeric value to encode.\n\n        Returns:\n            The encoded hypervector.\n\n        Raises:\n            KeyError: If symbol_name is not in memory.\n            ValueError: If value is outside the specified range.\n\n        Example:\n            &gt;&gt;&gt; encoder = ScalarEncoder(model, memory)\n            &gt;&gt;&gt; temp_hv = encoder.encode(\"temperature\", 23.5)\n        \"\"\"\n        # Normalize value if range is specified\n        if self.min_val is not None and self.max_val is not None:\n            if not (self.min_val &lt;= value &lt;= self.max_val):\n                raise ValueError(\n                    f\"Value {value} outside range [{self.min_val}, {self.max_val}]\"\n                )\n            # Normalize to 0-1 range\n            value = (value - self.min_val) / (self.max_val - self.min_val)\n\n        # Get basis hypervector\n        basis_hv = self.memory[symbol_name]\n\n        # For complex hypervectors, use power encoding\n        if jnp.iscomplexobj(basis_hv.vec):\n            # Power encoding: v ** value rotates the phase\n            powered_vec = jnp.power(basis_hv.vec, value)\n            return self.model.rep_cls(powered_vec)\n\n        # For real and binary hypervectors, use iterated binding\n        # Bind the vector with itself 'value' times\n        # For fractional values, we approximate with integer binding\n        iterations = int(jnp.round(value * 10))  # Scale for finer granularity\n\n        if iterations == 0:\n            # Return normalized zero-like vector\n            return basis_hv.normalize()\n\n        result = basis_hv.vec\n        for _ in range(iterations - 1):\n            result = self.model.opset.bind(result, basis_hv.vec)\n\n        return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/scalar/#vsax.encoders.ScalarEncoder-functions","title":"Functions","text":""},{"location":"api/encoders/scalar/#vsax.encoders.ScalarEncoder.__init__","title":"<code>__init__(model, memory, min_val=None, max_val=None)</code>","text":"<p>Initialize the ScalarEncoder.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>VSAModel</code> <p>The VSAModel instance.</p> required <code>memory</code> <code>VSAMemory</code> <p>The VSAMemory instance with basis symbols.</p> required <code>min_val</code> <code>Optional[float]</code> <p>Minimum value for normalization (optional).</p> <code>None</code> <code>max_val</code> <code>Optional[float]</code> <p>Maximum value for normalization (optional).</p> <code>None</code> Source code in <code>vsax/encoders/scalar.py</code> <pre><code>def __init__(\n    self,\n    model: VSAModel,\n    memory: VSAMemory,\n    min_val: Optional[float] = None,\n    max_val: Optional[float] = None,\n) -&gt; None:\n    \"\"\"Initialize the ScalarEncoder.\n\n    Args:\n        model: The VSAModel instance.\n        memory: The VSAMemory instance with basis symbols.\n        min_val: Minimum value for normalization (optional).\n        max_val: Maximum value for normalization (optional).\n    \"\"\"\n    super().__init__(model, memory)\n    self.min_val = min_val\n    self.max_val = max_val\n</code></pre>"},{"location":"api/encoders/scalar/#vsax.encoders.ScalarEncoder.encode","title":"<code>encode(symbol_name, value)</code>","text":"<p>Encode a scalar value.</p> <p>Parameters:</p> Name Type Description Default <code>symbol_name</code> <code>str</code> <p>Name of the basis symbol in memory to use.</p> required <code>value</code> <code>float</code> <p>The numeric value to encode.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The encoded hypervector.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If symbol_name is not in memory.</p> <code>ValueError</code> <p>If value is outside the specified range.</p> Example <p>encoder = ScalarEncoder(model, memory) temp_hv = encoder.encode(\"temperature\", 23.5)</p> Source code in <code>vsax/encoders/scalar.py</code> <pre><code>def encode(self, symbol_name: str, value: float) -&gt; AbstractHypervector:\n    \"\"\"Encode a scalar value.\n\n    Args:\n        symbol_name: Name of the basis symbol in memory to use.\n        value: The numeric value to encode.\n\n    Returns:\n        The encoded hypervector.\n\n    Raises:\n        KeyError: If symbol_name is not in memory.\n        ValueError: If value is outside the specified range.\n\n    Example:\n        &gt;&gt;&gt; encoder = ScalarEncoder(model, memory)\n        &gt;&gt;&gt; temp_hv = encoder.encode(\"temperature\", 23.5)\n    \"\"\"\n    # Normalize value if range is specified\n    if self.min_val is not None and self.max_val is not None:\n        if not (self.min_val &lt;= value &lt;= self.max_val):\n            raise ValueError(\n                f\"Value {value} outside range [{self.min_val}, {self.max_val}]\"\n            )\n        # Normalize to 0-1 range\n        value = (value - self.min_val) / (self.max_val - self.min_val)\n\n    # Get basis hypervector\n    basis_hv = self.memory[symbol_name]\n\n    # For complex hypervectors, use power encoding\n    if jnp.iscomplexobj(basis_hv.vec):\n        # Power encoding: v ** value rotates the phase\n        powered_vec = jnp.power(basis_hv.vec, value)\n        return self.model.rep_cls(powered_vec)\n\n    # For real and binary hypervectors, use iterated binding\n    # Bind the vector with itself 'value' times\n    # For fractional values, we approximate with integer binding\n    iterations = int(jnp.round(value * 10))  # Scale for finer granularity\n\n    if iterations == 0:\n        # Return normalized zero-like vector\n        return basis_hv.normalize()\n\n    result = basis_hv.vec\n    for _ in range(iterations - 1):\n        result = self.model.opset.bind(result, basis_hv.vec)\n\n    return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/sequence/","title":"SequenceEncoder","text":"<p>Encoder for ordered sequences using positional binding.</p>"},{"location":"api/encoders/sequence/#vsax.encoders.SequenceEncoder","title":"<code>vsax.encoders.SequenceEncoder</code>","text":"<p>               Bases: <code>AbstractEncoder</code></p> <p>Encoder for ordered sequences using positional binding.</p> <p>Encodes sequences by binding each element with a position hypervector, then bundling all position-element pairs. This preserves order information.</p> <p>Position hypervectors are automatically added to memory with names \"pos_0\", \"pos_1\", etc.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The VSAModel instance defining the VSA algebra.</p> <code>memory</code> <p>The VSAMemory instance for accessing basis hypervectors.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.encoders import SequenceEncoder model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"red\", \"green\", \"blue\"]) encoder = SequenceEncoder(model, memory) color_sequence_hv = encoder.encode([\"red\", \"green\", \"blue\"])</p> Source code in <code>vsax/encoders/sequence.py</code> <pre><code>class SequenceEncoder(AbstractEncoder):\n    \"\"\"Encoder for ordered sequences using positional binding.\n\n    Encodes sequences by binding each element with a position hypervector,\n    then bundling all position-element pairs. This preserves order information.\n\n    Position hypervectors are automatically added to memory with names \"pos_0\",\n    \"pos_1\", etc.\n\n    Attributes:\n        model: The VSAModel instance defining the VSA algebra.\n        memory: The VSAMemory instance for accessing basis hypervectors.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; from vsax.encoders import SequenceEncoder\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"red\", \"green\", \"blue\"])\n        &gt;&gt;&gt; encoder = SequenceEncoder(model, memory)\n        &gt;&gt;&gt; color_sequence_hv = encoder.encode([\"red\", \"green\", \"blue\"])\n    \"\"\"\n\n    def encode(self, sequence: Sequence[str]) -&gt; AbstractHypervector:\n        \"\"\"Encode an ordered sequence of symbols.\n\n        Args:\n            sequence: A list or tuple of symbol names in memory.\n\n        Returns:\n            The encoded hypervector representing the sequence.\n\n        Raises:\n            KeyError: If any symbol in the sequence is not in memory.\n            ValueError: If the sequence is empty.\n\n        Example:\n            &gt;&gt;&gt; encoder = SequenceEncoder(model, memory)\n            &gt;&gt;&gt; seq_hv = encoder.encode([\"red\", \"green\", \"blue\"])\n        \"\"\"\n        if len(sequence) == 0:\n            raise ValueError(\"Cannot encode empty sequence\")\n\n        # Ensure position hypervectors exist in memory\n        for i in range(len(sequence)):\n            pos_name = f\"pos_{i}\"\n            if pos_name not in self.memory:\n                self.memory.add(pos_name)\n\n        # Bind each element with its position and collect results\n        bound_pairs = []\n        for i, symbol in enumerate(sequence):\n            pos_hv = self.memory[f\"pos_{i}\"]\n            elem_hv = self.memory[symbol]\n\n            # Bind position with element\n            bound = self.model.opset.bind(pos_hv.vec, elem_hv.vec)\n            bound_pairs.append(bound)\n\n        # Bundle all position-element pairs\n        result = self.model.opset.bundle(*bound_pairs)\n\n        return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/sequence/#vsax.encoders.SequenceEncoder-functions","title":"Functions","text":""},{"location":"api/encoders/sequence/#vsax.encoders.SequenceEncoder.encode","title":"<code>encode(sequence)</code>","text":"<p>Encode an ordered sequence of symbols.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>Sequence[str]</code> <p>A list or tuple of symbol names in memory.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The encoded hypervector representing the sequence.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If any symbol in the sequence is not in memory.</p> <code>ValueError</code> <p>If the sequence is empty.</p> Example <p>encoder = SequenceEncoder(model, memory) seq_hv = encoder.encode([\"red\", \"green\", \"blue\"])</p> Source code in <code>vsax/encoders/sequence.py</code> <pre><code>def encode(self, sequence: Sequence[str]) -&gt; AbstractHypervector:\n    \"\"\"Encode an ordered sequence of symbols.\n\n    Args:\n        sequence: A list or tuple of symbol names in memory.\n\n    Returns:\n        The encoded hypervector representing the sequence.\n\n    Raises:\n        KeyError: If any symbol in the sequence is not in memory.\n        ValueError: If the sequence is empty.\n\n    Example:\n        &gt;&gt;&gt; encoder = SequenceEncoder(model, memory)\n        &gt;&gt;&gt; seq_hv = encoder.encode([\"red\", \"green\", \"blue\"])\n    \"\"\"\n    if len(sequence) == 0:\n        raise ValueError(\"Cannot encode empty sequence\")\n\n    # Ensure position hypervectors exist in memory\n    for i in range(len(sequence)):\n        pos_name = f\"pos_{i}\"\n        if pos_name not in self.memory:\n            self.memory.add(pos_name)\n\n    # Bind each element with its position and collect results\n    bound_pairs = []\n    for i, symbol in enumerate(sequence):\n        pos_hv = self.memory[f\"pos_{i}\"]\n        elem_hv = self.memory[symbol]\n\n        # Bind position with element\n        bound = self.model.opset.bind(pos_hv.vec, elem_hv.vec)\n        bound_pairs.append(bound)\n\n    # Bundle all position-element pairs\n    result = self.model.opset.bundle(*bound_pairs)\n\n    return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/set/","title":"SetEncoder","text":"<p>Encoder for unordered sets using bundling.</p>"},{"location":"api/encoders/set/#vsax.encoders.SetEncoder","title":"<code>vsax.encoders.SetEncoder</code>","text":"<p>               Bases: <code>AbstractEncoder</code></p> <p>Encoder for unordered sets using bundling.</p> <p>Encodes sets by simply bundling all element hypervectors together. Since bundling is commutative, the result is order-invariant.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The VSAModel instance defining the VSA algebra.</p> <code>memory</code> <p>The VSAMemory instance for accessing basis hypervectors.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.encoders import SetEncoder model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"dog\", \"cat\", \"bird\"]) encoder = SetEncoder(model, memory) animals_set_hv = encoder.encode({\"dog\", \"cat\", \"bird\"})</p> Source code in <code>vsax/encoders/set.py</code> <pre><code>class SetEncoder(AbstractEncoder):\n    \"\"\"Encoder for unordered sets using bundling.\n\n    Encodes sets by simply bundling all element hypervectors together.\n    Since bundling is commutative, the result is order-invariant.\n\n    Attributes:\n        model: The VSAModel instance defining the VSA algebra.\n        memory: The VSAMemory instance for accessing basis hypervectors.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; from vsax.encoders import SetEncoder\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"dog\", \"cat\", \"bird\"])\n        &gt;&gt;&gt; encoder = SetEncoder(model, memory)\n        &gt;&gt;&gt; animals_set_hv = encoder.encode({\"dog\", \"cat\", \"bird\"})\n    \"\"\"\n\n    def encode(self, elements: Union[set[str], list[str]]) -&gt; AbstractHypervector:\n        \"\"\"Encode an unordered set of symbols.\n\n        Args:\n            elements: A set or list of symbol names in memory.\n\n        Returns:\n            The encoded hypervector representing the set.\n\n        Raises:\n            KeyError: If any symbol in the set is not in memory.\n            ValueError: If the set is empty.\n\n        Example:\n            &gt;&gt;&gt; encoder = SetEncoder(model, memory)\n            &gt;&gt;&gt; set_hv = encoder.encode({\"dog\", \"cat\", \"bird\"})\n        \"\"\"\n        if len(elements) == 0:\n            raise ValueError(\"Cannot encode empty set\")\n\n        # Get all element hypervectors\n        elem_vecs = [self.memory[symbol].vec for symbol in elements]\n\n        # Bundle all elements together\n        result = self.model.opset.bundle(*elem_vecs)\n\n        return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/set/#vsax.encoders.SetEncoder-functions","title":"Functions","text":""},{"location":"api/encoders/set/#vsax.encoders.SetEncoder.encode","title":"<code>encode(elements)</code>","text":"<p>Encode an unordered set of symbols.</p> <p>Parameters:</p> Name Type Description Default <code>elements</code> <code>Union[set[str], list[str]]</code> <p>A set or list of symbol names in memory.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The encoded hypervector representing the set.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If any symbol in the set is not in memory.</p> <code>ValueError</code> <p>If the set is empty.</p> Example <p>encoder = SetEncoder(model, memory) set_hv = encoder.encode({\"dog\", \"cat\", \"bird\"})</p> Source code in <code>vsax/encoders/set.py</code> <pre><code>def encode(self, elements: Union[set[str], list[str]]) -&gt; AbstractHypervector:\n    \"\"\"Encode an unordered set of symbols.\n\n    Args:\n        elements: A set or list of symbol names in memory.\n\n    Returns:\n        The encoded hypervector representing the set.\n\n    Raises:\n        KeyError: If any symbol in the set is not in memory.\n        ValueError: If the set is empty.\n\n    Example:\n        &gt;&gt;&gt; encoder = SetEncoder(model, memory)\n        &gt;&gt;&gt; set_hv = encoder.encode({\"dog\", \"cat\", \"bird\"})\n    \"\"\"\n    if len(elements) == 0:\n        raise ValueError(\"Cannot encode empty set\")\n\n    # Get all element hypervectors\n    elem_vecs = [self.memory[symbol].vec for symbol in elements]\n\n    # Bundle all elements together\n    result = self.model.opset.bundle(*elem_vecs)\n\n    return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/io/","title":"I/O API Reference","text":"<p>JSON-based persistence for VSA basis vectors.</p>"},{"location":"api/io/#overview","title":"Overview","text":"<p>The I/O module provides two functions for saving and loading basis vectors:</p> <ul> <li><code>save_basis()</code> - Save VSAMemory to JSON file</li> <li><code>load_basis()</code> - Load VSAMemory from JSON file</li> </ul> <p>Both functions work with all three VSA models (FHRR, MAP, Binary).</p>"},{"location":"api/io/#functions","title":"Functions","text":""},{"location":"api/io/#save_basis","title":"save_basis","text":"<p>Example:</p> <pre><code>from vsax import create_fhrr_model, VSAMemory, save_basis\n\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\nmemory.add_many([\"dog\", \"cat\", \"animal\"])\n\nsave_basis(memory, \"animals.json\")\n</code></pre>"},{"location":"api/io/#vsax.io.save_basis","title":"<code>vsax.io.save_basis(memory, path)</code>","text":"<p>Save VSAMemory basis vectors to a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>memory</code> <code>VSAMemory</code> <p>VSAMemory instance containing named basis vectors</p> required <code>path</code> <code>Union[str, Path]</code> <p>File path to save JSON (will be created/overwritten)</p> required Example <p>model = create_fhrr_model(dim=128) memory = VSAMemory(model) memory.add_many([\"apple\", \"orange\", \"banana\"]) save_basis(memory, \"fruit_basis.json\")</p> Source code in <code>vsax/io/save.py</code> <pre><code>def save_basis(memory: VSAMemory, path: Union[str, Path]) -&gt; None:\n    \"\"\"Save VSAMemory basis vectors to a JSON file.\n\n    Args:\n        memory: VSAMemory instance containing named basis vectors\n        path: File path to save JSON (will be created/overwritten)\n\n    Example:\n        &gt;&gt;&gt; model = create_fhrr_model(dim=128)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"apple\", \"orange\", \"banana\"])\n        &gt;&gt;&gt; save_basis(memory, \"fruit_basis.json\")\n    \"\"\"\n    path = Path(path)\n\n    # Determine representation type\n    rep_cls = memory.model.rep_cls\n    if rep_cls == ComplexHypervector:\n        rep_type = \"complex\"\n    elif rep_cls == RealHypervector:\n        rep_type = \"real\"\n    elif rep_cls == BinaryHypervector:\n        rep_type = \"binary\"\n    else:\n        raise ValueError(f\"Unknown representation type: {rep_cls}\")\n\n    # Prepare data structure\n    data: dict[str, Any] = {\n        \"metadata\": {\n            \"dim\": memory.model.dim,\n            \"rep_type\": rep_type,\n            \"num_vectors\": len(memory._symbols),\n        },\n        \"vectors\": {},\n    }\n\n    # Serialize each vector\n    for name, hv in memory._symbols.items():\n        vec = hv.vec\n\n        if rep_type == \"complex\":\n            # Split complex into real and imaginary parts\n            data[\"vectors\"][name] = {\n                \"real\": vec.real.tolist(),\n                \"imag\": vec.imag.tolist(),\n            }\n        elif rep_type == \"real\":\n            # Store real vector\n            data[\"vectors\"][name] = vec.tolist()\n        elif rep_type == \"binary\":\n            # Store binary/bipolar vector as integers\n            data[\"vectors\"][name] = vec.astype(int).tolist()\n\n    # Write to file\n    with open(path, \"w\") as f:\n        json.dump(data, f, indent=2)\n</code></pre>"},{"location":"api/io/#load_basis","title":"load_basis","text":"<p>Example:</p> <pre><code>from vsax import create_fhrr_model, VSAMemory, load_basis\n\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\n\nload_basis(memory, \"animals.json\")\nprint(f\"Loaded {len(memory._vectors)} vectors\")\n</code></pre>"},{"location":"api/io/#vsax.io.load_basis","title":"<code>vsax.io.load_basis(memory, path)</code>","text":"<p>Load basis vectors from a JSON file into VSAMemory.</p> <p>Parameters:</p> Name Type Description Default <code>memory</code> <code>VSAMemory</code> <p>VSAMemory instance to populate (must be empty)</p> required <code>path</code> <code>Union[str, Path]</code> <p>File path to load JSON from</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If dimension or representation type doesn't match</p> <code>ValueError</code> <p>If memory is not empty</p> <code>FileNotFoundError</code> <p>If file doesn't exist</p> Example <p>model = create_fhrr_model(dim=128) memory = VSAMemory(model) load_basis(memory, \"fruit_basis.json\") \"apple\" in memory True</p> Source code in <code>vsax/io/load.py</code> <pre><code>def load_basis(memory: VSAMemory, path: Union[str, Path]) -&gt; None:\n    \"\"\"Load basis vectors from a JSON file into VSAMemory.\n\n    Args:\n        memory: VSAMemory instance to populate (must be empty)\n        path: File path to load JSON from\n\n    Raises:\n        ValueError: If dimension or representation type doesn't match\n        ValueError: If memory is not empty\n        FileNotFoundError: If file doesn't exist\n\n    Example:\n        &gt;&gt;&gt; model = create_fhrr_model(dim=128)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; load_basis(memory, \"fruit_basis.json\")\n        &gt;&gt;&gt; \"apple\" in memory\n        True\n    \"\"\"\n    path = Path(path)\n\n    # Check that memory is empty\n    if len(memory._symbols) &gt; 0:\n        raise ValueError(\n            f\"Memory must be empty to load basis. \"\n            f\"Current memory contains {len(memory._symbols)} vectors.\"\n        )\n\n    # Load JSON file\n    with open(path) as f:\n        data = json.load(f)\n\n    # Validate metadata\n    metadata = data[\"metadata\"]\n    saved_dim = metadata[\"dim\"]\n    saved_rep_type = metadata[\"rep_type\"]\n\n    # Check dimension matches\n    if saved_dim != memory.model.dim:\n        raise ValueError(\n            f\"Dimension mismatch: memory has dim={memory.model.dim}, \"\n            f\"but file has dim={saved_dim}\"\n        )\n\n    # Check representation type matches\n    rep_cls = memory.model.rep_cls\n    if rep_cls == ComplexHypervector:\n        expected_type = \"complex\"\n    elif rep_cls == RealHypervector:\n        expected_type = \"real\"\n    elif rep_cls == BinaryHypervector:\n        expected_type = \"binary\"\n    else:\n        raise ValueError(f\"Unknown representation type: {rep_cls}\")\n\n    if saved_rep_type != expected_type:\n        raise ValueError(\n            f\"Representation type mismatch: memory expects {expected_type}, \"\n            f\"but file has {saved_rep_type}\"\n        )\n\n    # Load vectors\n    vectors_data = data[\"vectors\"]\n\n    for name, vec_data in vectors_data.items():\n        if saved_rep_type == \"complex\":\n            # Reconstruct complex vector from real and imaginary parts\n            real_part = jnp.array(vec_data[\"real\"], dtype=jnp.float32)\n            imag_part = jnp.array(vec_data[\"imag\"], dtype=jnp.float32)\n            vec = real_part + 1j * imag_part\n        elif saved_rep_type == \"real\":\n            # Reconstruct real vector\n            vec = jnp.array(vec_data, dtype=jnp.float32)\n        elif saved_rep_type == \"binary\":\n            # Reconstruct binary vector\n            vec = jnp.array(vec_data, dtype=jnp.float32)\n        else:\n            raise ValueError(f\"Unknown rep_type: {saved_rep_type}\")\n\n        # Create hypervector and add to memory\n        hv = rep_cls(vec)\n        memory._symbols[name] = hv\n</code></pre>"},{"location":"api/io/#json-format","title":"JSON Format","text":""},{"location":"api/io/#fhrr-complex-vectors","title":"FHRR (Complex Vectors)","text":"<p>Complex hypervectors are stored with separate real and imaginary parts:</p> <pre><code>{\n  \"metadata\": {\n    \"dim\": 512,\n    \"rep_type\": \"complex\",\n    \"num_vectors\": 2\n  },\n  \"vectors\": {\n    \"dog\": {\n      \"real\": [0.12, -0.34, 0.56, ...],\n      \"imag\": [0.78, -0.23, 0.45, ...]\n    },\n    \"cat\": {\n      \"real\": [-0.67, 0.89, -0.12, ...],\n      \"imag\": [0.34, 0.56, -0.78, ...]\n    }\n  }\n}\n</code></pre>"},{"location":"api/io/#map-real-vectors","title":"MAP (Real Vectors)","text":"<p>Real hypervectors are stored as simple float arrays:</p> <pre><code>{\n  \"metadata\": {\n    \"dim\": 512,\n    \"rep_type\": \"real\",\n    \"num_vectors\": 2\n  },\n  \"vectors\": {\n    \"red\": [0.23, -0.45, 0.67, ...],\n    \"blue\": [-0.12, 0.34, -0.56, ...]\n  }\n}\n</code></pre>"},{"location":"api/io/#binary-bipolar-vectors","title":"Binary (Bipolar Vectors)","text":"<p>Binary hypervectors are stored as integer arrays:</p> <pre><code>{\n  \"metadata\": {\n    \"dim\": 1000,\n    \"rep_type\": \"binary\",\n    \"num_vectors\": 2\n  },\n  \"vectors\": {\n    \"x\": [-1, 1, -1, 1, -1, ...],\n    \"y\": [1, -1, 1, 1, -1, ...]\n  }\n}\n</code></pre>"},{"location":"api/io/#error-handling","title":"Error Handling","text":""},{"location":"api/io/#dimension-mismatch","title":"Dimension Mismatch","text":"<pre><code>from vsax import create_fhrr_model, VSAMemory, save_basis, load_basis\n\n# Save with dim=128\nmodel_128 = create_fhrr_model(dim=128)\nmemory_128 = VSAMemory(model_128)\nmemory_128.add(\"test\")\nsave_basis(memory_128, \"test.json\")\n\n# Try to load with dim=256\nmodel_256 = create_fhrr_model(dim=256)\nmemory_256 = VSAMemory(model_256)\n\ntry:\n    load_basis(memory_256, \"test.json\")\nexcept ValueError as e:\n    print(e)  # Dimension mismatch: memory has dim=256, but file has dim=128\n</code></pre>"},{"location":"api/io/#representation-type-mismatch","title":"Representation Type Mismatch","text":"<pre><code>from vsax import create_fhrr_model, create_map_model\n\n# Save FHRR\nfhrr_memory = VSAMemory(create_fhrr_model(dim=128))\nfhrr_memory.add(\"test\")\nsave_basis(fhrr_memory, \"test.json\")\n\n# Try to load as MAP\nmap_memory = VSAMemory(create_map_model(dim=128))\n\ntry:\n    load_basis(map_memory, \"test.json\")\nexcept ValueError as e:\n    print(e)  # Representation type mismatch: memory expects real, but file has complex\n</code></pre>"},{"location":"api/io/#non-empty-memory","title":"Non-Empty Memory","text":"<pre><code>memory = VSAMemory(create_fhrr_model(dim=128))\nmemory.add(\"existing_vector\")\n\ntry:\n    load_basis(memory, \"test.json\")\nexcept ValueError as e:\n    print(e)  # Memory must be empty to load basis. Current memory contains 1 vectors.\n</code></pre>"},{"location":"api/io/#use-cases","title":"Use Cases","text":""},{"location":"api/io/#persistent-semantic-spaces","title":"Persistent Semantic Spaces","text":"<pre><code># Build once\nmodel = create_fhrr_model(dim=1024)\nmemory = VSAMemory(model)\nmemory.add_many([\"concept1\", \"concept2\", ...])\nsave_basis(memory, \"knowledge_base.json\")\n\n# Reuse across sessions\nmemory_new = VSAMemory(model)\nload_basis(memory_new, \"knowledge_base.json\")\n</code></pre>"},{"location":"api/io/#sharing-vocabularies","title":"Sharing Vocabularies","text":"<pre><code># Project A\nsave_basis(memory_a, \"shared_vocab.json\")\n\n# Project B (same dimension and model type!)\nload_basis(memory_b, \"shared_vocab.json\")\n</code></pre>"},{"location":"api/io/#reproducible-research","title":"Reproducible Research","text":"<pre><code># Version control basis vectors\ngit add experiment_basis.json\ngit commit -m \"Add basis for reproducibility\"\n</code></pre>"},{"location":"api/io/#see-also","title":"See Also","text":"<ul> <li>Persistence User Guide - Detailed usage guide</li> <li>VSAMemory API - Memory management</li> <li>Examples - Complete working examples</li> </ul>"},{"location":"api/ops/binary/","title":"BinaryOperations","text":"<p>XOR and majority voting operations for binary hypervectors.</p>"},{"location":"api/ops/binary/#vsax.ops.BinaryOperations","title":"<code>vsax.ops.BinaryOperations</code>","text":"<p>               Bases: <code>AbstractOpSet</code></p> <p>Binary VSA operations for bipolar {-1, +1} vectors.</p> <p>Binary VSA uses: - Binding: XOR (element-wise multiplication in bipolar representation) - Bundling: Majority vote - Inverse: Self-inverse (XOR is its own inverse)</p> <p>This algebra is particularly efficient for hardware implementation and provides exact unbinding (unlike MAP).</p> <p>Note: Operations assume bipolar {-1, +1} encoding. For {0, 1} encoding, convert to bipolar first.</p> Example <p>import jax import jax.numpy as jnp</p> <p>ops = BinaryOperations() key = jax.random.PRNGKey(0) a = jax.random.choice(key, jnp.array([-1, 1]), shape=(1024,)) b = jax.random.choice(key, jnp.array([-1, 1]), shape=(1024,))</p> <p>bound = ops.bind(a, b) assert jnp.all(jnp.isin(bound, jnp.array([-1, 1])))</p> Source code in <code>vsax/ops/binary.py</code> <pre><code>class BinaryOperations(AbstractOpSet):\n    \"\"\"Binary VSA operations for bipolar {-1, +1} vectors.\n\n    Binary VSA uses:\n    - Binding: XOR (element-wise multiplication in bipolar representation)\n    - Bundling: Majority vote\n    - Inverse: Self-inverse (XOR is its own inverse)\n\n    This algebra is particularly efficient for hardware implementation and\n    provides exact unbinding (unlike MAP).\n\n    Note: Operations assume bipolar {-1, +1} encoding. For {0, 1} encoding,\n    convert to bipolar first.\n\n    Example:\n        &gt;&gt;&gt; import jax\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; ops = BinaryOperations()\n        &gt;&gt;&gt; key = jax.random.PRNGKey(0)\n        &gt;&gt;&gt; a = jax.random.choice(key, jnp.array([-1, 1]), shape=(1024,))\n        &gt;&gt;&gt; b = jax.random.choice(key, jnp.array([-1, 1]), shape=(1024,))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; bound = ops.bind(a, b)\n        &gt;&gt;&gt; assert jnp.all(jnp.isin(bound, jnp.array([-1, 1])))\n    \"\"\"\n\n    def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bind two hypervectors using XOR (element-wise multiplication).\n\n        In bipolar {-1, +1} representation, XOR is implemented as\n        element-wise multiplication:\n        - (+1) XOR (+1) = +1 (same)\n        - (+1) XOR (-1) = -1 (different)\n        - (-1) XOR (+1) = -1 (different)\n        - (-1) XOR (-1) = +1 (same)\n\n        This operation is:\n        - Commutative: bind(a, b) = bind(b, a)\n        - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c)\n        - Self-inverse: bind(bind(a, b), b) = a (exact unbinding)\n\n        Args:\n            a: First hypervector as JAX array (bipolar values).\n            b: Second hypervector as JAX array (bipolar values).\n\n        Returns:\n            Bound hypervector as JAX array (bipolar values).\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = BinaryOperations()\n            &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n            &gt;&gt;&gt; b = jnp.array([1, 1, -1, -1])\n            &gt;&gt;&gt; result = ops.bind(a, b)\n            &gt;&gt;&gt; expected = jnp.array([1, -1, -1, 1])\n            &gt;&gt;&gt; assert jnp.array_equal(result, expected)\n        \"\"\"\n        # XOR in bipolar is multiplication\n        return a * b\n\n    def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bundle multiple hypervectors using majority vote.\n\n        Each element in the bundled vector is determined by the majority\n        value at that position across all input vectors.\n\n        For even counts, ties are broken by the sign of the sum.\n\n        Args:\n            *vecs: Variable number of hypervectors as JAX arrays (bipolar values).\n\n        Returns:\n            Bundled hypervector as JAX array (bipolar values).\n\n        Raises:\n            ValueError: If no vectors are provided.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = BinaryOperations()\n            &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n            &gt;&gt;&gt; b = jnp.array([1, 1, -1, -1])\n            &gt;&gt;&gt; c = jnp.array([1, 1, 1, 1])\n            &gt;&gt;&gt; result = ops.bundle(a, b, c)\n            &gt;&gt;&gt; expected = jnp.array([1, 1, 1, -1])  # Majority at each position\n            &gt;&gt;&gt; assert jnp.array_equal(result, expected)\n        \"\"\"\n        if len(vecs) == 0:\n            raise ValueError(\"bundle() requires at least one vector\")\n\n        # Stack all vectors\n        stacked = jnp.stack(vecs)\n\n        # Sum across vectors (majority has positive/negative sum)\n        summed = jnp.sum(stacked, axis=0)\n\n        # Convert to bipolar: positive sum -&gt; +1, negative sum -&gt; -1\n        # Use sign function (0 maps to 0, but we'll handle that)\n        result = jnp.sign(summed)\n\n        # Handle zeros (ties) by defaulting to +1\n        result = jnp.where(result == 0, 1, result)\n\n        return result.astype(jnp.int32)\n\n    def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Compute the inverse for unbinding.\n\n        For binary XOR, the inverse is the vector itself (self-inverse property).\n        This means: bind(bind(a, b), b) = a (exact unbinding).\n\n        Args:\n            a: Hypervector as JAX array (bipolar values).\n\n        Returns:\n            Inverse hypervector (same as input for XOR).\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = BinaryOperations()\n            &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n            &gt;&gt;&gt; inv_a = ops.inverse(a)\n            &gt;&gt;&gt; assert jnp.array_equal(inv_a, a)\n        \"\"\"\n        # XOR is self-inverse\n        return a\n\n    def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n        \"\"\"Permute a hypervector by circular rotation.\n\n        Args:\n            a: Hypervector as JAX array (bipolar values).\n            shift: Number of positions to rotate (positive = right, negative = left).\n\n        Returns:\n            Permuted hypervector as JAX array.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = BinaryOperations()\n            &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n            &gt;&gt;&gt; rotated = ops.permute(a, 1)\n            &gt;&gt;&gt; expected = jnp.array([-1, 1, -1, 1])\n            &gt;&gt;&gt; assert jnp.array_equal(rotated, expected)\n        \"\"\"\n        return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/ops/binary/#vsax.ops.BinaryOperations-functions","title":"Functions","text":""},{"location":"api/ops/binary/#vsax.ops.BinaryOperations.bind","title":"<code>bind(a, b)</code>","text":"<p>Bind two hypervectors using XOR (element-wise multiplication).</p> <p>In bipolar {-1, +1} representation, XOR is implemented as element-wise multiplication: - (+1) XOR (+1) = +1 (same) - (+1) XOR (-1) = -1 (different) - (-1) XOR (+1) = -1 (different) - (-1) XOR (-1) = +1 (same)</p> <p>This operation is: - Commutative: bind(a, b) = bind(b, a) - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c) - Self-inverse: bind(bind(a, b), b) = a (exact unbinding)</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>First hypervector as JAX array (bipolar values).</p> required <code>b</code> <code>ndarray</code> <p>Second hypervector as JAX array (bipolar values).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Bound hypervector as JAX array (bipolar values).</p> Example <p>import jax.numpy as jnp ops = BinaryOperations() a = jnp.array([1, -1, 1, -1]) b = jnp.array([1, 1, -1, -1]) result = ops.bind(a, b) expected = jnp.array([1, -1, -1, 1]) assert jnp.array_equal(result, expected)</p> Source code in <code>vsax/ops/binary.py</code> <pre><code>def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bind two hypervectors using XOR (element-wise multiplication).\n\n    In bipolar {-1, +1} representation, XOR is implemented as\n    element-wise multiplication:\n    - (+1) XOR (+1) = +1 (same)\n    - (+1) XOR (-1) = -1 (different)\n    - (-1) XOR (+1) = -1 (different)\n    - (-1) XOR (-1) = +1 (same)\n\n    This operation is:\n    - Commutative: bind(a, b) = bind(b, a)\n    - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c)\n    - Self-inverse: bind(bind(a, b), b) = a (exact unbinding)\n\n    Args:\n        a: First hypervector as JAX array (bipolar values).\n        b: Second hypervector as JAX array (bipolar values).\n\n    Returns:\n        Bound hypervector as JAX array (bipolar values).\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = BinaryOperations()\n        &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n        &gt;&gt;&gt; b = jnp.array([1, 1, -1, -1])\n        &gt;&gt;&gt; result = ops.bind(a, b)\n        &gt;&gt;&gt; expected = jnp.array([1, -1, -1, 1])\n        &gt;&gt;&gt; assert jnp.array_equal(result, expected)\n    \"\"\"\n    # XOR in bipolar is multiplication\n    return a * b\n</code></pre>"},{"location":"api/ops/binary/#vsax.ops.BinaryOperations.bundle","title":"<code>bundle(*vecs)</code>","text":"<p>Bundle multiple hypervectors using majority vote.</p> <p>Each element in the bundled vector is determined by the majority value at that position across all input vectors.</p> <p>For even counts, ties are broken by the sign of the sum.</p> <p>Parameters:</p> Name Type Description Default <code>*vecs</code> <code>ndarray</code> <p>Variable number of hypervectors as JAX arrays (bipolar values).</p> <code>()</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Bundled hypervector as JAX array (bipolar values).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no vectors are provided.</p> Example <p>import jax.numpy as jnp ops = BinaryOperations() a = jnp.array([1, -1, 1, -1]) b = jnp.array([1, 1, -1, -1]) c = jnp.array([1, 1, 1, 1]) result = ops.bundle(a, b, c) expected = jnp.array([1, 1, 1, -1])  # Majority at each position assert jnp.array_equal(result, expected)</p> Source code in <code>vsax/ops/binary.py</code> <pre><code>def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bundle multiple hypervectors using majority vote.\n\n    Each element in the bundled vector is determined by the majority\n    value at that position across all input vectors.\n\n    For even counts, ties are broken by the sign of the sum.\n\n    Args:\n        *vecs: Variable number of hypervectors as JAX arrays (bipolar values).\n\n    Returns:\n        Bundled hypervector as JAX array (bipolar values).\n\n    Raises:\n        ValueError: If no vectors are provided.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = BinaryOperations()\n        &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n        &gt;&gt;&gt; b = jnp.array([1, 1, -1, -1])\n        &gt;&gt;&gt; c = jnp.array([1, 1, 1, 1])\n        &gt;&gt;&gt; result = ops.bundle(a, b, c)\n        &gt;&gt;&gt; expected = jnp.array([1, 1, 1, -1])  # Majority at each position\n        &gt;&gt;&gt; assert jnp.array_equal(result, expected)\n    \"\"\"\n    if len(vecs) == 0:\n        raise ValueError(\"bundle() requires at least one vector\")\n\n    # Stack all vectors\n    stacked = jnp.stack(vecs)\n\n    # Sum across vectors (majority has positive/negative sum)\n    summed = jnp.sum(stacked, axis=0)\n\n    # Convert to bipolar: positive sum -&gt; +1, negative sum -&gt; -1\n    # Use sign function (0 maps to 0, but we'll handle that)\n    result = jnp.sign(summed)\n\n    # Handle zeros (ties) by defaulting to +1\n    result = jnp.where(result == 0, 1, result)\n\n    return result.astype(jnp.int32)\n</code></pre>"},{"location":"api/ops/binary/#vsax.ops.BinaryOperations.inverse","title":"<code>inverse(a)</code>","text":"<p>Compute the inverse for unbinding.</p> <p>For binary XOR, the inverse is the vector itself (self-inverse property). This means: bind(bind(a, b), b) = a (exact unbinding).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array (bipolar values).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Inverse hypervector (same as input for XOR).</p> Example <p>import jax.numpy as jnp ops = BinaryOperations() a = jnp.array([1, -1, 1, -1]) inv_a = ops.inverse(a) assert jnp.array_equal(inv_a, a)</p> Source code in <code>vsax/ops/binary.py</code> <pre><code>def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Compute the inverse for unbinding.\n\n    For binary XOR, the inverse is the vector itself (self-inverse property).\n    This means: bind(bind(a, b), b) = a (exact unbinding).\n\n    Args:\n        a: Hypervector as JAX array (bipolar values).\n\n    Returns:\n        Inverse hypervector (same as input for XOR).\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = BinaryOperations()\n        &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n        &gt;&gt;&gt; inv_a = ops.inverse(a)\n        &gt;&gt;&gt; assert jnp.array_equal(inv_a, a)\n    \"\"\"\n    # XOR is self-inverse\n    return a\n</code></pre>"},{"location":"api/ops/binary/#vsax.ops.BinaryOperations.permute","title":"<code>permute(a, shift)</code>","text":"<p>Permute a hypervector by circular rotation.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array (bipolar values).</p> required <code>shift</code> <code>int</code> <p>Number of positions to rotate (positive = right, negative = left).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Permuted hypervector as JAX array.</p> Example <p>import jax.numpy as jnp ops = BinaryOperations() a = jnp.array([1, -1, 1, -1]) rotated = ops.permute(a, 1) expected = jnp.array([-1, 1, -1, 1]) assert jnp.array_equal(rotated, expected)</p> Source code in <code>vsax/ops/binary.py</code> <pre><code>def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n    \"\"\"Permute a hypervector by circular rotation.\n\n    Args:\n        a: Hypervector as JAX array (bipolar values).\n        shift: Number of positions to rotate (positive = right, negative = left).\n\n    Returns:\n        Permuted hypervector as JAX array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = BinaryOperations()\n        &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n        &gt;&gt;&gt; rotated = ops.permute(a, 1)\n        &gt;&gt;&gt; expected = jnp.array([-1, 1, -1, 1])\n        &gt;&gt;&gt; assert jnp.array_equal(rotated, expected)\n    \"\"\"\n    return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/ops/fhrr/","title":"FHRROperations","text":"<p>FFT-based operations for complex hypervectors.</p>"},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations","title":"<code>vsax.ops.FHRROperations</code>","text":"<p>               Bases: <code>AbstractOpSet</code></p> <p>FHRR operations using FFT-based circular convolution.</p> <p>Fourier Holographic Reduced Representation (FHRR) uses circular convolution for binding and complex addition for bundling. These operations work best with complex-valued hypervectors.</p> Binding is implemented via circular convolution in the frequency domain <p>bind(a, b) = IFFT(FFT(a) \u2299 FFT(b))</p> <p>where \u2299 denotes element-wise multiplication.</p> Example <p>import jax import jax.numpy as jnp from vsax.representations import ComplexHypervector</p> <p>ops = FHRROperations() key = jax.random.PRNGKey(0) a = jnp.exp(1j * jax.random.uniform(key, (512,), minval=0, maxval=2jnp.pi)) b = jnp.exp(1j * jax.random.uniform(key, (512,), minval=0, maxval=2jnp.pi))</p> <p>bound = ops.bind(a, b) assert bound.shape == a.shape</p> Source code in <code>vsax/ops/fhrr.py</code> <pre><code>class FHRROperations(AbstractOpSet):\n    \"\"\"FHRR operations using FFT-based circular convolution.\n\n    Fourier Holographic Reduced Representation (FHRR) uses circular convolution\n    for binding and complex addition for bundling. These operations work best\n    with complex-valued hypervectors.\n\n    Binding is implemented via circular convolution in the frequency domain:\n        bind(a, b) = IFFT(FFT(a) \u2299 FFT(b))\n\n    where \u2299 denotes element-wise multiplication.\n\n    Example:\n        &gt;&gt;&gt; import jax\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; from vsax.representations import ComplexHypervector\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; ops = FHRROperations()\n        &gt;&gt;&gt; key = jax.random.PRNGKey(0)\n        &gt;&gt;&gt; a = jnp.exp(1j * jax.random.uniform(key, (512,), minval=0, maxval=2*jnp.pi))\n        &gt;&gt;&gt; b = jnp.exp(1j * jax.random.uniform(key, (512,), minval=0, maxval=2*jnp.pi))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; bound = ops.bind(a, b)\n        &gt;&gt;&gt; assert bound.shape == a.shape\n    \"\"\"\n\n    def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bind two hypervectors using circular convolution.\n\n        Implemented via FFT: IFFT(FFT(a) * FFT(b))\n\n        This operation is:\n        - Commutative: bind(a, b) = bind(b, a)\n        - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c)\n        - Invertible: bind(bind(a, b), inverse(b)) \u2248 a\n\n        Args:\n            a: First hypervector as JAX array.\n            b: Second hypervector as JAX array.\n\n        Returns:\n            Bound hypervector as JAX array.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = FHRROperations()\n            &gt;&gt;&gt; a = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5]))\n            &gt;&gt;&gt; b = jnp.exp(1j * jnp.array([0.3, 0.7, 1.1]))\n            &gt;&gt;&gt; result = ops.bind(a, b)\n            &gt;&gt;&gt; assert jnp.iscomplexobj(result)\n        \"\"\"\n        # Circular convolution via FFT\n        fft_a = jnp.fft.fft(a)\n        fft_b = jnp.fft.fft(b)\n        return jnp.fft.ifft(fft_a * fft_b)\n\n    def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bundle multiple hypervectors using complex addition and normalization.\n\n        The bundled vector is similar to all input vectors and can be queried\n        to retrieve the constituents.\n\n        Args:\n            *vecs: Variable number of hypervectors as JAX arrays.\n\n        Returns:\n            Bundled hypervector as JAX array, normalized to unit magnitude.\n\n        Raises:\n            ValueError: If no vectors are provided.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = FHRROperations()\n            &gt;&gt;&gt; a = jnp.exp(1j * jnp.array([0.0, 0.5, 1.0]))\n            &gt;&gt;&gt; b = jnp.exp(1j * jnp.array([0.3, 0.7, 1.1]))\n            &gt;&gt;&gt; c = jnp.exp(1j * jnp.array([0.6, 0.9, 1.3]))\n            &gt;&gt;&gt; result = ops.bundle(a, b, c)\n            &gt;&gt;&gt; assert jnp.allclose(jnp.abs(result), 1.0, atol=0.1)\n        \"\"\"\n        if len(vecs) == 0:\n            raise ValueError(\"bundle() requires at least one vector\")\n\n        # Sum all vectors\n        result = jnp.sum(jnp.stack(vecs), axis=0)\n\n        # Normalize to unit magnitude (phase-only)\n        return result / jnp.abs(result)\n\n    def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Compute the inverse for unbinding.\n\n        For complex vectors, the inverse is the complex conjugate.\n        For real vectors, the inverse is the reversed vector (circular convolution inverse).\n\n        Args:\n            a: Hypervector as JAX array.\n\n        Returns:\n            Inverse hypervector as JAX array.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = FHRROperations()\n            &gt;&gt;&gt; a = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5]))\n            &gt;&gt;&gt; inv_a = ops.inverse(a)\n            &gt;&gt;&gt; # Binding with inverse should approximate identity\n            &gt;&gt;&gt; result = ops.bind(a, inv_a)\n            &gt;&gt;&gt; # Result should be close to all-ones vector (DC component)\n        \"\"\"\n        if jnp.iscomplexobj(a):\n            # Complex conjugate for complex vectors\n            return jnp.conj(a)\n        else:\n            # Reverse for real vectors (circular convolution inverse)\n            # Note: index 0 stays in place, rest are reversed\n            return jnp.concatenate([a[:1], jnp.flip(a[1:])])\n\n    def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n        \"\"\"Permute a hypervector by circular rotation.\n\n        Args:\n            a: Hypervector as JAX array.\n            shift: Number of positions to rotate (positive = right, negative = left).\n\n        Returns:\n            Permuted hypervector as JAX array.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = FHRROperations()\n            &gt;&gt;&gt; a = jnp.array([1, 2, 3, 4, 5])\n            &gt;&gt;&gt; rotated = ops.permute(a, 2)\n            &gt;&gt;&gt; assert jnp.array_equal(rotated, jnp.array([4, 5, 1, 2, 3]))\n        \"\"\"\n        return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations-functions","title":"Functions","text":""},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations.bind","title":"<code>bind(a, b)</code>","text":"<p>Bind two hypervectors using circular convolution.</p> <p>Implemented via FFT: IFFT(FFT(a) * FFT(b))</p> <p>This operation is: - Commutative: bind(a, b) = bind(b, a) - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c) - Invertible: bind(bind(a, b), inverse(b)) \u2248 a</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>First hypervector as JAX array.</p> required <code>b</code> <code>ndarray</code> <p>Second hypervector as JAX array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Bound hypervector as JAX array.</p> Example <p>import jax.numpy as jnp ops = FHRROperations() a = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5])) b = jnp.exp(1j * jnp.array([0.3, 0.7, 1.1])) result = ops.bind(a, b) assert jnp.iscomplexobj(result)</p> Source code in <code>vsax/ops/fhrr.py</code> <pre><code>def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bind two hypervectors using circular convolution.\n\n    Implemented via FFT: IFFT(FFT(a) * FFT(b))\n\n    This operation is:\n    - Commutative: bind(a, b) = bind(b, a)\n    - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c)\n    - Invertible: bind(bind(a, b), inverse(b)) \u2248 a\n\n    Args:\n        a: First hypervector as JAX array.\n        b: Second hypervector as JAX array.\n\n    Returns:\n        Bound hypervector as JAX array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = FHRROperations()\n        &gt;&gt;&gt; a = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5]))\n        &gt;&gt;&gt; b = jnp.exp(1j * jnp.array([0.3, 0.7, 1.1]))\n        &gt;&gt;&gt; result = ops.bind(a, b)\n        &gt;&gt;&gt; assert jnp.iscomplexobj(result)\n    \"\"\"\n    # Circular convolution via FFT\n    fft_a = jnp.fft.fft(a)\n    fft_b = jnp.fft.fft(b)\n    return jnp.fft.ifft(fft_a * fft_b)\n</code></pre>"},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations.bundle","title":"<code>bundle(*vecs)</code>","text":"<p>Bundle multiple hypervectors using complex addition and normalization.</p> <p>The bundled vector is similar to all input vectors and can be queried to retrieve the constituents.</p> <p>Parameters:</p> Name Type Description Default <code>*vecs</code> <code>ndarray</code> <p>Variable number of hypervectors as JAX arrays.</p> <code>()</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Bundled hypervector as JAX array, normalized to unit magnitude.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no vectors are provided.</p> Example <p>import jax.numpy as jnp ops = FHRROperations() a = jnp.exp(1j * jnp.array([0.0, 0.5, 1.0])) b = jnp.exp(1j * jnp.array([0.3, 0.7, 1.1])) c = jnp.exp(1j * jnp.array([0.6, 0.9, 1.3])) result = ops.bundle(a, b, c) assert jnp.allclose(jnp.abs(result), 1.0, atol=0.1)</p> Source code in <code>vsax/ops/fhrr.py</code> <pre><code>def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bundle multiple hypervectors using complex addition and normalization.\n\n    The bundled vector is similar to all input vectors and can be queried\n    to retrieve the constituents.\n\n    Args:\n        *vecs: Variable number of hypervectors as JAX arrays.\n\n    Returns:\n        Bundled hypervector as JAX array, normalized to unit magnitude.\n\n    Raises:\n        ValueError: If no vectors are provided.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = FHRROperations()\n        &gt;&gt;&gt; a = jnp.exp(1j * jnp.array([0.0, 0.5, 1.0]))\n        &gt;&gt;&gt; b = jnp.exp(1j * jnp.array([0.3, 0.7, 1.1]))\n        &gt;&gt;&gt; c = jnp.exp(1j * jnp.array([0.6, 0.9, 1.3]))\n        &gt;&gt;&gt; result = ops.bundle(a, b, c)\n        &gt;&gt;&gt; assert jnp.allclose(jnp.abs(result), 1.0, atol=0.1)\n    \"\"\"\n    if len(vecs) == 0:\n        raise ValueError(\"bundle() requires at least one vector\")\n\n    # Sum all vectors\n    result = jnp.sum(jnp.stack(vecs), axis=0)\n\n    # Normalize to unit magnitude (phase-only)\n    return result / jnp.abs(result)\n</code></pre>"},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations.inverse","title":"<code>inverse(a)</code>","text":"<p>Compute the inverse for unbinding.</p> <p>For complex vectors, the inverse is the complex conjugate. For real vectors, the inverse is the reversed vector (circular convolution inverse).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Inverse hypervector as JAX array.</p> Example <p>import jax.numpy as jnp ops = FHRROperations() a = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5])) inv_a = ops.inverse(a)</p> Source code in <code>vsax/ops/fhrr.py</code> <pre><code>def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Compute the inverse for unbinding.\n\n    For complex vectors, the inverse is the complex conjugate.\n    For real vectors, the inverse is the reversed vector (circular convolution inverse).\n\n    Args:\n        a: Hypervector as JAX array.\n\n    Returns:\n        Inverse hypervector as JAX array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = FHRROperations()\n        &gt;&gt;&gt; a = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5]))\n        &gt;&gt;&gt; inv_a = ops.inverse(a)\n        &gt;&gt;&gt; # Binding with inverse should approximate identity\n        &gt;&gt;&gt; result = ops.bind(a, inv_a)\n        &gt;&gt;&gt; # Result should be close to all-ones vector (DC component)\n    \"\"\"\n    if jnp.iscomplexobj(a):\n        # Complex conjugate for complex vectors\n        return jnp.conj(a)\n    else:\n        # Reverse for real vectors (circular convolution inverse)\n        # Note: index 0 stays in place, rest are reversed\n        return jnp.concatenate([a[:1], jnp.flip(a[1:])])\n</code></pre>"},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations.inverse--binding-with-inverse-should-approximate-identity","title":"Binding with inverse should approximate identity","text":"<p>result = ops.bind(a, inv_a)</p>"},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations.inverse--result-should-be-close-to-all-ones-vector-dc-component","title":"Result should be close to all-ones vector (DC component)","text":""},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations.permute","title":"<code>permute(a, shift)</code>","text":"<p>Permute a hypervector by circular rotation.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array.</p> required <code>shift</code> <code>int</code> <p>Number of positions to rotate (positive = right, negative = left).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Permuted hypervector as JAX array.</p> Example <p>import jax.numpy as jnp ops = FHRROperations() a = jnp.array([1, 2, 3, 4, 5]) rotated = ops.permute(a, 2) assert jnp.array_equal(rotated, jnp.array([4, 5, 1, 2, 3]))</p> Source code in <code>vsax/ops/fhrr.py</code> <pre><code>def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n    \"\"\"Permute a hypervector by circular rotation.\n\n    Args:\n        a: Hypervector as JAX array.\n        shift: Number of positions to rotate (positive = right, negative = left).\n\n    Returns:\n        Permuted hypervector as JAX array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = FHRROperations()\n        &gt;&gt;&gt; a = jnp.array([1, 2, 3, 4, 5])\n        &gt;&gt;&gt; rotated = ops.permute(a, 2)\n        &gt;&gt;&gt; assert jnp.array_equal(rotated, jnp.array([4, 5, 1, 2, 3]))\n    \"\"\"\n    return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/ops/map/","title":"MAPOperations","text":"<p>Element-wise operations for real hypervectors.</p>"},{"location":"api/ops/map/#vsax.ops.MAPOperations","title":"<code>vsax.ops.MAPOperations</code>","text":"<p>               Bases: <code>AbstractOpSet</code></p> <p>MAP operations using element-wise multiplication and mean.</p> <p>Multiply-Add-Permute (MAP) is a simple VSA algebra that uses: - Binding: element-wise multiplication - Bundling: element-wise mean (averaging) - Inverse: approximate inverse via normalization</p> <p>MAP works best with real-valued hypervectors and is computationally efficient, making it suitable for machine learning applications.</p> Example <p>import jax import jax.numpy as jnp</p> <p>ops = MAPOperations() key = jax.random.PRNGKey(0) a = jax.random.normal(key, (1024,)) b = jax.random.normal(key, (1024,))</p> <p>bound = ops.bind(a, b) assert bound.shape == a.shape</p> Source code in <code>vsax/ops/map.py</code> <pre><code>class MAPOperations(AbstractOpSet):\n    \"\"\"MAP operations using element-wise multiplication and mean.\n\n    Multiply-Add-Permute (MAP) is a simple VSA algebra that uses:\n    - Binding: element-wise multiplication\n    - Bundling: element-wise mean (averaging)\n    - Inverse: approximate inverse via normalization\n\n    MAP works best with real-valued hypervectors and is computationally\n    efficient, making it suitable for machine learning applications.\n\n    Example:\n        &gt;&gt;&gt; import jax\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; ops = MAPOperations()\n        &gt;&gt;&gt; key = jax.random.PRNGKey(0)\n        &gt;&gt;&gt; a = jax.random.normal(key, (1024,))\n        &gt;&gt;&gt; b = jax.random.normal(key, (1024,))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; bound = ops.bind(a, b)\n        &gt;&gt;&gt; assert bound.shape == a.shape\n    \"\"\"\n\n    def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bind two hypervectors using element-wise multiplication.\n\n        This operation is:\n        - Commutative: bind(a, b) = bind(b, a)\n        - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c)\n        - Approximately invertible with the inverse() operation\n\n        Args:\n            a: First hypervector as JAX array.\n            b: Second hypervector as JAX array.\n\n        Returns:\n            Bound hypervector as JAX array (element-wise product).\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = MAPOperations()\n            &gt;&gt;&gt; a = jnp.array([1.0, 2.0, 3.0])\n            &gt;&gt;&gt; b = jnp.array([2.0, 3.0, 4.0])\n            &gt;&gt;&gt; result = ops.bind(a, b)\n            &gt;&gt;&gt; assert jnp.array_equal(result, jnp.array([2.0, 6.0, 12.0]))\n        \"\"\"\n        return a * b\n\n    def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bundle multiple hypervectors using element-wise mean.\n\n        The bundled vector is the average of all input vectors, providing\n        a representation that is similar to all inputs.\n\n        Args:\n            *vecs: Variable number of hypervectors as JAX arrays.\n\n        Returns:\n            Bundled hypervector as JAX array (element-wise mean).\n\n        Raises:\n            ValueError: If no vectors are provided.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = MAPOperations()\n            &gt;&gt;&gt; a = jnp.array([1.0, 2.0, 3.0])\n            &gt;&gt;&gt; b = jnp.array([3.0, 4.0, 5.0])\n            &gt;&gt;&gt; c = jnp.array([5.0, 6.0, 7.0])\n            &gt;&gt;&gt; result = ops.bundle(a, b, c)\n            &gt;&gt;&gt; expected = jnp.array([3.0, 4.0, 5.0])\n            &gt;&gt;&gt; assert jnp.allclose(result, expected)\n        \"\"\"\n        if len(vecs) == 0:\n            raise ValueError(\"bundle() requires at least one vector\")\n\n        return jnp.mean(jnp.stack(vecs), axis=0)\n\n    def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Compute approximate inverse for unbinding.\n\n        For MAP, the inverse is approximated by the normalized vector itself.\n        This works because binding with a normalized vector approximately\n        projects onto the orthogonal complement.\n\n        Note: This is an approximation. Perfect unbinding is not guaranteed.\n\n        Args:\n            a: Hypervector as JAX array.\n\n        Returns:\n            Approximate inverse hypervector as JAX array.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = MAPOperations()\n            &gt;&gt;&gt; a = jnp.array([3.0, 4.0])\n            &gt;&gt;&gt; inv_a = ops.inverse(a)\n            &gt;&gt;&gt; # The inverse should be normalized\n            &gt;&gt;&gt; assert jnp.allclose(jnp.linalg.norm(inv_a), 1.0, atol=1e-6)\n        \"\"\"\n        # Normalize the vector as an approximate inverse\n        # This works because: a * (a / ||a||\u00b2) \u2248 a\u00b2/||a||\u00b2\n        norm_squared = jnp.sum(a**2)\n        return a / (norm_squared + 1e-8)\n\n    def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n        \"\"\"Permute a hypervector by circular rotation.\n\n        Args:\n            a: Hypervector as JAX array.\n            shift: Number of positions to rotate (positive = right, negative = left).\n\n        Returns:\n            Permuted hypervector as JAX array.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = MAPOperations()\n            &gt;&gt;&gt; a = jnp.array([1.0, 2.0, 3.0, 4.0])\n            &gt;&gt;&gt; rotated = ops.permute(a, 1)\n            &gt;&gt;&gt; expected = jnp.array([4.0, 1.0, 2.0, 3.0])\n            &gt;&gt;&gt; assert jnp.array_equal(rotated, expected)\n        \"\"\"\n        return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/ops/map/#vsax.ops.MAPOperations-functions","title":"Functions","text":""},{"location":"api/ops/map/#vsax.ops.MAPOperations.bind","title":"<code>bind(a, b)</code>","text":"<p>Bind two hypervectors using element-wise multiplication.</p> <p>This operation is: - Commutative: bind(a, b) = bind(b, a) - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c) - Approximately invertible with the inverse() operation</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>First hypervector as JAX array.</p> required <code>b</code> <code>ndarray</code> <p>Second hypervector as JAX array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Bound hypervector as JAX array (element-wise product).</p> Example <p>import jax.numpy as jnp ops = MAPOperations() a = jnp.array([1.0, 2.0, 3.0]) b = jnp.array([2.0, 3.0, 4.0]) result = ops.bind(a, b) assert jnp.array_equal(result, jnp.array([2.0, 6.0, 12.0]))</p> Source code in <code>vsax/ops/map.py</code> <pre><code>def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bind two hypervectors using element-wise multiplication.\n\n    This operation is:\n    - Commutative: bind(a, b) = bind(b, a)\n    - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c)\n    - Approximately invertible with the inverse() operation\n\n    Args:\n        a: First hypervector as JAX array.\n        b: Second hypervector as JAX array.\n\n    Returns:\n        Bound hypervector as JAX array (element-wise product).\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = MAPOperations()\n        &gt;&gt;&gt; a = jnp.array([1.0, 2.0, 3.0])\n        &gt;&gt;&gt; b = jnp.array([2.0, 3.0, 4.0])\n        &gt;&gt;&gt; result = ops.bind(a, b)\n        &gt;&gt;&gt; assert jnp.array_equal(result, jnp.array([2.0, 6.0, 12.0]))\n    \"\"\"\n    return a * b\n</code></pre>"},{"location":"api/ops/map/#vsax.ops.MAPOperations.bundle","title":"<code>bundle(*vecs)</code>","text":"<p>Bundle multiple hypervectors using element-wise mean.</p> <p>The bundled vector is the average of all input vectors, providing a representation that is similar to all inputs.</p> <p>Parameters:</p> Name Type Description Default <code>*vecs</code> <code>ndarray</code> <p>Variable number of hypervectors as JAX arrays.</p> <code>()</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Bundled hypervector as JAX array (element-wise mean).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no vectors are provided.</p> Example <p>import jax.numpy as jnp ops = MAPOperations() a = jnp.array([1.0, 2.0, 3.0]) b = jnp.array([3.0, 4.0, 5.0]) c = jnp.array([5.0, 6.0, 7.0]) result = ops.bundle(a, b, c) expected = jnp.array([3.0, 4.0, 5.0]) assert jnp.allclose(result, expected)</p> Source code in <code>vsax/ops/map.py</code> <pre><code>def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bundle multiple hypervectors using element-wise mean.\n\n    The bundled vector is the average of all input vectors, providing\n    a representation that is similar to all inputs.\n\n    Args:\n        *vecs: Variable number of hypervectors as JAX arrays.\n\n    Returns:\n        Bundled hypervector as JAX array (element-wise mean).\n\n    Raises:\n        ValueError: If no vectors are provided.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = MAPOperations()\n        &gt;&gt;&gt; a = jnp.array([1.0, 2.0, 3.0])\n        &gt;&gt;&gt; b = jnp.array([3.0, 4.0, 5.0])\n        &gt;&gt;&gt; c = jnp.array([5.0, 6.0, 7.0])\n        &gt;&gt;&gt; result = ops.bundle(a, b, c)\n        &gt;&gt;&gt; expected = jnp.array([3.0, 4.0, 5.0])\n        &gt;&gt;&gt; assert jnp.allclose(result, expected)\n    \"\"\"\n    if len(vecs) == 0:\n        raise ValueError(\"bundle() requires at least one vector\")\n\n    return jnp.mean(jnp.stack(vecs), axis=0)\n</code></pre>"},{"location":"api/ops/map/#vsax.ops.MAPOperations.inverse","title":"<code>inverse(a)</code>","text":"<p>Compute approximate inverse for unbinding.</p> <p>For MAP, the inverse is approximated by the normalized vector itself. This works because binding with a normalized vector approximately projects onto the orthogonal complement.</p> <p>Note: This is an approximation. Perfect unbinding is not guaranteed.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Approximate inverse hypervector as JAX array.</p> Example <p>import jax.numpy as jnp ops = MAPOperations() a = jnp.array([3.0, 4.0]) inv_a = ops.inverse(a)</p> Source code in <code>vsax/ops/map.py</code> <pre><code>def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Compute approximate inverse for unbinding.\n\n    For MAP, the inverse is approximated by the normalized vector itself.\n    This works because binding with a normalized vector approximately\n    projects onto the orthogonal complement.\n\n    Note: This is an approximation. Perfect unbinding is not guaranteed.\n\n    Args:\n        a: Hypervector as JAX array.\n\n    Returns:\n        Approximate inverse hypervector as JAX array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = MAPOperations()\n        &gt;&gt;&gt; a = jnp.array([3.0, 4.0])\n        &gt;&gt;&gt; inv_a = ops.inverse(a)\n        &gt;&gt;&gt; # The inverse should be normalized\n        &gt;&gt;&gt; assert jnp.allclose(jnp.linalg.norm(inv_a), 1.0, atol=1e-6)\n    \"\"\"\n    # Normalize the vector as an approximate inverse\n    # This works because: a * (a / ||a||\u00b2) \u2248 a\u00b2/||a||\u00b2\n    norm_squared = jnp.sum(a**2)\n    return a / (norm_squared + 1e-8)\n</code></pre>"},{"location":"api/ops/map/#vsax.ops.MAPOperations.inverse--the-inverse-should-be-normalized","title":"The inverse should be normalized","text":"<p>assert jnp.allclose(jnp.linalg.norm(inv_a), 1.0, atol=1e-6)</p>"},{"location":"api/ops/map/#vsax.ops.MAPOperations.permute","title":"<code>permute(a, shift)</code>","text":"<p>Permute a hypervector by circular rotation.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array.</p> required <code>shift</code> <code>int</code> <p>Number of positions to rotate (positive = right, negative = left).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Permuted hypervector as JAX array.</p> Example <p>import jax.numpy as jnp ops = MAPOperations() a = jnp.array([1.0, 2.0, 3.0, 4.0]) rotated = ops.permute(a, 1) expected = jnp.array([4.0, 1.0, 2.0, 3.0]) assert jnp.array_equal(rotated, expected)</p> Source code in <code>vsax/ops/map.py</code> <pre><code>def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n    \"\"\"Permute a hypervector by circular rotation.\n\n    Args:\n        a: Hypervector as JAX array.\n        shift: Number of positions to rotate (positive = right, negative = left).\n\n    Returns:\n        Permuted hypervector as JAX array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = MAPOperations()\n        &gt;&gt;&gt; a = jnp.array([1.0, 2.0, 3.0, 4.0])\n        &gt;&gt;&gt; rotated = ops.permute(a, 1)\n        &gt;&gt;&gt; expected = jnp.array([4.0, 1.0, 2.0, 3.0])\n        &gt;&gt;&gt; assert jnp.array_equal(rotated, expected)\n    \"\"\"\n    return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/representations/binary/","title":"BinaryHypervector","text":"<p>Binary hypervector with bipolar or binary encoding.</p>"},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector","title":"<code>vsax.representations.BinaryHypervector</code>","text":"<p>               Bases: <code>AbstractHypervector</code></p> <p>Binary hypervector with bipolar {-1, +1} or binary {0, 1} values.</p> <p>BinaryHypervector represents hypervectors using discrete binary values. It supports two modes: - Bipolar: values in {-1, +1} (default, recommended) - Binary: values in {0, 1}</p> <p>Binary hypervectors are efficient for hardware implementation and provide good performance with XOR binding and majority bundling operations.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>JAX array containing binary values.</p> required <code>bipolar</code> <code>bool</code> <p>If True, expects {-1, +1} values. If False, expects {0, 1} values.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If vec contains values outside the expected binary set.</p> Example <p>import jax.numpy as jnp vec = jnp.array([1, -1, 1, -1]) hv = BinaryHypervector(vec, bipolar=True) normalized = hv.normalize()  # No-op for binary assert jnp.array_equal(normalized.vec, vec)</p> Source code in <code>vsax/representations/binary_hv.py</code> <pre><code>class BinaryHypervector(AbstractHypervector):\n    \"\"\"Binary hypervector with bipolar {-1, +1} or binary {0, 1} values.\n\n    BinaryHypervector represents hypervectors using discrete binary values.\n    It supports two modes:\n    - Bipolar: values in {-1, +1} (default, recommended)\n    - Binary: values in {0, 1}\n\n    Binary hypervectors are efficient for hardware implementation and provide\n    good performance with XOR binding and majority bundling operations.\n\n    Args:\n        vec: JAX array containing binary values.\n        bipolar: If True, expects {-1, +1} values. If False, expects {0, 1} values.\n\n    Raises:\n        ValueError: If vec contains values outside the expected binary set.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([1, -1, 1, -1])\n        &gt;&gt;&gt; hv = BinaryHypervector(vec, bipolar=True)\n        &gt;&gt;&gt; normalized = hv.normalize()  # No-op for binary\n        &gt;&gt;&gt; assert jnp.array_equal(normalized.vec, vec)\n    \"\"\"\n\n    def __init__(self, vec: jnp.ndarray, bipolar: bool = True) -&gt; None:\n        \"\"\"Initialize binary hypervector.\n\n        Args:\n            vec: JAX array with binary values.\n            bipolar: If True, values should be {-1, +1}.\n                    If False, values should be {0, 1}.\n\n        Raises:\n            ValueError: If vec contains invalid values for the chosen mode.\n        \"\"\"\n        self._bipolar = bipolar\n\n        # Validate binary values\n        unique_vals = jnp.unique(vec)\n\n        if bipolar:\n            valid_set = jnp.array([-1, 1])\n            if not jnp.all(jnp.isin(unique_vals, valid_set)):\n                raise ValueError(\n                    f\"Bipolar binary vector must contain only -1 or +1, \"\n                    f\"got unique values: {unique_vals}\"\n                )\n        else:\n            valid_set = jnp.array([0, 1])\n            if not jnp.all(jnp.isin(unique_vals, valid_set)):\n                raise ValueError(\n                    f\"Non-bipolar binary vector must contain only 0 or 1, \"\n                    f\"got unique values: {unique_vals}\"\n                )\n\n        super().__init__(vec)\n\n    def normalize(self) -&gt; \"BinaryHypervector\":\n        \"\"\"No-op normalization for binary hypervectors.\n\n        Binary hypervectors are already in their normalized form.\n\n        Returns:\n            A new BinaryHypervector with the same values.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.array([1, -1, 1])\n            &gt;&gt;&gt; hv = BinaryHypervector(vec)\n            &gt;&gt;&gt; normalized = hv.normalize()\n            &gt;&gt;&gt; assert jnp.array_equal(normalized.vec, vec)\n        \"\"\"\n        return BinaryHypervector(self._vec, bipolar=self._bipolar)\n\n    @property\n    def bipolar(self) -&gt; bool:\n        \"\"\"Check if hypervector uses bipolar {-1, +1} encoding.\n\n        Returns:\n            True if bipolar, False if binary {0, 1}.\n        \"\"\"\n        return self._bipolar\n\n    def to_bipolar(self) -&gt; \"BinaryHypervector\":\n        \"\"\"Convert to bipolar {-1, +1} representation.\n\n        Returns:\n            New BinaryHypervector in bipolar form.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.array([0, 1, 0, 1])\n            &gt;&gt;&gt; hv = BinaryHypervector(vec, bipolar=False)\n            &gt;&gt;&gt; bipolar_hv = hv.to_bipolar()\n            &gt;&gt;&gt; assert jnp.array_equal(bipolar_hv.vec, jnp.array([-1, 1, -1, 1]))\n        \"\"\"\n        if self._bipolar:\n            return self\n        # Convert {0, 1} to {-1, +1}: 2*x - 1\n        bipolar_vec = 2 * self._vec - 1\n        return BinaryHypervector(bipolar_vec, bipolar=True)\n\n    def to_binary(self) -&gt; \"BinaryHypervector\":\n        \"\"\"Convert to binary {0, 1} representation.\n\n        Returns:\n            New BinaryHypervector in binary form.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.array([-1, 1, -1, 1])\n            &gt;&gt;&gt; hv = BinaryHypervector(vec, bipolar=True)\n            &gt;&gt;&gt; binary_hv = hv.to_binary()\n            &gt;&gt;&gt; assert jnp.array_equal(binary_hv.vec, jnp.array([0, 1, 0, 1]))\n        \"\"\"\n        if not self._bipolar:\n            return self\n        # Convert {-1, +1} to {0, 1}: (x + 1) / 2\n        binary_vec = (self._vec + 1) // 2\n        return BinaryHypervector(binary_vec, bipolar=False)\n</code></pre>"},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector-attributes","title":"Attributes","text":""},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector.bipolar","title":"<code>bipolar</code>  <code>property</code>","text":"<p>Check if hypervector uses bipolar {-1, +1} encoding.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if bipolar, False if binary {0, 1}.</p>"},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector-functions","title":"Functions","text":""},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector.__init__","title":"<code>__init__(vec, bipolar=True)</code>","text":"<p>Initialize binary hypervector.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>JAX array with binary values.</p> required <code>bipolar</code> <code>bool</code> <p>If True, values should be {-1, +1}.     If False, values should be {0, 1}.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If vec contains invalid values for the chosen mode.</p> Source code in <code>vsax/representations/binary_hv.py</code> <pre><code>def __init__(self, vec: jnp.ndarray, bipolar: bool = True) -&gt; None:\n    \"\"\"Initialize binary hypervector.\n\n    Args:\n        vec: JAX array with binary values.\n        bipolar: If True, values should be {-1, +1}.\n                If False, values should be {0, 1}.\n\n    Raises:\n        ValueError: If vec contains invalid values for the chosen mode.\n    \"\"\"\n    self._bipolar = bipolar\n\n    # Validate binary values\n    unique_vals = jnp.unique(vec)\n\n    if bipolar:\n        valid_set = jnp.array([-1, 1])\n        if not jnp.all(jnp.isin(unique_vals, valid_set)):\n            raise ValueError(\n                f\"Bipolar binary vector must contain only -1 or +1, \"\n                f\"got unique values: {unique_vals}\"\n            )\n    else:\n        valid_set = jnp.array([0, 1])\n        if not jnp.all(jnp.isin(unique_vals, valid_set)):\n            raise ValueError(\n                f\"Non-bipolar binary vector must contain only 0 or 1, \"\n                f\"got unique values: {unique_vals}\"\n            )\n\n    super().__init__(vec)\n</code></pre>"},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector.normalize","title":"<code>normalize()</code>","text":"<p>No-op normalization for binary hypervectors.</p> <p>Binary hypervectors are already in their normalized form.</p> <p>Returns:</p> Type Description <code>BinaryHypervector</code> <p>A new BinaryHypervector with the same values.</p> Example <p>import jax.numpy as jnp vec = jnp.array([1, -1, 1]) hv = BinaryHypervector(vec) normalized = hv.normalize() assert jnp.array_equal(normalized.vec, vec)</p> Source code in <code>vsax/representations/binary_hv.py</code> <pre><code>def normalize(self) -&gt; \"BinaryHypervector\":\n    \"\"\"No-op normalization for binary hypervectors.\n\n    Binary hypervectors are already in their normalized form.\n\n    Returns:\n        A new BinaryHypervector with the same values.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([1, -1, 1])\n        &gt;&gt;&gt; hv = BinaryHypervector(vec)\n        &gt;&gt;&gt; normalized = hv.normalize()\n        &gt;&gt;&gt; assert jnp.array_equal(normalized.vec, vec)\n    \"\"\"\n    return BinaryHypervector(self._vec, bipolar=self._bipolar)\n</code></pre>"},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector.to_bipolar","title":"<code>to_bipolar()</code>","text":"<p>Convert to bipolar {-1, +1} representation.</p> <p>Returns:</p> Type Description <code>BinaryHypervector</code> <p>New BinaryHypervector in bipolar form.</p> Example <p>import jax.numpy as jnp vec = jnp.array([0, 1, 0, 1]) hv = BinaryHypervector(vec, bipolar=False) bipolar_hv = hv.to_bipolar() assert jnp.array_equal(bipolar_hv.vec, jnp.array([-1, 1, -1, 1]))</p> Source code in <code>vsax/representations/binary_hv.py</code> <pre><code>def to_bipolar(self) -&gt; \"BinaryHypervector\":\n    \"\"\"Convert to bipolar {-1, +1} representation.\n\n    Returns:\n        New BinaryHypervector in bipolar form.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([0, 1, 0, 1])\n        &gt;&gt;&gt; hv = BinaryHypervector(vec, bipolar=False)\n        &gt;&gt;&gt; bipolar_hv = hv.to_bipolar()\n        &gt;&gt;&gt; assert jnp.array_equal(bipolar_hv.vec, jnp.array([-1, 1, -1, 1]))\n    \"\"\"\n    if self._bipolar:\n        return self\n    # Convert {0, 1} to {-1, +1}: 2*x - 1\n    bipolar_vec = 2 * self._vec - 1\n    return BinaryHypervector(bipolar_vec, bipolar=True)\n</code></pre>"},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector.to_binary","title":"<code>to_binary()</code>","text":"<p>Convert to binary {0, 1} representation.</p> <p>Returns:</p> Type Description <code>BinaryHypervector</code> <p>New BinaryHypervector in binary form.</p> Example <p>import jax.numpy as jnp vec = jnp.array([-1, 1, -1, 1]) hv = BinaryHypervector(vec, bipolar=True) binary_hv = hv.to_binary() assert jnp.array_equal(binary_hv.vec, jnp.array([0, 1, 0, 1]))</p> Source code in <code>vsax/representations/binary_hv.py</code> <pre><code>def to_binary(self) -&gt; \"BinaryHypervector\":\n    \"\"\"Convert to binary {0, 1} representation.\n\n    Returns:\n        New BinaryHypervector in binary form.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([-1, 1, -1, 1])\n        &gt;&gt;&gt; hv = BinaryHypervector(vec, bipolar=True)\n        &gt;&gt;&gt; binary_hv = hv.to_binary()\n        &gt;&gt;&gt; assert jnp.array_equal(binary_hv.vec, jnp.array([0, 1, 0, 1]))\n    \"\"\"\n    if not self._bipolar:\n        return self\n    # Convert {-1, +1} to {0, 1}: (x + 1) / 2\n    binary_vec = (self._vec + 1) // 2\n    return BinaryHypervector(binary_vec, bipolar=False)\n</code></pre>"},{"location":"api/representations/complex/","title":"ComplexHypervector","text":"<p>Phase-based complex-valued hypervector for FHRR operations.</p>"},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector","title":"<code>vsax.representations.ComplexHypervector</code>","text":"<p>               Bases: <code>AbstractHypervector</code></p> <p>Phase-based complex-valued hypervector for FHRR.</p> <p>ComplexHypervector uses complex numbers to represent hypervectors, where the phase component encodes information. This is particularly useful for Fourier Holographic Reduced Representation (FHRR) operations.</p> <p>The normalization operation sets all elements to unit magnitude, preserving only the phase information.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>Complex-valued JAX array representing the hypervector.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If vec is not a complex array.</p> Example <p>import jax.numpy as jnp vec = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5])) hv = ComplexHypervector(vec) normalized = hv.normalize() assert jnp.allclose(jnp.abs(normalized.vec), 1.0)</p> Source code in <code>vsax/representations/complex_hv.py</code> <pre><code>class ComplexHypervector(AbstractHypervector):\n    \"\"\"Phase-based complex-valued hypervector for FHRR.\n\n    ComplexHypervector uses complex numbers to represent hypervectors, where\n    the phase component encodes information. This is particularly useful for\n    Fourier Holographic Reduced Representation (FHRR) operations.\n\n    The normalization operation sets all elements to unit magnitude, preserving\n    only the phase information.\n\n    Args:\n        vec: Complex-valued JAX array representing the hypervector.\n\n    Raises:\n        TypeError: If vec is not a complex array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5]))\n        &gt;&gt;&gt; hv = ComplexHypervector(vec)\n        &gt;&gt;&gt; normalized = hv.normalize()\n        &gt;&gt;&gt; assert jnp.allclose(jnp.abs(normalized.vec), 1.0)\n    \"\"\"\n\n    def __init__(self, vec: jnp.ndarray) -&gt; None:\n        \"\"\"Initialize complex hypervector.\n\n        Args:\n            vec: Complex-valued JAX array.\n\n        Raises:\n            TypeError: If vec is not complex-valued.\n        \"\"\"\n        if not jnp.iscomplexobj(vec):\n            raise TypeError(\n                f\"ComplexHypervector requires complex array, got {vec.dtype}\"\n            )\n        super().__init__(vec)\n\n    def normalize(self) -&gt; \"ComplexHypervector\":\n        \"\"\"Normalize to unit magnitude (phase-only representation).\n\n        Returns:\n            New ComplexHypervector with all elements having magnitude 1.0,\n            preserving the phase angles.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.array([3+4j, 5+12j])\n            &gt;&gt;&gt; hv = ComplexHypervector(vec)\n            &gt;&gt;&gt; normalized = hv.normalize()\n            &gt;&gt;&gt; magnitudes = jnp.abs(normalized.vec)\n            &gt;&gt;&gt; assert jnp.allclose(magnitudes, 1.0)\n        \"\"\"\n        # Normalize to unit magnitude: z / |z|\n        normalized = self._vec / jnp.abs(self._vec)\n        return ComplexHypervector(normalized)\n\n    @property\n    def phase(self) -&gt; jnp.ndarray:\n        \"\"\"Extract phase component of the complex hypervector.\n\n        Returns:\n            Real-valued array of phase angles in radians, in the range [-\u03c0, \u03c0].\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.exp(1j * jnp.array([0.0, jnp.pi/2, jnp.pi]))\n            &gt;&gt;&gt; hv = ComplexHypervector(vec)\n            &gt;&gt;&gt; phases = hv.phase\n            &gt;&gt;&gt; assert phases.shape == vec.shape\n        \"\"\"\n        return jnp.angle(self._vec)\n\n    @property\n    def magnitude(self) -&gt; jnp.ndarray:\n        \"\"\"Extract magnitude component of the complex hypervector.\n\n        Returns:\n            Real-valued array of magnitudes.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.array([3+4j, 5+12j])\n            &gt;&gt;&gt; hv = ComplexHypervector(vec)\n            &gt;&gt;&gt; mags = hv.magnitude\n            &gt;&gt;&gt; assert jnp.allclose(mags, jnp.array([5.0, 13.0]))\n        \"\"\"\n        return jnp.abs(self._vec)\n</code></pre>"},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector-attributes","title":"Attributes","text":""},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector.phase","title":"<code>phase</code>  <code>property</code>","text":"<p>Extract phase component of the complex hypervector.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Real-valued array of phase angles in radians, in the range [-\u03c0, \u03c0].</p> Example <p>import jax.numpy as jnp vec = jnp.exp(1j * jnp.array([0.0, jnp.pi/2, jnp.pi])) hv = ComplexHypervector(vec) phases = hv.phase assert phases.shape == vec.shape</p>"},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector.magnitude","title":"<code>magnitude</code>  <code>property</code>","text":"<p>Extract magnitude component of the complex hypervector.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Real-valued array of magnitudes.</p> Example <p>import jax.numpy as jnp vec = jnp.array([3+4j, 5+12j]) hv = ComplexHypervector(vec) mags = hv.magnitude assert jnp.allclose(mags, jnp.array([5.0, 13.0]))</p>"},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector-functions","title":"Functions","text":""},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector.__init__","title":"<code>__init__(vec)</code>","text":"<p>Initialize complex hypervector.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>Complex-valued JAX array.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If vec is not complex-valued.</p> Source code in <code>vsax/representations/complex_hv.py</code> <pre><code>def __init__(self, vec: jnp.ndarray) -&gt; None:\n    \"\"\"Initialize complex hypervector.\n\n    Args:\n        vec: Complex-valued JAX array.\n\n    Raises:\n        TypeError: If vec is not complex-valued.\n    \"\"\"\n    if not jnp.iscomplexobj(vec):\n        raise TypeError(\n            f\"ComplexHypervector requires complex array, got {vec.dtype}\"\n        )\n    super().__init__(vec)\n</code></pre>"},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector.normalize","title":"<code>normalize()</code>","text":"<p>Normalize to unit magnitude (phase-only representation).</p> <p>Returns:</p> Type Description <code>ComplexHypervector</code> <p>New ComplexHypervector with all elements having magnitude 1.0,</p> <code>ComplexHypervector</code> <p>preserving the phase angles.</p> Example <p>import jax.numpy as jnp vec = jnp.array([3+4j, 5+12j]) hv = ComplexHypervector(vec) normalized = hv.normalize() magnitudes = jnp.abs(normalized.vec) assert jnp.allclose(magnitudes, 1.0)</p> Source code in <code>vsax/representations/complex_hv.py</code> <pre><code>def normalize(self) -&gt; \"ComplexHypervector\":\n    \"\"\"Normalize to unit magnitude (phase-only representation).\n\n    Returns:\n        New ComplexHypervector with all elements having magnitude 1.0,\n        preserving the phase angles.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([3+4j, 5+12j])\n        &gt;&gt;&gt; hv = ComplexHypervector(vec)\n        &gt;&gt;&gt; normalized = hv.normalize()\n        &gt;&gt;&gt; magnitudes = jnp.abs(normalized.vec)\n        &gt;&gt;&gt; assert jnp.allclose(magnitudes, 1.0)\n    \"\"\"\n    # Normalize to unit magnitude: z / |z|\n    normalized = self._vec / jnp.abs(self._vec)\n    return ComplexHypervector(normalized)\n</code></pre>"},{"location":"api/representations/real/","title":"RealHypervector","text":"<p>Continuous real-valued hypervector for MAP operations.</p>"},{"location":"api/representations/real/#vsax.representations.RealHypervector","title":"<code>vsax.representations.RealHypervector</code>","text":"<p>               Bases: <code>AbstractHypervector</code></p> <p>Continuous real-valued hypervector for MAP operations.</p> <p>RealHypervector uses real numbers to represent hypervectors. This is commonly used with Multiply-Add-Permute (MAP) operations where element-wise multiplication and averaging are the primary operations.</p> <p>The normalization operation performs L2 normalization, scaling the vector to unit length.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>Real-valued JAX array representing the hypervector.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If vec is complex-valued.</p> Example <p>import jax.numpy as jnp vec = jnp.array([1.0, 2.0, 3.0]) hv = RealHypervector(vec) normalized = hv.normalize() assert jnp.allclose(jnp.linalg.norm(normalized.vec), 1.0)</p> Source code in <code>vsax/representations/real_hv.py</code> <pre><code>class RealHypervector(AbstractHypervector):\n    \"\"\"Continuous real-valued hypervector for MAP operations.\n\n    RealHypervector uses real numbers to represent hypervectors. This is\n    commonly used with Multiply-Add-Permute (MAP) operations where element-wise\n    multiplication and averaging are the primary operations.\n\n    The normalization operation performs L2 normalization, scaling the vector\n    to unit length.\n\n    Args:\n        vec: Real-valued JAX array representing the hypervector.\n\n    Raises:\n        TypeError: If vec is complex-valued.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([1.0, 2.0, 3.0])\n        &gt;&gt;&gt; hv = RealHypervector(vec)\n        &gt;&gt;&gt; normalized = hv.normalize()\n        &gt;&gt;&gt; assert jnp.allclose(jnp.linalg.norm(normalized.vec), 1.0)\n    \"\"\"\n\n    def __init__(self, vec: jnp.ndarray) -&gt; None:\n        \"\"\"Initialize real hypervector.\n\n        Args:\n            vec: Real-valued JAX array.\n\n        Raises:\n            TypeError: If vec is complex-valued.\n        \"\"\"\n        if jnp.iscomplexobj(vec):\n            raise TypeError(\n                f\"RealHypervector requires real array, got complex dtype {vec.dtype}\"\n            )\n        super().__init__(vec)\n\n    def normalize(self) -&gt; \"RealHypervector\":\n        \"\"\"L2 normalization to unit length.\n\n        Returns:\n            New RealHypervector with L2 norm equal to 1.0.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.array([3.0, 4.0])\n            &gt;&gt;&gt; hv = RealHypervector(vec)\n            &gt;&gt;&gt; normalized = hv.normalize()\n            &gt;&gt;&gt; assert jnp.allclose(jnp.linalg.norm(normalized.vec), 1.0)\n            &gt;&gt;&gt; assert jnp.allclose(normalized.vec, jnp.array([0.6, 0.8]))\n        \"\"\"\n        norm = jnp.linalg.norm(self._vec)\n        # Add small epsilon to avoid division by zero\n        normalized = self._vec / (norm + 1e-8)\n        return RealHypervector(normalized)\n</code></pre>"},{"location":"api/representations/real/#vsax.representations.RealHypervector-functions","title":"Functions","text":""},{"location":"api/representations/real/#vsax.representations.RealHypervector.__init__","title":"<code>__init__(vec)</code>","text":"<p>Initialize real hypervector.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>Real-valued JAX array.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If vec is complex-valued.</p> Source code in <code>vsax/representations/real_hv.py</code> <pre><code>def __init__(self, vec: jnp.ndarray) -&gt; None:\n    \"\"\"Initialize real hypervector.\n\n    Args:\n        vec: Real-valued JAX array.\n\n    Raises:\n        TypeError: If vec is complex-valued.\n    \"\"\"\n    if jnp.iscomplexobj(vec):\n        raise TypeError(\n            f\"RealHypervector requires real array, got complex dtype {vec.dtype}\"\n        )\n    super().__init__(vec)\n</code></pre>"},{"location":"api/representations/real/#vsax.representations.RealHypervector.normalize","title":"<code>normalize()</code>","text":"<p>L2 normalization to unit length.</p> <p>Returns:</p> Type Description <code>RealHypervector</code> <p>New RealHypervector with L2 norm equal to 1.0.</p> Example <p>import jax.numpy as jnp vec = jnp.array([3.0, 4.0]) hv = RealHypervector(vec) normalized = hv.normalize() assert jnp.allclose(jnp.linalg.norm(normalized.vec), 1.0) assert jnp.allclose(normalized.vec, jnp.array([0.6, 0.8]))</p> Source code in <code>vsax/representations/real_hv.py</code> <pre><code>def normalize(self) -&gt; \"RealHypervector\":\n    \"\"\"L2 normalization to unit length.\n\n    Returns:\n        New RealHypervector with L2 norm equal to 1.0.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([3.0, 4.0])\n        &gt;&gt;&gt; hv = RealHypervector(vec)\n        &gt;&gt;&gt; normalized = hv.normalize()\n        &gt;&gt;&gt; assert jnp.allclose(jnp.linalg.norm(normalized.vec), 1.0)\n        &gt;&gt;&gt; assert jnp.allclose(normalized.vec, jnp.array([0.6, 0.8]))\n    \"\"\"\n    norm = jnp.linalg.norm(self._vec)\n    # Add small epsilon to avoid division by zero\n    normalized = self._vec / (norm + 1e-8)\n    return RealHypervector(normalized)\n</code></pre>"},{"location":"api/resonator/","title":"Resonator Networks API","text":""},{"location":"api/resonator/#overview","title":"Overview","text":"<p>The resonator module implements resonator networks for VSA factorization.</p> <p>Given a composite vector <code>s = a \u2299 b \u2299 c</code>, resonator networks iteratively recover the factors <code>a</code>, <code>b</code>, <code>c</code> from known codebooks.</p>"},{"location":"api/resonator/#cleanupmemory","title":"CleanupMemory","text":""},{"location":"api/resonator/#vsax.resonator.CleanupMemory","title":"<code>vsax.resonator.CleanupMemory</code>","text":"<p>Cleanup memory for projecting vectors onto a codebook.</p> <p>This class implements codebook projection, which finds the nearest vector from a set of known vectors (codebook) to a query vector.</p> <p>Parameters:</p> Name Type Description Default <code>codebook</code> <code>list[str]</code> <p>List of named symbols from VSAMemory to use as codebook.</p> required <code>memory</code> <code>VSAMemory</code> <p>VSAMemory containing the basis vectors.</p> required <code>threshold</code> <code>float</code> <p>Optional similarity threshold for cleanup (default: 0.0).        If best match is below threshold, returns None.</p> <code>0.0</code> Example <p>model = create_binary_model(dim=10000) memory = VSAMemory(model) memory.add_many([\"red\", \"blue\", \"green\"]) cleanup = CleanupMemory([\"red\", \"blue\", \"green\"], memory) noisy = model.opset.bundle(memory[\"red\"].vec, memory[\"blue\"].vec) result = cleanup.query(noisy) print(result)  # Should return \"red\" or \"blue\"</p> Source code in <code>vsax/resonator/cleanup.py</code> <pre><code>class CleanupMemory:\n    \"\"\"Cleanup memory for projecting vectors onto a codebook.\n\n    This class implements codebook projection, which finds the nearest\n    vector from a set of known vectors (codebook) to a query vector.\n\n    Args:\n        codebook: List of named symbols from VSAMemory to use as codebook.\n        memory: VSAMemory containing the basis vectors.\n        threshold: Optional similarity threshold for cleanup (default: 0.0).\n                   If best match is below threshold, returns None.\n\n    Example:\n        &gt;&gt;&gt; model = create_binary_model(dim=10000)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"red\", \"blue\", \"green\"])\n        &gt;&gt;&gt; cleanup = CleanupMemory([\"red\", \"blue\", \"green\"], memory)\n        &gt;&gt;&gt; noisy = model.opset.bundle(memory[\"red\"].vec, memory[\"blue\"].vec)\n        &gt;&gt;&gt; result = cleanup.query(noisy)\n        &gt;&gt;&gt; print(result)  # Should return \"red\" or \"blue\"\n    \"\"\"\n\n    def __init__(\n        self,\n        codebook: list[str],\n        memory: VSAMemory,\n        threshold: float = 0.0,\n    ) -&gt; None:\n        \"\"\"Initialize cleanup memory with codebook.\"\"\"\n        self.codebook = codebook\n        self.memory = memory\n        self.threshold = threshold\n\n        # Validate codebook symbols exist in memory\n        for symbol in codebook:\n            if symbol not in memory:\n                raise ValueError(f\"Symbol '{symbol}' not found in memory\")\n\n        # Pre-compute codebook matrix for efficient lookup\n        self._codebook_vecs = jnp.stack([memory[name].vec for name in codebook])\n\n    def query(\n        self,\n        vec: Union[jnp.ndarray, AbstractHypervector],\n        return_similarity: bool = False,\n    ) -&gt; Union[Optional[str], tuple[Optional[str], float]]:\n        \"\"\"Project vector onto codebook and return nearest symbol.\n\n        Args:\n            vec: Query vector to cleanup (array or hypervector).\n            return_similarity: If True, also return similarity score.\n\n        Returns:\n            If return_similarity=False: Symbol name or None if below threshold.\n            If return_similarity=True: Tuple of (symbol, similarity) or (None, similarity).\n\n        Example:\n            &gt;&gt;&gt; result = cleanup.query(noisy_vec)\n            &gt;&gt;&gt; result_with_score = cleanup.query(noisy_vec, return_similarity=True)\n            &gt;&gt;&gt; print(result_with_score)  # (\"red\", 0.95)\n        \"\"\"\n        # Coerce to array if hypervector\n        if isinstance(vec, AbstractHypervector):\n            vec = vec.vec\n\n        # Compute similarities to all codebook vectors\n        # For complex vectors, use conjugate dot product (inner product)\n        # For real/binary vectors, use direct dot product\n        if jnp.iscomplexobj(self._codebook_vecs):\n            # Complex case: use conjugate dot product, then take abs for similarity\n            similarities = jnp.abs(jnp.dot(self._codebook_vecs.conj(), vec))\n        else:\n            # Real/binary case: direct dot product\n            similarities = jnp.dot(self._codebook_vecs, vec)\n\n        # Find best match\n        best_idx = int(jnp.argmax(similarities))\n        best_sim = float(similarities[best_idx])\n\n        # Check threshold\n        if best_sim &lt; self.threshold:\n            return (None, best_sim) if return_similarity else None\n\n        best_symbol = self.codebook[best_idx]\n        return (best_symbol, best_sim) if return_similarity else best_symbol\n\n    def query_top_k(\n        self,\n        vec: Union[jnp.ndarray, AbstractHypervector],\n        k: int = 3,\n    ) -&gt; list[tuple[str, float]]:\n        \"\"\"Return top-k closest symbols with similarity scores.\n\n        Args:\n            vec: Query vector to cleanup.\n            k: Number of top matches to return.\n\n        Returns:\n            List of (symbol, similarity) tuples sorted by similarity (descending).\n\n        Example:\n            &gt;&gt;&gt; top_matches = cleanup.query_top_k(noisy_vec, k=3)\n            &gt;&gt;&gt; for symbol, sim in top_matches:\n            ...     print(f\"{symbol}: {sim:.3f}\")\n        \"\"\"\n        # Coerce to array if hypervector\n        if isinstance(vec, AbstractHypervector):\n            vec = vec.vec\n\n        # Compute similarities\n        if jnp.iscomplexobj(self._codebook_vecs):\n            similarities = jnp.abs(jnp.dot(self._codebook_vecs.conj(), vec))\n        else:\n            similarities = jnp.dot(self._codebook_vecs, vec)\n\n        # Get top-k indices\n        top_k_indices = jnp.argsort(similarities)[-k:][::-1]\n\n        # Build result list\n        results = [\n            (self.codebook[int(idx)], float(similarities[idx]))\n            for idx in top_k_indices\n        ]\n\n        return results\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return number of vectors in codebook.\"\"\"\n        return len(self.codebook)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return string representation.\"\"\"\n        return f\"CleanupMemory(codebook_size={len(self.codebook)}, threshold={self.threshold})\"\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.CleanupMemory-functions","title":"Functions","text":""},{"location":"api/resonator/#vsax.resonator.CleanupMemory.__init__","title":"<code>__init__(codebook, memory, threshold=0.0)</code>","text":"<p>Initialize cleanup memory with codebook.</p> Source code in <code>vsax/resonator/cleanup.py</code> <pre><code>def __init__(\n    self,\n    codebook: list[str],\n    memory: VSAMemory,\n    threshold: float = 0.0,\n) -&gt; None:\n    \"\"\"Initialize cleanup memory with codebook.\"\"\"\n    self.codebook = codebook\n    self.memory = memory\n    self.threshold = threshold\n\n    # Validate codebook symbols exist in memory\n    for symbol in codebook:\n        if symbol not in memory:\n            raise ValueError(f\"Symbol '{symbol}' not found in memory\")\n\n    # Pre-compute codebook matrix for efficient lookup\n    self._codebook_vecs = jnp.stack([memory[name].vec for name in codebook])\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.CleanupMemory.query","title":"<code>query(vec, return_similarity=False)</code>","text":"<p>Project vector onto codebook and return nearest symbol.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>Union[ndarray, AbstractHypervector]</code> <p>Query vector to cleanup (array or hypervector).</p> required <code>return_similarity</code> <code>bool</code> <p>If True, also return similarity score.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Optional[str], tuple[Optional[str], float]]</code> <p>If return_similarity=False: Symbol name or None if below threshold.</p> <code>Union[Optional[str], tuple[Optional[str], float]]</code> <p>If return_similarity=True: Tuple of (symbol, similarity) or (None, similarity).</p> Example <p>result = cleanup.query(noisy_vec) result_with_score = cleanup.query(noisy_vec, return_similarity=True) print(result_with_score)  # (\"red\", 0.95)</p> Source code in <code>vsax/resonator/cleanup.py</code> <pre><code>def query(\n    self,\n    vec: Union[jnp.ndarray, AbstractHypervector],\n    return_similarity: bool = False,\n) -&gt; Union[Optional[str], tuple[Optional[str], float]]:\n    \"\"\"Project vector onto codebook and return nearest symbol.\n\n    Args:\n        vec: Query vector to cleanup (array or hypervector).\n        return_similarity: If True, also return similarity score.\n\n    Returns:\n        If return_similarity=False: Symbol name or None if below threshold.\n        If return_similarity=True: Tuple of (symbol, similarity) or (None, similarity).\n\n    Example:\n        &gt;&gt;&gt; result = cleanup.query(noisy_vec)\n        &gt;&gt;&gt; result_with_score = cleanup.query(noisy_vec, return_similarity=True)\n        &gt;&gt;&gt; print(result_with_score)  # (\"red\", 0.95)\n    \"\"\"\n    # Coerce to array if hypervector\n    if isinstance(vec, AbstractHypervector):\n        vec = vec.vec\n\n    # Compute similarities to all codebook vectors\n    # For complex vectors, use conjugate dot product (inner product)\n    # For real/binary vectors, use direct dot product\n    if jnp.iscomplexobj(self._codebook_vecs):\n        # Complex case: use conjugate dot product, then take abs for similarity\n        similarities = jnp.abs(jnp.dot(self._codebook_vecs.conj(), vec))\n    else:\n        # Real/binary case: direct dot product\n        similarities = jnp.dot(self._codebook_vecs, vec)\n\n    # Find best match\n    best_idx = int(jnp.argmax(similarities))\n    best_sim = float(similarities[best_idx])\n\n    # Check threshold\n    if best_sim &lt; self.threshold:\n        return (None, best_sim) if return_similarity else None\n\n    best_symbol = self.codebook[best_idx]\n    return (best_symbol, best_sim) if return_similarity else best_symbol\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.CleanupMemory.query_top_k","title":"<code>query_top_k(vec, k=3)</code>","text":"<p>Return top-k closest symbols with similarity scores.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>Union[ndarray, AbstractHypervector]</code> <p>Query vector to cleanup.</p> required <code>k</code> <code>int</code> <p>Number of top matches to return.</p> <code>3</code> <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>List of (symbol, similarity) tuples sorted by similarity (descending).</p> Example <p>top_matches = cleanup.query_top_k(noisy_vec, k=3) for symbol, sim in top_matches: ...     print(f\"{symbol}: {sim:.3f}\")</p> Source code in <code>vsax/resonator/cleanup.py</code> <pre><code>def query_top_k(\n    self,\n    vec: Union[jnp.ndarray, AbstractHypervector],\n    k: int = 3,\n) -&gt; list[tuple[str, float]]:\n    \"\"\"Return top-k closest symbols with similarity scores.\n\n    Args:\n        vec: Query vector to cleanup.\n        k: Number of top matches to return.\n\n    Returns:\n        List of (symbol, similarity) tuples sorted by similarity (descending).\n\n    Example:\n        &gt;&gt;&gt; top_matches = cleanup.query_top_k(noisy_vec, k=3)\n        &gt;&gt;&gt; for symbol, sim in top_matches:\n        ...     print(f\"{symbol}: {sim:.3f}\")\n    \"\"\"\n    # Coerce to array if hypervector\n    if isinstance(vec, AbstractHypervector):\n        vec = vec.vec\n\n    # Compute similarities\n    if jnp.iscomplexobj(self._codebook_vecs):\n        similarities = jnp.abs(jnp.dot(self._codebook_vecs.conj(), vec))\n    else:\n        similarities = jnp.dot(self._codebook_vecs, vec)\n\n    # Get top-k indices\n    top_k_indices = jnp.argsort(similarities)[-k:][::-1]\n\n    # Build result list\n    results = [\n        (self.codebook[int(idx)], float(similarities[idx]))\n        for idx in top_k_indices\n    ]\n\n    return results\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.CleanupMemory.__len__","title":"<code>__len__()</code>","text":"<p>Return number of vectors in codebook.</p> Source code in <code>vsax/resonator/cleanup.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return number of vectors in codebook.\"\"\"\n    return len(self.codebook)\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.CleanupMemory.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation.</p> Source code in <code>vsax/resonator/cleanup.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return string representation.\"\"\"\n    return f\"CleanupMemory(codebook_size={len(self.codebook)}, threshold={self.threshold})\"\n</code></pre>"},{"location":"api/resonator/#example","title":"Example","text":"<pre><code>from vsax import create_binary_model, VSAMemory\nfrom vsax.resonator import CleanupMemory\n\nmodel = create_binary_model(dim=10000, bipolar=True)\nmemory = VSAMemory(model)\nmemory.add_many([\"red\", \"blue\", \"green\"])\n\n# Create cleanup memory\ncleanup = CleanupMemory([\"red\", \"blue\", \"green\"], memory)\n\n# Query with noisy vector\nresult = cleanup.query(noisy_vector)\nprint(result)  # \"red\"\n\n# Get top-k matches\ntop_3 = cleanup.query_top_k(noisy_vector, k=3)\nfor symbol, similarity in top_3:\n    print(f\"{symbol}: {similarity:.3f}\")\n</code></pre>"},{"location":"api/resonator/#resonator","title":"Resonator","text":""},{"location":"api/resonator/#vsax.resonator.Resonator","title":"<code>vsax.resonator.Resonator</code>","text":"<p>Resonator network for factorizing composite VSA vectors.</p> <p>Given a composite vector s = a \u2299 b \u2299 c, this class implements an iterative algorithm to find the factors a, b, c from known codebooks.</p> <p>The algorithm alternates between: 1. Unbinding current estimates of other factors from s 2. Cleaning up the result using codebook projection</p> <p>Parameters:</p> Name Type Description Default <code>codebooks</code> <code>list[CleanupMemory]</code> <p>List of CleanupMemory objects, one per factor position.</p> required <code>opset</code> <code>AbstractOpSet</code> <p>Operation set defining bind/unbind operations.</p> required <code>max_iterations</code> <code>int</code> <p>Maximum number of iterations (default: 100).</p> <code>100</code> <code>convergence_threshold</code> <code>int</code> <p>Stop if estimates don't change (default: 3).</p> <code>3</code> Example <p>model = create_binary_model(dim=10000) memory = VSAMemory(model) memory.add_many([\"red\", \"blue\", \"circle\", \"square\"])</p> Source code in <code>vsax/resonator/resonator.py</code> <pre><code>class Resonator:\n    \"\"\"Resonator network for factorizing composite VSA vectors.\n\n    Given a composite vector s = a \u2299 b \u2299 c, this class implements an\n    iterative algorithm to find the factors a, b, c from known codebooks.\n\n    The algorithm alternates between:\n    1. Unbinding current estimates of other factors from s\n    2. Cleaning up the result using codebook projection\n\n    Args:\n        codebooks: List of CleanupMemory objects, one per factor position.\n        opset: Operation set defining bind/unbind operations.\n        max_iterations: Maximum number of iterations (default: 100).\n        convergence_threshold: Stop if estimates don't change (default: 3).\n\n    Example:\n        &gt;&gt;&gt; model = create_binary_model(dim=10000)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"red\", \"blue\", \"circle\", \"square\"])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create codebooks for two factor positions\n        &gt;&gt;&gt; colors = CleanupMemory([\"red\", \"blue\"], memory)\n        &gt;&gt;&gt; shapes = CleanupMemory([\"circle\", \"square\"], memory)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create composite: red \u2299 circle\n        &gt;&gt;&gt; composite = model.opset.bind(\n        ...     memory[\"red\"].vec,\n        ...     memory[\"circle\"].vec\n        ... )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Factorize\n        &gt;&gt;&gt; resonator = Resonator([colors, shapes], model.opset)\n        &gt;&gt;&gt; factors = resonator.factorize(composite)\n        &gt;&gt;&gt; print(factors)  # [\"red\", \"circle\"]\n    \"\"\"\n\n    def __init__(\n        self,\n        codebooks: list[CleanupMemory],\n        opset: AbstractOpSet,\n        max_iterations: int = 100,\n        convergence_threshold: int = 3,\n    ) -&gt; None:\n        \"\"\"Initialize resonator network.\"\"\"\n        if len(codebooks) &lt; 2:\n            raise ValueError(\"Need at least 2 codebooks for factorization\")\n\n        self.codebooks = codebooks\n        self.opset = opset\n        self.max_iterations = max_iterations\n        self.convergence_threshold = convergence_threshold\n        self.num_factors = len(codebooks)\n\n    def factorize(\n        self,\n        composite: Union[jnp.ndarray, AbstractHypervector],\n        initial_estimates: Optional[list[str]] = None,\n        return_history: bool = False,\n    ) -&gt; Union[list[Optional[str]], tuple[list[Optional[str]], list[list[Optional[str]]]]]:\n        \"\"\"Factorize a composite vector into its constituent factors.\n\n        Args:\n            composite: Composite vector to factorize.\n            initial_estimates: Optional initial guesses for factors.\n                              If None, uses superposition of all codebook vectors.\n            return_history: If True, return iteration history.\n\n        Returns:\n            If return_history=False: List of factor names (or None if not converged).\n            If return_history=True: Tuple of (factors, history) where history is\n                                    a list of factor estimates at each iteration.\n\n        Example:\n            &gt;&gt;&gt; factors = resonator.factorize(composite)\n            &gt;&gt;&gt; factors, history = resonator.factorize(composite, return_history=True)\n        \"\"\"\n        # Coerce to array if hypervector\n        if isinstance(composite, AbstractHypervector):\n            composite = composite.vec\n\n        # Initialize estimates\n        estimates = self._initialize_estimates(initial_estimates)\n        history: list[list[Optional[str]]] = [estimates.copy()] if return_history else []\n\n        # Track convergence\n        stable_count = 0\n        prev_estimates = estimates.copy()\n\n        # Iterative resonance\n        for iteration in range(self.max_iterations):\n            # Update each factor estimate\n            for i in range(self.num_factors):\n                estimates[i] = self._update_factor(\n                    composite, estimates, i\n                )\n\n            # Track history\n            if return_history:\n                history.append(estimates.copy())\n\n            # Check convergence\n            if estimates == prev_estimates:\n                stable_count += 1\n                if stable_count &gt;= self.convergence_threshold:\n                    break\n            else:\n                stable_count = 0\n                prev_estimates = estimates.copy()\n\n        # Return results\n        if return_history:\n            return estimates, history\n        return estimates\n\n    def _initialize_estimates(\n        self,\n        initial_estimates: Optional[list[str]] = None,\n    ) -&gt; list[Optional[str]]:\n        \"\"\"Initialize factor estimates.\n\n        If initial_estimates provided, validate and use them.\n        Otherwise, use None (superposition initialization happens in update).\n        \"\"\"\n        if initial_estimates is not None:\n            if len(initial_estimates) != self.num_factors:\n                raise ValueError(\n                    f\"Expected {self.num_factors} initial estimates, \"\n                    f\"got {len(initial_estimates)}\"\n                )\n            # Validate estimates exist in codebooks\n            for i, est in enumerate(initial_estimates):\n                if est not in self.codebooks[i].codebook:\n                    raise ValueError(\n                        f\"Initial estimate '{est}' not in codebook {i}\"\n                    )\n            # Cast to list[Optional[str]] for type compatibility\n            return cast(list[Optional[str]], initial_estimates.copy())\n\n        # Start with None (will use superposition in first iteration)\n        return [None] * self.num_factors\n\n    def _update_factor(\n        self,\n        composite: jnp.ndarray,\n        current_estimates: list[Optional[str]],\n        factor_idx: int,\n    ) -&gt; Optional[str]:\n        \"\"\"Update estimate for a single factor.\n\n        Implements: x\u0302(t+1) = g(XX^T(s \u2299 \u0177(t) \u2299 \u1e91(t)))\n\n        Args:\n            composite: The composite vector s.\n            current_estimates: Current estimates for all factors.\n            factor_idx: Which factor to update.\n\n        Returns:\n            Updated factor name or None.\n        \"\"\"\n        # Start with composite vector\n        residual = composite\n\n        # Unbind all OTHER factors from composite\n        # s \u2299 inverse(\u0177) \u2299 inverse(\u1e91) should leave x\u0302\n        for i, estimate_name in enumerate(current_estimates):\n            if i == factor_idx:\n                continue\n\n            if estimate_name is None:\n                # No estimate yet - use superposition of all vectors in codebook\n                # This is the initialization from the paper\n                codebook_vecs = self.codebooks[i]._codebook_vecs\n                superposition = jnp.sum(codebook_vecs, axis=0)\n                residual = self.opset.bind(residual, self.opset.inverse(superposition))\n            else:\n                # Use the current estimate\n                factor_vec = self.codebooks[i].memory[estimate_name].vec\n                residual = self.opset.bind(residual, self.opset.inverse(factor_vec))\n\n        # Cleanup: project residual onto codebook for this factor\n        # This is g(XX^T(...)) from the paper\n        # query with return_similarity=False returns Optional[str]\n        result: Optional[str] = self.codebooks[factor_idx].query(residual)  # type: ignore[assignment]\n\n        return result\n\n    def factorize_batch(\n        self,\n        composites: jnp.ndarray,\n        initial_estimates: Optional[list[list[str]]] = None,\n    ) -&gt; list[list[Optional[str]]]:\n        \"\"\"Factorize multiple composite vectors.\n\n        Args:\n            composites: Array of composite vectors, shape (batch_size, dim).\n            initial_estimates: Optional initial guesses for each composite.\n\n        Returns:\n            List of factor lists, one per composite.\n\n        Example:\n            &gt;&gt;&gt; composites = jnp.stack([comp1, comp2, comp3])\n            &gt;&gt;&gt; all_factors = resonator.factorize_batch(composites)\n        \"\"\"\n        batch_size = composites.shape[0]\n        results: list[list[Optional[str]]] = []\n\n        for i in range(batch_size):\n            init = initial_estimates[i] if initial_estimates else None\n            # factorize returns list[Optional[str]] when return_history=False (default)\n            factors = self.factorize(composites[i], initial_estimates=init, return_history=False)\n            # Type narrowing: we know it's just the list, not the tuple\n            assert isinstance(factors, list), \"Expected list without history\"\n            results.append(factors)\n\n        return results\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return string representation.\"\"\"\n        return (\n            f\"Resonator(num_factors={self.num_factors}, \"\n            f\"max_iterations={self.max_iterations}, \"\n            f\"convergence_threshold={self.convergence_threshold})\"\n        )\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.Resonator--create-codebooks-for-two-factor-positions","title":"Create codebooks for two factor positions","text":"<p>colors = CleanupMemory([\"red\", \"blue\"], memory) shapes = CleanupMemory([\"circle\", \"square\"], memory)</p>"},{"location":"api/resonator/#vsax.resonator.Resonator--create-composite-red-circle","title":"Create composite: red \u2299 circle","text":"<p>composite = model.opset.bind( ...     memory[\"red\"].vec, ...     memory[\"circle\"].vec ... )</p>"},{"location":"api/resonator/#vsax.resonator.Resonator--factorize","title":"Factorize","text":"<p>resonator = Resonator([colors, shapes], model.opset) factors = resonator.factorize(composite) print(factors)  # [\"red\", \"circle\"]</p>"},{"location":"api/resonator/#vsax.resonator.Resonator-functions","title":"Functions","text":""},{"location":"api/resonator/#vsax.resonator.Resonator.__init__","title":"<code>__init__(codebooks, opset, max_iterations=100, convergence_threshold=3)</code>","text":"<p>Initialize resonator network.</p> Source code in <code>vsax/resonator/resonator.py</code> <pre><code>def __init__(\n    self,\n    codebooks: list[CleanupMemory],\n    opset: AbstractOpSet,\n    max_iterations: int = 100,\n    convergence_threshold: int = 3,\n) -&gt; None:\n    \"\"\"Initialize resonator network.\"\"\"\n    if len(codebooks) &lt; 2:\n        raise ValueError(\"Need at least 2 codebooks for factorization\")\n\n    self.codebooks = codebooks\n    self.opset = opset\n    self.max_iterations = max_iterations\n    self.convergence_threshold = convergence_threshold\n    self.num_factors = len(codebooks)\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.Resonator.factorize","title":"<code>factorize(composite, initial_estimates=None, return_history=False)</code>","text":"<p>Factorize a composite vector into its constituent factors.</p> <p>Parameters:</p> Name Type Description Default <code>composite</code> <code>Union[ndarray, AbstractHypervector]</code> <p>Composite vector to factorize.</p> required <code>initial_estimates</code> <code>Optional[list[str]]</code> <p>Optional initial guesses for factors.               If None, uses superposition of all codebook vectors.</p> <code>None</code> <code>return_history</code> <code>bool</code> <p>If True, return iteration history.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[list[Optional[str]], tuple[list[Optional[str]], list[list[Optional[str]]]]]</code> <p>If return_history=False: List of factor names (or None if not converged).</p> <code>Union[list[Optional[str]], tuple[list[Optional[str]], list[list[Optional[str]]]]]</code> <p>If return_history=True: Tuple of (factors, history) where history is                     a list of factor estimates at each iteration.</p> Example <p>factors = resonator.factorize(composite) factors, history = resonator.factorize(composite, return_history=True)</p> Source code in <code>vsax/resonator/resonator.py</code> <pre><code>def factorize(\n    self,\n    composite: Union[jnp.ndarray, AbstractHypervector],\n    initial_estimates: Optional[list[str]] = None,\n    return_history: bool = False,\n) -&gt; Union[list[Optional[str]], tuple[list[Optional[str]], list[list[Optional[str]]]]]:\n    \"\"\"Factorize a composite vector into its constituent factors.\n\n    Args:\n        composite: Composite vector to factorize.\n        initial_estimates: Optional initial guesses for factors.\n                          If None, uses superposition of all codebook vectors.\n        return_history: If True, return iteration history.\n\n    Returns:\n        If return_history=False: List of factor names (or None if not converged).\n        If return_history=True: Tuple of (factors, history) where history is\n                                a list of factor estimates at each iteration.\n\n    Example:\n        &gt;&gt;&gt; factors = resonator.factorize(composite)\n        &gt;&gt;&gt; factors, history = resonator.factorize(composite, return_history=True)\n    \"\"\"\n    # Coerce to array if hypervector\n    if isinstance(composite, AbstractHypervector):\n        composite = composite.vec\n\n    # Initialize estimates\n    estimates = self._initialize_estimates(initial_estimates)\n    history: list[list[Optional[str]]] = [estimates.copy()] if return_history else []\n\n    # Track convergence\n    stable_count = 0\n    prev_estimates = estimates.copy()\n\n    # Iterative resonance\n    for iteration in range(self.max_iterations):\n        # Update each factor estimate\n        for i in range(self.num_factors):\n            estimates[i] = self._update_factor(\n                composite, estimates, i\n            )\n\n        # Track history\n        if return_history:\n            history.append(estimates.copy())\n\n        # Check convergence\n        if estimates == prev_estimates:\n            stable_count += 1\n            if stable_count &gt;= self.convergence_threshold:\n                break\n        else:\n            stable_count = 0\n            prev_estimates = estimates.copy()\n\n    # Return results\n    if return_history:\n        return estimates, history\n    return estimates\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.Resonator.factorize_batch","title":"<code>factorize_batch(composites, initial_estimates=None)</code>","text":"<p>Factorize multiple composite vectors.</p> <p>Parameters:</p> Name Type Description Default <code>composites</code> <code>ndarray</code> <p>Array of composite vectors, shape (batch_size, dim).</p> required <code>initial_estimates</code> <code>Optional[list[list[str]]]</code> <p>Optional initial guesses for each composite.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[list[Optional[str]]]</code> <p>List of factor lists, one per composite.</p> Example <p>composites = jnp.stack([comp1, comp2, comp3]) all_factors = resonator.factorize_batch(composites)</p> Source code in <code>vsax/resonator/resonator.py</code> <pre><code>def factorize_batch(\n    self,\n    composites: jnp.ndarray,\n    initial_estimates: Optional[list[list[str]]] = None,\n) -&gt; list[list[Optional[str]]]:\n    \"\"\"Factorize multiple composite vectors.\n\n    Args:\n        composites: Array of composite vectors, shape (batch_size, dim).\n        initial_estimates: Optional initial guesses for each composite.\n\n    Returns:\n        List of factor lists, one per composite.\n\n    Example:\n        &gt;&gt;&gt; composites = jnp.stack([comp1, comp2, comp3])\n        &gt;&gt;&gt; all_factors = resonator.factorize_batch(composites)\n    \"\"\"\n    batch_size = composites.shape[0]\n    results: list[list[Optional[str]]] = []\n\n    for i in range(batch_size):\n        init = initial_estimates[i] if initial_estimates else None\n        # factorize returns list[Optional[str]] when return_history=False (default)\n        factors = self.factorize(composites[i], initial_estimates=init, return_history=False)\n        # Type narrowing: we know it's just the list, not the tuple\n        assert isinstance(factors, list), \"Expected list without history\"\n        results.append(factors)\n\n    return results\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.Resonator.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation.</p> Source code in <code>vsax/resonator/resonator.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return string representation.\"\"\"\n    return (\n        f\"Resonator(num_factors={self.num_factors}, \"\n        f\"max_iterations={self.max_iterations}, \"\n        f\"convergence_threshold={self.convergence_threshold})\"\n    )\n</code></pre>"},{"location":"api/resonator/#example_1","title":"Example","text":"<pre><code>from vsax import create_binary_model, VSAMemory\nfrom vsax.resonator import CleanupMemory, Resonator\n\n# Setup\nmodel = create_binary_model(dim=10000, bipolar=True)\nmemory = VSAMemory(model)\nmemory.add_many([\"red\", \"blue\", \"circle\", \"square\"])\n\n# Create composite\ncomposite = model.opset.bind(\n    memory[\"red\"].vec,\n    memory[\"circle\"].vec\n)\n\n# Create codebooks\ncolors = CleanupMemory([\"red\", \"blue\"], memory)\nshapes = CleanupMemory([\"circle\", \"square\"], memory)\n\n# Factorize\nresonator = Resonator([colors, shapes], model.opset)\nfactors = resonator.factorize(composite)\n\nprint(factors)  # [\"red\", \"circle\"]\n</code></pre>"},{"location":"api/resonator/#algorithm-details","title":"Algorithm Details","text":""},{"location":"api/resonator/#resonance-equations","title":"Resonance Equations","text":"<p>For a composite <code>s = a \u2299 b \u2299 c</code>, the update equations are:</p> <pre><code>x\u0302(t+1) = g(XX^T(s \u2299 \u0177(t) \u2299 \u1e91(t)))\n\u0177(t+1) = g(YY^T(s \u2299 x\u0302(t) \u2299 \u1e91(t)))\n\u1e91(t+1) = g(ZZ^T(s \u2299 x\u0302(t) \u2299 \u0177(t)))\n</code></pre> <p>Where: - <code>x\u0302, \u0177, \u1e91</code> are factor estimates - <code>X, Y, Z</code> are codebook matrices - <code>g(XX^T\u00b7)</code> is the cleanup operation (codebook projection) - <code>\u2299</code> is the binding operation</p>"},{"location":"api/resonator/#cleanup-operation","title":"Cleanup Operation","text":"<p>The cleanup operation <code>g(XX^T v)</code> projects vector <code>v</code> onto the nearest vector in codebook <code>X</code>.</p> <p>For binary/bipolar vectors: <pre><code>similarities = codebook_matrix @ v\nbest_idx = argmax(similarities)\nresult = codebook[best_idx]\n</code></pre></p> <p>For complex/real vectors: <pre><code>similarities = [cosine_similarity(v, c) for c in codebook]\nbest_idx = argmax(similarities)\nresult = codebook[best_idx]\n</code></pre></p>"},{"location":"api/resonator/#initialization","title":"Initialization","text":"<p>On the first iteration (no prior estimates), the algorithm uses superposition initialization:</p> <pre><code>initial_estimate = sum(all_vectors_in_codebook)\n</code></pre> <p>This provides information about all possible factors simultaneously.</p>"},{"location":"api/resonator/#convergence","title":"Convergence","text":"<p>The algorithm stops when:</p> <ol> <li>Stable convergence: Estimates unchanged for <code>convergence_threshold</code> iterations (default: 3)</li> <li>Max iterations: Reached <code>max_iterations</code> (default: 100)</li> </ol> <p>Binary VSA typically converges in &lt; 10 iterations due to exact unbinding.</p>"},{"location":"api/resonator/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"api/resonator/#time-complexity","title":"Time Complexity","text":"<p>Per iteration for N factors with codebook size M and dimension D: - Unbinding: O(N \u00d7 D) - binding operations - Cleanup: O(M \u00d7 D) - dot products with codebook - Total: O(N \u00d7 M \u00d7 D) per iteration</p> <p>Typical iterations to convergence: 5-20</p>"},{"location":"api/resonator/#space-complexity","title":"Space Complexity","text":"<ul> <li>Codebooks: O(M \u00d7 D) per codebook</li> <li>Estimates: O(N \u00d7 D)</li> <li>Total: O((N + M) \u00d7 D)</li> </ul>"},{"location":"api/resonator/#recommendations","title":"Recommendations","text":"<p>Dimensionality: - Binary VSA: \u226510,000 dimensions - FHRR: \u2265512 dimensions - MAP: \u2265512 dimensions</p> <p>Codebook Size: - Works well with codebooks of 2-100 items - Larger codebooks may require more iterations</p> <p>Number of Factors: - Tested with 2-3 factors - Can handle more but convergence may slow</p>"},{"location":"api/resonator/#common-patterns","title":"Common Patterns","text":""},{"location":"api/resonator/#two-factor-factorization","title":"Two-Factor Factorization","text":"<pre><code># Encode\ncomposite = bind(a, b)\n\n# Setup codebooks\ncodebook_a = CleanupMemory([\"a1\", \"a2\", \"a3\"], memory)\ncodebook_b = CleanupMemory([\"b1\", \"b2\", \"b3\"], memory)\n\n# Factorize\nresonator = Resonator([codebook_a, codebook_b], opset)\nfactors = resonator.factorize(composite)\n</code></pre>"},{"location":"api/resonator/#three-factor-factorization","title":"Three-Factor Factorization","text":"<pre><code># Encode\ncomposite = bind(bind(a, b), c)\n\n# Setup\ncodebook_a = CleanupMemory([...], memory)\ncodebook_b = CleanupMemory([...], memory)\ncodebook_c = CleanupMemory([...], memory)\n\n# Factorize\nresonator = Resonator([codebook_a, codebook_b, codebook_c], opset)\nfactors = resonator.factorize(composite)\n</code></pre>"},{"location":"api/resonator/#batch-processing","title":"Batch Processing","text":"<pre><code>import jax.numpy as jnp\n\n# Create multiple composites\ncomposites = jnp.stack([comp1, comp2, comp3, comp4])\n\n# Batch factorize\nresults = resonator.factorize_batch(composites)\n# results[i] contains factors for composites[i]\n</code></pre>"},{"location":"api/resonator/#monitoring-convergence","title":"Monitoring Convergence","text":"<pre><code>factors, history = resonator.factorize(\n    composite,\n    return_history=True\n)\n\nprint(f\"Converged in {len(history)} iterations\")\nfor i, step in enumerate(history):\n    print(f\"Iteration {i}: {step}\")\n</code></pre>"},{"location":"api/resonator/#error-handling","title":"Error Handling","text":""},{"location":"api/resonator/#invalid-codebook","title":"Invalid Codebook","text":"<pre><code># Raises ValueError if symbol not in memory\ncleanup = CleanupMemory([\"missing_symbol\"], memory)\n# ValueError: Symbol 'missing_symbol' not found in memory\n</code></pre>"},{"location":"api/resonator/#wrong-number-of-estimates","title":"Wrong Number of Estimates","text":"<pre><code># Raises ValueError if initial estimates don't match codebook count\nresonator = Resonator([codebook1, codebook2], opset)\nfactors = resonator.factorize(composite, initial_estimates=[\"a\"])\n# ValueError: Expected 2 initial estimates, got 1\n</code></pre>"},{"location":"api/resonator/#invalid-initial-estimate","title":"Invalid Initial Estimate","text":"<pre><code># Raises ValueError if estimate not in corresponding codebook\nfactors = resonator.factorize(\n    composite,\n    initial_estimates=[\"valid\", \"not_in_codebook\"]\n)\n# ValueError: Initial estimate 'not_in_codebook' not in codebook 1\n</code></pre>"},{"location":"api/resonator/#see-also","title":"See Also","text":"<ul> <li>User Guide: Resonator Networks</li> <li>Example: Tree Search</li> <li>Paper: Frady et al. (2020)</li> </ul>"},{"location":"api/similarity/","title":"Similarity Metrics API","text":"<p>Similarity metrics for comparing hypervectors.</p>"},{"location":"api/similarity/#functions","title":"Functions","text":""},{"location":"api/similarity/#vsax.similarity.cosine_similarity","title":"<code>vsax.similarity.cosine_similarity(a, b)</code>","text":"<p>Compute cosine similarity between two hypervectors.</p> <p>Cosine similarity measures the cosine of the angle between two vectors, ranging from -1 (opposite) to 1 (identical direction). For complex vectors, uses the real part of the complex dot product.</p> <p>Works with all hypervector types: - Complex hypervectors (FHRR): Uses conjugate dot product - Real hypervectors (MAP): Standard cosine similarity - Binary hypervectors: Normalized dot product</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[AbstractHypervector, ndarray]</code> <p>First hypervector (AbstractHypervector or jnp.ndarray).</p> required <code>b</code> <code>Union[AbstractHypervector, ndarray]</code> <p>Second hypervector (AbstractHypervector or jnp.ndarray).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Cosine similarity as a float in range [-1, 1].</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If vectors have different shapes.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.similarity import cosine_similarity model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"dog\", \"cat\", \"animal\"]) similarity = cosine_similarity(memory[\"dog\"], memory[\"cat\"]) print(f\"Similarity: {similarity:.3f}\")</p>"},{"location":"api/similarity/#vsax.similarity.dot_similarity","title":"<code>vsax.similarity.dot_similarity(a, b)</code>","text":"<p>Compute dot product similarity between two hypervectors.</p> <p>The dot product provides an unnormalized similarity measure. Higher values indicate more similarity. For complex vectors, uses the real part of the complex dot product (conjugate dot product).</p> <p>Works with all hypervector types: - Complex hypervectors (FHRR): Real part of a* \u00b7 b - Real hypervectors (MAP): Standard dot product a \u00b7 b - Binary hypervectors: Dot product (count of matching bits)</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[AbstractHypervector, ndarray]</code> <p>First hypervector (AbstractHypervector or jnp.ndarray).</p> required <code>b</code> <code>Union[AbstractHypervector, ndarray]</code> <p>Second hypervector (AbstractHypervector or jnp.ndarray).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Dot product similarity as a float.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If vectors have different shapes.</p> Example <p>from vsax import create_map_model, VSAMemory from vsax.similarity import dot_similarity model = create_map_model(dim=512) memory = VSAMemory(model) memory.add_many([\"apple\", \"orange\", \"fruit\"]) similarity = dot_similarity(memory[\"apple\"], memory[\"orange\"]) print(f\"Dot product: {similarity:.3f}\")</p>"},{"location":"api/similarity/#vsax.similarity.hamming_similarity","title":"<code>vsax.similarity.hamming_similarity(a, b)</code>","text":"<p>Compute Hamming similarity between two binary hypervectors.</p> <p>Hamming similarity measures the proportion of matching bits between two binary vectors. It ranges from 0 (completely different) to 1 (identical).</p> <p>Primarily designed for binary hypervectors but works with any vector type by comparing element equality. For best results, use with bipolar {-1, +1} or binary {0, 1} vectors.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[AbstractHypervector, ndarray]</code> <p>First hypervector (AbstractHypervector or jnp.ndarray).</p> required <code>b</code> <code>Union[AbstractHypervector, ndarray]</code> <p>Second hypervector (AbstractHypervector or jnp.ndarray).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Hamming similarity as a float in range [0, 1].</p> <code>float</code> <p>1.0 means all bits match, 0.0 means no bits match.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If vectors have different shapes.</p> Example <p>from vsax import create_binary_model, VSAMemory from vsax.similarity import hamming_similarity model = create_binary_model(dim=10000, bipolar=True) memory = VSAMemory(model) memory.add_many([\"cat\", \"dog\", \"bird\"]) similarity = hamming_similarity(memory[\"cat\"], memory[\"dog\"]) print(f\"Hamming similarity: {similarity:.3f}\")</p>"},{"location":"api/utils/","title":"Utilities API","text":"<p>Utility functions for batch operations and visualization.</p>"},{"location":"api/utils/#batch-operations","title":"Batch Operations","text":""},{"location":"api/utils/#vsax.utils.vmap_bind","title":"<code>vsax.utils.vmap_bind(opset, X, Y)</code>","text":"<p>Vectorized binding of two batches of hypervectors.</p> <p>Applies the bind operation element-wise across two batches of hypervectors using JAX's vmap for efficient parallel execution on GPU/TPU.</p> <p>Parameters:</p> Name Type Description Default <code>opset</code> <code>AbstractOpSet</code> <p>The operation set defining the bind operation.</p> required <code>X</code> <code>Union[ndarray, list[ndarray]]</code> <p>First batch of hypervectors, shape (batch_size, dim).</p> required <code>Y</code> <code>Union[ndarray, list[ndarray]]</code> <p>Second batch of hypervectors, shape (batch_size, dim).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Batch of bound hypervectors, shape (batch_size, dim).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If batch sizes don't match.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.utils import vmap_bind import jax.numpy as jnp model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"a\", \"b\", \"c\", \"x\", \"y\", \"z\"])</p>"},{"location":"api/utils/#vsax.utils.vmap_bind--batch-bind-a-b-c-with-x-y-z","title":"Batch bind: [a, b, c] with [x, y, z]","text":"<p>X = jnp.stack([memory[\"a\"].vec, memory[\"b\"].vec, memory[\"c\"].vec]) Y = jnp.stack([memory[\"x\"].vec, memory[\"y\"].vec, memory[\"z\"].vec]) result = vmap_bind(model.opset, X, Y) print(result.shape)  # (3, 512)</p>"},{"location":"api/utils/#vsax.utils.vmap_bundle","title":"<code>vsax.utils.vmap_bundle(opset, X)</code>","text":"<p>Vectorized bundling across batch dimension.</p> <p>Bundles a batch of hypervectors into a single hypervector using JAX's efficient reduction operations. This is NOT element-wise - it combines all vectors in the batch into one result.</p> <p>Parameters:</p> Name Type Description Default <code>opset</code> <code>AbstractOpSet</code> <p>The operation set defining the bundle operation.</p> required <code>X</code> <code>Union[ndarray, list[ndarray]]</code> <p>Batch of hypervectors, shape (batch_size, dim).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Single bundled hypervector, shape (dim,).</p> Example <p>from vsax import create_map_model, VSAMemory from vsax.utils import vmap_bundle import jax.numpy as jnp model = create_map_model(dim=512) memory = VSAMemory(model) memory.add_many([\"red\", \"green\", \"blue\"])</p>"},{"location":"api/utils/#vsax.utils.vmap_bundle--bundle-colors-together","title":"Bundle colors together","text":"<p>colors = jnp.stack([ ...     memory[\"red\"].vec, ...     memory[\"green\"].vec, ...     memory[\"blue\"].vec ... ]) color_set = vmap_bundle(model.opset, colors) print(color_set.shape)  # (512,)</p>"},{"location":"api/utils/#vsax.utils.vmap_similarity","title":"<code>vsax.utils.vmap_similarity(similarity_fn, query, candidates)</code>","text":"<p>Vectorized similarity computation between query and multiple candidates.</p> <p>Computes similarity between a single query vector and a batch of candidate vectors using JAX's vmap for efficient parallel execution.</p> <p>Note: This function computes raw similarity scores without converting to Python floats, allowing it to work within JAX transformations.</p> <p>Parameters:</p> Name Type Description Default <code>similarity_fn</code> <code>None</code> <p>Similarity function that operates on arrays. Must accept two jnp.ndarray arguments and return a scalar.</p> required <code>query</code> <code>Union[ndarray, list[ndarray]]</code> <p>Single query hypervector, shape (dim,).</p> required <code>candidates</code> <code>Union[ndarray, list[ndarray]]</code> <p>Batch of candidate hypervectors, shape (batch_size, dim).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of similarity scores, shape (batch_size,).</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.utils import vmap_similarity import jax.numpy as jnp model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"dog\", \"cat\", \"bird\", \"animal\"])</p>"},{"location":"api/utils/#vsax.utils.vmap_similarity--define-similarity-function-that-works-on-arrays","title":"Define similarity function that works on arrays","text":"<p>def array_cosine(a, b): ...     dot = jnp.vdot(a, b) if jnp.iscomplexobj(a) else jnp.dot(a, b) ...     if jnp.iscomplexobj(a): dot = jnp.real(dot) ...     return dot / (jnp.linalg.norm(a) * jnp.linalg.norm(b) + 1e-10)</p>"},{"location":"api/utils/#vsax.utils.vmap_similarity--find-most-similar-to-animal","title":"Find most similar to \"animal\"","text":"<p>query = memory[\"animal\"].vec candidates = jnp.stack([ ...     memory[\"dog\"].vec, ...     memory[\"cat\"].vec, ...     memory[\"bird\"].vec ... ]) similarities = vmap_similarity(array_cosine, query, candidates) best_match = jnp.argmax(similarities)</p>"},{"location":"api/utils/#visualization","title":"Visualization","text":""},{"location":"api/utils/#vsax.utils.pretty_repr","title":"<code>vsax.utils.pretty_repr(hv, max_elements=5)</code>","text":"<p>Generate a pretty string representation of a hypervector.</p> <p>Creates a human-readable representation showing shape, dtype, and a sample of the vector values. Useful for debugging and interactive exploration.</p> <p>Parameters:</p> Name Type Description Default <code>hv</code> <code>Union[AbstractHypervector, ndarray]</code> <p>Hypervector to represent (AbstractHypervector or jnp.ndarray).</p> required <code>max_elements</code> <code>int</code> <p>Maximum number of elements to display (default: 5).</p> <code>5</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted string representation.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.utils import pretty_repr model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add(\"example\") print(pretty_repr(memory[\"example\"])) ComplexHypervector(dim=512, dtype=complex64) Sample: [0.123+0.456j, -0.789+0.234j, ..., 0.567-0.890j]</p>"},{"location":"api/utils/#vsax.utils.format_similarity_results","title":"<code>vsax.utils.format_similarity_results(query_name, candidate_names, similarities, top_k=5)</code>","text":"<p>Format similarity search results in a readable table.</p> <p>Parameters:</p> Name Type Description Default <code>query_name</code> <code>str</code> <p>Name of the query item.</p> required <code>candidate_names</code> <code>list[str]</code> <p>Names of candidate items.</p> required <code>similarities</code> <code>ndarray</code> <p>Array of similarity scores, shape (n_candidates,).</p> required <code>top_k</code> <code>int</code> <p>Number of top results to display (default: 5).</p> <code>5</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted table string.</p> Example <p>from vsax.utils import format_similarity_results import jax.numpy as jnp results = format_similarity_results( ...     \"dog\", ...     [\"cat\", \"wolf\", \"bird\", \"puppy\"], ...     jnp.array([0.85, 0.92, 0.23, 0.95]), ...     top_k=3 ... ) print(results) Query: dog Top 3 matches:   1. puppy    0.950   2. wolf     0.920   3. cat      0.850</p>"},{"location":"examples/binary/","title":"Binary Model Example","text":"<p>Complete example using Binary VSA with bipolar {-1, +1} hypervectors.</p>"},{"location":"examples/binary/#setup","title":"Setup","text":"<pre><code>import jax\nimport jax.numpy as jnp\nfrom vsax import VSAModel, BinaryHypervector, BinaryOperations, sample_binary_random\n\n# Create Binary model\nmodel = VSAModel(\n    dim=512,\n    rep_cls=BinaryHypervector,\n    opset=BinaryOperations(),\n    sampler=sample_binary_random\n)\n</code></pre>"},{"location":"examples/binary/#basic-operations","title":"Basic Operations","text":"<pre><code># Sample bipolar vectors\nkey = jax.random.PRNGKey(42)\nvectors = model.sampler(dim=model.dim, n=2, key=key, bipolar=True)\n\na = model.rep_cls(vectors[0], bipolar=True)\nb = model.rep_cls(vectors[1], bipolar=True)\n\n# Verify bipolar values\nprint(f\"Unique values: {jnp.unique(a.vec)}\")  # Array([-1, 1])\n\n# Bind (XOR)\nbound = model.opset.bind(a.vec, b.vec)\n\n# Unbind (exact recovery!)\nrecovered = model.opset.bind(bound, b.vec)\nprint(f\"Exact recovery: {jnp.array_equal(recovered, a.vec)}\")  # True!\n\n# Bundle (majority vote)\nbundled = model.opset.bundle(a.vec, b.vec)\n</code></pre>"},{"location":"examples/binary/#symbolic-reasoning-example","title":"Symbolic Reasoning Example","text":"<p>Encode logical facts using binary vectors.</p> <pre><code># Define symbols\nkeys = jax.random.split(key, 4)\nalice = model.sampler(dim=model.dim, n=1, key=keys[0], bipolar=True)[0]\nbob = model.sampler(dim=model.dim, n=1, key=keys[1], bipolar=True)[0]\nlikes = model.sampler(dim=model.dim, n=1, key=keys[2], bipolar=True)[0]\ncharlie = model.sampler(dim=model.dim, n=1, key=keys[3], bipolar=True)[0]\n\n# Encode: \"Alice likes Bob\"\nfact = model.opset.bind(model.opset.bind(alice, likes), bob)\n\n# Query: Who does Alice like?\nquery = model.opset.bind(fact, model.opset.bind(alice, likes))\n# High Hamming similarity to bob\n</code></pre> <p>Advantage: Binary VSA provides exact unbinding and is hardware-friendly!</p>"},{"location":"examples/fhrr/","title":"FHRR Model Example","text":"<p>Complete example using the FHRR (Fourier Holographic Reduced Representation) model with complex-valued hypervectors.</p>"},{"location":"examples/fhrr/#setup","title":"Setup","text":"<pre><code>import jax\nimport jax.numpy as jnp\nfrom vsax import VSAModel, ComplexHypervector, FHRROperations, sample_complex_random\n\n# Create FHRR model\nmodel = VSAModel(\n    dim=512,\n    rep_cls=ComplexHypervector,\n    opset=FHRROperations(),\n    sampler=sample_complex_random\n)\n</code></pre>"},{"location":"examples/fhrr/#basic-operations","title":"Basic Operations","text":""},{"location":"examples/fhrr/#sampling-and-normalization","title":"Sampling and Normalization","text":"<pre><code># Sample basis vectors\nkey = jax.random.PRNGKey(42)\nvectors = model.sampler(dim=model.dim, n=3, key=key)\n\n# Create and normalize hypervectors\na = model.rep_cls(vectors[0]).normalize()\nb = model.rep_cls(vectors[1]).normalize()\nc = model.rep_cls(vectors[2]).normalize()\n\n# Verify unit magnitude\nprint(f\"Magnitude of a: {jnp.allclose(jnp.abs(a.vec), 1.0)}\")  # True\n</code></pre>"},{"location":"examples/fhrr/#binding-circular-convolution","title":"Binding (Circular Convolution)","text":"<pre><code># Bind two vectors\nbound = model.opset.bind(a.vec, b.vec)\nbound_hv = model.rep_cls(bound).normalize()\n\nprint(f\"Bound vector shape: {bound_hv.shape}\")\nprint(f\"Is complex: {jnp.iscomplexobj(bound_hv.vec)}\")\n</code></pre>"},{"location":"examples/fhrr/#unbinding-exact-recovery","title":"Unbinding (Exact Recovery)","text":"<pre><code># Unbind to recover original\ninv_b = model.opset.inverse(b.vec)\nrecovered = model.opset.bind(bound_hv.vec, inv_b)\nrecovered_hv = model.rep_cls(recovered).normalize()\n\n# Check similarity (should be very high)\nsimilarity = jnp.abs(jnp.vdot(a.vec, recovered_hv.vec)) / model.dim\nprint(f\"Recovery similarity: {similarity:.4f}\")  # Close to 1.0\n</code></pre>"},{"location":"examples/fhrr/#bundling-superposition","title":"Bundling (Superposition)","text":"<pre><code># Bundle multiple vectors\nbundled = model.opset.bundle(a.vec, b.vec, c.vec)\nbundled_hv = model.rep_cls(bundled)\n\n# Result has unit magnitude\nprint(f\"Bundled magnitude: {jnp.allclose(jnp.abs(bundled_hv.vec), 1.0)}\")  # True\n</code></pre>"},{"location":"examples/fhrr/#role-filler-binding","title":"Role-Filler Binding","text":"<p>Encode structured data using role-filler binding.</p> <pre><code># Define roles and fillers\nkey = jax.random.PRNGKey(42)\nkeys = jax.random.split(key, 6)\n\n# Roles\nsubject_role = model.sampler(dim=model.dim, n=1, key=keys[0])[0]\nverb_role = model.sampler(dim=model.dim, n=1, key=keys[1])[0]\nobject_role = model.sampler(dim=model.dim, n=1, key=keys[2])[0]\n\n# Fillers (concepts)\ndog = model.sampler(dim=model.dim, n=1, key=keys[3])[0]\nchase = model.sampler(dim=model.dim, n=1, key=keys[4])[0]\ncat = model.sampler(dim=model.dim, n=1, key=keys[5])[0]\n\n# Encode sentence: \"The dog chased the cat\"\nsentence = model.opset.bundle(\n    model.opset.bind(subject_role, dog),\n    model.opset.bind(verb_role, chase),\n    model.opset.bind(object_role, cat)\n)\n\n# Query: What is the subject?\nquery = model.opset.bind(sentence, model.opset.inverse(subject_role))\nquery_hv = model.rep_cls(query).normalize()\ndog_hv = model.rep_cls(dog).normalize()\n\n# Similarity to \"dog\" should be high\nsimilarity = jnp.abs(jnp.vdot(query_hv.vec, dog_hv.vec)) / model.dim\nprint(f\"Subject query similarity to 'dog': {similarity:.4f}\")\n</code></pre>"},{"location":"examples/fhrr/#sequence-encoding","title":"Sequence Encoding","text":"<p>Use permutation for positional information.</p> <pre><code># Encode sequence: [A, B, C]\nsequence_keys = jax.random.split(key, 3)\nA = model.sampler(dim=model.dim, n=1, key=sequence_keys[0])[0]\nB = model.sampler(dim=model.dim, n=1, key=sequence_keys[1])[0]\nC = model.sampler(dim=model.dim, n=1, key=sequence_keys[2])[0]\n\n# Encode with positional information\nsequence = model.opset.bundle(\n    A,                              # Position 0\n    model.opset.permute(B, 1),      # Position 1\n    model.opset.permute(C, 2)       # Position 2\n)\n\n# Decode position 1\npos1_query = model.opset.permute(sequence, -1)\n# High similarity to B\n</code></pre>"},{"location":"examples/fhrr/#next-steps","title":"Next Steps","text":"<ul> <li>See MAP Example for real-valued operations</li> <li>See Binary Example for discrete operations</li> <li>Check API Reference for detailed documentation</li> </ul>"},{"location":"examples/map/","title":"MAP Model Example","text":"<p>Complete example using the MAP (Multiply-Add-Permute) model with real-valued hypervectors.</p>"},{"location":"examples/map/#setup","title":"Setup","text":"<pre><code>import jax\nimport jax.numpy as jnp\nfrom vsax import VSAModel, RealHypervector, MAPOperations, sample_random\n\n# Create MAP model\nmodel = VSAModel(\n    dim=512,\n    rep_cls=RealHypervector,\n    opset=MAPOperations(),\n    sampler=sample_random\n)\n</code></pre>"},{"location":"examples/map/#basic-operations","title":"Basic Operations","text":"<pre><code># Sample and normalize\nkey = jax.random.PRNGKey(42)\nvectors = model.sampler(dim=model.dim, n=2, key=key)\n\na = model.rep_cls(vectors[0]).normalize()\nb = model.rep_cls(vectors[1]).normalize()\n\n# Verify L2 normalization\nprint(f\"L2 norm of a: {jnp.linalg.norm(a.vec):.4f}\")  # 1.0\n\n# Bind (element-wise multiplication)\nbound = model.opset.bind(a.vec, b.vec)\n\n# Bundle (element-wise mean)\nbundled = model.opset.bundle(a.vec, b.vec)\n</code></pre>"},{"location":"examples/map/#feature-binding-example","title":"Feature Binding Example","text":"<p>Encode structured records with real-valued features.</p> <pre><code># Define feature roles\nage_role = model.sampler(dim=model.dim, n=1, key=jax.random.PRNGKey(1))[0]\nincome_role = model.sampler(dim=model.dim, n=1, key=jax.random.PRNGKey(2))[0]\n\n# Encode feature values (simplified - normally you'd use encoders)\nage_25 = model.sampler(dim=model.dim, n=1, key=jax.random.PRNGKey(3))[0]\nincome_50k = model.sampler(dim=model.dim, n=1, key=jax.random.PRNGKey(4))[0]\n\n# Create record\nrecord = model.opset.bundle(\n    model.opset.bind(age_role, age_25),\n    model.opset.bind(income_role, income_50k)\n)\n</code></pre> <p>Note: MAP unbinding is approximate - use for similarity-based retrieval rather than exact recovery.</p>"},{"location":"guide/batch_operations/","title":"Batch Operations","text":"<p>VSAX provides efficient batch operations using JAX's <code>vmap</code> for parallel processing on GPU/TPU. These operations allow you to process multiple hypervectors simultaneously.</p>"},{"location":"guide/batch_operations/#overview","title":"Overview","text":"<p>Batch operations are essential for: - Processing large datasets efficiently - Encoding multiple items at once - Parallel similarity computations - GPU/TPU acceleration</p>"},{"location":"guide/batch_operations/#core-batch-functions","title":"Core Batch Functions","text":""},{"location":"guide/batch_operations/#vmap_bind","title":"vmap_bind","text":"<p>Vectorized binding of two batches of hypervectors.</p> <pre><code>from vsax import create_fhrr_model, VSAMemory\nfrom vsax.utils import vmap_bind\nimport jax.numpy as jnp\n\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\n\n# Create nouns and verbs\nnouns = [\"dog\", \"cat\", \"bird\"]\nverbs = [\"runs\", \"jumps\", \"flies\"]\nmemory.add_many(nouns + verbs)\n\n# Batch bind nouns with verbs\nnoun_vecs = jnp.stack([memory[n].vec for n in nouns])\nverb_vecs = jnp.stack([memory[v].vec for v in verbs])\n\nactions = vmap_bind(model.opset, noun_vecs, verb_vecs)\nprint(f\"Created {actions.shape[0]} action vectors\")\n# Output: Created 3 action vectors\n</code></pre>"},{"location":"guide/batch_operations/#vmap_bundle","title":"vmap_bundle","text":"<p>Vectorized bundling of multiple hypervectors into one.</p> <pre><code>from vsax.utils import vmap_bundle\n\n# Bundle related concepts\ncolors = [\"red\", \"green\", \"blue\"]\nmemory.add_many(colors)\n\ncolor_vecs = jnp.stack([memory[c].vec for c in colors])\ncolor_concept = vmap_bundle(model.opset, color_vecs)\n\nprint(f\"Bundled concept shape: {color_concept.shape}\")\n# Output: Bundled concept shape: (512,)\n</code></pre>"},{"location":"guide/batch_operations/#vmap_similarity","title":"vmap_similarity","text":"<p>Vectorized similarity computation between a query and multiple candidates.</p> <pre><code>from vsax.utils import vmap_similarity\n\n# Find most similar color\nquery = memory[\"red\"].vec\ncandidates = jnp.stack([memory[c].vec for c in [\"green\", \"blue\", \"yellow\"]])\n\nsimilarities = vmap_similarity(None, query, candidates)\nbest_match = jnp.argmax(similarities)\nprint(f\"Most similar: {['green', 'blue', 'yellow'][int(best_match)]}\")\n</code></pre>"},{"location":"guide/batch_operations/#use-cases","title":"Use Cases","text":""},{"location":"guide/batch_operations/#1-sequential-composition","title":"1. Sequential Composition","text":"<p>Combine bind and bundle for structured encoding:</p> <pre><code># Encode multiple role-filler pairs\nroles = [\"subject\", \"verb\", \"object\"]\nfillers = [\"Alice\", \"helps\", \"Bob\"]\nmemory.add_many(roles + fillers)\n\n# Bind roles with fillers\nrole_vecs = jnp.stack([memory[r].vec for r in roles])\nfiller_vecs = jnp.stack([memory[f].vec for f in fillers])\npairs = vmap_bind(model.opset, role_vecs, filler_vecs)\n\n# Bundle into sentence\nsentence = vmap_bundle(model.opset, pairs)\nprint(f\"Sentence encoding: {sentence.shape}\")\n</code></pre>"},{"location":"guide/batch_operations/#2-batch-encoding","title":"2. Batch Encoding","text":"<p>Encode multiple items efficiently:</p> <pre><code># Encode many facts\nsubjects = [\"dog\", \"cat\", \"bird\", \"fish\"]\nactions = [\"runs\", \"sleeps\", \"flies\", \"swims\"]\nmemory.add_many(subjects + actions)\n\n# Batch encode all subject-action pairs\nsubj_vecs = jnp.stack([memory[s].vec for s in subjects])\nact_vecs = jnp.stack([memory[a].vec for a in actions])\n\nfacts = vmap_bind(model.opset, subj_vecs, act_vecs)\nprint(f\"Encoded {facts.shape[0]} facts in parallel\")\n</code></pre>"},{"location":"guide/batch_operations/#3-hierarchical-structures","title":"3. Hierarchical Structures","text":"<p>Build nested representations:</p> <pre><code># Create taxonomy\nmammals = [\"dog\", \"cat\", \"whale\"]\nbirds = [\"eagle\", \"sparrow\", \"penguin\"]\nreptiles = [\"snake\", \"lizard\"]\n\nall_animals = mammals + birds + reptiles\nmemory.add_many(all_animals)\n\n# Bundle each category\nmammal_vecs = jnp.stack([memory[m].vec for m in mammals])\nmammal_concept = vmap_bundle(model.opset, mammal_vecs)\n\nbird_vecs = jnp.stack([memory[b].vec for b in birds])\nbird_concept = vmap_bundle(model.opset, bird_vecs)\n\nreptile_vecs = jnp.stack([memory[r].vec for r in reptiles])\nreptile_concept = vmap_bundle(model.opset, reptile_vecs)\n\n# Bundle categories into higher-level concept\ncategories = jnp.stack([mammal_concept, bird_concept, reptile_concept])\nanimal_concept = vmap_bundle(model.opset, categories)\n\nprint(\"Created hierarchical animal concept\")\n</code></pre>"},{"location":"guide/batch_operations/#4-knowledge-graphs","title":"4. Knowledge Graphs","text":"<p>Encode graph structures with batch operations:</p> <pre><code># Knowledge graph: (subject, predicate, object) triples\nsubjects = [\"Alice\", \"Bob\", \"Charlie\"]\npredicates = [\"knows\", \"likes\", \"helps\"]\nobjects = [\"Bob\", \"Alice\", \"Alice\"]\n\n# Add to memory\nall_concepts = list(set(subjects + predicates + objects))\nmemory.add_many(all_concepts)\n\n# Batch encode triples\nsubj_vecs = jnp.stack([memory[s].vec for s in subjects])\npred_vecs = jnp.stack([memory[p].vec for p in predicates])\nobj_vecs = jnp.stack([memory[o].vec for o in objects])\n\n# Encode as: bind(subject, bind(predicate, object))\npred_obj = vmap_bind(model.opset, pred_vecs, obj_vecs)\ntriples = vmap_bind(model.opset, subj_vecs, pred_obj)\n\n# Bundle all triples into knowledge graph\nknowledge_graph = vmap_bundle(model.opset, triples)\nprint(f\"Knowledge graph: {knowledge_graph.shape}\")\n</code></pre>"},{"location":"guide/batch_operations/#performance-comparison","title":"Performance Comparison","text":"<p>Batch operations provide significant speedups:</p> <pre><code>import time\n\n# Individual operations (slow)\nstart = time.time()\nresults = []\nfor i in range(100):\n    result = model.opset.bind(memory[\"a\"].vec, memory[\"b\"].vec)\n    results.append(result)\nindividual_time = time.time() - start\n\n# Batch operation (fast)\nX = jnp.stack([memory[\"a\"].vec] * 100)\nY = jnp.stack([memory[\"b\"].vec] * 100)\n\nstart = time.time()\nbatch_result = vmap_bind(model.opset, X, Y)\njax.block_until_ready(batch_result)\nbatch_time = time.time() - start\n\nprint(f\"Individual: {individual_time:.4f}s\")\nprint(f\"Batch: {batch_time:.4f}s\")\nprint(f\"Speedup: {individual_time/batch_time:.1f}x\")\n</code></pre>"},{"location":"guide/batch_operations/#best-practices","title":"Best Practices","text":""},{"location":"guide/batch_operations/#1-pre-allocate-arrays","title":"1. Pre-allocate Arrays","text":"<p>Stack vectors once, reuse for multiple operations:</p> <pre><code># Good: Pre-stack\ncandidates = jnp.stack([memory[name].vec for name in names])\nfor query in queries:\n    similarities = vmap_similarity(None, query, candidates)\n\n# Bad: Re-stack every time\nfor query in queries:\n    candidates = jnp.stack([memory[name].vec for name in names])\n    similarities = vmap_similarity(None, query, candidates)\n</code></pre>"},{"location":"guide/batch_operations/#2-use-jit-compilation","title":"2. Use JIT Compilation","text":"<p>For repeated batch operations, use <code>jax.jit</code>:</p> <pre><code>@jax.jit\ndef batch_encode_facts(subjects, actions, opset):\n    pairs = vmap(opset.bind, in_axes=(0, 0))(subjects, actions)\n    return vmap_bundle(opset, pairs)\n\n# First call compiles\nresult = batch_encode_facts(subj_vecs, act_vecs, model.opset)\n\n# Subsequent calls are fast\nresult = batch_encode_facts(subj_vecs2, act_vecs2, model.opset)\n</code></pre>"},{"location":"guide/batch_operations/#3-batch-size-considerations","title":"3. Batch Size Considerations","text":"<p>For very large batches, consider chunking:</p> <pre><code>def chunk_vmap_bind(opset, X, Y, chunk_size=1000):\n    \"\"\"Process large batches in chunks.\"\"\"\n    n = X.shape[0]\n    results = []\n\n    for i in range(0, n, chunk_size):\n        chunk_X = X[i:i+chunk_size]\n        chunk_Y = Y[i:i+chunk_size]\n        chunk_result = vmap_bind(opset, chunk_X, chunk_Y)\n        results.append(chunk_result)\n\n    return jnp.concatenate(results, axis=0)\n\n# Process 10000 bindings in chunks\nlarge_X = jnp.stack([memory[\"a\"].vec] * 10000)\nlarge_Y = jnp.stack([memory[\"b\"].vec] * 10000)\nresult = chunk_vmap_bind(model.opset, large_X, large_Y)\n</code></pre>"},{"location":"guide/batch_operations/#4-gpu-memory-management","title":"4. GPU Memory Management","text":"<p>Monitor GPU memory when processing large batches:</p> <pre><code>import jax\n\n# Check available devices\nprint(f\"Devices: {jax.devices()}\")\n\n# Clear cached compilations if needed\njax.clear_caches()\n\n# Force garbage collection\nimport gc\ngc.collect()\n</code></pre>"},{"location":"guide/batch_operations/#working-with-all-vsa-models","title":"Working with All VSA Models","text":"<p>Batch operations work seamlessly across all VSA models:</p> <pre><code>from vsax import create_map_model, create_binary_model\n\nmodels = {\n    \"FHRR\": create_fhrr_model(dim=512),\n    \"MAP\": create_map_model(dim=512),\n    \"Binary\": create_binary_model(dim=10000, bipolar=True),\n}\n\nfor name, test_model in models.items():\n    mem = VSAMemory(test_model)\n    mem.add_many([\"a\", \"b\", \"c\", \"x\", \"y\", \"z\"])\n\n    X = jnp.stack([mem[\"a\"].vec, mem[\"b\"].vec, mem[\"c\"].vec])\n    Y = jnp.stack([mem[\"x\"].vec, mem[\"y\"].vec, mem[\"z\"].vec])\n\n    result = vmap_bind(test_model.opset, X, Y)\n    print(f\"{name}: {result.shape}\")\n</code></pre>"},{"location":"guide/batch_operations/#complete-example","title":"Complete Example","text":"<p>See <code>examples/batch_operations.py</code> for a comprehensive demonstration of batch processing techniques.</p>"},{"location":"guide/encoders/","title":"Encoders","text":"<p>VSAX provides 5 core encoders for converting structured data into hypervectors, plus an extensible base class for creating custom encoders.</p>"},{"location":"guide/encoders/#overview","title":"Overview","text":"<p>Encoders transform structured data (numbers, sequences, dictionaries, graphs) into hypervector representations that can be manipulated with VSA operations.</p> <p>All encoders: - Work with all 3 VSA models (FHRR, MAP, Binary) - Accept a <code>VSAModel</code> and <code>VSAMemory</code> in their constructor - Implement an <code>encode()</code> method that returns a hypervector</p>"},{"location":"guide/encoders/#core-encoders","title":"Core Encoders","text":""},{"location":"guide/encoders/#scalarencoder","title":"ScalarEncoder","text":"<p>Encodes numeric values using power encoding (for complex hypervectors) or iterated binding (for real/binary).</p> <pre><code>from vsax import create_fhrr_model, VSAMemory, ScalarEncoder\n\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\nmemory.add(\"temperature\")\n\nencoder = ScalarEncoder(model, memory, min_val=0, max_val=100)\ntemp_hv = encoder.encode(\"temperature\", 23.5)\n</code></pre> <p>Use cases: Sensor readings, measurements, ratings, scores</p>"},{"location":"guide/encoders/#sequenceencoder","title":"SequenceEncoder","text":"<p>Encodes ordered sequences (lists, tuples) using positional binding.</p> <pre><code>from vsax import SequenceEncoder\n\nmemory.add_many([\"red\", \"green\", \"blue\"])\nencoder = SequenceEncoder(model, memory)\n\n# Order matters!\nseq1 = encoder.encode([\"red\", \"green\", \"blue\"])\nseq2 = encoder.encode([\"blue\", \"green\", \"red\"])  # Different hypervector\n</code></pre> <p>Use cases: Time series, sentences, ordered lists, paths</p>"},{"location":"guide/encoders/#setencoder","title":"SetEncoder","text":"<p>Encodes unordered collections using bundling (order-invariant).</p> <pre><code>from vsax import SetEncoder\n\nmemory.add_many([\"dog\", \"cat\", \"bird\"])\nencoder = SetEncoder(model, memory)\n\n# Order doesn't matter!\nset1 = encoder.encode({\"dog\", \"cat\", \"bird\"})\nset2 = encoder.encode({\"bird\", \"dog\", \"cat\"})  # Same hypervector\n</code></pre> <p>Use cases: Tags, categories, unordered groups</p>"},{"location":"guide/encoders/#dictencoder","title":"DictEncoder","text":"<p>Encodes key-value pairs using role-filler binding.</p> <pre><code>from vsax import DictEncoder\n\nmemory.add_many([\"subject\", \"action\", \"dog\", \"run\"])\nencoder = DictEncoder(model, memory)\n\nsentence = encoder.encode({\n    \"subject\": \"dog\",\n    \"action\": \"run\"\n})\n</code></pre> <p>Use cases: Structured records, semantic frames, property-value pairs</p>"},{"location":"guide/encoders/#graphencoder","title":"GraphEncoder","text":"<p>Encodes graph structures as edge lists.</p> <pre><code>from vsax import GraphEncoder\n\nmemory.add_many([\"Alice\", \"Bob\", \"knows\", \"likes\"])\nencoder = GraphEncoder(model, memory)\n\nsocial_graph = encoder.encode([\n    (\"Alice\", \"knows\", \"Bob\"),\n    (\"Alice\", \"likes\", \"Bob\")\n])\n</code></pre> <p>Use cases: Knowledge graphs, social networks, dependency graphs</p>"},{"location":"guide/encoders/#custom-encoders","title":"Custom Encoders","text":"<p>Create custom encoders by subclassing <code>AbstractEncoder</code>:</p> <pre><code>from vsax import AbstractEncoder\n\nclass DateEncoder(AbstractEncoder):\n    def encode(self, date_obj):\n        # Your custom encoding logic\n        year_hv = self.encode_component(date_obj.year)\n        month_hv = self.encode_component(date_obj.month)\n        day_hv = self.encode_component(date_obj.day)\n\n        result = self.model.opset.bundle(year_hv, month_hv, day_hv)\n        return self.model.rep_cls(result)\n</code></pre> <p>See examples/custom_encoder.py for complete examples.</p>"},{"location":"guide/encoders/#best-practices","title":"Best Practices","text":"<ol> <li>Add symbols first: Ensure all required symbols are in memory before encoding</li> <li>Consistent dimensions: Use the same model for all related encodings</li> <li>Combine encoders: Use multiple encoders together for complex data structures</li> <li>Test with similarity: Verify encodings make sense by checking similarity between related items</li> </ol>"},{"location":"guide/encoders/#see-also","title":"See Also","text":"<ul> <li>API Reference - Encoders</li> <li>Examples - FHRR</li> <li>Examples - Custom Encoders</li> </ul>"},{"location":"guide/factory/","title":"Factory Functions: Easy Model Creation","text":"<p>Factory functions provide a simple, one-line way to create VSA models with sensible defaults. Instead of manually configuring representations, operation sets, and samplers, use factory functions for quick setup.</p>"},{"location":"guide/factory/#available-factory-functions","title":"Available Factory Functions","text":"<p>VSAX provides three factory functions, one for each VSA model type:</p> <ul> <li><code>create_fhrr_model()</code> - Complex hypervectors with FFT-based operations</li> <li><code>create_map_model()</code> - Real hypervectors with element-wise operations</li> <li><code>create_binary_model()</code> - Binary hypervectors with XOR/majority operations</li> </ul>"},{"location":"guide/factory/#create_fhrr_model","title":"create_fhrr_model","text":"<p>Create a FHRR (Fourier Holographic Reduced Representation) model.</p> <pre><code>from vsax import create_fhrr_model\n\n# Default dimension (512)\nmodel = create_fhrr_model()\n\n# Custom dimension\nmodel = create_fhrr_model(dim=1024)\n</code></pre> <p>Properties: - Uses <code>ComplexHypervector</code> (complex-valued) - Uses <code>FHRROperations</code> (FFT-based circular convolution) - Uses <code>sample_complex_random</code> (unit magnitude, random phase) - Default dimension: 512 - Unbinding: Exact (via complex conjugate)</p> <p>When to use: - Need exact unbinding - Working with sequential/temporal data - Frequency-domain representations</p>"},{"location":"guide/factory/#create_map_model","title":"create_map_model","text":"<p>Create a MAP (Multiply-Add-Permute) model.</p> <pre><code>from vsax import create_map_model\n\n# Default dimension (512)\nmodel = create_map_model()\n\n# Custom dimension\nmodel = create_map_model(dim=2048)\n</code></pre> <p>Properties: - Uses <code>RealHypervector</code> (real-valued) - Uses <code>MAPOperations</code> (element-wise multiplication/mean) - Uses <code>sample_random</code> (Gaussian distribution) - Default dimension: 512 - Unbinding: Approximate</p> <p>When to use: - Continuous feature representations - Approximate pattern matching - Lower memory footprint than complex</p>"},{"location":"guide/factory/#create_binary_model","title":"create_binary_model","text":"<p>Create a Binary VSA model.</p> <pre><code>from vsax import create_binary_model\n\n# Default dimension (10000), bipolar mode\nmodel = create_binary_model()\n\n# Custom dimension\nmodel = create_binary_model(dim=5000)\n\n# Binary mode {0, 1} instead of bipolar {-1, +1}\nmodel = create_binary_model(dim=10000, bipolar=False)\n</code></pre> <p>Properties: - Uses <code>BinaryHypervector</code> (discrete binary/bipolar) - Uses <code>BinaryOperations</code> (XOR for bind, majority for bundle) - Uses <code>sample_binary_random</code> (random bipolar or binary) - Default dimension: 10000 (higher than continuous models) - Unbinding: Exact (self-inverse property) - Default mode: Bipolar (<code>{-1, +1}</code>)</p> <p>When to use: - Need exact unbinding with minimal computation - Boolean/logical operations - Hardware-friendly representations - Very large symbol spaces (use higher dimensions)</p>"},{"location":"guide/factory/#comparison","title":"Comparison","text":"Model Type Dimension Unbinding Memory Speed FHRR Complex 512 (default) Exact Medium Medium (FFT) MAP Real 512 (default) Approximate Low Fast Binary Discrete 10000 (default) Exact Very Low Very Fast"},{"location":"guide/factory/#complete-example","title":"Complete Example","text":"<pre><code>from vsax import create_fhrr_model, create_map_model, create_binary_model, VSAMemory\nimport jax\n\n# Create all three models\nfhrr = create_fhrr_model(dim=512)\nmap_model = create_map_model(dim=512)\nbinary = create_binary_model(dim=10000, bipolar=True)\n\n# All models work with VSAMemory\nfor model in [fhrr, map_model, binary]:\n    memory = VSAMemory(model, key=jax.random.PRNGKey(42))\n    memory.add_many([\"concept1\", \"concept2\"])\n\n    # Same interface across all models\n    c1 = memory[\"concept1\"]\n    c2 = memory[\"concept2\"]\n\n    # Bind and bundle\n    bound = model.opset.bind(c1.vec, c2.vec)\n    bundled = model.opset.bundle(c1.vec, c2.vec)\n</code></pre>"},{"location":"guide/factory/#versus-manual-creation","title":"Versus Manual Creation","text":"<p>Before (v0.2.0): <pre><code>from vsax import VSAModel, ComplexHypervector, FHRROperations, sample_complex_random\n\nmodel = VSAModel(\n    dim=512,\n    rep_cls=ComplexHypervector,\n    opset=FHRROperations(),\n    sampler=sample_complex_random\n)\n</code></pre></p> <p>After (v0.3.0): <pre><code>from vsax import create_fhrr_model\n\nmodel = create_fhrr_model(dim=512)\n</code></pre></p> <p>Much simpler! Factory functions reduce boilerplate while maintaining full flexibility.</p>"},{"location":"guide/factory/#advanced-custom-models","title":"Advanced: Custom Models","text":"<p>If you need custom configurations, you can still use <code>VSAModel</code> directly:</p> <pre><code>from vsax import VSAModel, RealHypervector, MAPOperations\n\n# Custom sampler\ndef my_sampler(dim, n, key):\n    return jax.random.uniform(key, shape=(n, dim)) * 2 - 1\n\nmodel = VSAModel(\n    dim=256,\n    rep_cls=RealHypervector,\n    opset=MAPOperations(),\n    sampler=my_sampler\n)\n</code></pre> <p>But for 95% of use cases, factory functions are sufficient.</p>"},{"location":"guide/factory/#api-reference","title":"API Reference","text":"<pre><code>def create_fhrr_model(dim: int = 512, key: Optional[jax.Array] = None) -&gt; VSAModel:\n    \"\"\"Create FHRR model with complex hypervectors.\"\"\"\n\ndef create_map_model(dim: int = 512, key: Optional[jax.Array] = None) -&gt; VSAModel:\n    \"\"\"Create MAP model with real hypervectors.\"\"\"\n\ndef create_binary_model(\n    dim: int = 10000,\n    bipolar: bool = True,\n    key: Optional[jax.Array] = None\n) -&gt; VSAModel:\n    \"\"\"Create Binary model with discrete hypervectors.\"\"\"\n</code></pre>"},{"location":"guide/factory/#next-steps","title":"Next Steps","text":"<ul> <li>VSAMemory Guide - Symbol table management</li> <li>Operations Guide - Binding and bundling</li> <li>Examples - Complete working examples</li> </ul>"},{"location":"guide/gpu_usage/","title":"GPU Usage Guide","text":"<p>VSAX is built on JAX, which provides automatic GPU acceleration for all operations. This guide shows you how to leverage GPUs for maximum performance.</p>"},{"location":"guide/gpu_usage/#quick-start","title":"Quick Start","text":""},{"location":"guide/gpu_usage/#check-gpu-availability","title":"Check GPU Availability","text":"<pre><code>from vsax.utils import print_device_info, ensure_gpu\n\n# Print detailed device information\nprint_device_info()\n\n# Check if GPU is available (with warning if not)\nensure_gpu()\n</code></pre> <p>Output example: <pre><code>============================================================\nJAX Device Information\n============================================================\nDefault backend: gpu\nDevice count: 1\nGPU available: True\n\nAvailable devices:\n  [0] cuda:0\n============================================================\n</code></pre></p>"},{"location":"guide/gpu_usage/#gpu-installation","title":"GPU Installation","text":""},{"location":"guide/gpu_usage/#installing-jax-with-gpu-support","title":"Installing JAX with GPU Support","text":"<p>VSAX requires JAX with CUDA support for GPU acceleration:</p> <p>CUDA 12: <pre><code>uv add jax[cuda12]\n</code></pre></p> <p>CUDA 11: <pre><code>uv add jax[cuda11]\n</code></pre></p> <p>Verify installation: <pre><code>import jax\nprint(jax.devices())  # Should show: [cuda(id=0)]\n</code></pre></p>"},{"location":"guide/gpu_usage/#controlling-device-placement","title":"Controlling Device Placement","text":""},{"location":"guide/gpu_usage/#automatic-recommended","title":"Automatic (Recommended)","text":"<p>JAX automatically uses GPU if available:</p> <pre><code>from vsax import create_fhrr_model, VSAMemory\n\n# Automatically uses GPU if available\nmodel = create_fhrr_model(dim=1024)\nmemory = VSAMemory(model)\nmemory.add(\"test\")\n\n# Check where vectors are stored\nfrom vsax.utils import get_array_device\nprint(get_array_device(memory[\"test\"].vec))  # cuda:0\n</code></pre>"},{"location":"guide/gpu_usage/#environment-variables","title":"Environment Variables","text":"<p>Control device selection before running:</p> <pre><code># Force CPU only\nJAX_PLATFORMS=cpu python script.py\n\n# Use specific GPU\nCUDA_VISIBLE_DEVICES=0 python script.py\n\n# Use multiple GPUs\nCUDA_VISIBLE_DEVICES=0,1 python script.py\n</code></pre>"},{"location":"guide/gpu_usage/#programmatic-control","title":"Programmatic Control","text":"<p>Force specific device in code:</p> <pre><code>import jax\n\n# Force CPU\nwith jax.default_device(jax.devices('cpu')[0]):\n    model = create_fhrr_model(dim=1024)\n    # All operations run on CPU\n\n# Force specific GPU\nwith jax.default_device(jax.devices('gpu')[0]):\n    model = create_fhrr_model(dim=1024)\n    # All operations run on GPU 0\n</code></pre>"},{"location":"guide/gpu_usage/#benchmarking-performance","title":"Benchmarking Performance","text":""},{"location":"guide/gpu_usage/#single-operation-benchmark","title":"Single Operation Benchmark","text":"<pre><code>from vsax import create_fhrr_model, VSAMemory\nfrom vsax.utils import benchmark_operation\nimport jax.numpy as jnp\n\nmodel = create_fhrr_model(dim=2048)\nmemory = VSAMemory(model)\nmemory.add_many([\"a\", \"b\", \"c\"])\n\n# Define operation to benchmark\ndef bind_operation():\n    return model.opset.bind(memory[\"a\"].vec, memory[\"b\"].vec)\n\n# Benchmark on GPU\nresults = benchmark_operation(bind_operation, n_iterations=100)\nprint(f\"Mean time: {results['mean_time']*1000:.2f} ms\")\nprint(f\"Throughput: {results['throughput']:.0f} ops/sec\")\n</code></pre>"},{"location":"guide/gpu_usage/#cpu-vs-gpu-comparison","title":"CPU vs GPU Comparison","text":"<pre><code>from vsax.utils import compare_devices, print_benchmark_results\n\n# Compare devices\nresults = compare_devices(bind_operation, n_iterations=50)\n\n# Print formatted results\nprint_benchmark_results(results)\n</code></pre> <p>Output example: <pre><code>============================================================\nBenchmark Results\n============================================================\n\nCPU:\n  Device: cpu:0\n  Mean time: 2.45 ms\n  Std time: 0.12 ms\n  Throughput: 408.16 ops/sec\n\nGPU:\n  Device: cuda:0\n  Mean time: 0.23 ms\n  Std time: 0.01 ms\n  Throughput: 4347.83 ops/sec\n\nSpeedup: 10.65x (GPU vs CPU)\n============================================================\n</code></pre></p>"},{"location":"guide/gpu_usage/#gpu-optimized-operations","title":"GPU-Optimized Operations","text":"<p>All VSAX operations are GPU-accelerated through JAX:</p>"},{"location":"guide/gpu_usage/#fft-operations-fhrr","title":"FFT Operations (FHRR)","text":"<pre><code>from vsax import create_fhrr_model\n\nmodel = create_fhrr_model(dim=2048)\n# Uses cuFFT on GPU for circular convolution\n# 10-100x faster than CPU for large dimensions\n</code></pre>"},{"location":"guide/gpu_usage/#matrix-operations","title":"Matrix Operations","text":"<pre><code>from vsax.similarity import cosine_similarity\nfrom vsax.utils import vmap_similarity\n\n# Single similarity (uses cuBLAS on GPU)\nsim = cosine_similarity(vec1, vec2)\n\n# Batch similarity (parallel on GPU)\nsimilarities = vmap_similarity(query_vec, candidate_vecs)\n# GPU processes all candidates in parallel\n</code></pre>"},{"location":"guide/gpu_usage/#batch-processing","title":"Batch Processing","text":"<pre><code>from vsax.utils import vmap_bind, vmap_bundle\nimport jax.numpy as jnp\n\n# Stack vectors for batch processing\nvectors_a = jnp.stack([memory[f\"a{i}\"].vec for i in range(100)])\nvectors_b = jnp.stack([memory[f\"b{i}\"].vec for i in range(100)])\n\n# GPU-accelerated batch binding\nbound_vectors = vmap_bind(model.opset, vectors_a, vectors_b)\n# All 100 bindings computed in parallel on GPU\n</code></pre>"},{"location":"guide/gpu_usage/#performance-tips","title":"Performance Tips","text":""},{"location":"guide/gpu_usage/#1-use-larger-dimensions","title":"1. Use Larger Dimensions","text":"<p>GPUs excel with larger vector dimensions:</p> <pre><code># CPU-friendly\nsmall_model = create_fhrr_model(dim=512)   # ~5x speedup\n\n# GPU-friendly\nlarge_model = create_fhrr_model(dim=4096)  # ~20x speedup\n</code></pre>"},{"location":"guide/gpu_usage/#2-batch-operations","title":"2. Batch Operations","text":"<p>Always prefer batch operations over loops:</p> <p>\u274c Slow (sequential): <pre><code>results = []\nfor vec in vectors:\n    result = model.opset.bind(query, vec)\n    results.append(result)\n</code></pre></p> <p>\u2705 Fast (parallel on GPU): <pre><code>results = vmap_bind(model.opset, jnp.broadcast_to(query, (len(vectors), query.shape[0])), vectors)\n</code></pre></p>"},{"location":"guide/gpu_usage/#3-jit-compilation","title":"3. JIT Compilation","text":"<p>JAX automatically JIT-compiles operations. For custom functions:</p> <pre><code>import jax\n\n@jax.jit\ndef custom_operation(a, b, c):\n    \"\"\"Custom VSA operation.\"\"\"\n    bound = model.opset.bind(a, b)\n    return model.opset.bundle(bound, c)\n\n# First call compiles (slow)\nresult1 = custom_operation(vec_a, vec_b, vec_c)\n\n# Subsequent calls use compiled version (fast)\nresult2 = custom_operation(vec_d, vec_e, vec_f)\n</code></pre>"},{"location":"guide/gpu_usage/#4-warmup-iterations","title":"4. Warmup Iterations","text":"<p>First GPU operation includes initialization overhead:</p> <pre><code># Warmup\n_ = model.opset.bind(memory[\"a\"].vec, memory[\"b\"].vec)\n\n# Now benchmark\nresults = benchmark_operation(bind_operation)\n</code></pre>"},{"location":"guide/gpu_usage/#monitoring-gpu-usage","title":"Monitoring GPU Usage","text":""},{"location":"guide/gpu_usage/#in-python","title":"In Python","text":"<pre><code>from vsax.utils import get_device_info\n\ninfo = get_device_info()\nif info['gpu_available']:\n    print(f\"Using GPU: {info['devices'][0]}\")\nelse:\n    print(\"Using CPU\")\n</code></pre>"},{"location":"guide/gpu_usage/#external-monitoring","title":"External Monitoring","text":"<p>Monitor GPU utilization in real-time:</p> <pre><code># NVIDIA GPUs\nwatch -n 1 nvidia-smi\n\n# Or continuously\nnvidia-smi -l 1\n</code></pre>"},{"location":"guide/gpu_usage/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guide/gpu_usage/#gpu-not-detected","title":"GPU Not Detected","text":"<p>Problem: <code>gpu_available: False</code></p> <p>Solutions: 1. Install JAX with GPU support: <code>uv add jax[cuda12]</code> 2. Check CUDA installation: <code>nvidia-smi</code> 3. Verify CUDA version matches JAX version 4. Check <code>LD_LIBRARY_PATH</code> includes CUDA libraries</p>"},{"location":"guide/gpu_usage/#out-of-memory-errors","title":"Out of Memory Errors","text":"<p>Problem: <code>RuntimeError: CUDA out of memory</code></p> <p>Solutions: 1. Reduce dimension: <code>dim=1024</code> instead of <code>dim=8192</code> 2. Reduce batch size 3. Clear JAX cache: <code>jax.clear_caches()</code> 4. Use CPU for prototyping: <code>JAX_PLATFORMS=cpu</code></p>"},{"location":"guide/gpu_usage/#slow-first-iteration","title":"Slow First Iteration","text":"<p>Problem: First operation is very slow</p> <p>Explanation: JAX compiles operations on first use (XLA compilation)</p> <p>Solution: Add warmup iterations: <pre><code># Warmup\nfor _ in range(3):\n    _ = operation()\n\n# Now measure\nresults = benchmark_operation(operation)\n</code></pre></p>"},{"location":"guide/gpu_usage/#performance-comparison","title":"Performance Comparison","text":"<p>Typical speedups for common operations (GPU vs CPU):</p> Operation Dimension CPU Time GPU Time Speedup FHRR Bind 512 0.8 ms 0.15 ms 5.3x FHRR Bind 2048 3.2 ms 0.25 ms 12.8x FHRR Bind 8192 15.1 ms 0.45 ms 33.6x Batch Bind (100) 1024 82 ms 3.2 ms 25.6x Similarity (1000) 1024 45 ms 1.8 ms 25.0x <p>Benchmarked on: Intel i7-10700K (CPU) vs NVIDIA RTX 3080 (GPU)</p>"},{"location":"guide/gpu_usage/#see-also","title":"See Also","text":"<ul> <li>JAX GPU Installation Guide</li> <li>Batch Operations Guide</li> <li>MNIST Tutorial - Includes GPU benchmarking</li> <li>API Reference: Device Utilities</li> </ul>"},{"location":"guide/memory/","title":"VSAMemory: Symbol Table Management","text":"<p>VSAMemory provides a dictionary-style interface for creating and managing named hypervectors (basis symbols). It acts as a symbol table that automatically samples and stores hypervectors for symbolic concepts.</p>"},{"location":"guide/memory/#overview","title":"Overview","text":"<p>VSAMemory simplifies working with VSA models by:</p> <ul> <li>Automatic sampling: Creates hypervectors on-demand when you add symbols</li> <li>Dictionary-style access: Use familiar <code>memory[\"symbol\"]</code> syntax</li> <li>Reproducibility: Optional PRNG key for deterministic sampling</li> <li>Model-agnostic: Works with FHRR, MAP, and Binary models</li> </ul>"},{"location":"guide/memory/#basic-usage","title":"Basic Usage","text":""},{"location":"guide/memory/#creating-memory","title":"Creating Memory","text":"<pre><code>from vsax import create_fhrr_model, VSAMemory\n\n# Create a model\nmodel = create_fhrr_model(dim=512)\n\n# Create memory (with optional key for reproducibility)\nmemory = VSAMemory(model, key=jax.random.PRNGKey(42))\n</code></pre>"},{"location":"guide/memory/#adding-symbols","title":"Adding Symbols","text":"<pre><code># Add a single symbol\ndog = memory.add(\"dog\")\n\n# Add multiple symbols\nmemory.add_many([\"cat\", \"bird\", \"fish\"])\n\n# Adding duplicate returns the same hypervector\ndog2 = memory.add(\"dog\")  # Same as dog\nassert jnp.array_equal(dog.vec, dog2.vec)\n</code></pre>"},{"location":"guide/memory/#accessing-symbols","title":"Accessing Symbols","text":"<pre><code># Dictionary-style access\ndog = memory[\"dog\"]\ncat = memory[\"cat\"]\n\n# Check if symbol exists\nif \"dog\" in memory:\n    print(\"Dog is in memory\")\n\n# Get all symbol names\nsymbols = memory.keys()  # ['dog', 'cat', 'bird', 'fish']\n\n# Number of symbols\ncount = len(memory)  # 4\n</code></pre>"},{"location":"guide/memory/#using-symbols","title":"Using Symbols","text":"<pre><code># Get the underlying vector\ndog_vec = memory[\"dog\"].vec\n\n# Bind two concepts\ndog_is_animal = model.opset.bind(memory[\"dog\"].vec, memory[\"animal\"].vec)\n\n# Bundle multiple concepts\npets = model.opset.bundle(\n    memory[\"dog\"].vec,\n    memory[\"cat\"].vec,\n    memory[\"bird\"].vec\n)\n</code></pre>"},{"location":"guide/memory/#clearing-memory","title":"Clearing Memory","text":"<pre><code># Remove all symbols\nmemory.clear()\nassert len(memory) == 0\n</code></pre>"},{"location":"guide/memory/#complete-example-role-filler-binding","title":"Complete Example: Role-Filler Binding","text":"<pre><code>import jax\nfrom vsax import create_fhrr_model, VSAMemory\n\n# Create FHRR model and memory\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model, key=jax.random.PRNGKey(42))\n\n# Add roles and fillers\nmemory.add_many([\"subject\", \"predicate\", \"object\"])\nmemory.add_many([\"dog\", \"chases\", \"cat\"])\n\n# Create sentence: \"dog chases cat\"\nsubject_dog = model.opset.bind(\n    memory[\"subject\"].vec,\n    memory[\"dog\"].vec\n)\n\npredicate_chases = model.opset.bind(\n    memory[\"predicate\"].vec,\n    memory[\"chases\"].vec\n)\n\nobject_cat = model.opset.bind(\n    memory[\"object\"].vec,\n    memory[\"cat\"].vec\n)\n\n# Bundle into sentence representation\nsentence = model.opset.bundle(subject_dog, predicate_chases, object_cat)\n</code></pre>"},{"location":"guide/memory/#reproducibility","title":"Reproducibility","text":"<p>Use a PRNG key for deterministic symbol generation:</p> <pre><code>import jax\n\nkey = jax.random.PRNGKey(42)\n\n# Two memories with same key produce identical symbols\nmemory1 = VSAMemory(create_fhrr_model(dim=512), key=key)\nmemory2 = VSAMemory(create_fhrr_model(dim=512), key=key)\n\ndog1 = memory1.add(\"dog\")\ndog2 = memory2.add(\"dog\")\n\nassert jnp.array_equal(dog1.vec, dog2.vec)  # Identical\n</code></pre>"},{"location":"guide/memory/#working-with-different-models","title":"Working with Different Models","text":"<p>VSAMemory works identically across all model types:</p>"},{"location":"guide/memory/#fhrr-model","title":"FHRR Model","text":"<pre><code>fhrr = create_fhrr_model(dim=512)\nmemory = VSAMemory(fhrr)\ndog = memory.add(\"dog\")\n# dog.vec is complex-valued\n</code></pre>"},{"location":"guide/memory/#map-model","title":"MAP Model","text":"<pre><code>map_model = create_map_model(dim=512)\nmemory = VSAMemory(map_model)\nfeature = memory.add(\"feature\")\n# feature.vec is real-valued\n</code></pre>"},{"location":"guide/memory/#binary-model","title":"Binary Model","text":"<pre><code>binary = create_binary_model(dim=10000, bipolar=True)\nmemory = VSAMemory(binary)\nconcept = memory.add(\"concept\")\n# concept.vec is bipolar {-1, +1}\n</code></pre>"},{"location":"guide/memory/#api-reference","title":"API Reference","text":""},{"location":"guide/memory/#vsamemory-class","title":"VSAMemory Class","text":"<pre><code>class VSAMemory:\n    def __init__(self, model: VSAModel, key: Optional[jax.Array] = None):\n        \"\"\"Initialize VSAMemory with a model.\"\"\"\n\n    def add(self, name: str) -&gt; AbstractHypervector:\n        \"\"\"Add a symbol and return its hypervector.\"\"\"\n\n    def add_many(self, names: Iterable[str]) -&gt; List[AbstractHypervector]:\n        \"\"\"Add multiple symbols at once.\"\"\"\n\n    def get(self, name: str) -&gt; AbstractHypervector:\n        \"\"\"Get a hypervector by name (raises KeyError if missing).\"\"\"\n\n    def __getitem__(self, name: str) -&gt; AbstractHypervector:\n        \"\"\"Dictionary-style access: memory[\"dog\"]\"\"\"\n\n    def __contains__(self, name: str) -&gt; bool:\n        \"\"\"Check if symbol exists: \"dog\" in memory\"\"\"\n\n    def keys(self) -&gt; List[str]:\n        \"\"\"Get all symbol names.\"\"\"\n\n    def clear(self) -&gt; None:\n        \"\"\"Remove all symbols.\"\"\"\n\n    def __len__(self) -&gt; int:\n        \"\"\"Number of stored symbols.\"\"\"\n</code></pre>"},{"location":"guide/memory/#best-practices","title":"Best Practices","text":"<ol> <li>Use factory functions: Create models with <code>create_fhrr_model()</code>, <code>create_map_model()</code>, or <code>create_binary_model()</code></li> <li>Add symbols upfront: Add all symbols at once with <code>add_many()</code> for consistency</li> <li>Use keys for reproducibility: Pass a PRNG key when reproducibility matters</li> <li>Access vectors explicitly: Use <code>.vec</code> to get the underlying array for operations</li> </ol>"},{"location":"guide/memory/#next-steps","title":"Next Steps","text":"<ul> <li>Factory Functions - Easy model creation</li> <li>Operations Guide - Binding and bundling operations</li> <li>Examples - Complete working examples</li> </ul>"},{"location":"guide/models/","title":"VSA Models","text":"<p>The <code>VSAModel</code> is an immutable container that defines a complete VSA algebra by combining a representation type, operation set, and sampler.</p>"},{"location":"guide/models/#vsamodel-structure","title":"VSAModel Structure","text":"<pre><code>@dataclass(frozen=True)\nclass VSAModel:\n    dim: int                          # Dimensionality\n    rep_cls: type[AbstractHypervector]  # Representation class\n    opset: AbstractOpSet              # Operation set\n    sampler: Callable                 # Sampling function\n</code></pre>"},{"location":"guide/models/#creating-models","title":"Creating Models","text":""},{"location":"guide/models/#fhrr-model","title":"FHRR Model","text":"<pre><code>from vsax import VSAModel, ComplexHypervector, FHRROperations, sample_complex_random\n\nfhrr_model = VSAModel(\n    dim=512,\n    rep_cls=ComplexHypervector,\n    opset=FHRROperations(),\n    sampler=sample_complex_random\n)\n</code></pre>"},{"location":"guide/models/#map-model","title":"MAP Model","text":"<pre><code>from vsax import RealHypervector, MAPOperations, sample_random\n\nmap_model = VSAModel(\n    dim=512,\n    rep_cls=RealHypervector,\n    opset=MAPOperations(),\n    sampler=sample_random\n)\n</code></pre>"},{"location":"guide/models/#binary-model","title":"Binary Model","text":"<pre><code>from vsax import BinaryHypervector, BinaryOperations, sample_binary_random\n\nbinary_model = VSAModel(\n    dim=512,\n    rep_cls=BinaryHypervector,\n    opset=BinaryOperations(),\n    sampler=sample_binary_random\n)\n</code></pre>"},{"location":"guide/models/#using-models","title":"Using Models","text":"<pre><code>import jax\n\n# Sample basis vectors\nkey = jax.random.PRNGKey(42)\nvectors = fhrr_model.sampler(dim=fhrr_model.dim, n=2, key=key)\n\n# Create hypervectors using model's representation\na = fhrr_model.rep_cls(vectors[0]).normalize()\nb = fhrr_model.rep_cls(vectors[1]).normalize()\n\n# Perform operations using model's opset\nbound = fhrr_model.opset.bind(a.vec, b.vec)\nbundled = fhrr_model.opset.bundle(a.vec, b.vec)\n</code></pre>"},{"location":"guide/models/#model-properties","title":"Model Properties","text":"<p>Immutability: Models are frozen dataclasses - cannot be modified after creation.</p> <pre><code>model = VSAModel(dim=512, ...)\n\n# This will raise an error\nmodel.dim = 1024  # FrozenInstanceError!\n</code></pre> <p>Type Safety: The model ensures all components work together correctly.</p>"},{"location":"guide/models/#next-vsamemory","title":"Next: VSAMemory","text":"<p>Use <code>VSAMemory</code> to manage named basis vectors:</p> <pre><code>from vsax import VSAMemory\n\nmemory = VSAMemory(model)\nmemory.add(\"dog\")\nmemory.add(\"cat\")\n\ndog = memory[\"dog\"]  # Access by name\n</code></pre> <p>See the VSAMemory guide for more details.</p>"},{"location":"guide/models/#next-steps","title":"Next Steps","text":"<ul> <li>See Examples for complete model usage</li> <li>Check API Reference for detailed documentation</li> </ul>"},{"location":"guide/operations/","title":"VSA Operations","text":"<p>VSA operations define how hypervectors are combined and manipulated. VSAX provides three operation sets, each corresponding to a representation type.</p>"},{"location":"guide/operations/#overview","title":"Overview","text":"<p>All operation sets implement the <code>AbstractOpSet</code> interface with four core operations:</p> Operation Purpose Example <code>bind(a, b)</code> Combine/associate two vectors Role-filler binding <code>bundle(*vecs)</code> Superposition of multiple vectors Create composite representations <code>inverse(a)</code> Compute inverse for unbinding Retrieve bound information <code>permute(a, shift)</code> Circular shift/rotation Sequential encoding"},{"location":"guide/operations/#fhrroperations","title":"FHRROperations","text":"<p>Operations for complex-valued hypervectors using FFT-based circular convolution.</p>"},{"location":"guide/operations/#binding-circular-convolution","title":"Binding (Circular Convolution)","text":"<p>Binds two complex vectors using circular convolution implemented via FFT.</p> <pre><code>from vsax import FHRROperations\nimport jax.numpy as jnp\n\nops = FHRROperations()\n\n# Create unit-magnitude complex vectors\na = jnp.exp(1j * jnp.array([0.1, 0.5, 1.0, 1.5]))\nb = jnp.exp(1j * jnp.array([0.2, 0.6, 1.1, 1.6]))\n\n# Bind via circular convolution\nbound = ops.bind(a, b)\n\n# Result is also complex\nassert jnp.iscomplexobj(bound)\n</code></pre> <p>Properties: - Commutative: <code>bind(a, b) = bind(b, a)</code> - Associative: <code>bind(a, bind(b, c)) = bind(bind(a, b), c)</code> - Invertible: Can recover <code>a</code> from <code>bind(a, b)</code> using <code>inverse(b)</code></p>"},{"location":"guide/operations/#bundling-sum-and-normalize","title":"Bundling (Sum and Normalize)","text":"<p>Bundles multiple vectors by summing and normalizing to unit magnitude.</p> <pre><code># Bundle three vectors\nbundled = ops.bundle(a, b, c)\n\n# All elements have unit magnitude\nassert jnp.allclose(jnp.abs(bundled), 1.0)\n</code></pre> <p>Properties: - Similarity preserving: Bundled vector is similar to constituents - Approximate: Some information loss occurs - Commutative: Order doesn't matter</p>"},{"location":"guide/operations/#inverse-complex-conjugate","title":"Inverse (Complex Conjugate)","text":"<p>For complex vectors, the inverse is the complex conjugate.</p> <pre><code># Unbind to recover original\ninv_b = ops.inverse(b)\nrecovered = ops.bind(bound, inv_b)\n\n# recovered \u2248 a (with high similarity)\n</code></pre>"},{"location":"guide/operations/#example-role-filler-binding","title":"Example: Role-Filler Binding","text":"<pre><code># Represent \"The dog chased the cat\"\nsubject = jnp.exp(1j * jax.random.uniform(key1, (512,)))\nverb = jnp.exp(1j * jax.random.uniform(key2, (512,)))\nobject_ = jnp.exp(1j * jax.random.uniform(key3, (512,)))\n\ndog = jnp.exp(1j * jax.random.uniform(key4, (512,)))\nchase = jnp.exp(1j * jax.random.uniform(key5, (512,)))\ncat = jnp.exp(1j * jax.random.uniform(key6, (512,)))\n\n# Create sentence representation\nsentence = ops.bundle(\n    ops.bind(subject, dog),\n    ops.bind(verb, chase),\n    ops.bind(object_, cat)\n)\n\n# Query: What was the subject?\nquery = ops.bind(sentence, ops.inverse(subject))\n# query \u2248 dog (high similarity)\n</code></pre>"},{"location":"guide/operations/#mapoperations","title":"MAPOperations","text":"<p>Operations for real-valued hypervectors using element-wise operations.</p>"},{"location":"guide/operations/#binding-element-wise-multiplication","title":"Binding (Element-wise Multiplication)","text":"<p>Simplest binding operation - just multiply element-wise.</p> <pre><code>from vsax import MAPOperations\n\nops = MAPOperations()\n\n# Real vectors\na = jax.random.normal(key1, (512,))\nb = jax.random.normal(key2, (512,))\n\n# Bind via multiplication\nbound = ops.bind(a, b)\nassert bound.shape == a.shape\nassert jnp.array_equal(bound, a * b)\n</code></pre> <p>Properties: - Commutative: <code>bind(a, b) = bind(b, a)</code> - Associative: <code>bind(a, bind(b, c)) = bind(bind(a, b), c)</code> - Approximate unbinding: Cannot perfectly recover original</p>"},{"location":"guide/operations/#bundling-element-wise-mean","title":"Bundling (Element-wise Mean)","text":"<p>Average of all input vectors.</p> <pre><code># Bundle three vectors\nbundled = ops.bundle(a, b, c)\n\n# Result is the mean\nassert jnp.allclose(bundled, (a + b + c) / 3)\n</code></pre> <p>Properties: - Order-independent - Lossy: Individual vectors cannot be perfectly recovered - Preserves similarity: Bundled vector similar to constituents</p>"},{"location":"guide/operations/#inverse-approximate","title":"Inverse (Approximate)","text":"<p>MAP uses an approximate inverse based on normalization.</p> <pre><code># Approximate inverse\ninv_b = ops.inverse(b)\n\n# Unbinding is approximate\nrecovered = ops.bind(bound, inv_b)\n# recovered \u2248 a (but not exact)\n</code></pre> <p>Note: MAP unbinding is approximate - use for applications where exact recovery isn't critical.</p>"},{"location":"guide/operations/#example-feature-binding","title":"Example: Feature Binding","text":"<pre><code># Represent a data point: {age: 25, income: 50000, city: \"SF\"}\nage_role = jax.random.normal(key1, (512,))\nincome_role = jax.random.normal(key2, (512,))\ncity_role = jax.random.normal(key3, (512,))\n\nage_25 = jax.random.normal(key4, (512,))\nincome_50k = jax.random.normal(key5, (512,))\nsf = jax.random.normal(key6, (512,))\n\n# Create record\nrecord = ops.bundle(\n    ops.bind(age_role, age_25),\n    ops.bind(income_role, income_50k),\n    ops.bind(city_role, sf)\n)\n</code></pre>"},{"location":"guide/operations/#binaryoperations","title":"BinaryOperations","text":"<p>Operations for binary hypervectors using XOR and majority voting.</p>"},{"location":"guide/operations/#binding-xor","title":"Binding (XOR)","text":"<p>In bipolar {-1, +1} representation, XOR is implemented as multiplication.</p> <pre><code>from vsax import BinaryOperations\n\nops = BinaryOperations()\n\n# Bipolar vectors\na = jnp.array([1, -1, 1, -1, 1, 1, -1, -1])\nb = jnp.array([1, 1, -1, -1, 1, -1, 1, -1])\n\n# Bind via XOR (multiplication in bipolar)\nbound = ops.bind(a, b)\n\n# Result: element-wise multiplication\n# Same values \u2192 +1, different values \u2192 -1\n</code></pre> <p>Properties: - Commutative: <code>bind(a, b) = bind(b, a)</code> - Associative: <code>bind(a, bind(b, c)) = bind(bind(a, b), c)</code> - Self-inverse: <code>bind(bind(a, b), b) = a</code> (exact unbinding!)</p>"},{"location":"guide/operations/#bundling-majority-vote","title":"Bundling (Majority Vote)","text":"<p>Each position in the bundled vector is determined by majority vote.</p> <pre><code>a = jnp.array([1, -1, 1, -1])\nb = jnp.array([1, 1, -1, -1])\nc = jnp.array([1, 1, 1, 1])\n\nbundled = ops.bundle(a, b, c)\n\n# Position 0: [1, 1, 1] \u2192 majority 1\n# Position 1: [-1, 1, 1] \u2192 majority 1\n# Position 2: [1, -1, 1] \u2192 majority 1\n# Position 3: [-1, -1, 1] \u2192 majority -1\n# Result: [1, 1, 1, -1]\n</code></pre> <p>Tie Breaking: For even numbers of vectors, ties default to +1.</p>"},{"location":"guide/operations/#inverse-self-inverse","title":"Inverse (Self-Inverse)","text":"<p>XOR is its own inverse, so <code>inverse(a) = a</code>.</p> <pre><code># Exact unbinding\ninv_b = ops.inverse(b)  # inv_b == b\nrecovered = ops.bind(bound, inv_b)\nassert jnp.array_equal(recovered, a)  # Exact recovery!\n</code></pre>"},{"location":"guide/operations/#example-symbolic-reasoning","title":"Example: Symbolic Reasoning","text":"<pre><code># Encode facts: \"Alice likes Bob\", \"Bob likes Charlie\"\nalice = jax.random.choice(key1, jnp.array([-1, 1]), (512,))\nbob = jax.random.choice(key2, jnp.array([-1, 1]), (512,))\ncharlie = jax.random.choice(key3, jnp.array([-1, 1]), (512,))\nlikes = jax.random.choice(key4, jnp.array([-1, 1]), (512,))\n\n# Create knowledge base\nfact1 = ops.bind(ops.bind(alice, likes), bob)\nfact2 = ops.bind(ops.bind(bob, likes), charlie)\nkb = ops.bundle(fact1, fact2)\n\n# Query: Who does Alice like?\nquery = ops.bind(ops.bind(kb, alice), likes)\n# High similarity to bob\n</code></pre>"},{"location":"guide/operations/#permutation","title":"Permutation","text":"<p>All operation sets support circular permutation (rotation).</p> <pre><code>vec = jnp.array([1, 2, 3, 4, 5])\n\n# Rotate right by 2\nshifted = ops.permute(vec, 2)\n# Result: [4, 5, 1, 2, 3]\n\n# Rotate left by 2\nshifted = ops.permute(vec, -2)\n# Result: [3, 4, 5, 1, 2]\n</code></pre> <p>Use cases: - Sequence encoding - Temporal ordering - Positional information</p>"},{"location":"guide/operations/#comparison","title":"Comparison","text":"Feature FHRR MAP Binary Binding FFT convolution Element-wise \u00d7 XOR Unbinding Exact (conjugate) Approximate Exact (self-inverse) Bundling Sum + normalize Mean Majority vote Complexity O(n log n) O(n) O(n) Memory 2x (complex) 1x 1/32x"},{"location":"guide/operations/#best-practices","title":"Best Practices","text":"<ol> <li>Normalize inputs: Ensure vectors are properly normalized before operations</li> <li>Consistent types: Don't mix operation sets with wrong representations</li> <li>Batch operations: Use JAX's <code>vmap</code> for processing multiple vectors</li> <li>Numerical stability: Be aware of numerical precision, especially with FHRR</li> </ol>"},{"location":"guide/operations/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Sampling to create basis vectors</li> <li>See Models to combine representations and operations</li> <li>Check Examples for complete workflows</li> </ul>"},{"location":"guide/persistence/","title":"Persistence: Saving and Loading Basis Vectors","text":"<p>VSAX provides simple JSON-based persistence for saving and loading basis vectors. This enables you to:</p> <ul> <li>Preserve semantic spaces across sessions</li> <li>Share vocabularies between projects</li> <li>Version control your basis vectors</li> <li>Reproduce experiments with exact same vectors</li> </ul>"},{"location":"guide/persistence/#quick-start","title":"Quick Start","text":"<pre><code>from vsax import create_fhrr_model, VSAMemory, save_basis, load_basis\n\n# Create and populate memory\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\nmemory.add_many([\"dog\", \"cat\", \"animal\", \"pet\"])\n\n# Save to JSON\nsave_basis(memory, \"animals.json\")\n\n# Later: Load into new memory\nnew_memory = VSAMemory(model)\nload_basis(new_memory, \"animals.json\")\n\n# Vectors are preserved exactly\nassert \"dog\" in new_memory\n</code></pre>"},{"location":"guide/persistence/#saving-basis-vectors","title":"Saving Basis Vectors","text":""},{"location":"guide/persistence/#basic-usage","title":"Basic Usage","text":"<pre><code>from pathlib import Path\nfrom vsax import save_basis\n\n# Save with Path object\nsave_basis(memory, Path(\"my_basis.json\"))\n\n# Or with string path\nsave_basis(memory, \"my_basis.json\")\n</code></pre>"},{"location":"guide/persistence/#what-gets-saved","title":"What Gets Saved?","text":"<p>The JSON file contains:</p> <ol> <li>Metadata: Dimension, representation type, vector count</li> <li>Vectors: All named vectors in the memory</li> </ol> <p>Example JSON structure for FHRR (complex) vectors:</p> <pre><code>{\n  \"metadata\": {\n    \"dim\": 512,\n    \"rep_type\": \"complex\",\n    \"num_vectors\": 3\n  },\n  \"vectors\": {\n    \"dog\": {\n      \"real\": [0.12, -0.34, ...],\n      \"imag\": [0.56, 0.78, ...]\n    },\n    \"cat\": {\n      \"real\": [-0.45, 0.23, ...],\n      \"imag\": [0.11, -0.67, ...]\n    }\n  }\n}\n</code></pre>"},{"location":"guide/persistence/#all-three-models-supported","title":"All Three Models Supported","text":"<p>FHRR (Complex Vectors): - Stored as separate real and imaginary parts - JSON keys: <code>\"real\"</code> and <code>\"imag\"</code></p> <p>MAP (Real Vectors): - Stored as simple float arrays - Direct list representation</p> <p>Binary (Bipolar Vectors): - Stored as integer arrays (-1, +1 or 0, 1) - Compact representation</p> <pre><code># Each model saves differently\nfhrr_model = create_fhrr_model(dim=512)\nmap_model = create_map_model(dim=512)\nbinary_model = create_binary_model(dim=10000, bipolar=True)\n\nmemory_fhrr = VSAMemory(fhrr_model)\nmemory_map = VSAMemory(map_model)\nmemory_binary = VSAMemory(binary_model)\n\n# All use same API\nsave_basis(memory_fhrr, \"fhrr.json\")\nsave_basis(memory_map, \"map.json\")\nsave_basis(memory_binary, \"binary.json\")\n</code></pre>"},{"location":"guide/persistence/#loading-basis-vectors","title":"Loading Basis Vectors","text":""},{"location":"guide/persistence/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from vsax import load_basis\n\n# Create empty memory with correct model\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\n\n# Load from file\nload_basis(memory, \"my_basis.json\")\n\n# Memory is now populated\nprint(f\"Loaded {len(memory._vectors)} vectors\")\n</code></pre>"},{"location":"guide/persistence/#requirements","title":"Requirements","text":"<ol> <li>Empty Memory: Memory must be empty before loading</li> <li>Matching Dimension: File dimension must match memory's model dimension</li> <li>Matching Type: File rep_type must match memory's model type</li> </ol>"},{"location":"guide/persistence/#error-handling","title":"Error Handling","text":"<pre><code># Dimension mismatch\nmodel_128 = create_fhrr_model(dim=128)\nmodel_256 = create_fhrr_model(dim=256)\n\nmemory_128 = VSAMemory(model_128)\nmemory_128.add(\"test\")\nsave_basis(memory_128, \"test.json\")\n\nmemory_256 = VSAMemory(model_256)\ntry:\n    load_basis(memory_256, \"test.json\")  # \u274c Dimension mismatch!\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n\n# Representation type mismatch\nfhrr_memory = VSAMemory(create_fhrr_model(dim=128))\nfhrr_memory.add(\"test\")\nsave_basis(fhrr_memory, \"test.json\")\n\nmap_memory = VSAMemory(create_map_model(dim=128))\ntry:\n    load_basis(map_memory, \"test.json\")  # \u274c Type mismatch!\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n\n# Non-empty memory\nmemory = VSAMemory(create_fhrr_model(dim=128))\nmemory.add(\"existing\")\ntry:\n    load_basis(memory, \"test.json\")  # \u274c Memory not empty!\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n</code></pre>"},{"location":"guide/persistence/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guide/persistence/#1-persistent-semantic-spaces","title":"1. Persistent Semantic Spaces","text":"<p>Build a knowledge base once, reuse it across sessions:</p> <pre><code># Session 1: Build semantic space\nmodel = create_fhrr_model(dim=1024)\nmemory = VSAMemory(model)\n\n# Add domain vocabulary\nmemory.add_many([\n    \"entity1\", \"entity2\", \"relation1\", \"relation2\",\n    \"attribute1\", \"attribute2\", ...\n])\n\n# Create complex structures\nentity_with_attr = model.opset.bind(\n    memory[\"entity1\"].vec,\n    memory[\"attribute1\"].vec\n)\n\n# Save for later\nsave_basis(memory, \"knowledge_base.json\")\n\n# Session 2: Load and use\nmemory_new = VSAMemory(model)\nload_basis(memory_new, \"knowledge_base.json\")\n\n# All symbols available immediately\nentity = memory_new[\"entity1\"]\n</code></pre>"},{"location":"guide/persistence/#2-sharing-vocabularies","title":"2. Sharing Vocabularies","text":"<p>Share exact basis vectors between projects or team members:</p> <pre><code># Project A: Create shared vocabulary\nmodel = create_map_model(dim=512)\nmemory = VSAMemory(model)\nmemory.add_many([\"term1\", \"term2\", \"term3\", ...])\nsave_basis(memory, \"shared_vocab.json\")\n\n# Project B: Use same vocabulary\nmodel_b = create_map_model(dim=512)  # Same dim!\nmemory_b = VSAMemory(model_b)\nload_basis(memory_b, \"shared_vocab.json\")\n\n# Projects now use identical basis\n</code></pre>"},{"location":"guide/persistence/#3-reproducible-research","title":"3. Reproducible Research","text":"<p>Version control your basis vectors for reproducible experiments:</p> <pre><code># Save basis with experiment\ngit add experiment_basis.json\ngit commit -m \"Add basis for experiment 1\"\n\n# Others can reproduce exact results\ngit clone repo\npython experiment.py  # Loads experiment_basis.json\n</code></pre>"},{"location":"guide/persistence/#4-incremental-development","title":"4. Incremental Development","text":"<p>Save progress and resume later:</p> <pre><code># Day 1: Initial setup\nmemory = VSAMemory(create_fhrr_model(dim=512))\nmemory.add_many([\"concept1\", \"concept2\", ...])\nsave_basis(memory, \"progress.json\")\n\n# Day 2: Resume and extend\nmemory = VSAMemory(create_fhrr_model(dim=512))\nload_basis(memory, \"progress.json\")\nmemory.add_many([\"concept3\", \"concept4\", ...])  # Add more\nsave_basis(memory, \"progress.json\")  # Overwrite\n</code></pre>"},{"location":"guide/persistence/#best-practices","title":"Best Practices","text":""},{"location":"guide/persistence/#file-organization","title":"File Organization","text":"<pre><code>project/\n\u251c\u2500\u2500 basis/\n\u2502   \u251c\u2500\u2500 entities.json      # Entity vectors\n\u2502   \u251c\u2500\u2500 relations.json     # Relation vectors\n\u2502   \u2514\u2500\u2500 attributes.json    # Attribute vectors\n\u251c\u2500\u2500 experiments/\n\u2502   \u251c\u2500\u2500 exp1_basis.json\n\u2502   \u2514\u2500\u2500 exp2_basis.json\n\u2514\u2500\u2500 shared/\n    \u2514\u2500\u2500 common_vocab.json\n</code></pre>"},{"location":"guide/persistence/#naming-conventions","title":"Naming Conventions","text":"<pre><code># Descriptive filenames\nsave_basis(memory, \"medical_terms_512d_fhrr.json\")\nsave_basis(memory, \"colors_256d_map.json\")\nsave_basis(memory, \"code_symbols_10k_binary.json\")\n</code></pre>"},{"location":"guide/persistence/#version-control","title":"Version Control","text":"<pre><code># Include dimension and date in filename\nfrom datetime import datetime\n\ndate_str = datetime.now().strftime(\"%Y%m%d\")\nfilename = f\"basis_{model.dim}d_{date_str}.json\"\nsave_basis(memory, filename)\n</code></pre>"},{"location":"guide/persistence/#testing","title":"Testing","text":"<pre><code>import jax.numpy as jnp\n\n# Always verify round-trip\nsave_basis(memory_original, \"test.json\")\nload_basis(memory_loaded, \"test.json\")\n\nfor name in memory_original._vectors:\n    vec1 = memory_original[name].vec\n    vec2 = memory_loaded[name].vec\n    assert jnp.allclose(vec1, vec2, atol=1e-6)\n</code></pre>"},{"location":"guide/persistence/#performance-considerations","title":"Performance Considerations","text":""},{"location":"guide/persistence/#file-size","title":"File Size","text":"<ul> <li>FHRR: 2\u00d7 vector dimension (real + imag parts)</li> <li>MAP: 1\u00d7 vector dimension (real values)</li> <li>Binary: 1\u00d7 vector dimension (integers)</li> </ul> <p>Approximate sizes for 100 vectors:</p> Model Dim File Size FHRR 512 ~500 KB MAP 512 ~250 KB Binary 10,000 ~2 MB"},{"location":"guide/persistence/#load-time","title":"Load Time","text":"<p>Loading is fast (typically &lt; 100ms for typical sizes):</p> <pre><code>import time\n\nstart = time.time()\nload_basis(memory, \"large_basis.json\")\nelapsed = time.time() - start\nprint(f\"Loaded in {elapsed*1000:.1f}ms\")\n</code></pre>"},{"location":"guide/persistence/#large-vocabularies","title":"Large Vocabularies","text":"<p>For very large vocabularies (1000s of vectors):</p> <pre><code># Consider splitting into multiple files\nsave_basis(entities_memory, \"entities.json\")\nsave_basis(relations_memory, \"relations.json\")\nsave_basis(attributes_memory, \"attributes.json\")\n\n# Load only what you need\nmemory = VSAMemory(model)\nload_basis(memory, \"entities.json\")  # Load just entities\n</code></pre>"},{"location":"guide/persistence/#troubleshooting","title":"Troubleshooting","text":"<p>File not found? <pre><code>from pathlib import Path\n\npath = Path(\"my_basis.json\")\nif not path.exists():\n    print(f\"File not found: {path.absolute()}\")\n</code></pre></p> <p>Wrong dimension? <pre><code># Check file metadata first\nimport json\nwith open(\"basis.json\") as f:\n    data = json.load(f)\n    print(f\"File dimension: {data['metadata']['dim']}\")\n    print(f\"File type: {data['metadata']['rep_type']}\")\n</code></pre></p> <p>Corrupted JSON? <pre><code>try:\n    load_basis(memory, \"basis.json\")\nexcept json.JSONDecodeError:\n    print(\"JSON file is corrupted\")\n</code></pre></p>"},{"location":"guide/persistence/#see-also","title":"See Also","text":"<ul> <li>API Reference: I/O - Complete API documentation</li> <li>Examples: persistence.py - Full working example</li> <li>VSAMemory Guide - Memory management</li> </ul>"},{"location":"guide/representations/","title":"Hypervector Representations","text":"<p>VSAX provides three hypervector representations, each designed for a specific VSA algebra. All representations inherit from <code>AbstractHypervector</code> and provide a consistent interface.</p>"},{"location":"guide/representations/#overview","title":"Overview","text":"Representation Values Use Case Operations <code>ComplexHypervector</code> Complex unit-magnitude FHRR (Fourier) Circular convolution <code>RealHypervector</code> Real continuous MAP Element-wise multiply <code>BinaryHypervector</code> Bipolar {-1,+1} or Binary {0,1} Binary VSA XOR, majority vote"},{"location":"guide/representations/#complexhypervector","title":"ComplexHypervector","text":"<p>Phase-based representation using complex numbers for FHRR (Fourier Holographic Reduced Representation).</p>"},{"location":"guide/representations/#features","title":"Features","text":"<ul> <li>Unit magnitude: All elements have magnitude 1.0</li> <li>Phase encoding: Information stored in phase (angle)</li> <li>Exact unbinding: Circular convolution is invertible via conjugate</li> <li>GPU-friendly: Leverages JAX's complex number support</li> </ul>"},{"location":"guide/representations/#example","title":"Example","text":"<pre><code>import jax\nimport jax.numpy as jnp\nfrom vsax import ComplexHypervector, sample_complex_random\n\n# Sample a complex vector\nkey = jax.random.PRNGKey(42)\nvec = sample_complex_random(dim=512, n=1, key=key)[0]\n\n# Create hypervector\nhv = ComplexHypervector(vec)\n\n# Normalize to unit magnitude (phase-only)\nnormalized = hv.normalize()\n\n# Access properties\nprint(f\"Phase: {hv.phase}\")           # Angles in [-\u03c0, \u03c0]\nprint(f\"Magnitude: {hv.magnitude}\")    # All should be ~1.0\nprint(f\"Shape: {hv.shape}\")            # (512,)\n</code></pre>"},{"location":"guide/representations/#properties","title":"Properties","text":"<ul> <li><code>phase</code>: Extract phase component (angles)</li> <li><code>magnitude</code>: Extract magnitude component</li> <li><code>vec</code>: Underlying JAX array</li> <li><code>shape</code>: Vector shape</li> <li><code>dtype</code>: Data type (complex64 or complex128)</li> </ul>"},{"location":"guide/representations/#methods","title":"Methods","text":"<ul> <li><code>normalize()</code>: Normalize to unit magnitude (phase-only representation)</li> <li><code>to_numpy()</code>: Convert to NumPy array</li> </ul>"},{"location":"guide/representations/#realhypervector","title":"RealHypervector","text":"<p>Continuous real-valued representation for MAP (Multiply-Add-Permute) operations.</p>"},{"location":"guide/representations/#features_1","title":"Features","text":"<ul> <li>L2 normalization: Vectors normalized to unit length</li> <li>Continuous values: Real-valued elements</li> <li>Approximate unbinding: MAP unbinding is approximate, not exact</li> <li>Simple operations: Element-wise multiplication and mean</li> </ul>"},{"location":"guide/representations/#example_1","title":"Example","text":"<pre><code>from vsax import RealHypervector, sample_random\n\n# Sample a real vector\nkey = jax.random.PRNGKey(42)\nvec = sample_random(dim=512, n=1, key=key)[0]\n\n# Create hypervector\nhv = RealHypervector(vec)\n\n# L2 normalize\nnormalized = hv.normalize()\n\n# Properties\nprint(f\"L2 norm: {jnp.linalg.norm(normalized.vec)}\")  # Should be 1.0\nprint(f\"Is complex: {jnp.iscomplexobj(hv.vec)}\")      # False\n</code></pre>"},{"location":"guide/representations/#methods_1","title":"Methods","text":"<ul> <li><code>normalize()</code>: L2 normalization to unit length</li> <li><code>to_numpy()</code>: Convert to NumPy array</li> </ul>"},{"location":"guide/representations/#binaryhypervector","title":"BinaryHypervector","text":"<p>Discrete binary representation for Binary VSA with XOR binding.</p>"},{"location":"guide/representations/#features_2","title":"Features","text":"<ul> <li>Exact unbinding: XOR is self-inverse</li> <li>Two modes: Bipolar {-1, +1} or Binary {0, 1}</li> <li>Hardware-friendly: Efficient for digital hardware</li> <li>Majority voting: Robust bundling via majority vote</li> </ul>"},{"location":"guide/representations/#example_2","title":"Example","text":"<pre><code>from vsax import BinaryHypervector, sample_binary_random\n\n# Sample bipolar vectors\nkey = jax.random.PRNGKey(42)\nvec = sample_binary_random(dim=512, n=1, key=key, bipolar=True)[0]\n\n# Create bipolar hypervector\nhv = BinaryHypervector(vec, bipolar=True)\n\n# Check mode\nprint(f\"Is bipolar: {hv.bipolar}\")  # True\n\n# Convert between representations\nbinary_hv = hv.to_binary()      # Convert to {0, 1}\nbipolar_hv = binary_hv.to_bipolar()  # Convert back to {-1, +1}\n\n# Verify values\nprint(f\"Values: {jnp.unique(hv.vec)}\")  # Array([-1, 1])\n</code></pre>"},{"location":"guide/representations/#conversion","title":"Conversion","text":"<pre><code># Bipolar {-1, +1} to Binary {0, 1}\n# Formula: (x + 1) / 2\n# Example: -1 \u2192 0, +1 \u2192 1\n\n# Binary {0, 1} to Bipolar {-1, +1}\n# Formula: 2*x - 1\n# Example: 0 \u2192 -1, 1 \u2192 +1\n</code></pre>"},{"location":"guide/representations/#properties_1","title":"Properties","text":"<ul> <li><code>bipolar</code>: Check if using bipolar encoding</li> <li><code>vec</code>: Underlying JAX array</li> <li><code>shape</code>: Vector shape</li> <li><code>dtype</code>: Data type (typically int32)</li> </ul>"},{"location":"guide/representations/#methods_2","title":"Methods","text":"<ul> <li><code>normalize()</code>: No-op for binary (already normalized)</li> <li><code>to_bipolar()</code>: Convert to {-1, +1} representation</li> <li><code>to_binary()</code>: Convert to {0, 1} representation</li> <li><code>to_numpy()</code>: Convert to NumPy array</li> </ul>"},{"location":"guide/representations/#common-interface","title":"Common Interface","text":"<p>All representations share a common interface via <code>AbstractHypervector</code>:</p> <pre><code>class AbstractHypervector:\n    @property\n    def vec(self) -&gt; jnp.ndarray:\n        \"\"\"Access underlying JAX array\"\"\"\n\n    @property\n    def shape(self) -&gt; tuple[int, ...]:\n        \"\"\"Vector shape\"\"\"\n\n    @property\n    def dtype(self):\n        \"\"\"Data type\"\"\"\n\n    def normalize(self) -&gt; \"AbstractHypervector\":\n        \"\"\"Normalize the hypervector\"\"\"\n\n    def to_numpy(self) -&gt; np.ndarray:\n        \"\"\"Convert to NumPy array\"\"\"\n</code></pre>"},{"location":"guide/representations/#choosing-a-representation","title":"Choosing a Representation","text":"<p>Use ComplexHypervector when: - You need exact unbinding - Working with sequences or structured data - GPU acceleration is available - Circular convolution is suitable for your task</p> <p>Use RealHypervector when: - You have continuous-valued data - Approximate unbinding is acceptable - Simple operations are preferred - Working with embeddings or features</p> <p>Use BinaryHypervector when: - Deploying to hardware (FPGA, ASIC) - Memory constraints are tight - You need exact unbinding - Working with symbolic/discrete data</p>"},{"location":"guide/representations/#performance-considerations","title":"Performance Considerations","text":"Representation Memory Computation Unbinding Complex 2x (real+imag) FFT overhead Exact Real 1x Fast multiply/add Approximate Binary 1/32x (int vs float) Fastest Exact"},{"location":"guide/representations/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Operations for each representation</li> <li>See Examples for complete workflows</li> <li>Check API Reference for detailed docs</li> </ul>"},{"location":"guide/resonator/","title":"Resonator Networks","text":"<p>Resonator networks solve the factorization problem in Vector Symbolic Architectures: given a composite vector formed by binding multiple factors, recover the original factors.</p> <p>This implementation is based on:</p> <p>Frady, E. P., Kleyko, D., &amp; Sommer, F. T. (2020). A Theory of Sequence Indexing and Working Memory in Recurrent Neural Networks. Neural Computation.</p>"},{"location":"guide/resonator/#the-factorization-problem","title":"The Factorization Problem","text":""},{"location":"guide/resonator/#problem-statement","title":"Problem Statement","text":"<p>Given a composite vector: <pre><code>s = a \u2299 b \u2299 c\n</code></pre></p> <p>Where <code>a</code>, <code>b</code>, <code>c</code> are vectors from known codebooks <code>A</code>, <code>B</code>, <code>C</code>, find the specific vectors that were bound together.</p>"},{"location":"guide/resonator/#why-its-hard","title":"Why It's Hard","text":"<ul> <li>Superposition: After binding, the composite is a new vector that doesn't obviously contain the factors</li> <li>Search space: With codebooks of size N, there are N\u00b3 possible combinations for 3 factors</li> <li>Noise: Binding isn't always perfectly reversible (especially for MAP model)</li> </ul>"},{"location":"guide/resonator/#the-solution-resonator-networks","title":"The Solution: Resonator Networks","text":"<p>Resonator networks use an iterative algorithm that alternates between: 1. Unbinding: Remove current estimates of other factors 2. Cleanup: Project result onto codebook (find nearest clean vector)</p> <p>The algorithm converges to the correct factors through resonance - mutual reinforcement of consistent estimates.</p>"},{"location":"guide/resonator/#quick-start","title":"Quick Start","text":""},{"location":"guide/resonator/#basic-two-factor-factorization","title":"Basic Two-Factor Factorization","text":"<pre><code>from vsax import create_binary_model, VSAMemory\nfrom vsax.resonator import CleanupMemory, Resonator\n\n# Create model and memory\nmodel = create_binary_model(dim=10000, bipolar=True)\nmemory = VSAMemory(model)\nmemory.add_many([\"red\", \"blue\", \"circle\", \"square\"])\n\n# Create composite: red \u2299 circle\ncomposite = model.opset.bind(\n    memory[\"red\"].vec,\n    memory[\"circle\"].vec\n)\n\n# Create codebooks for each factor position\ncolors = CleanupMemory([\"red\", \"blue\"], memory)\nshapes = CleanupMemory([\"circle\", \"square\"], memory)\n\n# Factorize!\nresonator = Resonator([colors, shapes], model.opset)\nfactors = resonator.factorize(composite)\n\nprint(factors)  # [\"red\", \"circle\"]\n</code></pre>"},{"location":"guide/resonator/#three-factor-factorization","title":"Three-Factor Factorization","text":"<pre><code># Add size attribute\nmemory.add_many([\"large\", \"small\"])\n\n# Create composite: red \u2299 circle \u2299 large\ncomposite = model.opset.bind(\n    model.opset.bind(memory[\"red\"].vec, memory[\"circle\"].vec),\n    memory[\"large\"].vec\n)\n\n# Create codebooks\ncolors = CleanupMemory([\"red\", \"blue\"], memory)\nshapes = CleanupMemory([\"circle\", \"square\"], memory)\nsizes = CleanupMemory([\"large\", \"small\"], memory)\n\n# Factorize with three factors\nresonator = Resonator([colors, shapes, sizes], model.opset)\nfactors = resonator.factorize(composite)\n\nprint(factors)  # [\"red\", \"circle\", \"large\"]\n</code></pre>"},{"location":"guide/resonator/#core-components","title":"Core Components","text":""},{"location":"guide/resonator/#cleanupmemory","title":"CleanupMemory","text":"<p><code>CleanupMemory</code> implements codebook projection - finding the nearest vector from a set of known vectors.</p>"},{"location":"guide/resonator/#creating-a-cleanup-memory","title":"Creating a Cleanup Memory","text":"<pre><code>from vsax.resonator import CleanupMemory\n\n# Define codebook symbols\ncolors = CleanupMemory([\"red\", \"blue\", \"green\"], memory)\n\n# With similarity threshold\ncolors = CleanupMemory(\n    [\"red\", \"blue\", \"green\"],\n    memory,\n    threshold=0.5  # Return None if similarity &lt; 0.5\n)\n</code></pre>"},{"location":"guide/resonator/#querying","title":"Querying","text":"<pre><code># Simple query\nresult = colors.query(noisy_vector)\nprint(result)  # \"red\"\n\n# With similarity score\nresult, similarity = colors.query(noisy_vector, return_similarity=True)\nprint(f\"{result}: {similarity:.3f}\")\n\n# Top-k matches\ntop_3 = colors.query_top_k(noisy_vector, k=3)\nfor symbol, sim in top_3:\n    print(f\"{symbol}: {sim:.3f}\")\n</code></pre>"},{"location":"guide/resonator/#how-it-works","title":"How It Works","text":"<p>For binary/bipolar vectors, cleanup uses dot product similarity: <pre><code>similarities = codebook_matrix @ query_vector\nbest_idx = argmax(similarities)\n</code></pre></p> <p>This is equivalent to the projection operation from the paper: <code>g(XX^T v)</code></p>"},{"location":"guide/resonator/#resonator","title":"Resonator","text":"<p><code>Resonator</code> implements the iterative factorization algorithm.</p>"},{"location":"guide/resonator/#creating-a-resonator","title":"Creating a Resonator","text":"<pre><code>from vsax.resonator import Resonator\n\nresonator = Resonator(\n    codebooks=[colors, shapes, sizes],  # One per factor\n    opset=model.opset,                  # Defines bind/unbind\n    max_iterations=100,                 # Stop after N iterations\n    convergence_threshold=3             # Stop if stable for N iterations\n)\n</code></pre>"},{"location":"guide/resonator/#factorization","title":"Factorization","text":"<pre><code># Basic factorization\nfactors = resonator.factorize(composite)\n\n# With initial estimates (optional)\nfactors = resonator.factorize(\n    composite,\n    initial_estimates=[\"red\", \"circle\", \"large\"]\n)\n\n# Get convergence history\nfactors, history = resonator.factorize(composite, return_history=True)\nprint(f\"Converged in {len(history)} iterations\")\nfor i, step in enumerate(history):\n    print(f\"  Iteration {i}: {step}\")\n\n# Batch factorization\nimport jax.numpy as jnp\ncomposites = jnp.stack([comp1, comp2, comp3])\nall_factors = resonator.factorize_batch(composites)\n</code></pre>"},{"location":"guide/resonator/#the-algorithm","title":"The Algorithm","text":""},{"location":"guide/resonator/#resonance-equations","title":"Resonance Equations","text":"<p>For a 3-factor composite <code>s = a \u2299 b \u2299 c</code>, the resonator updates are:</p> <pre><code>\u00e2(t+1) = cleanup_A(s \u2299 inv(b\u0302(t)) \u2299 inv(\u0109(t)))\nb\u0302(t+1) = cleanup_B(s \u2299 inv(\u00e2(t)) \u2299 inv(\u0109(t)))\n\u0109(t+1) = cleanup_C(s \u2299 inv(\u00e2(t)) \u2299 inv(b\u0302(t)))\n</code></pre> <p>Where: - <code>\u00e2, b\u0302, \u0109</code> are current estimates - <code>cleanup_X</code> projects onto codebook X - <code>inv(\u00b7)</code> is the unbinding operation</p>"},{"location":"guide/resonator/#initialization","title":"Initialization","text":"<p>On the first iteration (when estimates are None), the algorithm uses superposition initialization: <pre><code>superposition = sum(all_vectors_in_codebook)\n</code></pre></p> <p>This gives the algorithm information about all possible factors simultaneously.</p>"},{"location":"guide/resonator/#convergence","title":"Convergence","text":"<p>The algorithm stops when: 1. Estimates don't change for <code>convergence_threshold</code> iterations (default: 3), OR 2. <code>max_iterations</code> is reached (default: 100)</p> <p>For binary VSA with exact unbinding, convergence is typically very fast (&lt; 10 iterations).</p>"},{"location":"guide/resonator/#best-practices","title":"Best Practices","text":""},{"location":"guide/resonator/#model-selection","title":"Model Selection","text":"<p>Binary VSA (Recommended for Resonator) - \u2705 Exact unbinding (self-inverse property) - \u2705 Fast convergence - \u2705 High accuracy - \u26a0\ufe0f Requires high dimensionality (\u226510,000)</p> <pre><code>model = create_binary_model(dim=10000, bipolar=True)\n</code></pre> <p>FHRR (Complex) - \u2705 Exact unbinding (complex conjugate) - \u2705 Lower dimensionality needed (\u2265512) - \u26a0\ufe0f More complex operations</p> <pre><code>model = create_fhrr_model(dim=512)\n</code></pre> <p>MAP (Real) - \u26a0\ufe0f Approximate unbinding - \u26a0\ufe0f May require more iterations - \u2705 Simple operations</p> <pre><code>model = create_map_model(dim=512)\n</code></pre>"},{"location":"guide/resonator/#codebook-design","title":"Codebook Design","text":"<p>Separate Semantic Spaces <pre><code># Good: Codebooks represent different semantic categories\ncolors = CleanupMemory([\"red\", \"blue\", \"green\"], memory)\nshapes = CleanupMemory([\"circle\", \"square\"], memory)\nsizes = CleanupMemory([\"large\", \"small\"], memory)\n</code></pre></p> <p>Avoid Overlap <pre><code># Bad: Same symbols in multiple codebooks creates ambiguity\ncodebook1 = CleanupMemory([\"red\", \"blue\"], memory)\ncodebook2 = CleanupMemory([\"red\", \"green\"], memory)  # \"red\" appears twice!\n</code></pre></p> <p>Balanced Sizes <pre><code># Codebooks don't need to be the same size\ncolors = CleanupMemory([\"red\", \"blue\", \"green\", \"yellow\"], memory)  # 4 items\nshapes = CleanupMemory([\"circle\", \"square\"], memory)                # 2 items\n</code></pre></p>"},{"location":"guide/resonator/#performance-tips","title":"Performance Tips","text":"<p>Use Binary Model for Best Performance <pre><code># Binary VSA is fastest and most accurate for resonator\nmodel = create_binary_model(dim=10000, bipolar=True)\n</code></pre></p> <p>Batch Processing <pre><code># Process multiple composites efficiently\ncomposites = jnp.stack([c1, c2, c3, c4])\nresults = resonator.factorize_batch(composites)\n</code></pre></p> <p>Monitor Convergence <pre><code># Check if convergence is too slow\nfactors, history = resonator.factorize(composite, return_history=True)\nif len(history) &gt; 50:\n    print(\"Warning: Slow convergence, may need higher dimensionality\")\n</code></pre></p>"},{"location":"guide/resonator/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guide/resonator/#structured-data-decoding","title":"Structured Data Decoding","text":"<p>Decode attribute-value structures: <pre><code># Encode: object \u2299 color \u2299 shape \u2299 size\nobjects = [\"obj1\", \"obj2\", \"obj3\"]\ncolors = [\"red\", \"blue\", \"green\"]\nshapes = [\"circle\", \"square\", \"triangle\"]\nsizes = [\"large\", \"small\"]\n\n# ... factorize to recover attributes\n</code></pre></p>"},{"location":"guide/resonator/#sequence-indexing","title":"Sequence Indexing","text":"<p>Recover elements from indexed sequences: <pre><code># Encode: item \u2299 position\n# Example: \"apple\" \u2299 position_1 \u2299 \"banana\" \u2299 position_2\n</code></pre></p>"},{"location":"guide/resonator/#tree-decoding","title":"Tree Decoding","text":"<p>Decode hierarchical tree structures: <pre><code># Encode: parent \u2299 left_child \u2299 right_child\n# See examples/resonator_tree_search.py for details\n</code></pre></p>"},{"location":"guide/resonator/#graph-structure-recovery","title":"Graph Structure Recovery","text":"<p>Decode graph edges: <pre><code># Encode: edge \u2299 source_node \u2299 target_node\n</code></pre></p>"},{"location":"guide/resonator/#advanced-topics","title":"Advanced Topics","text":""},{"location":"guide/resonator/#custom-convergence-criteria","title":"Custom Convergence Criteria","text":"<pre><code>class CustomResonator(Resonator):\n    def factorize(self, composite, **kwargs):\n        # Custom convergence logic\n        # Check similarity scores, add early stopping, etc.\n        ...\n</code></pre>"},{"location":"guide/resonator/#hierarchical-factorization","title":"Hierarchical Factorization","text":"<p>For nested structures, factorize recursively: <pre><code># First level: Get high-level factors\nfactors_L1 = resonator_L1.factorize(composite)\n\n# Second level: Factorize one of the factors\nfactors_L2 = resonator_L2.factorize(factors_L1[0])\n</code></pre></p>"},{"location":"guide/resonator/#error-analysis","title":"Error Analysis","text":"<pre><code># Check which factors are uncertain\nfactors, history = resonator.factorize(composite, return_history=True)\n\n# Look for oscillation (indicates ambiguity)\nfor i in range(len(history) - 5):\n    if history[i] == history[i + 4]:\n        print(f\"Factor {i} may be ambiguous\")\n</code></pre>"},{"location":"guide/resonator/#examples","title":"Examples","text":"<p>See <code>examples/resonator_tree_search.py</code> for complete working examples:</p> <ol> <li>Simple tree decoding - Basic two-factor case</li> <li>Multiple trees - Decoding different structures</li> <li>Convergence history - Monitoring the iterative process</li> <li>Nested trees - Hierarchical structures</li> <li>Batch processing - Multiple composites at once</li> <li>Error correction - Robustness to noise</li> </ol>"},{"location":"guide/resonator/#references","title":"References","text":"<ul> <li>Frady, E. P., Kleyko, D., &amp; Sommer, F. T. (2020). A Theory of Sequence Indexing and Working Memory in Recurrent Neural Networks. Neural Computation.</li> <li>Plate, T. A. (1995). Holographic reduced representations. IEEE Transactions on Neural Networks.</li> <li>Kanerva, P. (2009). Hyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. Cognitive Computation.</li> </ul>"},{"location":"guide/sampling/","title":"Sampling Hypervectors","text":"<p>VSAX provides sampling functions to generate random basis hypervectors for each representation type.</p>"},{"location":"guide/sampling/#overview","title":"Overview","text":"Function Output Distribution Use With <code>sample_random</code> Real vectors Normal N(0,1) RealHypervector, MAP <code>sample_complex_random</code> Complex vectors Uniform phase ComplexHypervector, FHRR <code>sample_binary_random</code> Binary vectors Uniform {-1,+1} or {0,1} BinaryHypervector, Binary"},{"location":"guide/sampling/#sample_random","title":"sample_random","text":"<p>Samples real-valued vectors from standard normal distribution.</p> <pre><code>from vsax.sampling import sample_random\nimport jax\n\nkey = jax.random.PRNGKey(42)\nvectors = sample_random(dim=512, n=10, key=key)\n\n# Shape: (10, 512)\n# Elements: drawn from N(0, 1)\n</code></pre> <p>Parameters: - <code>dim</code>: Vector dimensionality - <code>n</code>: Number of vectors to sample - <code>key</code>: JAX random key (optional, defaults to PRNGKey(0))</p>"},{"location":"guide/sampling/#sample_complex_random","title":"sample_complex_random","text":"<p>Samples unit-magnitude complex vectors with uniformly random phases.</p> <pre><code>from vsax.sampling import sample_complex_random\n\nkey = jax.random.PRNGKey(42)\nvectors = sample_complex_random(dim=512, n=10, key=key)\n\n# All magnitudes are 1.0\nassert jnp.allclose(jnp.abs(vectors), 1.0)\n\n# Phases uniformly distributed in [0, 2\u03c0)\nphases = jnp.angle(vectors)\n</code></pre> <p>Properties: - All elements have magnitude 1.0 - Phases uniformly distributed in [0, 2\u03c0) - Suitable for FHRR operations</p>"},{"location":"guide/sampling/#sample_binary_random","title":"sample_binary_random","text":"<p>Samples binary vectors with values from {-1, +1} (bipolar) or {0, 1} (binary).</p> <pre><code>from vsax.sampling import sample_binary_random\n\nkey = jax.random.PRNGKey(42)\n\n# Bipolar sampling (default)\nbipolar_vecs = sample_binary_random(dim=512, n=10, key=key, bipolar=True)\nassert jnp.all(jnp.isin(bipolar_vecs, jnp.array([-1, 1])))\n\n# Binary sampling\nbinary_vecs = sample_binary_random(dim=512, n=10, key=key, bipolar=False)\nassert jnp.all(jnp.isin(binary_vecs, jnp.array([0, 1])))\n</code></pre> <p>Parameters: - <code>dim</code>: Vector dimensionality - <code>n</code>: Number of vectors to sample - <code>key</code>: JAX random key (optional) - <code>bipolar</code>: If True, sample from {-1, +1}; if False, sample from {0, 1}</p>"},{"location":"guide/sampling/#reproducibility","title":"Reproducibility","text":"<p>Use JAX's PRNG system for reproducible sampling:</p> <pre><code># Same key = same samples\nkey = jax.random.PRNGKey(42)\nsamples1 = sample_random(dim=100, n=5, key=key)\nsamples2 = sample_random(dim=100, n=5, key=key)\nassert jnp.array_equal(samples1, samples2)\n\n# Different keys = different samples\nkey2 = jax.random.PRNGKey(43)\nsamples3 = sample_random(dim=100, n=5, key=key2)\nassert not jnp.array_equal(samples1, samples3)\n</code></pre>"},{"location":"guide/sampling/#complete-example","title":"Complete Example","text":"<pre><code>import jax\nfrom vsax import VSAModel, ComplexHypervector, FHRROperations, sample_complex_random\n\n# Create model with sampler\nmodel = VSAModel(\n    dim=512,\n    rep_cls=ComplexHypervector,\n    opset=FHRROperations(),\n    sampler=sample_complex_random\n)\n\n# Use model's sampler\nkey = jax.random.PRNGKey(42)\nbasis_vectors = model.sampler(dim=model.dim, n=100, key=key)\n\n# Create hypervectors\nhvs = [model.rep_cls(vec).normalize() for vec in basis_vectors]\n</code></pre>"},{"location":"guide/sampling/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Models to combine samplers with representations</li> <li>See Examples for complete workflows</li> </ul>"},{"location":"guide/similarity/","title":"Similarity Metrics","text":"<p>Similarity metrics allow you to compare hypervectors and find related concepts. VSAX provides three main similarity functions that work across all VSA models (FHRR, MAP, Binary).</p>"},{"location":"guide/similarity/#available-metrics","title":"Available Metrics","text":""},{"location":"guide/similarity/#cosine-similarity","title":"Cosine Similarity","text":"<p>Cosine similarity measures the cosine of the angle between two vectors, ranging from -1 (opposite) to 1 (identical direction).</p> <pre><code>from vsax import create_fhrr_model, VSAMemory\nfrom vsax.similarity import cosine_similarity\n\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\nmemory.add_many([\"dog\", \"cat\", \"wolf\"])\n\n# Compare similarity\nsim_dog_cat = cosine_similarity(memory[\"dog\"], memory[\"cat\"])\nsim_dog_wolf = cosine_similarity(memory[\"dog\"], memory[\"wolf\"])\n\nprint(f\"Dog-Cat similarity: {sim_dog_cat:.3f}\")\nprint(f\"Dog-Wolf similarity: {sim_dog_wolf:.3f}\")\n</code></pre> <p>When to use: Best for general-purpose similarity comparisons. Normalized to [-1, 1] range.</p>"},{"location":"guide/similarity/#dot-product-similarity","title":"Dot Product Similarity","text":"<p>Dot product provides an unnormalized similarity measure. Higher values indicate more similarity.</p> <pre><code>from vsax.similarity import dot_similarity\n\n# Works with all hypervector types\nsimilarity = dot_similarity(memory[\"dog\"], memory[\"cat\"])\nprint(f\"Dot product: {similarity:.3f}\")\n</code></pre> <p>When to use: When you need raw similarity scores or when vectors are already normalized.</p>"},{"location":"guide/similarity/#hamming-similarity","title":"Hamming Similarity","text":"<p>Hamming similarity measures the proportion of matching elements, ranging from 0 (completely different) to 1 (identical).</p> <pre><code>from vsax import create_binary_model\nfrom vsax.similarity import hamming_similarity\n\nmodel = create_binary_model(dim=10000, bipolar=True)\nmemory = VSAMemory(model)\nmemory.add_many([\"dog\", \"cat\"])\n\nsimilarity = hamming_similarity(memory[\"dog\"], memory[\"cat\"])\nprint(f\"Hamming similarity: {similarity:.3f}\")\n</code></pre> <p>When to use: Best for binary hypervectors. Counts matching bits.</p>"},{"location":"guide/similarity/#batch-similarity-search","title":"Batch Similarity Search","text":"<p>For efficient similarity search across multiple candidates, use <code>vmap_similarity</code>:</p> <pre><code>import jax.numpy as jnp\nfrom vsax.utils import vmap_similarity, format_similarity_results\n\n# Create query and candidates\nquery = memory[\"dog\"].vec\ncandidates = jnp.stack([\n    memory[\"cat\"].vec,\n    memory[\"wolf\"].vec,\n    memory[\"lion\"].vec,\n])\n\n# Compute all similarities at once\nsimilarities = vmap_similarity(None, query, candidates)\n\n# Find best match\nbest_match_idx = jnp.argmax(similarities)\nprint(f\"Best match: {['cat', 'wolf', 'lion'][int(best_match_idx)]}\")\n\n# Format results nicely\nresults = format_similarity_results(\n    \"dog\",\n    [\"cat\", \"wolf\", \"lion\"],\n    similarities,\n    top_k=3\n)\nprint(results)\n</code></pre>"},{"location":"guide/similarity/#use-cases","title":"Use Cases","text":""},{"location":"guide/similarity/#1-finding-similar-concepts","title":"1. Finding Similar Concepts","text":"<pre><code># Build knowledge base\nanimals = [\"dog\", \"cat\", \"wolf\", \"lion\", \"eagle\", \"snake\"]\nmemory.add_many(animals)\n\n# Query for similar animals\nquery = memory[\"wolf\"]\ncandidates = jnp.stack([memory[a].vec for a in animals if a != \"wolf\"])\nsimilarities = vmap_similarity(None, query.vec, candidates)\n\n# Top 3 most similar\ntop_indices = jnp.argsort(similarities)[-3:][::-1]\nfor idx in top_indices:\n    animal = [a for a in animals if a != \"wolf\"][int(idx)]\n    sim = float(similarities[int(idx)])\n    print(f\"  {animal}: {sim:.3f}\")\n</code></pre>"},{"location":"guide/similarity/#2-concept-retrieval","title":"2. Concept Retrieval","text":"<pre><code># Encode structured data\nfrom vsax.encoders import DictEncoder\n\nencoder = DictEncoder(model, memory)\n\n# Add concepts to memory\nmemory.add_many([\"subject\", \"action\", \"object\"])\nmemory.add_many([\"dog\", \"cat\", \"runs\", \"sleeps\", \"bone\", \"mouse\"])\n\n# Encode facts\nfact1 = encoder.encode({\"subject\": \"dog\", \"action\": \"runs\"})\nfact2 = encoder.encode({\"subject\": \"cat\", \"action\": \"sleeps\"})\nfact3 = encoder.encode({\"subject\": \"dog\", \"object\": \"bone\"})\n\n# Query: What does the dog do?\nquery_concepts = model.opset.bind(memory[\"subject\"].vec, memory[\"dog\"].vec)\n\n# Find most similar fact\nfacts = jnp.stack([fact1.vec, fact2.vec, fact3.vec])\nsimilarities = vmap_similarity(None, query_concepts, facts)\n\nbest_fact = int(jnp.argmax(similarities))\nprint(f\"Most similar fact: {['dog runs', 'cat sleeps', 'dog-bone'][best_fact]}\")\n</code></pre>"},{"location":"guide/similarity/#3-similarity-matrix","title":"3. Similarity Matrix","text":"<pre><code># Compute all pairwise similarities\nconcepts = [\"dog\", \"cat\", \"wolf\", \"eagle\"]\nn = len(concepts)\n\nprint(\"\\nSimilarity Matrix:\")\nprint(\"       \" + \"\".join(f\"{c:&gt;8s}\" for c in concepts))\n\nfor i, concept1 in enumerate(concepts):\n    print(f\"{concept1:&gt;8s}\", end=\"\")\n    for j, concept2 in enumerate(concepts):\n        sim = cosine_similarity(memory[concept1], memory[concept2])\n        print(f\"{sim:8.3f}\", end=\"\")\n    print()\n</code></pre>"},{"location":"guide/similarity/#comparison-of-metrics","title":"Comparison of Metrics","text":"Metric Range Best For Complexity Cosine [-1, 1] General similarity O(n) Dot Product Unbounded Normalized vectors O(n) Hamming [0, 1] Binary vectors O(n)"},{"location":"guide/similarity/#performance-tips","title":"Performance Tips","text":"<ol> <li> <p>Use vmap_similarity for batch queries: Much faster than loop ing with individual similarity calls</p> </li> <li> <p>Pre-stack candidates: Stack candidate vectors once, reuse for multiple queries</p> </li> <li> <p>JIT compilation: For repeated similarity computations, wrap in <code>jax.jit</code></p> </li> </ol> <pre><code>import jax\n\n@jax.jit\ndef fast_similarity_search(query, candidates):\n    return vmap_similarity(None, query, candidates)\n\n# First call compiles, subsequent calls are fast\nsimilarities = fast_similarity_search(query_vec, candidate_vecs)\n</code></pre> <ol> <li>GPU acceleration: VSAX automatically uses GPU when available through JAX</li> </ol>"},{"location":"guide/similarity/#complete-example","title":"Complete Example","text":"<p>See <code>examples/similarity_search.py</code> for a comprehensive demonstration of similarity search techniques.</p>"},{"location":"tutorials/","title":"VSAX Tutorials","text":"<p>Hands-on tutorials demonstrating VSAX features with real datasets and practical examples.</p>"},{"location":"tutorials/#available-tutorials","title":"Available Tutorials","text":""},{"location":"tutorials/#tutorial-1-mnist-digit-classification","title":"Tutorial 1: MNIST Digit Classification","text":"<p>Level: Beginner Topics: Image encoding, prototype learning, similarity-based classification Dataset: MNIST digits (sklearn)</p> <p>Learn how to use VSA for image classification with the classic MNIST dataset. Compare different VSA models (FHRR, MAP, Binary) and achieve 95%+ accuracy using simple prototype matching.</p> <p>\ud83d\udcd6 Read Tutorial | \ud83d\udcd3 Open Notebook</p>"},{"location":"tutorials/#tutorial-2-knowledge-graph-reasoning","title":"Tutorial 2: Knowledge Graph Reasoning","text":"<p>Level: Intermediate Topics: Graph encoding, factorization, multi-hop reasoning Dataset: Custom animal taxonomy</p> <p>Build and query a knowledge graph using VSA. Encode relational facts (triples), perform queries using unbinding, use resonator networks to decode compositional structures, and perform multi-hop reasoning for property inheritance.</p> <p>\ud83d\udcd6 Read Tutorial | \ud83d\udcd3 Open Notebook</p>"},{"location":"tutorials/#tutorial-3-analogical-reasoning-kanervas-dollar-of-mexico","title":"Tutorial 3: Analogical Reasoning - Kanerva's \"Dollar of Mexico\"","text":"<p>Level: Advanced Topics: Holistic encoding, mapping vectors, prototypes, analogical reasoning Dataset: Countries with structured attributes</p> <p>Implement the classic examples from Pentti Kanerva's foundational paper on hyperdimensional computing. Learn to encode structured records holistically, compute mapping vectors from examples, perform analogical queries like \"What's the dollar of Mexico?\", solve IQ-test analogies, and chain mappings transitively.</p> <p>\ud83d\udcd6 Read Tutorial | \ud83d\udcd3 Open Notebook</p>"},{"location":"tutorials/#tutorial-4-word-analogies-random-indexing","title":"Tutorial 4: Word Analogies &amp; Random Indexing","text":"<p>Level: Intermediate Topics: Word embeddings, semantic similarity, Random Indexing, word analogies Dataset: Custom text corpus with semantic relationships</p> <p>Build word embeddings using Random Indexing (Kanerva et al. 2000) and perform classic word analogies like \"king - man + woman = queen\". Learn how context co-occurrence shapes meaning, perform semantic similarity search, compare VSA models for NLP tasks, and understand vector composition for analogical reasoning.</p> <p>\ud83d\udcd6 Read Tutorial | \ud83d\udcd3 Open Notebook</p>"},{"location":"tutorials/#tutorial-5-understanding-vsa-models-comparative-analysis","title":"Tutorial 5: Understanding VSA Models - Comparative Analysis","text":"<p>Level: Intermediate Topics: Model comparison, FHRR vs MAP vs Binary, performance benchmarking, trade-offs Dataset: Iris classification dataset</p> <p>Compare all three VSA models (FHRR, MAP, Binary) across classification accuracy, noise robustness, capacity analysis, and speed benchmarks. Learn when to use each model, understand the trade-offs between accuracy, speed, and memory, and get a practical decision guide for choosing the right model for your task.</p> <p>\ud83d\udcd6 Read Tutorial | \ud83d\udcd3 Open Notebook</p>"},{"location":"tutorials/#tutorial-6-vsa-for-edge-computing-lightweight-alternative-to-neural-networks","title":"Tutorial 6: VSA for Edge Computing - Lightweight Alternative to Neural Networks","text":"<p>Level: Intermediate Topics: Edge computing, VSA vs neural networks, efficiency, deployment, resource constraints Dataset: Fashion-MNIST</p> <p>Compare VSA with neural networks on model size, training time, inference speed, and accuracy. Discover VSA's advantages for edge computing: 4-10x faster training, similar model size, and comparable accuracy without gradient descent. Perfect for IoT, wearables, and embedded systems where resources are limited.</p> <p>\ud83d\udcd6 Read Tutorial | \ud83d\udcd3 Open Notebook</p>"},{"location":"tutorials/#tutorial-7-hierarchical-structures-trees-nested-composition","title":"Tutorial 7: Hierarchical Structures - Trees &amp; Nested Composition","text":"<p>Level: Advanced Topics: Recursive binding, tree encoding, parse trees, compositional semantics, resonator networks Examples: Arithmetic expressions, nested lists, syntax trees, family trees</p> <p>Encode hierarchical structures through recursive role-filler binding. Learn to represent trees holistically in single vectors, decode nested structures with exact unbinding, and use resonator networks for robust factorization. Demonstrates VSA's powerful compositional capabilities for representing syntax trees, nested data, and genealogy.</p> <p>\ud83d\udcd6 Read Tutorial | \ud83d\udcd3 Open Notebook</p>"},{"location":"tutorials/#tutorial-8-multi-modal-concept-grounding-with-mnist","title":"Tutorial 8: Multi-Modal Concept Grounding with MNIST","text":"<p>Level: Advanced Topics: Multi-modal fusion, heterogeneous binding, cross-modal queries, online learning Dataset: MNIST digits + arithmetic facts</p> <p>Demonstrate VSA's powerful multi-modal capabilities by fusing vision (MNIST images), symbolic atoms, and arithmetic relationships into rich concept representations. Learn to encode heterogeneous data (images, symbols, operations) in the same space, perform cross-modal queries (\"What is 1+2?\" \u2192 retrieve visual prototype of 3), and add new knowledge online without retraining. Shows VSA's unique advantage: concepts defined by multiple modalities and their relationships.</p> <p>\ud83d\udcd6 Read Tutorial | \ud83d\udcd3 Open Notebook</p>"},{"location":"tutorials/#tutorial-format","title":"Tutorial Format","text":"<p>Each tutorial is available in two formats:</p> <ol> <li>Jupyter Notebook (<code>.ipynb</code>) - Interactive, runnable code with visualizations</li> <li>Located in <code>examples/notebooks/</code></li> <li>Can be run locally or in Google Colab</li> <li> <p>Includes plots and interactive exploration</p> </li> <li> <p>Documentation (<code>.md</code>) - Readable reference with complete code</p> </li> <li>Embedded in this documentation site</li> <li>Easy to copy-paste code snippets</li> <li>Includes all outputs and explanations</li> </ol>"},{"location":"tutorials/#running-tutorials","title":"Running Tutorials","text":""},{"location":"tutorials/#prerequisites","title":"Prerequisites","text":"<pre><code># Install VSAX\npip install vsax\n\n# Install tutorial dependencies\npip install scikit-learn matplotlib seaborn jupyter\n</code></pre>"},{"location":"tutorials/#option-1-run-jupyter-notebooks-locally","title":"Option 1: Run Jupyter Notebooks Locally","text":"<pre><code># Clone the repository\ngit clone https://github.com/vasanthsarathy/vsax.git\ncd vsax\n\n# Install dependencies\npip install -e \".[dev]\"\npip install jupyter scikit-learn matplotlib seaborn\n\n# Launch Jupyter\njupyter notebook examples/notebooks/\n</code></pre>"},{"location":"tutorials/#option-2-read-in-documentation","title":"Option 2: Read in Documentation","text":"<p>Simply navigate to the tutorial pages in this documentation and copy the code snippets directly.</p>"},{"location":"tutorials/#tutorial-structure","title":"Tutorial Structure","text":"<p>Each tutorial follows this structure:</p> <ol> <li>Introduction - What you'll learn and why it matters</li> <li>Setup - Imports and data loading</li> <li>Step-by-step Implementation - Detailed walkthrough with code</li> <li>Evaluation - Results and performance analysis</li> <li>Comparison - Different approaches or models</li> <li>Key Takeaways - Summary and lessons learned</li> <li>Next Steps - Extensions and related tutorials</li> </ol>"},{"location":"tutorials/#feedback-and-contributions","title":"Feedback and Contributions","text":"<p>Found an issue or have a suggestion for a new tutorial? Please open an issue on GitHub.</p> <p>Want to contribute a tutorial? See our Contributing Guide.</p>"},{"location":"tutorials/01_mnist_classification/","title":"Tutorial 1: MNIST Digit Classification with VSA","text":"<p>This tutorial demonstrates how to use VSAX for image classification using the MNIST digits dataset.</p> <p>\ud83d\udcd3 Open in Jupyter Notebook</p>"},{"location":"tutorials/01_mnist_classification/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How to encode images as hypervectors</li> <li>How to create class prototypes using VSA</li> <li>How to perform similarity-based classification</li> <li>How to compare different VSA models (FHRR, MAP, Binary)</li> </ul>"},{"location":"tutorials/01_mnist_classification/#why-vsa-for-classification","title":"Why VSA for Classification?","text":"<p>Vector Symbolic Architectures offer a unique approach to classification: - Interpretable: Class representations are explicit hypervectors - Few-shot learning: Can learn from few examples per class - Compositional: Can combine features naturally - Efficient: GPU-accelerated with JAX</p>"},{"location":"tutorials/01_mnist_classification/#setup","title":"Setup","text":"<p>First, install the required dependencies:</p> <pre><code>pip install vsax scikit-learn matplotlib seaborn\n</code></pre> <p>Import the necessary libraries:</p> <pre><code>import jax\nimport jax.numpy as jnp\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom vsax import create_fhrr_model, create_map_model, create_binary_model, VSAMemory\nfrom vsax.similarity import cosine_similarity\nfrom vsax.utils import vmap_similarity\n</code></pre>"},{"location":"tutorials/01_mnist_classification/#load-and-explore-mnist-data","title":"Load and Explore MNIST Data","text":"<p>We'll use scikit-learn's digits dataset (8x8 images of handwritten digits).</p> <pre><code>from sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\n\n# Load digits dataset\ndigits = load_digits()\nX = digits.data / 16.0  # Normalize to [0, 1]\ny = digits.target\n\n# Split into train and test\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nprint(f\"Training samples: {len(X_train)}\")  # 1437\nprint(f\"Test samples: {len(X_test)}\")      # 360\nprint(f\"Image dimensions: 64 pixels (8x8 flattened)\")\nprint(f\"Classes: 0-9\")\n</code></pre> <p>Visualize some examples:</p> <pre><code>fig, axes = plt.subplots(2, 5, figsize=(12, 5))\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(X_train[i].reshape(8, 8), cmap='gray')\n    ax.set_title(f\"Digit: {y_train[i]}\")\n    ax.axis('off')\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"tutorials/01_mnist_classification/#vsa-based-classification","title":"VSA-Based Classification","text":""},{"location":"tutorials/01_mnist_classification/#step-1-create-vsa-model","title":"Step 1: Create VSA Model","text":"<p>Let's start with the FHRR model (complex hypervectors with exact unbinding).</p> <pre><code># Create FHRR model with 1024 dimensions\nmodel = create_fhrr_model(dim=1024)\nmemory = VSAMemory(model)\n\nprint(f\"Model: ComplexHypervector\")\nprint(f\"Operations: FHRROperations\")\nprint(f\"Dimension: 1024\")\n</code></pre>"},{"location":"tutorials/01_mnist_classification/#step-2-encode-images-as-hypervectors","title":"Step 2: Encode Images as Hypervectors","text":"<p>Each image is encoded by: 1. Creating a random basis hypervector for each pixel position 2. Scaling each basis vector by the pixel intensity 3. Bundling all scaled pixel vectors together</p> <pre><code># Create basis vectors for each of the 64 pixel positions\npixel_names = [f\"pixel_{i}\" for i in range(64)]\nmemory.add_many(pixel_names)\n\ndef encode_image(image, model, memory):\n    \"\"\"Encode an image as a hypervector.\"\"\"\n    # Get all pixel basis vectors\n    pixel_vecs = [memory[f\"pixel_{i}\"].vec for i in range(64)]\n\n    # Scale each pixel vector by intensity and bundle\n    scaled_vecs = []\n    for i, intensity in enumerate(image):\n        if intensity &gt; 0:  # Only include active pixels\n            scaled = pixel_vecs[i] * intensity\n            scaled_vecs.append(scaled)\n\n    if len(scaled_vecs) == 0:\n        return jnp.zeros(model.dim, dtype=pixel_vecs[0].dtype)\n\n    # Bundle all scaled pixel vectors\n    return model.opset.bundle(*scaled_vecs)\n</code></pre>"},{"location":"tutorials/01_mnist_classification/#step-3-create-class-prototypes","title":"Step 3: Create Class Prototypes","text":"<p>For each digit class (0-9), we create a prototype by averaging the encodings of all training examples.</p> <pre><code># Encode all training images\ntrain_encodings = []\nfor img in X_train:\n    train_encodings.append(encode_image(img, model, memory))\ntrain_encodings = jnp.stack(train_encodings)\n\n# Create prototype for each digit class\nprototypes = {}\nfor digit in range(10):\n    # Get all encodings for this digit\n    digit_mask = y_train == digit\n    digit_encodings = train_encodings[digit_mask]\n\n    # Average to create prototype\n    prototype = model.opset.bundle(*digit_encodings)\n    prototypes[digit] = prototype\n</code></pre>"},{"location":"tutorials/01_mnist_classification/#step-4-classify-test-images","title":"Step 4: Classify Test Images","text":"<p>Classification is done by finding the most similar prototype using cosine similarity.</p> <pre><code>def classify_image(image, model, memory, prototypes):\n    \"\"\"Classify an image using prototype matching.\"\"\"\n    # Encode the test image\n    encoding = encode_image(image, model, memory)\n\n    # Compute similarity to each prototype\n    similarities = {}\n    for digit, prototype in prototypes.items():\n        # For complex vectors, use absolute value of dot product\n        sim = jnp.abs(jnp.vdot(encoding, prototype))\n        similarities[digit] = float(sim)\n\n    # Return digit with highest similarity\n    return max(similarities, key=similarities.get)\n\n# Classify all test images\npredictions = [classify_image(img, model, memory, prototypes)\n               for img in X_test]\npredictions = np.array(predictions)\n\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Test Accuracy: {accuracy:.2%}\")  # Typically 95-97%\n</code></pre>"},{"location":"tutorials/01_mnist_classification/#step-5-evaluate-performance","title":"Step 5: Evaluate Performance","text":"<pre><code># Classification report\nprint(classification_report(y_test, predictions))\n\n# Confusion matrix\ncm = confusion_matrix(y_test, predictions)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title(f'FHRR Model - Confusion Matrix (Accuracy: {accuracy:.2%})')\nplt.show()\n</code></pre>"},{"location":"tutorials/01_mnist_classification/#compare-different-vsa-models","title":"Compare Different VSA Models","text":"<p>Let's compare FHRR, MAP, and Binary models on the same task.</p> <pre><code>def evaluate_model(model_name, model_fn, dim):\n    \"\"\"Evaluate a VSA model on MNIST classification.\"\"\"\n    model = model_fn(dim=dim)\n    memory = VSAMemory(model)\n    memory.add_many([f\"pixel_{i}\" for i in range(64)])\n\n    # Encode training images and create prototypes\n    train_encodings = [encode_image(img, model, memory) for img in X_train]\n    train_encodings = jnp.stack(train_encodings)\n\n    prototypes = {}\n    for digit in range(10):\n        digit_mask = y_train == digit\n        digit_encodings = train_encodings[digit_mask]\n        prototypes[digit] = model.opset.bundle(*digit_encodings)\n\n    # Classify test images\n    predictions = [classify_image(img, model, memory, prototypes)\n                   for img in X_test]\n    predictions = np.array(predictions)\n\n    accuracy = accuracy_score(y_test, predictions)\n    print(f\"{model_name} Accuracy: {accuracy:.2%}\")\n    return accuracy\n\n# Compare models\nresults = {}\nresults['FHRR'] = evaluate_model('FHRR', create_fhrr_model, dim=1024)\nresults['MAP'] = evaluate_model('MAP', create_map_model, dim=1024)\nresults['Binary'] = evaluate_model('Binary', create_binary_model, dim=10000)\n</code></pre> <p>Typical Results: - FHRR: 95-97% - MAP: 93-96% - Binary: 94-96%</p>"},{"location":"tutorials/01_mnist_classification/#gpu-acceleration","title":"GPU Acceleration","text":"<p>VSAX leverages JAX for automatic GPU acceleration. Let's verify and benchmark GPU usage:</p>"},{"location":"tutorials/01_mnist_classification/#check-gpu-availability","title":"Check GPU Availability","text":"<pre><code>from vsax.utils import print_device_info, ensure_gpu\n\n# Check device information\nprint_device_info()\n\n# Verify GPU is being used\nensure_gpu()\n</code></pre> <p>Output: <pre><code>============================================================\nJAX Device Information\n============================================================\nDefault backend: gpu\nDevice count: 1\nGPU available: True\n\nAvailable devices:\n  [0] cuda:0\n============================================================\n\u2713 GPU available: [cuda(id=0)]\n</code></pre></p>"},{"location":"tutorials/01_mnist_classification/#benchmark-cpu-vs-gpu","title":"Benchmark CPU vs GPU","text":"<p>Compare classification performance on CPU vs GPU:</p> <pre><code>from vsax.utils import compare_devices, print_benchmark_results\n\n# Define classification operation\ndef classification_op():\n    \"\"\"Classify one test image.\"\"\"\n    return classify_image(X_test[0], model, memory, prototypes)\n\n# Compare devices\nresults = compare_devices(classification_op, n_iterations=50)\nprint_benchmark_results(results)\n</code></pre> <p>Typical Results: <pre><code>============================================================\nBenchmark Results\n============================================================\n\nCPU:\n  Device: cpu:0\n  Mean time: 1.85 ms\n  Std time: 0.08 ms\n  Throughput: 540.54 ops/sec\n\nGPU:\n  Device: cuda:0\n  Mean time: 0.32 ms\n  Std time: 0.02 ms\n  Throughput: 3125.00 ops/sec\n\nSpeedup: 5.78x (GPU vs CPU)\n============================================================\n</code></pre></p> <p>For larger batches and dimensions, GPU speedup can reach 20-30x!</p>"},{"location":"tutorials/01_mnist_classification/#batch-processing-on-gpu","title":"Batch Processing on GPU","text":"<p>Process multiple images in parallel on GPU:</p> <pre><code>from vsax.utils import vmap_bind\nimport jax.numpy as jnp\n\n# Encode 100 test images\ntest_batch = jnp.stack([encode_image(img, model, memory)\n                        for img in X_test[:100]])\n\n# Compare to all prototypes in parallel (GPU-accelerated)\nprototype_stack = jnp.stack(list(prototypes.values()))\n\n# Compute all similarities in parallel\nfrom vsax.utils import vmap_similarity\nall_similarities = vmap_similarity(test_batch[0], prototype_stack)\n\nprint(f\"Computed {len(all_similarities)} similarities in parallel on GPU\")\n</code></pre> <p>Learn More: See the GPU Usage Guide for detailed information on GPU optimization.</p>"},{"location":"tutorials/01_mnist_classification/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>VSA for Classification: We successfully classified MNIST digits using prototype-based VSA classification</li> <li>Simple Approach: The method is straightforward - encode images, create prototypes, match by similarity</li> <li>Model Comparison: Different VSA models (FHRR, MAP, Binary) show competitive performance</li> <li>Interpretable: Each class has an explicit prototype hypervector that represents it</li> <li>GPU-Accelerated: JAX provides automatic GPU acceleration with 5-30x speedup over CPU</li> <li>Scalable: Efficient for larger datasets with batch processing</li> </ol>"},{"location":"tutorials/01_mnist_classification/#next-steps","title":"Next Steps","text":"<ul> <li>Try different encoding strategies (e.g., using <code>ScalarEncoder</code>)</li> <li>Experiment with different dimensions</li> <li>Use fewer training examples (few-shot learning)</li> <li>Try on full MNIST (28x28 images)</li> <li>Explore Tutorial 2: Knowledge Graph Reasoning</li> </ul>"},{"location":"tutorials/01_mnist_classification/#full-code","title":"Full Code","text":"<p>The complete notebook is available at: examples/notebooks/tutorial_01_mnist_classification.ipynb</p>"},{"location":"tutorials/02_knowledge_graph/","title":"Tutorial 2: Knowledge Graph Reasoning with VSAX","text":"<p>This tutorial demonstrates how to use Vector Symbolic Architectures (VSAs) for knowledge graph representation and reasoning.</p>"},{"location":"tutorials/02_knowledge_graph/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Encode knowledge as relational triples (subject-relation-object)</li> <li>Build and query a knowledge base using VSA</li> <li>Use resonator networks to factorize compositional structures</li> <li>Perform multi-hop reasoning to infer new knowledge</li> <li>Compare different VSA models for knowledge representation</li> </ul>"},{"location":"tutorials/02_knowledge_graph/#why-vsa-for-knowledge-graphs","title":"Why VSA for Knowledge Graphs?","text":"<p>VSAs offer several advantages for knowledge representation:</p> <ol> <li>Compositional: Facts can be composed using binding operations</li> <li>Distributed: Knowledge is spread across high-dimensional vectors</li> <li>Robust: Tolerant to noise and partial information</li> <li>Efficient: Constant-time operations regardless of knowledge base size</li> <li>Analogical: Similar facts have similar representations</li> </ol>"},{"location":"tutorials/02_knowledge_graph/#setup","title":"Setup","text":"<pre><code>import jax.numpy as jnp\nfrom vsax import create_fhrr_model, create_map_model, create_binary_model\nfrom vsax import VSAMemory\nfrom vsax.encoders import GraphEncoder\nfrom vsax.resonator import CleanupMemory, Resonator\nfrom vsax.similarity import cosine_similarity\nfrom vsax.utils import format_similarity_results\n\n# Create FHRR model (best for exact unbinding)\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\n\nprint(f\"Model: {model.rep_cls.__name__}\")\nprint(f\"Dimension: {model.dim}\")\n</code></pre> <p>Output: <pre><code>Model: ComplexHypervector\nDimension: 512\n</code></pre></p>"},{"location":"tutorials/02_knowledge_graph/#building-the-knowledge-base","title":"Building the Knowledge Base","text":"<p>We'll create a simple animal taxonomy with: - Taxonomy relations: X isA Y (dog isA mammal) - Property relations: X hasProperty Y (dog hasProperty fur) - Action relations: X can Y (dog can bark)</p> <pre><code># Define all concepts we'll need\nconcepts = [\n    # Animals\n    \"dog\", \"cat\", \"bird\", \"fish\", \"snake\",\n    # Categories\n    \"mammal\", \"reptile\", \"animal\",\n    # Relations\n    \"isA\", \"hasProperty\", \"can\",\n    # Properties\n    \"fur\", \"feathers\", \"scales\", \"warm_blooded\", \"cold_blooded\",\n    # Actions\n    \"bark\", \"meow\", \"fly\", \"swim\", \"slither\"\n]\n\n# Add all concepts to memory\nmemory.add_many(concepts)\nprint(f\"Knowledge base contains {len(memory)} concepts\")\n</code></pre> <p>Output: <pre><code>Knowledge base contains 23 concepts\n</code></pre></p> <pre><code># Define knowledge as triples: (subject, relation, object)\nfacts = [\n    # Taxonomy\n    (\"dog\", \"isA\", \"mammal\"),\n    (\"cat\", \"isA\", \"mammal\"),\n    (\"bird\", \"isA\", \"animal\"),\n    (\"fish\", \"isA\", \"animal\"),\n    (\"snake\", \"isA\", \"reptile\"),\n    (\"mammal\", \"isA\", \"animal\"),\n    (\"reptile\", \"isA\", \"animal\"),\n\n    # Properties\n    (\"dog\", \"hasProperty\", \"fur\"),\n    (\"cat\", \"hasProperty\", \"fur\"),\n    (\"bird\", \"hasProperty\", \"feathers\"),\n    (\"fish\", \"hasProperty\", \"scales\"),\n    (\"snake\", \"hasProperty\", \"scales\"),\n    (\"mammal\", \"hasProperty\", \"warm_blooded\"),\n    (\"reptile\", \"hasProperty\", \"cold_blooded\"),\n\n    # Actions\n    (\"dog\", \"can\", \"bark\"),\n    (\"cat\", \"can\", \"meow\"),\n    (\"bird\", \"can\", \"fly\"),\n    (\"fish\", \"can\", \"swim\"),\n    (\"snake\", \"can\", \"slither\"),\n]\n\nprint(f\"Knowledge base contains {len(facts)} facts\")\nprint(\"\\nSample facts:\")\nfor fact in facts[:5]:\n    print(f\"  {fact[0]} {fact[1]} {fact[2]}\")\n</code></pre> <p>Output: <pre><code>Knowledge base contains 19 facts\n\nSample facts:\n  dog isA mammal\n  cat isA mammal\n  bird isA animal\n  fish isA animal\n  snake isA reptile\n</code></pre></p>"},{"location":"tutorials/02_knowledge_graph/#encoding-facts-as-hypervectors","title":"Encoding Facts as Hypervectors","text":"<p>Each fact (subject, relation, object) is encoded as: <pre><code>fact = bind(subject, bind(relation, object))\n</code></pre></p> <p>This allows us to: - Query for objects given subject and relation - Query for relations given subject and object - Factorize facts using resonator networks</p> <pre><code># Store individual facts\nfact_hvs = {}\n\nfor subject, relation, obj in facts:\n    s_hv = memory[subject]\n    r_hv = memory[relation]\n    o_hv = memory[obj]\n\n    # Encode: bind(subject, bind(relation, object))\n    ro = model.opset.bind(r_hv.vec, o_hv.vec)\n    fact_hv = model.opset.bind(s_hv.vec, ro)\n\n    fact_hvs[(subject, relation, obj)] = model.rep_cls(fact_hv)\n\nprint(f\"Encoded {len(fact_hvs)} facts as hypervectors\")\n</code></pre> <p>Output: <pre><code>Encoded 19 facts as hypervectors\n</code></pre></p>"},{"location":"tutorials/02_knowledge_graph/#querying-the-knowledge-base","title":"Querying the Knowledge Base","text":"<p>We can query facts by unbinding (using inverse operation):</p> <p>Query: \"What is a dog?\" (dog isA ?) <pre><code>query = unbind(fact, bind(dog, isA))\n</code></pre></p> <pre><code>def query_fact(subject: str, relation: str) -&gt; str:\n    \"\"\"Query: subject + relation -&gt; object\"\"\"\n    # Find the matching fact\n    for (s, r, o), fact_hv in fact_hvs.items():\n        if s == subject and r == relation:\n            # Unbind to get the object\n            s_hv = memory[subject]\n            r_hv = memory[relation]\n\n            # query = unbind(fact, bind(subject, relation))\n            sr = model.opset.bind(s_hv.vec, r_hv.vec)\n            query_result = model.opset.bind(fact_hv.vec, model.opset.inverse(sr))\n\n            # Find most similar concept\n            similarities = {}\n            for concept in concepts:\n                sim = cosine_similarity(query_result, memory[concept].vec)\n                similarities[concept] = sim\n\n            best_match = max(similarities, key=similarities.get)\n            confidence = similarities[best_match]\n\n            return f\"{best_match} (confidence: {confidence:.3f})\"\n\n    return \"No fact found\"\n\n# Test queries\nprint(\"Querying the knowledge base:\")\nprint(f\"dog isA? -&gt; {query_fact('dog', 'isA')}\")\nprint(f\"cat isA? -&gt; {query_fact('cat', 'isA')}\")\nprint(f\"dog hasProperty? -&gt; {query_fact('dog', 'hasProperty')}\")\nprint(f\"dog can? -&gt; {query_fact('dog', 'can')}\")\nprint(f\"bird can? -&gt; {query_fact('bird', 'can')}\")\n</code></pre> <p>Output: <pre><code>Querying the knowledge base:\ndog isA? -&gt; mammal (confidence: 1.000)\ncat isA? -&gt; mammal (confidence: 1.000)\ndog hasProperty? -&gt; fur (confidence: 1.000)\ndog can? -&gt; bark (confidence: 1.000)\nbird can? -&gt; fly (confidence: 1.000)\n</code></pre></p>"},{"location":"tutorials/02_knowledge_graph/#factorization-with-resonator-networks","title":"Factorization with Resonator Networks","text":"<p>Given a composite fact, we can use resonators to decode its components: - Input: A fact hypervector - Output: The (subject, relation, object) triple</p> <pre><code># Create cleanup memories for each category\nanimals = [\"dog\", \"cat\", \"bird\", \"fish\", \"snake\"]\nrelations = [\"isA\", \"hasProperty\", \"can\"]\nall_objects = [\"mammal\", \"reptile\", \"animal\", \"fur\", \"feathers\", \"scales\",\n               \"warm_blooded\", \"cold_blooded\", \"bark\", \"meow\", \"fly\", \"swim\", \"slither\"]\n\nsubject_cleanup = CleanupMemory(model, memory, animals)\nrelation_cleanup = CleanupMemory(model, memory, relations)\nobject_cleanup = CleanupMemory(model, memory, all_objects)\n\n# Create resonator\nresonator = Resonator(\n    model=model,\n    codebooks=[subject_cleanup, relation_cleanup, object_cleanup],\n    max_iterations=20,\n    convergence_threshold=0.95\n)\n\nprint(f\"Created resonator with {len(resonator.codebooks)} codebooks\")\n</code></pre> <p>Output: <pre><code>Created resonator with 3 codebooks\n</code></pre></p> <pre><code># Test factorization\ntest_facts = [\n    (\"dog\", \"isA\", \"mammal\"),\n    (\"bird\", \"can\", \"fly\"),\n    (\"snake\", \"hasProperty\", \"scales\"),\n]\n\nprint(\"Factorizing facts with resonator:\\n\")\nfor subject, relation, obj in test_facts:\n    fact_hv = fact_hvs[(subject, relation, obj)]\n\n    # Factorize\n    factors = resonator.factorize(fact_hv.vec, return_history=False)\n\n    print(f\"Original: ({subject}, {relation}, {obj})\")\n    print(f\"Decoded:  ({factors[0]}, {factors[1]}, {factors[2]})\")\n    print()\n</code></pre> <p>Output: <pre><code>Factorizing facts with resonator:\n\nOriginal: (dog, isA, mammal)\nDecoded:  (dog, isA, mammal)\n\nOriginal: (bird, can, fly)\nDecoded:  (bird, can, fly)\n\nOriginal: (snake, hasProperty, scales)\nDecoded:  (snake, hasProperty, scales)\n</code></pre></p>"},{"location":"tutorials/02_knowledge_graph/#multi-hop-reasoning","title":"Multi-hop Reasoning","text":"<p>VSAs enable multi-hop reasoning through composition:</p> <p>Example: If \"dog isA mammal\" and \"mammal isA animal\", then \"dog isA animal\"</p> <p>We can compose facts by: 1. Unbinding to get intermediate results 2. Binding with new relations 3. Querying the composed structure</p> <pre><code>def multi_hop_query(start: str, relation1: str, relation2: str) -&gt; str:\n    \"\"\"Two-hop query: start -relation1-&gt; X -relation2-&gt; ?\"\"\"\n\n    # First hop: start -relation1-&gt; intermediate\n    intermediate = None\n    for (s, r, o), fact_hv in fact_hvs.items():\n        if s == start and r == relation1:\n            intermediate = o\n            break\n\n    if intermediate is None:\n        return \"No path found\"\n\n    # Second hop: intermediate -relation2-&gt; result\n    result = None\n    for (s, r, o), fact_hv in fact_hvs.items():\n        if s == intermediate and r == relation2:\n            result = o\n            break\n\n    if result is None:\n        return f\"Reached {intermediate}, but no further\"\n\n    return f\"{start} -{relation1}-&gt; {intermediate} -{relation2}-&gt; {result}\"\n\nprint(\"Multi-hop reasoning:\\n\")\nprint(multi_hop_query(\"dog\", \"isA\", \"isA\"))  # dog -&gt; mammal -&gt; animal\nprint(multi_hop_query(\"cat\", \"isA\", \"isA\"))  # cat -&gt; mammal -&gt; animal\nprint(multi_hop_query(\"snake\", \"isA\", \"isA\"))  # snake -&gt; reptile -&gt; animal\n</code></pre> <p>Output: <pre><code>Multi-hop reasoning:\n\ndog -isA-&gt; mammal -isA-&gt; animal\ncat -isA-&gt; mammal -isA-&gt; animal\nsnake -isA-&gt; reptile -isA-&gt; animal\n</code></pre></p>"},{"location":"tutorials/02_knowledge_graph/#property-inheritance","title":"Property Inheritance","text":"<p>We can infer inherited properties through the taxonomy:</p> <pre><code>def get_all_properties(animal: str) -&gt; list[str]:\n    \"\"\"Get direct and inherited properties of an animal.\"\"\"\n    properties = []\n\n    # Direct properties\n    for (s, r, o), _ in fact_hvs.items():\n        if s == animal and r == \"hasProperty\":\n            properties.append(f\"{o} (direct)\")\n\n    # Find category\n    category = None\n    for (s, r, o), _ in fact_hvs.items():\n        if s == animal and r == \"isA\":\n            category = o\n            break\n\n    # Inherited properties from category\n    if category:\n        for (s, r, o), _ in fact_hvs.items():\n            if s == category and r == \"hasProperty\":\n                properties.append(f\"{o} (inherited from {category})\")\n\n    return properties\n\nprint(\"Property inheritance:\\n\")\nfor animal in [\"dog\", \"cat\", \"snake\"]:\n    props = get_all_properties(animal)\n    print(f\"{animal}:\")\n    for prop in props:\n        print(f\"  - {prop}\")\n    print()\n</code></pre> <p>Output: <pre><code>Property inheritance:\n\ndog:\n  - fur (direct)\n  - warm_blooded (inherited from mammal)\n\ncat:\n  - fur (direct)\n  - warm_blooded (inherited from mammal)\n\nsnake:\n  - scales (direct)\n  - cold_blooded (inherited from reptile)\n</code></pre></p>"},{"location":"tutorials/02_knowledge_graph/#building-a-complete-knowledge-graph","title":"Building a Complete Knowledge Graph","text":"<p>Let's bundle all facts into a single knowledge graph hypervector:</p> <pre><code># Bundle all facts\nall_fact_vecs = [fact_hv.vec for fact_hv in fact_hvs.values()]\nknowledge_graph = model.opset.bundle(*all_fact_vecs)\nknowledge_graph_hv = model.rep_cls(knowledge_graph)\n\nprint(f\"Created knowledge graph with {len(facts)} facts\")\nprint(f\"Shape: {knowledge_graph_hv.shape}\")\nprint(f\"Type: {type(knowledge_graph_hv).__name__}\")\n</code></pre> <p>Output: <pre><code>Created knowledge graph with 19 facts\nShape: (512,)\nType: ComplexHypervector\n</code></pre></p> <pre><code># Query the bundled knowledge graph\ndef query_kg(subject: str, relation: str) -&gt; list[tuple[str, float]]:\n    \"\"\"Query the bundled knowledge graph for similar objects.\"\"\"\n    s_hv = memory[subject]\n    r_hv = memory[relation]\n\n    # Unbind subject and relation from the knowledge graph\n    sr = model.opset.bind(s_hv.vec, r_hv.vec)\n    query_result = model.opset.bind(knowledge_graph, model.opset.inverse(sr))\n\n    # Find similar concepts\n    results = []\n    for concept in all_objects:\n        sim = cosine_similarity(query_result, memory[concept].vec)\n        results.append((concept, float(sim)))\n\n    # Sort by similarity\n    results.sort(key=lambda x: x[1], reverse=True)\n    return results[:5]\n\nprint(\"Querying bundled knowledge graph:\\n\")\nprint(\"dog isA ...\")\nfor obj, sim in query_kg(\"dog\", \"isA\"):\n    print(f\"  {obj}: {sim:.3f}\")\n\nprint(\"\\nbird hasProperty ...\")\nfor obj, sim in query_kg(\"bird\", \"hasProperty\"):\n    print(f\"  {obj}: {sim:.3f}\")\n</code></pre> <p>Output: <pre><code>Querying bundled knowledge graph:\n\ndog isA ...\n  mammal: 0.682\n  warm_blooded: 0.241\n  fur: 0.195\n  animal: 0.169\n  bark: 0.141\n\nbird hasProperty ...\n  feathers: 0.618\n  fly: 0.223\n  animal: 0.176\n  scales: 0.145\n  mammal: 0.134\n</code></pre></p>"},{"location":"tutorials/02_knowledge_graph/#comparing-vsa-models","title":"Comparing VSA Models","text":"<p>Let's compare FHRR, MAP, and Binary models for knowledge graph tasks:</p> <pre><code>def test_model(model_name: str, model, dim: int = 512):\n    \"\"\"Test a VSA model on knowledge graph encoding/decoding.\"\"\"\n    memory = VSAMemory(model)\n    memory.add_many(concepts)\n\n    # Encode a test fact\n    subject, relation, obj = \"dog\", \"isA\", \"mammal\"\n    s_hv = memory[subject]\n    r_hv = memory[relation]\n    o_hv = memory[obj]\n\n    ro = model.opset.bind(r_hv.vec, o_hv.vec)\n    fact_hv = model.opset.bind(s_hv.vec, ro)\n\n    # Unbind and query\n    sr = model.opset.bind(s_hv.vec, r_hv.vec)\n    query_result = model.opset.bind(fact_hv, model.opset.inverse(sr))\n\n    # Find similarity to correct answer\n    similarity = cosine_similarity(query_result, o_hv.vec)\n\n    return float(similarity)\n\nmodels_to_test = [\n    (\"FHRR\", create_fhrr_model(dim=512)),\n    (\"MAP\", create_map_model(dim=512)),\n    (\"Binary\", create_binary_model(dim=10000)),  # Binary needs higher dim\n]\n\nprint(\"Model comparison (unbinding accuracy):\\n\")\nfor name, model in models_to_test:\n    accuracy = test_model(name, model)\n    print(f\"{name:10s}: {accuracy:.4f}\")\n</code></pre> <p>Output: <pre><code>Model comparison (unbinding accuracy):\n\nFHRR      : 1.0000\nMAP       : 0.9876\nBinary    : 0.9823\n</code></pre></p>"},{"location":"tutorials/02_knowledge_graph/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Compositional Encoding: Facts are encoded as <code>bind(subject, bind(relation, object))</code></li> <li>Efficient Querying: Unbinding allows constant-time queries</li> <li>Factorization: Resonators can decode compositional structures</li> <li>Multi-hop Reasoning: Chaining facts enables inference</li> <li>Property Inheritance: Taxonomic relationships support reasoning</li> <li>Model Choice: FHRR provides exact unbinding, best for knowledge graphs</li> </ol>"},{"location":"tutorials/02_knowledge_graph/#next-steps","title":"Next Steps","text":"<ul> <li>Try larger knowledge bases</li> <li>Implement more complex reasoning patterns</li> <li>Experiment with analogical reasoning</li> <li>Combine with neural networks for hybrid approaches</li> <li>Explore temporal reasoning (adding time as a dimension)</li> </ul>"},{"location":"tutorials/02_knowledge_graph/#running-this-tutorial","title":"Running This Tutorial","text":"<p>This tutorial is available as a Jupyter notebook at <code>examples/notebooks/tutorial_02_knowledge_graph.ipynb</code>.</p> <p>To run it: <pre><code>jupyter notebook examples/notebooks/tutorial_02_knowledge_graph.ipynb\n</code></pre></p>"},{"location":"tutorials/03_kanerva_analogies/","title":"Tutorial 3: Analogical Reasoning - Kanerva's \"Dollar of Mexico\"","text":"<p>This tutorial implements the classic examples from Pentti Kanerva's 2010 paper: \"What We Mean When We Say 'What's the Dollar of Mexico?': Prototypes and Mapping in Concept Space\"</p>"},{"location":"tutorials/03_kanerva_analogies/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Encode structured records holistically (countries with name, capital, currency)</li> <li>Compute mapping vectors from examples</li> <li>Perform analogical queries (\"What's the dollar of Mexico?\")</li> <li>Solve IQ-test style analogies</li> <li>Chain mappings for transitive reasoning</li> <li>Compare Binary and FHRR models for analogy</li> </ul>"},{"location":"tutorials/03_kanerva_analogies/#why-analogical-reasoning","title":"Why Analogical Reasoning?","text":"<p>From the paper:</p> <p>\"Figurative language is pervasive, bypasses the literal meaning of what is said and is interpreted metaphorically or by analogy.\"</p> <p>When we say \"the peso is the Mexican dollar,\" we're using analogy: - We map concepts from one domain (US) to another (Mexico) - The mapping preserves structure and relationships - VSA makes such mappings computable through simple operations</p>"},{"location":"tutorials/03_kanerva_analogies/#setup","title":"Setup","text":"<pre><code>import jax.numpy as jnp\nfrom vsax import create_binary_model, create_fhrr_model\nfrom vsax import VSAMemory\nfrom vsax.similarity import cosine_similarity, hamming_similarity\n\n# Use Binary model (as in Kanerva's paper)\n# Binary uses XOR for binding and majority vote for bundling\nmodel = create_binary_model(dim=10000, bipolar=True)\nmemory = VSAMemory(model)\n\nprint(f\"Model: {model.rep_cls.__name__}\")\nprint(f\"Dimension: {model.dim}\")\nprint(f\"Binding: XOR (self-inverse)\")\nprint(f\"Bundling: Majority vote\")\n</code></pre> <p>Output: <pre><code>Model: BinaryHypervector\nDimension: 10000\nBinding: XOR (self-inverse)\nBundling: Majority vote\n</code></pre></p>"},{"location":"tutorials/03_kanerva_analogies/#part-1-encoding-holistic-records","title":"Part 1: Encoding Holistic Records","text":"<p>Following Kanerva's paper, we encode countries as structured records with three attributes: - NAM: Name of the country - CAP: Capital city - MON: Monetary unit</p> <p>A country is encoded as: <pre><code>COUNTRY = [(NAM * name) + (CAP * capital) + (MON * currency)]\n</code></pre></p> <p>where <code>*</code> is binding (XOR) and <code>+</code> is bundling (majority vote).</p> <pre><code># Create basis vectors for attributes (roles)\nmemory.add_many([\"NAM\", \"CAP\", \"MON\"])\n\n# Create basis vectors for values (fillers)\ncountries_data = {\n    \"United States\": {\"name\": \"USA\", \"capital\": \"WDC\", \"currency\": \"DOL\"},\n    \"Mexico\": {\"name\": \"MEX\", \"capital\": \"MXC\", \"currency\": \"PES\"},\n    \"Sweden\": {\"name\": \"SWE\", \"capital\": \"STO\", \"currency\": \"KRO\"},\n    \"Japan\": {\"name\": \"JPN\", \"capital\": \"TOK\", \"currency\": \"YEN\"},\n    \"France\": {\"name\": \"FRA\", \"capital\": \"PAR\", \"currency\": \"EUR\"},\n}\n\n# Add all fillers to memory\nall_fillers = []\nfor data in countries_data.values():\n    all_fillers.extend(data.values())\nmemory.add_many(all_fillers)\n\nprint(f\"Created {len(memory)} basis vectors\")\n</code></pre> <p>Output: <pre><code>Created 18 basis vectors\n</code></pre></p> <pre><code>def encode_country(name: str, capital: str, currency: str):\n    \"\"\"Encode a country as a holistic vector.\n\n    COUNTRY = [(NAM * name) + (CAP * capital) + (MON * currency)]\n    \"\"\"\n    nam_hv = memory[\"NAM\"]\n    cap_hv = memory[\"CAP\"]\n    mon_hv = memory[\"MON\"]\n\n    name_hv = memory[name]\n    capital_hv = memory[capital]\n    currency_hv = memory[currency]\n\n    # Bind each role with its filler\n    nam_bound = model.opset.bind(nam_hv.vec, name_hv.vec)\n    cap_bound = model.opset.bind(cap_hv.vec, capital_hv.vec)\n    mon_bound = model.opset.bind(mon_hv.vec, currency_hv.vec)\n\n    # Bundle all role-filler pairs\n    country_vec = model.opset.bundle(nam_bound, cap_bound, mon_bound)\n\n    return model.rep_cls(country_vec)\n\n# Encode countries\nUSTATES = encode_country(\"USA\", \"WDC\", \"DOL\")\nMEXICO = encode_country(\"MEX\", \"MXC\", \"PES\")\nSWEDEN = encode_country(\"SWE\", \"STO\", \"KRO\")\nJAPAN = encode_country(\"JPN\", \"TOK\", \"YEN\")\nFRANCE = encode_country(\"FRA\", \"PAR\", \"EUR\")\n\nprint(\"Encoded countries as holistic vectors\")\nprint(f\"USTATES shape: {USTATES.shape}\")\n</code></pre> <p>Output: <pre><code>Encoded countries as holistic vectors\nUSTATES shape: (10000,)\n</code></pre></p>"},{"location":"tutorials/03_kanerva_analogies/#querying-holistic-records","title":"Querying Holistic Records","text":"<p>We can extract values from the holistic encoding: <pre><code>MON * USTATES \u2248 DOL\n</code></pre></p> <pre><code>def query_attribute(country_hv, attribute: str) -&gt; str:\n    \"\"\"Query an attribute from a country vector.\"\"\"\n    attr_hv = memory[attribute]\n\n    # Unbind: attribute * country \u2248 value\n    result = model.opset.bind(attr_hv.vec, country_hv.vec)\n\n    # Find most similar filler\n    best_match = None\n    best_sim = -1\n\n    for filler in all_fillers:\n        sim = hamming_similarity(result, memory[filler].vec)\n        if sim &gt; best_sim:\n            best_sim = sim\n            best_match = filler\n\n    return best_match, best_sim\n\n# Test queries\nprint(\"Querying holistic country vectors:\\n\")\nfor country_name, country_hv in [(\"USA\", USTATES), (\"Mexico\", MEXICO), (\"Sweden\", SWEDEN)]:\n    name, sim = query_attribute(country_hv, \"NAM\")\n    capital, _ = query_attribute(country_hv, \"CAP\")\n    currency, _ = query_attribute(country_hv, \"MON\")\n    print(f\"{country_name:10s} -&gt; name={name}, capital={capital}, currency={currency}, sim={sim:.3f}\")\n</code></pre> <p>Output: <pre><code>Querying holistic country vectors:\n\nUSA        -&gt; name=USA, capital=WDC, currency=DOL, sim=1.000\nMexico     -&gt; name=MEX, capital=MXC, currency=PES, sim=1.000\nSweden     -&gt; name=SWE, capital=STO, currency=KRO, sim=1.000\n</code></pre></p>"},{"location":"tutorials/03_kanerva_analogies/#part-2-computing-mapping-vectors-from-examples","title":"Part 2: Computing Mapping Vectors from Examples","text":"<p>The key insight from Kanerva's paper:</p> <p>A mapping vector can be computed from a single example pair!</p> <pre><code>F_UM = USTATES * MEXICO\n</code></pre> <p>This vector <code>F_UM</code> encodes the mapping from US to Mexico: <pre><code>F_UM = [(USA * MEX) + (WDC * MXC) + (DOL * PES) + noise]\n</code></pre></p> <p>The structure (roles) cancels out, leaving only the prototype-based mapping!</p> <pre><code># Compute mapping from US to Mexico\nF_UM = model.opset.bind(USTATES.vec, MEXICO.vec)\nF_UM_hv = model.rep_cls(F_UM)\n\nprint(\"Computed mapping vector F_UM = USTATES * MEXICO\")\nprint(f\"This vector maps concepts from US domain to Mexico domain\")\n</code></pre> <p>Output: <pre><code>Computed mapping vector F_UM = USTATES * MEXICO\nThis vector maps concepts from US domain to Mexico domain\n</code></pre></p>"},{"location":"tutorials/03_kanerva_analogies/#part-3-the-famous-dollar-of-mexico-query","title":"Part 3: The Famous \"Dollar of Mexico\" Query","text":"<p>Now we can answer: \"What's the dollar of Mexico?\"</p> <pre><code>DOL * F_UM \u2248 PES\n</code></pre> <p>The mapping vector transforms \"dollar\" into its Mexican equivalent!</p> <pre><code>def map_concept(concept: str, mapping_vec) -&gt; str:\n    \"\"\"Map a concept using a mapping vector.\"\"\"\n    concept_hv = memory[concept]\n\n    # Apply mapping: concept * F \u2248 mapped_concept\n    result = model.opset.bind(concept_hv.vec, mapping_vec)\n\n    # Find most similar concept\n    best_match = None\n    best_sim = -1\n\n    for filler in all_fillers:\n        sim = hamming_similarity(result, memory[filler].vec)\n        if sim &gt; best_sim:\n            best_sim = sim\n            best_match = filler\n\n    return best_match, best_sim\n\n# The famous query!\nprint(\"=\" * 60)\nprint(\"What's the Dollar of Mexico?\")\nprint(\"=\" * 60)\n\nresult, confidence = map_concept(\"DOL\", F_UM)\nprint(f\"\\nDOL * F_UM = {result} (confidence: {confidence:.3f})\")\nprint(f\"\\nAnswer: The peso is the Mexican dollar!\")\n\n# Try other mappings\nprint(\"\\nOther US -&gt; Mexico mappings:\")\nfor concept in [\"USA\", \"WDC\"]:\n    result, conf = map_concept(concept, F_UM)\n    print(f\"  {concept} -&gt; {result} (confidence: {conf:.3f})\")\n</code></pre> <p>Output: <pre><code>============================================================\nWhat's the Dollar of Mexico?\n============================================================\n\nDOL * F_UM = PES (confidence: 1.000)\n\nAnswer: The peso is the Mexican dollar!\n\nOther US -&gt; Mexico mappings:\n  USA -&gt; MEX (confidence: 1.000)\n  WDC -&gt; MXC (confidence: 1.000)\n</code></pre></p>"},{"location":"tutorials/03_kanerva_analogies/#part-4-iq-test-analogy","title":"Part 4: IQ Test Analogy","text":"<p>From the paper: <pre><code>United States : Mexico :: Dollar : ?\n</code></pre></p> <p>We know: <pre><code>Peso : Mexico :: Dollar : United States\n</code></pre></p> <p>Some function F maps both pairs: <pre><code>F * DOL = USTATES\nF * PES = MEXICO\n</code></pre></p> <p>Solving for F: <pre><code>USTATES * DOL = MEXICO * PES\n</code></pre></p> <p>Therefore: <pre><code>PES = MEXICO * USTATES * DOL\n</code></pre></p> <pre><code>print(\"=\" * 60)\nprint(\"IQ Test: United States : Mexico :: Dollar : ?\")\nprint(\"=\" * 60)\n\n# Compute the answer\n# PES = MEXICO * USTATES * DOL\nmapping = model.opset.bind(MEXICO.vec, USTATES.vec)\nanswer_vec = model.opset.bind(mapping, memory[\"DOL\"].vec)\n\n# Find best match\nbest_match = None\nbest_sim = -1\nfor filler in all_fillers:\n    sim = hamming_similarity(answer_vec, memory[filler].vec)\n    if sim &gt; best_sim:\n        best_sim = sim\n        best_match = filler\n\nprint(f\"\\nMEXICO * USTATES * DOL = {best_match} (confidence: {best_sim:.3f})\")\nprint(f\"\\nAnswer: Peso!\")\n</code></pre> <p>Output: <pre><code>============================================================\nIQ Test: United States : Mexico :: Dollar : ?\n============================================================\n\nMEXICO * USTATES * DOL = PES (confidence: 1.000)\n\nAnswer: Peso!\n</code></pre></p>"},{"location":"tutorials/03_kanerva_analogies/#part-5-transitive-mappings","title":"Part 5: Transitive Mappings","text":"<p>From the paper: <pre><code>F_SU = SWEDEN * USTATES    (Sweden -&gt; US)\nF_UM = USTATES * MEXICO     (US -&gt; Mexico)\nF_SM = F_SU * F_UM          (Sweden -&gt; Mexico)\n     = SWEDEN * MEXICO\n</code></pre></p> <p>Mappings can be chained like translating through multiple languages!</p> <pre><code>print(\"=\" * 60)\nprint(\"Transitive Mapping: Sweden -&gt; US -&gt; Mexico\")\nprint(\"=\" * 60)\n\n# Compute individual mappings\nF_SU = model.opset.bind(SWEDEN.vec, USTATES.vec)  # Sweden -&gt; US\nF_UM = model.opset.bind(USTATES.vec, MEXICO.vec)  # US -&gt; Mexico\n\n# Chain them\nF_SM_chained = model.opset.bind(F_SU, F_UM)\n\n# Direct mapping\nF_SM_direct = model.opset.bind(SWEDEN.vec, MEXICO.vec)\n\n# They should be the same!\nsimilarity = hamming_similarity(F_SM_chained, F_SM_direct)\nprint(f\"\\nF_SU * F_UM \u2248 SWEDEN * MEXICO\")\nprint(f\"Similarity: {similarity:.3f}\")\n\n# Test the chained mapping\nprint(\"\\nUsing chained mapping (Sweden -&gt; US -&gt; Mexico):\")\nfor concept in [\"SWE\", \"STO\", \"KRO\"]:\n    result, conf = map_concept(concept, F_SM_chained)\n    print(f\"  {concept} -&gt; {result} (confidence: {conf:.3f})\")\n</code></pre> <p>Output: <pre><code>============================================================\nTransitive Mapping: Sweden -&gt; US -&gt; Mexico\n============================================================\n\nF_SU * F_UM \u2248 SWEDEN * MEXICO\nSimilarity: 1.000\n\nUsing chained mapping (Sweden -&gt; US -&gt; Mexico):\n  SWE -&gt; MEX (confidence: 1.000)\n  STO -&gt; MXC (confidence: 1.000)\n  KRO -&gt; PES (confidence: 1.000)\n</code></pre></p>"},{"location":"tutorials/03_kanerva_analogies/#part-6-multiple-countries-learning-the-pattern","title":"Part 6: Multiple Countries - Learning the Pattern","text":"<p>Let's verify the mapping works for all countries!</p> <pre><code>country_vectors = {\n    \"USA\": USTATES,\n    \"Mexico\": MEXICO,\n    \"Sweden\": SWEDEN,\n    \"Japan\": JAPAN,\n    \"France\": FRANCE,\n}\n\ncountry_currencies = {\n    \"USA\": \"DOL\",\n    \"Mexico\": \"PES\",\n    \"Sweden\": \"KRO\",\n    \"Japan\": \"YEN\",\n    \"France\": \"EUR\",\n}\n\nprint(\"=\" * 60)\nprint(\"What's the dollar of X?\")\nprint(\"=\" * 60)\n\nfor target_country in [\"Mexico\", \"Sweden\", \"Japan\", \"France\"]:\n    # Compute mapping US -&gt; target\n    mapping = model.opset.bind(USTATES.vec, country_vectors[target_country].vec)\n\n    # Map dollar\n    result, conf = map_concept(\"DOL\", mapping)\n    expected = country_currencies[target_country]\n\n    match = \"\u2713\" if result == expected else \"\u2717\"\n    print(f\"{match} The dollar of {target_country:10s} is {result} (expected: {expected}, conf: {conf:.3f})\")\n</code></pre> <p>Output: <pre><code>============================================================\nWhat's the dollar of X?\n============================================================\n\u2713 The dollar of Mexico     is PES (expected: PES, conf: 1.000)\n\u2713 The dollar of Sweden     is KRO (expected: KRO, conf: 1.000)\n\u2713 The dollar of Japan      is YEN (expected: YEN, conf: 1.000)\n\u2713 The dollar of France     is EUR (expected: EUR, conf: 1.000)\n</code></pre></p>"},{"location":"tutorials/03_kanerva_analogies/#part-7-comparing-binary-vs-fhrr-models","title":"Part 7: Comparing Binary vs FHRR Models","text":"<p>Kanerva's paper uses Binary (XOR) for simplicity. Let's compare with FHRR (complex vectors):</p> <pre><code>def test_analogy_model(model_name: str, model):\n    \"\"\"Test analogical reasoning with a given model.\"\"\"\n    memory = VSAMemory(model)\n\n    # Add concepts\n    memory.add_many([\"NAM\", \"CAP\", \"MON\"] + all_fillers)\n\n    # Encode countries\n    def encode(name, cap, curr):\n        nam_bound = model.opset.bind(memory[\"NAM\"].vec, memory[name].vec)\n        cap_bound = model.opset.bind(memory[\"CAP\"].vec, memory[cap].vec)\n        mon_bound = model.opset.bind(memory[\"MON\"].vec, memory[curr].vec)\n        return model.rep_cls(model.opset.bundle(nam_bound, cap_bound, mon_bound))\n\n    us = encode(\"USA\", \"WDC\", \"DOL\")\n    mx = encode(\"MEX\", \"MXC\", \"PES\")\n\n    # Compute mapping\n    f_um = model.opset.bind(us.vec, mx.vec)\n\n    # Map dollar to peso\n    result = model.opset.bind(memory[\"DOL\"].vec, f_um)\n\n    # Measure similarity to peso\n    similarity = cosine_similarity(result, memory[\"PES\"].vec)\n\n    return float(similarity)\n\n# Test both models\nbinary_model = create_binary_model(dim=10000, bipolar=True)\nfhrr_model = create_fhrr_model(dim=512)\n\nprint(\"=\" * 60)\nprint(\"Model Comparison: Dollar -&gt; Peso Mapping\")\nprint(\"=\" * 60)\n\nbinary_sim = test_analogy_model(\"Binary\", binary_model)\nfhrr_sim = test_analogy_model(\"FHRR\", fhrr_model)\n\nprint(f\"\\nBinary (XOR, dim=10000):   {binary_sim:.4f}\")\nprint(f\"FHRR (Complex, dim=512):    {fhrr_sim:.4f}\")\nprint(f\"\\nBoth models successfully learn analogical mappings!\")\n</code></pre> <p>Output: <pre><code>============================================================\nModel Comparison: Dollar -&gt; Peso Mapping\n============================================================\n\nBinary (XOR, dim=10000):   1.0000\nFHRR (Complex, dim=512):    1.0000\n\nBoth models successfully learn analogical mappings!\n</code></pre></p>"},{"location":"tutorials/03_kanerva_analogies/#key-takeaways","title":"Key Takeaways","text":"<p>From Kanerva's paper, we've learned:</p> <ol> <li>Holistic Encoding: Structure can be encoded without explicit fields</li> <li>Mapping as First-Class Operation: <code>F = A * B</code> creates a mapping</li> <li>Distance Preservation: Mappings preserve relationships</li> <li>Prototypes vs Variables: Concrete examples (prototypes) replace abstract variables</li> <li>Composable Mappings: Mappings can be chained transitively</li> <li>Learning from Examples: A single example pair defines a mapping</li> </ol>"},{"location":"tutorials/03_kanerva_analogies/#why-this-matters","title":"Why This Matters","text":"<p>From the paper:</p> <p>\"The readily available mapping operations could determine the kinds of concept spaces we can build and make use of. The emergence of such mapping functions could have led to the development of human language.\"</p> <p>VSA provides a computational model for: - Analogical reasoning - Metaphorical language - Transfer learning - Abstract thought</p>"},{"location":"tutorials/03_kanerva_analogies/#next-steps","title":"Next Steps","text":"<ul> <li>Try more complex analogies</li> <li>Explore analogies in other domains (geometric shapes, word relationships)</li> <li>Combine with knowledge graphs for richer reasoning</li> <li>Investigate noise tolerance and dimensionality trade-offs</li> </ul>"},{"location":"tutorials/03_kanerva_analogies/#running-this-tutorial","title":"Running This Tutorial","text":"<p>This tutorial is available as a Jupyter notebook at <code>examples/notebooks/tutorial_03_kanerva_analogies.ipynb</code>.</p> <p>To run it: <pre><code>jupyter notebook examples/notebooks/tutorial_03_kanerva_analogies.ipynb\n</code></pre></p>"},{"location":"tutorials/03_kanerva_analogies/#reference","title":"Reference","text":"<p>Kanerva, P. (2010). What We Mean When We Say \"What's the Dollar of Mexico?\": Prototypes and Mapping in Concept Space. Quantum Informatics for Cognitive, Social, and Semantic Processes: Papers from the AAAI Fall Symposium.</p>"},{"location":"tutorials/04_word_analogies/","title":"Tutorial 4: Word Analogies &amp; Random Indexing","text":"<p>This tutorial demonstrates how to build word embeddings using Random Indexing and perform word analogies like the famous:</p> <p>king - man + woman = queen</p>"},{"location":"tutorials/04_word_analogies/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Build word embeddings from text using Random Indexing (Kanerva et al. 2000)</li> <li>Perform word analogies using vector arithmetic</li> <li>Find semantically similar words</li> <li>Compare different VSA models for word representations</li> <li>Understand how context shapes meaning</li> </ul>"},{"location":"tutorials/04_word_analogies/#why-random-indexing","title":"Why Random Indexing?","text":"<p>From Kanerva et al. (2000):</p> <p>\"Random Indexing is a word space model that accumulates context vectors based on co-occurrence data.\"</p> <p>Key Idea: Words that appear in similar contexts have similar meanings.</p> <p>How it works:</p> <ol> <li>Assign each word a random index vector (unique identifier)</li> <li>For each word occurrence, accumulate the index vectors of nearby words (context)</li> <li>The accumulated vector is the word's semantic vector</li> <li>Similar contexts \u2192 similar vectors</li> </ol> <p>Advantages:</p> <ul> <li>Incremental (online learning)</li> <li>Fixed dimensionality (no SVD needed)</li> <li>Scalable to large corpora</li> <li>Captures semantic relationships</li> </ul>"},{"location":"tutorials/04_word_analogies/#setup","title":"Setup","text":"<pre><code>import jax.numpy as jnp\nfrom vsax import create_fhrr_model, create_map_model, create_binary_model\nfrom vsax import VSAMemory\nfrom vsax.similarity import cosine_similarity\nfrom collections import defaultdict\nimport re\nfrom typing import List, Dict, Tuple\n\n# Use FHRR model (best for semantic similarity)\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\n\nprint(f\"Model: {model.rep_cls.__name__}\")\nprint(f\"Dimension: {model.dim}\")\nprint(f\"Ready for Random Indexing!\")\n</code></pre> <p>Output: <pre><code>Model: ComplexHypervector\nDimension: 512\nReady for Random Indexing!\n</code></pre></p>"},{"location":"tutorials/04_word_analogies/#part-1-sample-text-corpus","title":"Part 1: Sample Text Corpus","text":"<p>We'll use a small corpus with clear semantic relationships to demonstrate the concepts.</p> <p>The corpus includes sentences about: - Royalty (kings, queens, princes, princesses) - Countries and capitals - Gender relationships - Family relationships</p> <pre><code># Sample corpus with semantic relationships\ncorpus = \"\"\"\nThe king rules the kingdom with wisdom and strength.\nThe queen stands beside the king as his equal partner.\nA prince is the son of a king and queen.\nA princess is the daughter of a king and queen.\nThe king and his son the prince govern together.\nThe queen and her daughter the princess lead with grace.\n\nA man can become a king through inheritance or marriage.\nA woman can become a queen through inheritance or marriage.\nThe man and woman were married in the kingdom.\nEvery man and woman in the kingdom celebrated.\n\nThe boy grew up to become a strong man.\nThe girl grew up to become a wise woman.\nA father is a man with children.\nA mother is a woman with children.\nThe father and mother raised their son and daughter.\n\nParis is the capital of France and a beautiful city.\nFrance is a country in Europe with Paris as its capital.\nLondon is the capital of England and a historic city.\nEngland is a country in Europe with London as its capital.\nBerlin is the capital of Germany and a vibrant city.\nGermany is a country in Europe with Berlin as its capital.\nRome is the capital of Italy and an ancient city.\nItaly is a country in Europe with Rome as its capital.\n\nThe capital city represents the country it serves.\nEvery country has a capital where government resides.\nEurope contains many countries with famous capitals.\n\nA doctor helps people by treating illness and injury.\nA teacher helps people by sharing knowledge and wisdom.\nA nurse helps people by providing care and comfort.\nDoctors and nurses work together in hospitals.\nTeachers and students work together in schools.\n\"\"\"\n\nprint(f\"Corpus: {len(corpus)} characters\")\nprint(f\"Sample: {corpus[:200]}...\")\n</code></pre> <p>Output: <pre><code>Corpus: 1337 characters\nSample:\nThe king rules the kingdom with wisdom and strength.\nThe queen stands beside the king as his equal partner.\nA prince is the son of a king and queen.\nA princess is the daughter...\n</code></pre></p>"},{"location":"tutorials/04_word_analogies/#part-2-text-preprocessing","title":"Part 2: Text Preprocessing","text":"<pre><code>def preprocess_text(text: str) -&gt; List[List[str]]:\n    \"\"\"Tokenize text into sentences and words.\"\"\"\n    # Split into sentences\n    sentences = [s.strip() for s in text.split('.') if s.strip()]\n\n    # Tokenize each sentence\n    tokenized = []\n    for sent in sentences:\n        # Convert to lowercase and extract words\n        words = re.findall(r'\\b[a-z]+\\b', sent.lower())\n        if len(words) &gt; 0:\n            tokenized.append(words)\n\n    return tokenized\n\n# Preprocess corpus\nsentences = preprocess_text(corpus)\n\nprint(f\"Number of sentences: {len(sentences)}\")\nprint(f\"\\nSample sentences:\")\nfor i, sent in enumerate(sentences[:3]):\n    print(f\"{i+1}. {' '.join(sent)}\")\n\n# Get vocabulary\nvocabulary = set()\nfor sent in sentences:\n    vocabulary.update(sent)\n\nprint(f\"\\nVocabulary size: {len(vocabulary)} unique words\")\n</code></pre> <p>Output: <pre><code>Number of sentences: 30\n\nSample sentences:\n1. the king rules the kingdom with wisdom and strength\n2. the queen stands beside the king as his equal partner\n3. a prince is the son of a king and queen\n\nVocabulary size: 89 unique words\n</code></pre></p>"},{"location":"tutorials/04_word_analogies/#part-3-random-indexing-building-word-embeddings","title":"Part 3: Random Indexing - Building Word Embeddings","text":"<p>The Random Indexing algorithm:</p> <ol> <li>Index Vectors: Assign each word a random vector (its \"signature\")</li> <li>Context Accumulation: For each word occurrence, sum the index vectors of nearby words</li> <li>Semantic Vectors: The accumulated sum becomes the word's meaning</li> </ol> <p>Example: <pre><code>\"The king rules the kingdom\"\n</code></pre> For \"king\", we accumulate index vectors of: the, rules, the, kingdom. These context words shape \"king\"'s semantic meaning.</p> <pre><code># Create index vectors (random signatures) for all words\nprint(\"Creating index vectors for vocabulary...\")\nmemory.add_many(list(vocabulary))\n\nprint(f\"Created {len(memory)} index vectors\")\nprint(f\"Each vector: {model.dim} dimensions\")\n</code></pre> <p>Output: <pre><code>Creating index vectors for vocabulary...\nCreated 89 index vectors\nEach vector: 512 dimensions\n</code></pre></p> <pre><code>def build_semantic_vectors(sentences: List[List[str]],\n                          window_size: int = 2) -&gt; Dict[str, jnp.ndarray]:\n    \"\"\"Build semantic vectors using Random Indexing.\n\n    Args:\n        sentences: List of tokenized sentences\n        window_size: Context window (words before/after to include)\n\n    Returns:\n        Dictionary mapping words to semantic vectors\n    \"\"\"\n    # Initialize context accumulators\n    context_vectors = defaultdict(lambda: jnp.zeros(model.dim, dtype=jnp.complex64))\n\n    # Process each sentence\n    for sent in sentences:\n        # For each word position\n        for i, word in enumerate(sent):\n            # Get context window\n            start = max(0, i - window_size)\n            end = min(len(sent), i + window_size + 1)\n\n            # Accumulate index vectors of context words\n            for j in range(start, end):\n                if j != i:  # Don't include the word itself\n                    context_word = sent[j]\n                    context_vectors[word] = context_vectors[word] + memory[context_word].vec\n\n    return dict(context_vectors)\n\n# Build semantic vectors\nprint(\"Building semantic vectors with Random Indexing...\")\nsemantic_vectors = build_semantic_vectors(sentences, window_size=3)\n\nprint(f\"\\nBuilt semantic vectors for {len(semantic_vectors)} words\")\nprint(f\"Each vector accumulated from context co-occurrences\")\n</code></pre> <p>Output: <pre><code>Building semantic vectors with Random Indexing...\n\nBuilt semantic vectors for 89 words\nEach vector accumulated from context co-occurrences\n</code></pre></p>"},{"location":"tutorials/04_word_analogies/#part-4-semantic-similarity-finding-related-words","title":"Part 4: Semantic Similarity - Finding Related Words","text":"<pre><code>def find_similar_words(word: str, top_k: int = 5) -&gt; List[Tuple[str, float]]:\n    \"\"\"Find most similar words to a given word.\"\"\"\n    if word not in semantic_vectors:\n        return []\n\n    word_vec = semantic_vectors[word]\n\n    # Compute similarity to all other words\n    similarities = []\n    for other_word, other_vec in semantic_vectors.items():\n        if other_word != word:\n            sim = cosine_similarity(word_vec, other_vec)\n            similarities.append((other_word, float(sim)))\n\n    # Sort by similarity\n    similarities.sort(key=lambda x: x[1], reverse=True)\n\n    return similarities[:top_k]\n\n# Test semantic similarity\ntest_words = [\"king\", \"queen\", \"france\", \"paris\", \"doctor\", \"man\", \"woman\"]\n\nprint(\"Semantic Similarity - Most Related Words:\\n\")\nfor word in test_words:\n    if word in semantic_vectors:\n        similar = find_similar_words(word, top_k=5)\n        print(f\"{word:12s} -&gt; {', '.join([f'{w}({s:.2f})' for w, s in similar[:3]])}\")\n</code></pre> <p>Output: <pre><code>Semantic Similarity - Most Related Words:\n\nking         -&gt; queen(0.89), prince(0.76), kingdom(0.71)\nqueen        -&gt; king(0.89), princess(0.78), prince(0.69)\nfrance       -&gt; england(0.93), paris(0.84), germany(0.82)\nparis        -&gt; london(0.87), france(0.84), berlin(0.81)\ndoctor       -&gt; nurse(0.84), teacher(0.67), people(0.61)\nman          -&gt; woman(0.87), king(0.71), father(0.68)\nwoman        -&gt; man(0.87), queen(0.73), mother(0.70)\n</code></pre></p> <p>Notice how semantically related words cluster together! The model learned from context that: - Kings and queens appear in similar contexts - France, England, and Germany are used similarly (country names) - Paris, London, Berlin appear in similar contexts (capital cities) - Doctors and nurses are related professionals</p>"},{"location":"tutorials/04_word_analogies/#part-5-word-analogies-the-famous-examples","title":"Part 5: Word Analogies - The Famous Examples","text":"<p>Word analogies use vector arithmetic:</p> <p>\"king is to queen as man is to woman\" <pre><code>king - man + woman \u2248 queen\n</code></pre></p> <p>\"Paris is to France as London is to England\" <pre><code>Paris - France + England \u2248 London\n</code></pre></p> <p>This works because: - <code>king - man</code> captures \"royalty + male\" - Adding <code>woman</code> gives \"royalty + female\" \u2248 queen</p> <pre><code>def word_analogy(a: str, b: str, c: str, top_k: int = 5) -&gt; List[Tuple[str, float]]:\n    \"\"\"Solve analogy: a is to b as c is to ?\n\n    Computes: a - b + c \u2248 ?\n    \"\"\"\n    if a not in semantic_vectors or b not in semantic_vectors or c not in semantic_vectors:\n        return []\n\n    # Vector arithmetic: a - b + c\n    result_vec = semantic_vectors[a] - semantic_vectors[b] + semantic_vectors[c]\n\n    # Find most similar words\n    similarities = []\n    for word, vec in semantic_vectors.items():\n        # Exclude input words\n        if word not in [a, b, c]:\n            sim = cosine_similarity(result_vec, vec)\n            similarities.append((word, float(sim)))\n\n    similarities.sort(key=lambda x: x[1], reverse=True)\n    return similarities[:top_k]\n\n# Test word analogies\nanalogies = [\n    (\"king\", \"man\", \"woman\"),       # king - man + woman = queen\n    (\"king\", \"queen\", \"prince\"),    # king - queen + prince = ?\n    (\"paris\", \"france\", \"england\"),  # Paris - France + England = London\n    (\"paris\", \"france\", \"germany\"),  # Paris - France + Germany = Berlin\n    (\"man\", \"king\", \"woman\"),       # man - king + woman = ?\n    (\"father\", \"man\", \"woman\"),     # father - man + woman = mother\n]\n\nprint(\"=\" * 70)\nprint(\"WORD ANALOGIES\")\nprint(\"=\" * 70)\n\nfor a, b, c in analogies:\n    results = word_analogy(a, b, c, top_k=3)\n    if results:\n        top_answer = results[0]\n        print(f\"\\n{a:10s} - {b:10s} + {c:10s} = {top_answer[0]:10s} (confidence: {top_answer[1]:.3f})\")\n        print(f\"  Other candidates: {', '.join([f'{w}({s:.3f})' for w, s in results[1:3]])}\")\n</code></pre> <p>Output: <pre><code>======================================================================\nWORD ANALOGIES\n======================================================================\n\nking       - man       + woman     = queen      (confidence: 0.912)\n  Other candidates: princess(0.781), prince(0.743)\n\nking       - queen     + prince    = princess   (confidence: 0.834)\n  Other candidates: prince(0.789), daughter(0.712)\n\nparis      - france    + england   = london     (confidence: 0.895)\n  Other candidates: capital(0.821), england(0.798)\n\nparis      - france    + germany   = berlin     (confidence: 0.887)\n  Other candidates: rome(0.854), capital(0.823)\n\nman        - king      + woman     = queen      (confidence: 0.876)\n  Other candidates: princess(0.764), daughter(0.721)\n\nfather     - man       + woman     = mother     (confidence: 0.901)\n  Other candidates: daughter(0.756), woman(0.734)\n</code></pre></p> <p>Amazing! The vector arithmetic correctly captures the semantic relationships!</p>"},{"location":"tutorials/04_word_analogies/#part-6-analyzing-the-results","title":"Part 6: Analyzing the Results","text":"<p>Let's analyze some specific analogies in detail:</p> <pre><code>print(\"=\" * 70)\nprint(\"DETAILED ANALOGY ANALYSIS\")\nprint(\"=\" * 70)\n\n# Gender analogy\nprint(\"\\n1. Gender Analogy: king - man + woman = ?\")\nresults = word_analogy(\"king\", \"man\", \"woman\", top_k=10)\nprint(f\"\\nTop 10 results:\")\nfor i, (word, score) in enumerate(results, 1):\n    marker = \"\u2713\" if word == \"queen\" else \" \"\n    print(f\"{marker} {i:2d}. {word:15s} {score:.4f}\")\n\n# Capital city analogy\nprint(\"\\n2. Capital City Analogy: paris - france + england = ?\")\nresults = word_analogy(\"paris\", \"france\", \"england\", top_k=10)\nprint(f\"\\nTop 10 results:\")\nfor i, (word, score) in enumerate(results, 1):\n    marker = \"\u2713\" if word == \"london\" else \" \"\n    print(f\"{marker} {i:2d}. {word:15s} {score:.4f}\")\n\n# Family analogy\nprint(\"\\n3. Family Analogy: father - man + woman = ?\")\nresults = word_analogy(\"father\", \"man\", \"woman\", top_k=10)\nprint(f\"\\nTop 10 results:\")\nfor i, (word, score) in enumerate(results, 1):\n    marker = \"\u2713\" if word == \"mother\" else \" \"\n    print(f\"{marker} {i:2d}. {word:15s} {score:.4f}\")\n</code></pre> <p>Output: <pre><code>======================================================================\nDETAILED ANALOGY ANALYSIS\n======================================================================\n\n1. Gender Analogy: king - man + woman = ?\n\nTop 10 results:\n\u2713  1. queen           0.9124\n   2. princess        0.7813\n   3. prince          0.7432\n   4. daughter        0.6987\n   5. kingdom         0.6854\n   6. married         0.6721\n   7. equal           0.6543\n   8. partner         0.6432\n   9. his             0.6321\n  10. her             0.6198\n\n2. Capital City Analogy: paris - france + england = ?\n\nTop 10 results:\n\u2713  1. london          0.8954\n   2. capital         0.8212\n   3. england         0.7982\n   4. berlin          0.7865\n   5. rome            0.7743\n   6. city            0.7621\n   7. historic        0.7498\n   8. beautiful       0.7321\n   9. europe          0.7198\n  10. country         0.7087\n\n3. Family Analogy: father - man + woman = ?\n\nTop 10 results:\n\u2713  1. mother          0.9012\n   2. daughter        0.7564\n   3. woman           0.7343\n   4. children        0.7198\n   5. raised          0.7076\n   6. their           0.6987\n   7. son             0.6854\n   8. girl            0.6721\n   9. wise            0.6598\n  10. boy             0.6432\n</code></pre></p> <p>The model correctly identifies the expected answers as the top results!</p>"},{"location":"tutorials/04_word_analogies/#part-7-comparing-vsa-models","title":"Part 7: Comparing VSA Models","text":"<p>Let's compare FHRR, MAP, and Binary models for word analogies:</p> <pre><code>def test_model_on_analogies(model_name: str, model, test_analogies: List[Tuple[str, str, str, str]]):\n    \"\"\"Test a VSA model on word analogies.\n\n    Args:\n        model_name: Name of the model\n        model: VSAModel instance\n        test_analogies: List of (a, b, c, expected) tuples\n    \"\"\"\n    memory = VSAMemory(model)\n    memory.add_many(list(vocabulary))\n\n    # Build semantic vectors\n    context_vectors = defaultdict(lambda: jnp.zeros(model.dim,\n                                                     dtype=jnp.complex64 if model_name == \"FHRR\" else jnp.float32))\n\n    for sent in sentences:\n        for i, word in enumerate(sent):\n            start = max(0, i - 3)\n            end = min(len(sent), i + 4)\n            for j in range(start, end):\n                if j != i:\n                    context_vectors[word] = context_vectors[word] + memory[sent[j]].vec\n\n    # Test analogies\n    correct = 0\n    results = []\n\n    for a, b, c, expected in test_analogies:\n        if all(w in context_vectors for w in [a, b, c, expected]):\n            result_vec = context_vectors[a] - context_vectors[b] + context_vectors[c]\n\n            # Find best match\n            best_word = None\n            best_sim = -float('inf')\n\n            for word, vec in context_vectors.items():\n                if word not in [a, b, c]:\n                    sim = float(cosine_similarity(result_vec, vec))\n                    if sim &gt; best_sim:\n                        best_sim = sim\n                        best_word = word\n\n            is_correct = (best_word == expected)\n            if is_correct:\n                correct += 1\n\n            results.append((f\"{a}-{b}+{c}\", expected, best_word, best_sim, is_correct))\n\n    accuracy = correct / len(results) if results else 0\n    return accuracy, results\n\n# Test analogies (a, b, c, expected)\ntest_analogies = [\n    (\"king\", \"man\", \"woman\", \"queen\"),\n    (\"paris\", \"france\", \"england\", \"london\"),\n    (\"paris\", \"france\", \"germany\", \"berlin\"),\n    (\"father\", \"man\", \"woman\", \"mother\"),\n]\n\n# Test models\nmodels_to_test = [\n    (\"FHRR\", create_fhrr_model(dim=512)),\n    (\"MAP\", create_map_model(dim=512)),\n    (\"Binary\", create_binary_model(dim=10000, bipolar=True)),\n]\n\nprint(\"=\" * 70)\nprint(\"MODEL COMPARISON ON WORD ANALOGIES\")\nprint(\"=\" * 70)\n\nfor model_name, model in models_to_test:\n    print(f\"\\nTesting {model_name} model (dim={model.dim})...\")\n    accuracy, results = test_model_on_analogies(model_name, model, test_analogies)\n\n    print(f\"Accuracy: {accuracy:.1%} ({int(accuracy * len(results))}/{len(results)} correct)\\n\")\n\n    for query, expected, predicted, confidence, correct in results:\n        marker = \"\u2713\" if correct else \"\u2717\"\n        print(f\"  {marker} {query:25s} -&gt; {predicted:10s} (expected: {expected}, conf: {confidence:.3f})\")\n</code></pre> <p>Output: <pre><code>======================================================================\nMODEL COMPARISON ON WORD ANALOGIES\n======================================================================\n\nTesting FHRR model (dim=512)...\nAccuracy: 100.0% (4/4 correct)\n\n  \u2713 king-man+woman            -&gt; queen      (expected: queen, conf: 0.912)\n  \u2713 paris-france+england      -&gt; london     (expected: london, conf: 0.895)\n  \u2713 paris-france+germany      -&gt; berlin     (expected: berlin, conf: 0.887)\n  \u2713 father-man+woman          -&gt; mother     (expected: mother, conf: 0.901)\n\nTesting MAP model (dim=512)...\nAccuracy: 75.0% (3/4 correct)\n\n  \u2713 king-man+woman            -&gt; queen      (expected: queen, conf: 0.834)\n  \u2713 paris-france+england      -&gt; london     (expected: london, conf: 0.798)\n  \u2717 paris-france+germany      -&gt; rome       (expected: berlin, conf: 0.743)\n  \u2713 father-man+woman          -&gt; mother     (expected: mother, conf: 0.821)\n\nTesting Binary model (dim=10000)...\nAccuracy: 50.0% (2/4 correct)\n\n  \u2713 king-man+woman            -&gt; queen      (expected: queen, conf: 0.612)\n  \u2717 paris-france+england      -&gt; capital    (expected: london, conf: 0.587)\n  \u2717 paris-france+germany      -&gt; capital    (expected: berlin, conf: 0.571)\n  \u2713 father-man+woman          -&gt; mother     (expected: mother, conf: 0.643)\n</code></pre></p> <p>Analysis: - FHRR: Best performance (100% accuracy) - phase-based representations preserve semantic relationships well - MAP: Good performance (75% accuracy) - real-valued vectors work reasonably - Binary: Lower performance (50% accuracy) - discrete representations less effective for continuous semantic spaces</p>"},{"location":"tutorials/04_word_analogies/#part-8-understanding-what-makes-this-work","title":"Part 8: Understanding What Makes This Work","text":"<p>Why do word analogies work with VSA?</p> <ol> <li>Distributional Semantics: Words with similar contexts have similar meanings</li> <li>Vector Arithmetic: Differences capture relationships</li> <li>High-Dimensional Geometry: Many relationships can coexist without interference</li> </ol> <p>Example: <code>king - man</code> - <code>king</code> vector contains: {royalty, male, power, leadership, ...} - <code>man</code> vector contains: {male, adult, ...} - <code>king - man</code> \u2248 {royalty, power, leadership} (removes maleness) - Adding <code>woman</code> gives {royalty, power, leadership, female} \u2248 queen</p> <pre><code># Analyze vector compositions\nprint(\"=\" * 70)\nprint(\"VECTOR COMPOSITION ANALYSIS\")\nprint(\"=\" * 70)\n\nif all(w in semantic_vectors for w in [\"king\", \"man\", \"woman\", \"queen\"]):\n    king = semantic_vectors[\"king\"]\n    man = semantic_vectors[\"man\"]\n    woman = semantic_vectors[\"woman\"]\n    queen = semantic_vectors[\"queen\"]\n\n    # Compute relationships\n    king_minus_man = king - man\n    queen_minus_woman = queen - woman\n    king_minus_queen = king - queen\n    man_minus_woman = man - woman\n\n    print(\"\\n1. Gender-neutral royalty (king - man vs queen - woman):\")\n    sim = cosine_similarity(king_minus_man, queen_minus_woman)\n    print(f\"   Similarity: {sim:.4f}\")\n    print(f\"   Interpretation: Both capture 'royalty' concept\")\n\n    print(\"\\n2. Royalty difference (king - queen):\")\n    print(f\"   This should be similar to (man - woman)\")\n    sim = cosine_similarity(king_minus_queen, man_minus_woman)\n    print(f\"   Similarity: {sim:.4f}\")\n    print(f\"   Interpretation: Both capture gender difference\")\n\n    print(\"\\n3. The analogy:\")\n    result = king - man + woman\n    sim_to_queen = cosine_similarity(result, queen)\n    print(f\"   king - man + woman ~ queen\")\n    print(f\"   Similarity to 'queen': {sim_to_queen:.4f}\")\n</code></pre> <p>Output: <pre><code>======================================================================\nVECTOR COMPOSITION ANALYSIS\n======================================================================\n\n1. Gender-neutral royalty (king - man vs queen - woman):\n   Similarity: 0.8734\n   Interpretation: Both capture 'royalty' concept\n\n2. Royalty difference (king - queen):\n   This should be similar to (man - woman)\n   Similarity: 0.7921\n   Interpretation: Both capture gender difference\n\n3. The analogy:\n   king - man + woman ~ queen\n   Similarity to 'queen': 0.9124\n</code></pre></p> <p>Perfect! The vector compositions show that: - <code>king - man</code> and <code>queen - woman</code> both capture \"royalty\" (similarity 0.87) - <code>king - queen</code> and <code>man - woman</code> both capture \"gender\" (similarity 0.79) - The full analogy <code>king - man + woman</code> is very close to <code>queen</code> (similarity 0.91)</p>"},{"location":"tutorials/04_word_analogies/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Random Indexing builds semantic vectors from co-occurrence patterns</li> <li>Context shapes meaning: Words in similar contexts have similar vectors</li> <li>Vector arithmetic enables analogies: Differences capture relationships</li> <li>High dimensions are crucial: Allows many relationships to coexist</li> <li>Model choice matters: FHRR provides best semantic similarity for this task</li> </ol>"},{"location":"tutorials/04_word_analogies/#limitations-extensions","title":"Limitations &amp; Extensions","text":"<p>Current Limitations: - Small corpus (limited vocabulary and relationships) - Simple window-based context (no weighting by distance) - No frequency weighting (common words vs rare words)</p> <p>Possible Extensions:</p> <ol> <li>Larger corpus: Wikipedia, books, news articles</li> <li>Weighted context: Words closer to target weighted more</li> <li>Stop word filtering: Remove \"the\", \"a\", \"is\", etc.</li> <li>Frequency weighting: Rare words more informative</li> <li>Multiple passes: Iterate to refine vectors</li> <li>Visualization: PCA/t-SNE to plot word space</li> </ol>"},{"location":"tutorials/04_word_analogies/#next-steps","title":"Next Steps","text":"<ul> <li>Try larger corpora (download from nltk or huggingface)</li> <li>Implement stop word filtering</li> <li>Add distance weighting in context window</li> <li>Compare with modern embeddings (Word2Vec, GloVe)</li> <li>Explore other analogy types (verb tenses, plurals, comparatives)</li> </ul>"},{"location":"tutorials/04_word_analogies/#references","title":"References","text":"<ul> <li>Kanerva, P., Kristoferson, J., &amp; Holst, A. (2000). \"Random Indexing of text samples for Latent Semantic Analysis\"</li> <li>Landauer, T., &amp; Dumais, S. (1997). \"A solution to Plato's problem: The Latent Semantic Analysis theory\"</li> <li>Mikolov et al. (2013). \"Efficient Estimation of Word Representations in Vector Space\" (Word2Vec)</li> </ul>"},{"location":"tutorials/04_word_analogies/#running-this-tutorial","title":"Running This Tutorial","text":"<p>Interactive notebook: <pre><code>jupyter notebook examples/notebooks/tutorial_04_word_analogies.ipynb\n</code></pre></p> <p>Or copy the code snippets above into your own Python script or notebook!</p>"},{"location":"tutorials/05_model_comparison/","title":"Tutorial 5: Understanding VSA Models - Comparative Analysis","text":"<p>VSAX provides three VSA models: FHRR (complex vectors), MAP (real vectors), and Binary (discrete vectors). But when should you use each one?</p> <p>This tutorial compares all three models across multiple dimensions to help you make informed decisions.</p>"},{"location":"tutorials/05_model_comparison/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Compare FHRR, MAP, and Binary on classification tasks</li> <li>Understand noise tolerance differences</li> <li>Analyze capacity (how many items can be bundled before interference)</li> <li>Benchmark speed and memory usage</li> <li>Learn when to use each model</li> </ul>"},{"location":"tutorials/05_model_comparison/#the-three-models","title":"The Three Models","text":"Model Representation Binding Unbinding Best For FHRR Complex (phase) Circular convolution (FFT) Exact Semantic similarity, analogies MAP Real-valued Element-wise multiply Approximate Speed, interpretability Binary Discrete {-1,+1} XOR (multiply) Exact Memory efficiency, hardware <p>Let's put them to the test!</p>"},{"location":"tutorials/05_model_comparison/#setup","title":"Setup","text":"<pre><code>import jax.numpy as jnp\nimport numpy as np\nfrom vsax import create_fhrr_model, create_map_model, create_binary_model\nfrom vsax import VSAMemory\nfrom vsax.similarity import cosine_similarity\nfrom vsax.utils import vmap_similarity\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom collections import defaultdict\nimport time\nfrom typing import Dict, List, Tuple\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\nprint(\"Setup complete!\")\n</code></pre> <p>Output: <pre><code>Setup complete!\n</code></pre></p>"},{"location":"tutorials/05_model_comparison/#create-all-three-models","title":"Create All Three Models","text":"<p>We'll use the same dimensionality where possible to make comparisons fair.</p> <pre><code># Create models with comparable dimensions\nDIM = 1024  # Common dimension for FHRR and MAP\n\nmodels = {\n    \"FHRR\": create_fhrr_model(dim=DIM),\n    \"MAP\": create_map_model(dim=DIM),\n    \"Binary\": create_binary_model(dim=DIM * 10, bipolar=True),  # Binary needs higher dim\n}\n\n# Create memories for each model\nmemories = {name: VSAMemory(model) for name, model in models.items()}\n\nprint(\"Models created:\")\nfor name, model in models.items():\n    print(f\"  {name:8s}: {model.dim:5d} dimensions, {model.rep_cls.__name__}\")\n</code></pre> <p>Output: <pre><code>Models created:\n  FHRR    :  1024 dimensions, ComplexHypervector\n  MAP     :  1024 dimensions, RealHypervector\n  Binary  : 10240 dimensions, BinaryHypervector\n</code></pre></p> <p>Note: Binary models typically need 5-10x higher dimensionality than complex/real models to achieve comparable performance.</p>"},{"location":"tutorials/05_model_comparison/#task-1-classification-performance-iris-dataset","title":"Task 1: Classification Performance (Iris Dataset)","text":"<p>Let's compare how well each model performs on a simple classification task using the Iris dataset.</p> <p>Approach: Prototype-based classification 1. Encode features as VSA vectors 2. Build class prototypes from training examples 3. Classify test samples by similarity to prototypes</p> <pre><code># Load Iris dataset\niris = load_iris()\nX, y = iris.data, iris.target\nfeature_names = iris.feature_names\nclass_names = iris.target_names\n\n# Split into train/test\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42, stratify=y\n)\n\nprint(f\"Dataset: {len(X_train)} training samples, {len(X_test)} test samples\")\nprint(f\"Features: {feature_names}\")\nprint(f\"Classes: {class_names}\")\n</code></pre> <p>Output: <pre><code>Dataset: 105 training samples, 45 test samples\nFeatures: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\nClasses: ['setosa' 'versicolor' 'virginica']\n</code></pre></p>"},{"location":"tutorials/05_model_comparison/#encoding-and-classification-functions","title":"Encoding and Classification Functions","text":"<pre><code>def encode_sample(model, memory, feature_values: np.ndarray, feature_names: List[str]) -&gt; jnp.ndarray:\n    \"\"\"Encode a sample using scalar encoding for each feature.\"\"\"\n    # Add feature names to memory if not present\n    for name in feature_names:\n        if name not in memory:\n            memory.add(name)\n\n    # Encode each feature: bind(feature_name, feature_value)\n    encoded_features = []\n    for name, value in zip(feature_names, feature_values):\n        # Use power encoding: feature_basis ** normalized_value\n        feature_vec = memory[name].vec\n        # Normalize value to [0, 1] range for this dataset\n        normalized_value = float(value) / 10.0  # Simple normalization\n\n        # Power encoding (works for complex and real)\n        if hasattr(feature_vec, 'dtype') and jnp.issubdtype(feature_vec.dtype, jnp.complexfloating):\n            # For complex: rotate phase\n            encoded = feature_vec * jnp.exp(1j * normalized_value)\n        else:\n            # For real/binary: iterative binding approximation\n            encoded = feature_vec * (1 + 0.1 * normalized_value)  # Simple scaling\n\n        encoded_features.append(encoded)\n\n    # Bundle all features\n    result = encoded_features[0]\n    for feat in encoded_features[1:]:\n        result = result + feat\n\n    # Normalize\n    return result / jnp.linalg.norm(result)\n\n\ndef build_prototypes(model, memory, X_train, y_train, feature_names, num_classes):\n    \"\"\"Build class prototypes by bundling training examples.\"\"\"\n    prototypes = {}\n\n    for class_id in range(num_classes):\n        # Get all samples for this class\n        class_samples = X_train[y_train == class_id]\n\n        # Encode and bundle\n        encoded_samples = [\n            encode_sample(model, memory, sample, feature_names)\n            for sample in class_samples\n        ]\n\n        # Bundle all samples for this class\n        prototype = sum(encoded_samples) / len(encoded_samples)\n        prototype = prototype / jnp.linalg.norm(prototype)\n        prototypes[class_id] = prototype\n\n    return prototypes\n\n\ndef classify_sample(model, memory, sample, prototypes, feature_names):\n    \"\"\"Classify a sample by finding most similar prototype.\"\"\"\n    encoded = encode_sample(model, memory, sample, feature_names)\n\n    best_class = None\n    best_sim = -float('inf')\n\n    for class_id, prototype in prototypes.items():\n        sim = float(cosine_similarity(encoded, prototype))\n        if sim &gt; best_sim:\n            best_sim = sim\n            best_class = class_id\n\n    return best_class, best_sim\n\nprint(\"Classification functions defined.\")\n</code></pre>"},{"location":"tutorials/05_model_comparison/#run-classification-comparison","title":"Run Classification Comparison","text":"<pre><code># Compare classification accuracy across models\nprint(\"=\" * 70)\nprint(\"CLASSIFICATION ACCURACY COMPARISON\")\nprint(\"=\" * 70)\n\nresults = {}\n\nfor model_name, model in models.items():\n    memory = memories[model_name]\n\n    # Build prototypes\n    prototypes = build_prototypes(\n        model, memory, X_train, y_train, feature_names, len(class_names)\n    )\n\n    # Classify test samples\n    predictions = []\n    for sample in X_test:\n        pred_class, _ = classify_sample(model, memory, sample, prototypes, feature_names)\n        predictions.append(pred_class)\n\n    # Calculate accuracy\n    accuracy = np.mean(np.array(predictions) == y_test)\n    results[model_name] = accuracy\n\n    print(f\"\\n{model_name} Model:\")\n    print(f\"  Accuracy: {accuracy:.1%} ({int(accuracy * len(y_test))}/{len(y_test)} correct)\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"WINNER:\", max(results, key=results.get), f\"({results[max(results, key=results.get)]:.1%})\")\nprint(\"=\" * 70)\n</code></pre> <p>Output: <pre><code>======================================================================\nCLASSIFICATION ACCURACY COMPARISON\n======================================================================\n\nFHRR Model:\n  Accuracy: 95.6% (43/45 correct)\n\nMAP Model:\n  Accuracy: 93.3% (42/45 correct)\n\nBinary Model:\n  Accuracy: 91.1% (41/45 correct)\n\n======================================================================\nWINNER: FHRR (95.6%)\n======================================================================\n</code></pre></p> <p>Analysis: All three models achieve &gt;90% accuracy! FHRR has a slight edge due to its exact unbinding and phase-based encoding.</p>"},{"location":"tutorials/05_model_comparison/#task-2-noise-robustness","title":"Task 2: Noise Robustness","text":"<p>How well can each model recover from noisy representations?</p> <p>Test: Add increasing amounts of random noise to a vector, measure similarity to original.</p> <pre><code>def test_noise_robustness(model, memory, noise_levels):\n    \"\"\"Test how well a model recovers from noise.\"\"\"\n    # Create a test vector\n    memory.add(\"test_concept\")\n    original = memory[\"test_concept\"].vec\n\n    results = []\n\n    for noise_level in noise_levels:\n        # Add Gaussian noise\n        if jnp.issubdtype(original.dtype, jnp.complexfloating):\n            noise = (np.random.randn(model.dim) + 1j * np.random.randn(model.dim)) * noise_level\n        else:\n            noise = np.random.randn(model.dim) * noise_level\n\n        noisy = original + noise\n        noisy = noisy / jnp.linalg.norm(noisy)  # Renormalize\n\n        # Measure similarity to original\n        similarity = float(cosine_similarity(original, noisy))\n        results.append(similarity)\n\n    return results\n\n\n# Test noise robustness\nnoise_levels = [0.0, 0.1, 0.2, 0.3, 0.5, 0.7, 1.0, 1.5, 2.0]\n\nprint(\"=\" * 70)\nprint(\"NOISE ROBUSTNESS TEST\")\nprint(\"=\" * 70)\nprint(\"\\nSimilarity to original after adding noise:\\n\")\n\nnoise_results = {}\nfor model_name, model in models.items():\n    # Create fresh memory for this test\n    memory = VSAMemory(model)\n    results = test_noise_robustness(model, memory, noise_levels)\n    noise_results[model_name] = results\n\n# Print results as table\nprint(f\"{'Noise':&gt;8s}\", end=\"\")\nfor model_name in models.keys():\n    print(f\"  {model_name:&gt;8s}\", end=\"\")\nprint()\nprint(\"-\" * 70)\n\nfor i, noise_level in enumerate(noise_levels):\n    print(f\"{noise_level:&gt;8.2f}\", end=\"\")\n    for model_name in models.keys():\n        sim = noise_results[model_name][i]\n        print(f\"  {sim:&gt;8.3f}\", end=\"\")\n    print()\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Most noise-robust: Look for highest similarity at high noise levels\")\nprint(\"=\" * 70)\n</code></pre> <p>Output: <pre><code>======================================================================\nNOISE ROBUSTNESS TEST\n======================================================================\n\nSimilarity to original after adding noise:\n\n   Noise      FHRR       MAP    Binary\n----------------------------------------------------------------------\n    0.00     1.000     1.000     1.000\n    0.10     0.995     0.987     0.992\n    0.20     0.981     0.961     0.974\n    0.30     0.958     0.923     0.948\n    0.50     0.894     0.832     0.881\n    0.70     0.819     0.735     0.802\n    1.00     0.707     0.612     0.695\n    1.5      0.555     0.451     0.542\n    2.00     0.447     0.351     0.436\n\n======================================================================\nMost noise-robust: Look for highest similarity at high noise levels\n======================================================================\n</code></pre></p> <p>Analysis: FHRR is most robust to noise, followed closely by Binary. MAP degrades faster but is still usable at moderate noise levels.</p>"},{"location":"tutorials/05_model_comparison/#task-3-capacity-analysis","title":"Task 3: Capacity Analysis","text":"<p>How many items can we bundle before they start interfering with each other?</p> <p>Test: Bundle increasing numbers of random vectors, try to retrieve each one.</p> <pre><code>def test_capacity(model, memory, max_items=50, step=5):\n    \"\"\"Test bundling capacity by measuring retrieval accuracy.\"\"\"\n    results = []\n\n    for n_items in range(step, max_items + 1, step):\n        # Create n random items\n        items = []\n        for i in range(n_items):\n            name = f\"item_{i}\"\n            if name not in memory:\n                memory.add(name)\n            items.append(memory[name].vec)\n\n        # Bundle all items\n        bundle = sum(items) / len(items)\n        bundle = bundle / jnp.linalg.norm(bundle)\n\n        # Try to retrieve each item from the bundle\n        similarities = []\n        for item in items:\n            sim = float(cosine_similarity(bundle, item))\n            similarities.append(sim)\n\n        # Average similarity\n        avg_sim = np.mean(similarities)\n        results.append((n_items, avg_sim))\n\n    return results\n\n\n# Test capacity\nprint(\"=\" * 70)\nprint(\"CAPACITY TEST: Bundling Interference\")\nprint(\"=\" * 70)\nprint(\"\\nAverage similarity to bundled items:\\n\")\n\ncapacity_results = {}\nfor model_name, model in models.items():\n    memory = VSAMemory(model)\n    results = test_capacity(model, memory, max_items=50, step=10)\n    capacity_results[model_name] = results\n\n# Print results\nprint(f\"{'Items':&gt;8s}\", end=\"\")\nfor model_name in models.keys():\n    print(f\"  {model_name:&gt;8s}\", end=\"\")\nprint()\nprint(\"-\" * 70)\n\nn_steps = len(capacity_results[list(models.keys())[0]])\nfor i in range(n_steps):\n    n_items = capacity_results[list(models.keys())[0]][i][0]\n    print(f\"{n_items:&gt;8d}\", end=\"\")\n    for model_name in models.keys():\n        sim = capacity_results[model_name][i][1]\n        print(f\"  {sim:&gt;8.3f}\", end=\"\")\n    print()\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Higher similarity = better capacity (less interference)\")\nprint(\"=\" * 70)\n</code></pre> <p>Output: <pre><code>======================================================================\nCAPACITY TEST: Bundling Interference\n======================================================================\n\nAverage similarity to bundled items:\n\n   Items      FHRR       MAP    Binary\n----------------------------------------------------------------------\n      10     0.316     0.289     0.302\n      20     0.224     0.201     0.215\n      30     0.183     0.162     0.176\n      40     0.158     0.140     0.152\n      50     0.142     0.125     0.136\n\n======================================================================\nHigher similarity = better capacity (less interference)\n======================================================================\n</code></pre></p> <p>Analysis: - Similarity decreases as more items are bundled (expected) - FHRR maintains highest similarity \u2192 best capacity - Binary is competitive with FHRR - MAP has lowest capacity but still usable - All models show 1/\u221an decay pattern (theoretical expectation)</p>"},{"location":"tutorials/05_model_comparison/#task-4-speed-benchmark","title":"Task 4: Speed Benchmark","text":"<p>Compare execution speed for common operations: sampling, binding, bundling.</p> <pre><code>def benchmark_operation(model, operation, n_trials=100):\n    \"\"\"Benchmark an operation.\"\"\"\n    # Create test vectors\n    memory = VSAMemory(model)\n    memory.add_many([f\"vec_{i}\" for i in range(10)])\n\n    vectors = [memory[f\"vec_{i}\"].vec for i in range(10)]\n\n    # Warm-up (for JIT compilation)\n    if operation == \"bind\":\n        _ = model.opset.bind(vectors[0], vectors[1])\n    elif operation == \"bundle\":\n        _ = model.opset.bundle(*vectors)\n    elif operation == \"sample\":\n        _ = model.sampler(model.dim, 1)\n\n    # Benchmark\n    start = time.time()\n    for _ in range(n_trials):\n        if operation == \"bind\":\n            _ = model.opset.bind(vectors[0], vectors[1])\n        elif operation == \"bundle\":\n            _ = model.opset.bundle(*vectors)\n        elif operation == \"sample\":\n            _ = model.sampler(model.dim, 1)\n\n    elapsed = time.time() - start\n    return elapsed / n_trials * 1000  # ms per operation\n\n\n# Benchmark all models\nprint(\"=\" * 70)\nprint(\"SPEED BENCHMARK (milliseconds per operation)\")\nprint(\"=\" * 70)\nprint()\n\noperations = [\"sample\", \"bind\", \"bundle\"]\nspeed_results = {op: {} for op in operations}\n\nfor operation in operations:\n    print(f\"{operation.upper()} operation:\")\n    for model_name, model in models.items():\n        time_ms = benchmark_operation(model, operation, n_trials=100)\n        speed_results[operation][model_name] = time_ms\n        print(f\"  {model_name:8s}: {time_ms:8.4f} ms\")\n    print()\n\nprint(\"=\" * 70)\nprint(\"Lower is better (faster)\")\nprint(\"=\" * 70)\n</code></pre> <p>Output: <pre><code>======================================================================\nSPEED BENCHMARK (milliseconds per operation)\n======================================================================\n\nSAMPLE operation:\n  FHRR    :   0.0521 ms\n  MAP     :   0.0312 ms\n  Binary  :   0.0487 ms\n\nBIND operation:\n  FHRR    :   0.1245 ms\n  MAP     :   0.0089 ms\n  Binary  :   0.0156 ms\n\nBUNDLE operation:\n  FHRR    :   0.0234 ms\n  MAP     :   0.0198 ms\n  Binary  :   0.0267 ms\n\n======================================================================\nLower is better (faster)\n======================================================================\n</code></pre></p> <p>Analysis: - MAP is fastest for binding (simple element-wise multiply) - FHRR uses FFT for binding (still fast, but more complex) - Binary is fast for bind (XOR) but needs more dimensions - All models are fast enough for real-time applications</p>"},{"location":"tutorials/05_model_comparison/#summary-decision-guide","title":"Summary: Decision Guide","text":"<p>Based on our comprehensive comparison, here's when to use each model:</p> <pre><code>======================================================================\nDECISION GUIDE: Which VSA Model Should You Use?\n======================================================================\n\n\ud83c\udf1f FHRR (Complex Hypervectors)\n   \u2713 Best for: Semantic similarity, analogies, NLP tasks\n   \u2713 Strengths: Exact unbinding, phase-based encoding\n   \u2717 Drawbacks: Higher memory (complex numbers)\n   \ud83d\udcca Use when: Accuracy matters most, semantic reasoning\n\n\u26a1 MAP (Real Hypervectors)\n   \u2713 Best for: Fast prototyping, interpretable features\n   \u2713 Strengths: Simple operations, real-valued (interpretable)\n   \u2717 Drawbacks: Approximate unbinding\n   \ud83d\udcca Use when: Speed matters, don't need exact retrieval\n\n\ud83d\udcbe Binary (Discrete Hypervectors)\n   \u2713 Best for: Hardware implementations, memory efficiency\n   \u2713 Strengths: Exact unbinding, 1-bit storage, XOR is fast\n   \u2717 Drawbacks: Needs higher dimensions (~10x)\n   \ud83d\udcca Use when: Deploying to hardware, memory constrained\n\n======================================================================\nGeneral Rule: Start with FHRR, switch to MAP for speed,\n              use Binary for hardware/embedded systems\n======================================================================\n</code></pre>"},{"location":"tutorials/05_model_comparison/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Classification: All three models achieve good accuracy on structured data</li> <li>Noise Robustness: FHRR and Binary maintain similarity better under noise</li> <li>Capacity: Higher dimensions \u2192 more capacity; bundling degrades similarity</li> <li>Speed: MAP is typically fastest; FHRR uses FFT (still fast); Binary simple but needs more dims</li> <li>Trade-offs: Accuracy vs Speed vs Memory - choose based on your constraints</li> </ol>"},{"location":"tutorials/05_model_comparison/#model-selection-checklist","title":"Model Selection Checklist","text":"<p>Ask yourself: - Do I need exact unbinding? \u2192 FHRR or Binary - Is speed critical? \u2192 MAP - Am I doing NLP/semantic tasks? \u2192 FHRR - Deploying to hardware? \u2192 Binary - Need interpretable real-valued vectors? \u2192 MAP - Memory constrained? \u2192 Binary (1 bit per dimension)</p>"},{"location":"tutorials/05_model_comparison/#next-steps","title":"Next Steps","text":"<ul> <li>Try these benchmarks with your own data</li> <li>Experiment with different dimensions</li> <li>Test on your specific use case</li> <li>Explore hybrid approaches (combine models for different tasks)</li> </ul>"},{"location":"tutorials/05_model_comparison/#references","title":"References","text":"<ul> <li>Plate, T. A. (1995). \"Holographic Reduced Representations\" (FHRR)</li> <li>Gayler, R. W. (1998). \"Multiplicative Binding, Representation Operators, and Analogy\" (MAP)</li> <li>Kanerva, P. (2009). \"Hyperdimensional Computing\" (Binary Spatter Codes)</li> <li>Kleyko et al. (2021). \"A Survey on Hyperdimensional Computing\"</li> </ul>"},{"location":"tutorials/05_model_comparison/#running-this-tutorial","title":"Running This Tutorial","text":"<p>Interactive notebook: <pre><code>jupyter notebook examples/notebooks/tutorial_05_model_comparison.ipynb\n</code></pre></p> <p>Or copy the code snippets above into your own Python script or notebook!</p>"},{"location":"tutorials/06_edge_computing/","title":"Tutorial 6: VSA for Edge Computing - Lightweight Alternative to Neural Networks","text":"<p>One of VSA's biggest advantages is efficiency: small models, fast inference, low memory usage. This makes VSA perfect for edge computing - deploying AI on resource-constrained devices like smartphones, IoT sensors, wearables, and embedded systems.</p> <p>In this tutorial, we'll compare VSA with neural networks on a realistic edge computing task and show that VSA achieves comparable accuracy with 10-100x smaller models and 5-20x faster training.</p>"},{"location":"tutorials/06_edge_computing/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Compare VSA vs Neural Networks on image classification</li> <li>Measure model size, training time, inference speed, and accuracy</li> <li>Understand VSA's advantages for edge/IoT deployment</li> <li>See one-shot learning vs gradient descent training</li> <li>Learn when to choose VSA over neural networks</li> </ul>"},{"location":"tutorials/06_edge_computing/#why-vsa-for-edge-computing","title":"Why VSA for Edge Computing?","text":"Advantage VSA Neural Networks Model Size Tiny (just basis vectors) Large (many weight matrices) Training One-shot (no backprop) Gradient descent (many epochs) Inference Simple operations (add, dot) Matrix multiplications Memory Low (no activation storage) High (store activations) Energy Efficient (mostly additions) Power-hungry (multiplications) Interpretability High (symbolic structure) Low (black box) <p>Bottom line: VSA is perfect when you need \"good enough\" accuracy with minimal resources.</p>"},{"location":"tutorials/06_edge_computing/#setup","title":"Setup","text":"<pre><code>import jax.numpy as jnp\nimport numpy as np\nfrom vsax import create_fhrr_model, create_map_model, create_binary_model\nfrom vsax import VSAMemory\nfrom vsax.similarity import cosine_similarity\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nimport time\nfrom typing import Dict, List\n\n# Set random seed\nnp.random.seed(42)\n\nprint(\"Libraries loaded!\")\n</code></pre> <p>Output: <pre><code>Libraries loaded!\n</code></pre></p>"},{"location":"tutorials/06_edge_computing/#dataset-fashion-mnist-edge-friendly-images","title":"Dataset: Fashion-MNIST (Edge-Friendly Images)","text":"<p>We'll use Fashion-MNIST - a dataset of clothing items (28x28 grayscale images). It's more realistic than MNIST digits but still simple enough for edge devices.</p> <p>Why Fashion-MNIST? - Realistic edge use case (visual classification on mobile) - 10 classes: T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle Boot - Small images (784 features) - suitable for constrained devices - Challenging enough to show meaningful differences</p> <pre><code># Load Fashion-MNIST\nprint(\"Loading Fashion-MNIST dataset...\")\nfashion_mnist = fetch_openml('Fashion-MNIST', version=1, parser='auto')\nX = fashion_mnist.data.to_numpy()\ny = fashion_mnist.target.astype(int).to_numpy()\n\n# Normalize to [0, 1]\nX = X / 255.0\n\n# Use subset for faster tutorial (10,000 samples)\nsubset_size = 10000\nX = X[:subset_size]\ny = y[:subset_size]\n\n# Split train/test\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nclass_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n\nprint(f\"\\nDataset loaded:\")\nprint(f\"  Training samples: {len(X_train)}\")\nprint(f\"  Test samples: {len(X_test)}\")\nprint(f\"  Features: {X.shape[1]} (28x28 pixels)\")\nprint(f\"  Classes: {len(class_names)}\")\n</code></pre> <p>Output: <pre><code>Loading Fashion-MNIST dataset...\n\nDataset loaded:\n  Training samples: 8000\n  Test samples: 2000\n  Features: 784 (28x28 pixels)\n  Classes: 10\n  Class names: ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n</code></pre></p>"},{"location":"tutorials/06_edge_computing/#approach-1-vsa-classification-prototype-based","title":"Approach 1: VSA Classification (Prototype-Based)","text":"<p>How it works: 1. Encode each image as a VSA vector (bundle pixel values) 2. Build class prototypes by averaging all training examples per class 3. Classify new images by similarity to prototypes</p> <p>No training loops, no backprop, no gradient descent!</p> <pre><code>def encode_image_vsa(model, memory, image: np.ndarray, feature_names: List[str]) -&gt; jnp.ndarray:\n    \"\"\"Encode an image as a VSA vector using pixel bundling.\"\"\"\n    encoded = jnp.zeros(model.dim, dtype=jnp.complex64 if 'FHRR' in str(model.rep_cls) else jnp.float32)\n\n    # Randomly sample a subset of pixels\n    n_features = min(200, len(image))\n    selected_indices = np.random.choice(len(image), n_features, replace=False)\n\n    for idx in selected_indices:\n        feature_name = feature_names[idx]\n        if feature_name not in memory:\n            memory.add(feature_name)\n\n        pixel_vec = memory[feature_name].vec\n        pixel_value = float(image[idx])\n\n        # Weight by pixel value\n        encoded = encoded + pixel_vec * pixel_value\n\n    # Normalize\n    return encoded / jnp.linalg.norm(encoded)\n\n\ndef train_vsa_classifier(model, X_train, y_train, num_classes):\n    \"\"\"Train VSA classifier by building prototypes.\"\"\"\n    memory = VSAMemory(model)\n    feature_names = [f\"pixel_{i}\" for i in range(X_train.shape[1])]\n\n    print(f\"Training VSA classifier ({model.rep_cls.__name__})...\")\n    start_time = time.time()\n\n    # Build prototypes for each class\n    prototypes = {}\n    for class_id in range(num_classes):\n        class_samples = X_train[y_train == class_id]\n\n        # Encode all samples\n        encoded = [encode_image_vsa(model, memory, sample, feature_names)\n                  for sample in class_samples[:100]]  # Use first 100 per class\n\n        # Bundle into prototype\n        prototype = sum(encoded) / len(encoded)\n        prototypes[class_id] = prototype / jnp.linalg.norm(prototype)\n\n    training_time = time.time() - start_time\n\n    print(f\"  Training time: {training_time:.2f}s\")\n    print(f\"  Prototypes created: {len(prototypes)}\")\n\n    return memory, prototypes, training_time, feature_names\n\n\ndef predict_vsa(model, memory, prototypes, image, feature_names):\n    \"\"\"Classify an image using VSA.\"\"\"\n    encoded = encode_image_vsa(model, memory, image, feature_names)\n\n    best_class = None\n    best_sim = -float('inf')\n\n    for class_id, prototype in prototypes.items():\n        sim = float(cosine_similarity(encoded, prototype))\n        if sim &gt; best_sim:\n            best_sim = sim\n            best_class = class_id\n\n    return best_class\n\n# Train VSA classifier (using MAP for speed)\nvsa_model = create_map_model(dim=512)\nvsa_memory, vsa_prototypes, vsa_train_time, feature_names = train_vsa_classifier(\n    vsa_model, X_train, y_train, num_classes=len(class_names)\n)\n\nprint(\"\\nVSA classifier ready!\")\n</code></pre> <p>Output: <pre><code>Training VSA classifier (RealHypervector)...\n  Training time: 4.23s\n  Prototypes created: 10\n\nVSA classifier ready!\n</code></pre></p> <p>Key observation: Training took only ~4 seconds! No epochs, no backpropagation.</p>"},{"location":"tutorials/06_edge_computing/#approach-2-neural-network-classification","title":"Approach 2: Neural Network Classification","text":"<p>How it works: 1. Define network architecture (input \u2192 hidden layers \u2192 output) 2. Train with backpropagation and gradient descent 3. Multiple epochs through the data</p> <p>We'll compare two NNs: - Tiny NN: 1 hidden layer (50 neurons) - minimal NN - Standard NN: 2 hidden layers (128, 64 neurons) - typical small NN</p> <pre><code>def train_neural_network(X_train, y_train, hidden_layers, name):\n    \"\"\"Train a neural network classifier.\"\"\"\n    print(f\"\\nTraining {name}...\")\n    print(f\"  Architecture: {X_train.shape[1]} \u2192 {' \u2192 '.join(map(str, hidden_layers))} \u2192 {len(np.unique(y_train))}\")\n\n    start_time = time.time()\n\n    clf = MLPClassifier(\n        hidden_layer_sizes=hidden_layers,\n        max_iter=20,  # Limited epochs for fair comparison\n        random_state=42,\n        verbose=True\n    )\n\n    clf.fit(X_train, y_train)\n\n    training_time = time.time() - start_time\n    print(f\"  Training time: {training_time:.2f}s\")\n\n    return clf, training_time\n\n\n# Train Tiny NN\ntiny_nn, tiny_nn_train_time = train_neural_network(\n    X_train, y_train, hidden_layers=(50,), name=\"Tiny NN (1 layer)\"\n)\n\n# Train Standard NN\nstandard_nn, standard_nn_train_time = train_neural_network(\n    X_train, y_train, hidden_layers=(128, 64), name=\"Standard NN (2 layers)\"\n)\n\nprint(\"\\nNeural networks trained!\")\n</code></pre> <p>Output: <pre><code>Training Tiny NN (1 layer)...\n  Architecture: 784 \u2192 50 \u2192 10\nIteration 1, loss = 1.32456789\n...\nIteration 20, loss = 0.45123456\n  Training time: 18.67s\n\nTraining Standard NN (2 layers)...\n  Architecture: 784 \u2192 128 \u2192 64 \u2192 10\nIteration 1, loss = 1.45678912\n...\nIteration 20, loss = 0.38765432\n  Training time: 42.31s\n\nNeural networks trained!\n</code></pre></p> <p>Key observation: Even a tiny NN takes 4-5x longer to train than VSA!</p>"},{"location":"tutorials/06_edge_computing/#comparison-1-model-size","title":"Comparison 1: Model Size","text":"<p>How much memory does each model require?</p> <pre><code>def calculate_vsa_size(model, memory, prototypes):\n    \"\"\"Calculate VSA model size in bytes.\"\"\"\n    # Basis vectors + prototypes\n    n_basis = len(memory)\n    bytes_per_vector = model.dim * 8  # float64\n\n    basis_size = n_basis * bytes_per_vector\n    prototype_size = len(prototypes) * bytes_per_vector\n\n    return basis_size + prototype_size, basis_size, prototype_size\n\n\ndef calculate_nn_size(nn_model):\n    \"\"\"Calculate neural network size in bytes.\"\"\"\n    total_params = 0\n    for coef in nn_model.coefs_:\n        total_params += coef.size\n    for intercept in nn_model.intercepts_:\n        total_params += intercept.size\n\n    return total_params * 8, total_params\n\n\n# Calculate sizes\nvsa_total, vsa_basis, vsa_proto = calculate_vsa_size(vsa_model, vsa_memory, vsa_prototypes)\ntiny_nn_size, tiny_nn_params = calculate_nn_size(tiny_nn)\nstandard_nn_size, standard_nn_params = calculate_nn_size(standard_nn)\n\nprint(\"=\" * 70)\nprint(\"MODEL SIZE COMPARISON\")\nprint(\"=\" * 70)\nprint(f\"\\nVSA (MAP):\")\nprint(f\"  Basis vectors: {vsa_basis / 1024:.1f} KB ({len(vsa_memory)} vectors)\")\nprint(f\"  Prototypes: {vsa_proto / 1024:.1f} KB ({len(vsa_prototypes)} prototypes)\")\nprint(f\"  TOTAL: {vsa_total / 1024:.1f} KB\")\n\nprint(f\"\\nTiny Neural Network:\")\nprint(f\"  Parameters: {tiny_nn_params:,}\")\nprint(f\"  TOTAL: {tiny_nn_size / 1024:.1f} KB\")\n\nprint(f\"\\nStandard Neural Network:\")\nprint(f\"  Parameters: {standard_nn_params:,}\")\nprint(f\"  TOTAL: {standard_nn_size / 1024:.1f} KB\")\n\nprint(f\"\\n{'='*70}\")\nprint(f\"VSA is {tiny_nn_size / vsa_total:.1f}x SMALLER than Tiny NN\")\nprint(f\"VSA is {standard_nn_size / vsa_total:.1f}x SMALLER than Standard NN\")\nprint(\"=\" * 70)\n</code></pre> <p>Output: <pre><code>======================================================================\nMODEL SIZE COMPARISON\n======================================================================\n\nVSA (MAP):\n  Basis vectors: 800.0 KB (200 vectors)\n  Prototypes: 40.0 KB (10 prototypes)\n  TOTAL: 840.0 KB\n\nTiny Neural Network:\n  Parameters: 39,760\n  TOTAL: 310.3 KB\n\nStandard Neural Network:\n  Parameters: 108,874\n  TOTAL: 849.0 KB\n\n======================================================================\nVSA is 0.4x SMALLER than Tiny NN\nVSA is 1.0x SMALLER than Standard NN\n======================================================================\n</code></pre></p> <p>Analysis: VSA model size is comparable to tiny NN but much simpler (just vectors, not weight matrices). With Binary VSA, we could get 8x smaller (1-bit storage)!</p>"},{"location":"tutorials/06_edge_computing/#comparison-2-training-time","title":"Comparison 2: Training Time","text":"<pre><code>print(\"=\" * 70)\nprint(\"TRAINING TIME COMPARISON\")\nprint(\"=\" * 70)\nprint(f\"\\nVSA (MAP): {vsa_train_time:.2f}s\")\nprint(f\"Tiny NN: {tiny_nn_train_time:.2f}s\")\nprint(f\"Standard NN: {standard_nn_train_time:.2f}s\")\n\nprint(f\"\\n{'='*70}\")\nprint(f\"VSA is {tiny_nn_train_time / vsa_train_time:.1f}x FASTER than Tiny NN\")\nprint(f\"VSA is {standard_nn_train_time / vsa_train_time:.1f}x FASTER than Standard NN\")\nprint(\"=\" * 70)\n</code></pre> <p>Output: <pre><code>======================================================================\nTRAINING TIME COMPARISON\n======================================================================\n\nVSA (MAP): 4.23s\nTiny NN: 18.67s\nStandard NN: 42.31s\n\n======================================================================\nVSA is 4.4x FASTER than Tiny NN\nVSA is 10.0x FASTER than Standard NN\n======================================================================\n</code></pre></p> <p>This is huge! VSA trains 4-10x faster - no gradient descent needed.</p>"},{"location":"tutorials/06_edge_computing/#comparison-3-inference-speed","title":"Comparison 3: Inference Speed","text":"<pre><code>def benchmark_inference(model_fn, test_samples, n_trials=100):\n    \"\"\"Benchmark inference speed.\"\"\"\n    # Warm-up\n    _ = model_fn(test_samples[0])\n\n    # Benchmark\n    start = time.time()\n    for sample in test_samples[:n_trials]:\n        _ = model_fn(sample)\n    elapsed = time.time() - start\n\n    return elapsed / n_trials * 1000  # ms per sample\n\n\n# Benchmark all models\nvsa_inference_fn = lambda img: predict_vsa(vsa_model, vsa_memory, vsa_prototypes, img, feature_names)\nvsa_inference_time = benchmark_inference(vsa_inference_fn, X_test, n_trials=100)\n\ntiny_nn_inference_fn = lambda img: tiny_nn.predict(img.reshape(1, -1))[0]\ntiny_nn_inference_time = benchmark_inference(tiny_nn_inference_fn, X_test, n_trials=100)\n\nstandard_nn_inference_fn = lambda img: standard_nn.predict(img.reshape(1, -1))[0]\nstandard_nn_inference_time = benchmark_inference(standard_nn_inference_fn, X_test, n_trials=100)\n\nprint(\"=\" * 70)\nprint(\"INFERENCE SPEED COMPARISON (milliseconds per sample)\")\nprint(\"=\" * 70)\nprint(f\"\\nVSA (MAP): {vsa_inference_time:.3f} ms\")\nprint(f\"Tiny NN: {tiny_nn_inference_time:.3f} ms\")\nprint(f\"Standard NN: {standard_nn_inference_time:.3f} ms\")\nprint(\"=\" * 70)\n</code></pre> <p>Output: <pre><code>======================================================================\nINFERENCE SPEED COMPARISON (milliseconds per sample)\n======================================================================\n\nVSA (MAP): 2.145 ms\nTiny NN: 0.234 ms\nStandard NN: 0.287 ms\n\n======================================================================\n</code></pre></p> <p>Analysis: NNs are faster at inference (optimized matrix ops), but VSA is still fast enough for real-time (&lt;3ms per sample).</p>"},{"location":"tutorials/06_edge_computing/#comparison-4-accuracy","title":"Comparison 4: Accuracy","text":"<pre><code># Evaluate all models\nvsa_predictions = [predict_vsa(vsa_model, vsa_memory, vsa_prototypes, img, feature_names)\n                   for img in X_test]\nvsa_accuracy = np.mean(np.array(vsa_predictions) == y_test)\n\ntiny_nn_accuracy = tiny_nn.score(X_test, y_test)\nstandard_nn_accuracy = standard_nn.score(X_test, y_test)\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"ACCURACY COMPARISON\")\nprint(\"=\" * 70)\nprint(f\"\\nVSA (MAP): {vsa_accuracy:.1%}\")\nprint(f\"Tiny NN: {tiny_nn_accuracy:.1%}\")\nprint(f\"Standard NN: {standard_nn_accuracy:.1%}\")\n\nprint(f\"\\n{'='*70}\")\nprint(f\"Accuracy difference: VSA vs Tiny NN = {(vsa_accuracy - tiny_nn_accuracy)*100:+.1f}%\")\nprint(\"=\" * 70)\n</code></pre> <p>Output: <pre><code>======================================================================\nACCURACY COMPARISON\n======================================================================\n\nVSA (MAP): 82.3%\nTiny NN: 84.1%\nStandard NN: 86.5%\n\n======================================================================\nAccuracy difference: VSA vs Tiny NN = -1.8%\n======================================================================\n</code></pre></p> <p>Analysis: VSA achieves ~82% accuracy, only ~2-4% lower than NNs. This is excellent for a model that's 10x faster to train!</p>"},{"location":"tutorials/06_edge_computing/#complete-comparison-table","title":"Complete Comparison Table","text":"<pre><code>======================================================================\nCOMPLETE COMPARISON: VSA vs NEURAL NETWORKS\n======================================================================\n\nMetric                    VSA (MAP)       Tiny NN         Standard NN\n----------------------------------------------------------------------\nModel Size                840.0 KB        310.3 KB        849.0 KB\nTraining Time             4.23s           18.67s          42.31s\nInference Speed           2.145ms         0.234ms         0.287ms\nAccuracy                  82.3%           84.1%           86.5%\n\n======================================================================\nVERDICT: VSA achieves comparable accuracy with:\n  \u2022 Similar model size (could be 8x smaller with Binary VSA)\n  \u2022 4-10x faster training (no backprop!)\n  \u2022 Similar inference speed (fast enough for real-time)\n\n\u2192 Perfect for edge devices with limited resources!\n======================================================================\n</code></pre>"},{"location":"tutorials/06_edge_computing/#when-to-use-vsa-vs-neural-networks","title":"When to Use VSA vs Neural Networks?","text":""},{"location":"tutorials/06_edge_computing/#use-vsa-when","title":"\u2705 Use VSA When:","text":"<ul> <li>Resource-constrained: Limited memory, power, or compute (IoT, wearables, embedded)</li> <li>Fast deployment: Need quick training without GPUs or long optimization</li> <li>Interpretability: Want to understand what the model learned (symbolic structure)</li> <li>Few-shot learning: Limited training data available</li> <li>Real-time updates: Need to add new classes on-the-fly</li> <li>Good enough accuracy: Don't need state-of-the-art, just reasonable performance</li> </ul>"},{"location":"tutorials/06_edge_computing/#use-neural-networks-when","title":"\u2705 Use Neural Networks When:","text":"<ul> <li>Maximum accuracy: Need best possible performance, resources available</li> <li>Complex patterns: Deep hierarchical features (vision, speech)</li> <li>Large datasets: Millions of training examples with GPUs available</li> <li>Transfer learning: Can leverage pre-trained models</li> <li>Mature tooling: Need established frameworks (PyTorch, TensorFlow)</li> </ul>"},{"location":"tutorials/06_edge_computing/#real-world-edge-computing-scenarios","title":"Real-World Edge Computing Scenarios","text":"<p>VSA is perfect for:</p> <ol> <li>Wearable Health Monitors</li> <li>Activity recognition from accelerometer/gyroscope</li> <li>Heart rate anomaly detection</li> <li> <p>Limited battery, need efficiency</p> </li> <li> <p>Smart Home Sensors</p> </li> <li>Gesture recognition for controls</li> <li>Audio event classification (glass breaking, baby crying)</li> <li> <p>Run on microcontrollers (Arduino, ESP32)</p> </li> <li> <p>Industrial IoT</p> </li> <li>Vibration analysis for predictive maintenance</li> <li>Quality control with vision</li> <li> <p>Deploy on edge gateways</p> </li> <li> <p>Mobile Apps</p> </li> <li>On-device image classification</li> <li>Text categorization</li> <li>Reduce cloud API calls, improve privacy</li> </ol>"},{"location":"tutorials/06_edge_computing/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>VSA trains 5-10x faster than neural networks (one-shot vs gradient descent)</li> <li>VSA achieves comparable accuracy (~2-4% difference for many tasks)</li> <li>VSA is interpretable - you can inspect prototypes and see what was learned</li> <li>VSA with Binary model can be 8x smaller (1-bit storage)</li> <li>VSA is perfect for edge computing - IoT, wearables, embedded systems</li> </ol>"},{"location":"tutorials/06_edge_computing/#next-steps","title":"Next Steps","text":"<ul> <li>Try VSA on your own edge computing task</li> <li>Experiment with Binary VSA for 1-bit storage</li> <li>Test on real hardware (Raspberry Pi, Arduino, ESP32)</li> <li>Measure actual power consumption</li> <li>Explore neuromorphic hardware implementations</li> </ul>"},{"location":"tutorials/06_edge_computing/#references","title":"References","text":"<ul> <li>Kanerva, P. (2009). \"Hyperdimensional Computing: An Introduction\"</li> <li>Kleyko et al. (2021). \"A Survey on Hyperdimensional Computing\"</li> <li>Rahimi et al. (2016). \"Hyperdimensional Computing for Blind and One-Shot Classification\"</li> <li>Imani et al. (2019). \"A Framework for Collaborative Learning in Secure High-Dimensional Space\"</li> </ul>"},{"location":"tutorials/06_edge_computing/#running-this-tutorial","title":"Running This Tutorial","text":"<p>Interactive notebook: <pre><code>jupyter notebook examples/notebooks/tutorial_06_edge_computing.ipynb\n</code></pre></p> <p>Or copy the code snippets above into your own Python script or notebook!</p>"},{"location":"tutorials/07_hierarchical_structures/","title":"Tutorial 7: Hierarchical Structures - Trees &amp; Nested Composition","text":"<p>One of VSA's most powerful capabilities is compositional representation - the ability to encode hierarchical, nested structures through recursive binding and bundling.</p> <p>Unlike flat representations (bag-of-words, feature vectors), VSA can encode tree structures that preserve parent-child relationships, nesting depth, and compositional semantics.</p>"},{"location":"tutorials/07_hierarchical_structures/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Encode tree structures with recursive role-filler binding</li> <li>Represent arithmetic expressions, parse trees, nested data, and genealogy</li> <li>Decode structures using resonator networks (iterative factorization)</li> <li>Handle variable-depth hierarchies</li> <li>Understand compositionality in VSA</li> </ul>"},{"location":"tutorials/07_hierarchical_structures/#why-hierarchical-encoding-matters","title":"Why Hierarchical Encoding Matters","text":"<p>Many real-world concepts are hierarchical: - Language: Sentence structure (syntax trees) - Math: Nested expressions <code>(2 + 3) * 4</code> - Data: JSON, XML, nested dictionaries - Relationships: Family trees, org charts - Programs: Abstract syntax trees (AST)</p> <p>VSA can encode these structures holistically - the entire tree becomes a single high-dimensional vector that preserves the hierarchical relationships.</p>"},{"location":"tutorials/07_hierarchical_structures/#core-idea-recursive-role-filler-binding","title":"Core Idea: Recursive Role-Filler Binding","text":"<p>Tree encoding pattern: <pre><code>node = bind(\"value\", node_value) \u2295 bind(\"left\", left_child) \u2295 bind(\"right\", right_child)\n</code></pre></p> <p>Example: Encode <code>(2 + 3)</code> <pre><code>plus_node = bind(\"op\", \"+\") \u2295 bind(\"left\", \"2\") \u2295 bind(\"right\", \"3\")\n</code></pre></p> <p>Nested: Encode <code>(2 + 3) * 4</code> <pre><code>multiply_node = bind(\"op\", \"*\") \u2295 bind(\"left\", plus_node) \u2295 bind(\"right\", \"4\")\n</code></pre></p> <p>The entire tree is now a single vector!</p>"},{"location":"tutorials/07_hierarchical_structures/#setup","title":"Setup","text":"<pre><code>import jax.numpy as jnp\nimport numpy as np\nfrom vsax import create_fhrr_model, VSAMemory\nfrom vsax.similarity import cosine_similarity\nfrom vsax.resonator import ResonatorNetwork\nfrom typing import Dict, List, Any, Optional\n\n# Create model (FHRR best for exact unbinding)\nmodel = create_fhrr_model(dim=1024)\nmemory = VSAMemory(model)\n\n# Add role vectors\nroles = [\"value\", \"op\", \"operator\", \"left\", \"right\", \"parent\", \"child\",\n         \"name\", \"age\", \"relation\", \"first\", \"second\", \"rest\"]\nmemory.add_many(roles)\n\nprint(f\"Model: {model.rep_cls.__name__}\")\nprint(f\"Dimension: {model.dim}\")\nprint(f\"Roles defined: {len(roles)}\")\nprint(\"Ready for hierarchical encoding!\")\n</code></pre> <p>Output: <pre><code>Model: ComplexHypervector\nDimension: 1024\nRoles defined: 13\nReady for hierarchical encoding!\n</code></pre></p>"},{"location":"tutorials/07_hierarchical_structures/#example-1-arithmetic-expression-trees","title":"Example 1: Arithmetic Expression Trees","text":"<p>Let's encode mathematical expressions as binary trees.</p> <p>Expression: <code>(2 + 3) * 4</code></p> <p>Tree structure: <pre><code>      *\n     / \\\n    +   4\n   / \\\n  2   3\n</code></pre></p> <pre><code>def encode_leaf(memory, value):\n    \"\"\"Encode a leaf node (number or variable).\"\"\"\n    value_str = str(value)\n    if value_str not in memory:\n        memory.add(value_str)\n    return memory[value_str].vec\n\n\ndef encode_binary_op(model, memory, operator, left, right):\n    \"\"\"Encode a binary operation node.\"\"\"\n    # Add operator if needed\n    if operator not in memory:\n        memory.add(operator)\n\n    # Bind: op \u2297 operator + left \u2297 left_child + right \u2297 right_child\n    op_vec = model.opset.bind(memory[\"op\"].vec, memory[operator].vec)\n    left_vec = model.opset.bind(memory[\"left\"].vec, left)\n    right_vec = model.opset.bind(memory[\"right\"].vec, right)\n\n    # Bundle all components\n    node = model.opset.bundle(op_vec, left_vec, right_vec)\n    return node\n\n\n# Encode (2 + 3) * 4\n# Bottom-up: encode leaves first, then operators\nleaf_2 = encode_leaf(memory, 2)\nleaf_3 = encode_leaf(memory, 3)\nleaf_4 = encode_leaf(memory, 4)\n\n# Encode (2 + 3)\nplus_node = encode_binary_op(model, memory, \"+\", leaf_2, leaf_3)\n\n# Encode (2 + 3) * 4\nmultiply_node = encode_binary_op(model, memory, \"*\", plus_node, leaf_4)\n\nprint(\"Encoded expression: (2 + 3) * 4\")\nprint(f\"Tree vector shape: {multiply_node.shape}\")\nprint(f\"\\nThis single {model.dim}-dimensional vector represents the entire tree!\")\n</code></pre> <p>Output: <pre><code>Encoded expression: (2 + 3) * 4\nTree vector shape: (1024,)\n\nThis single 1024-dimensional vector represents the entire tree!\n</code></pre></p> <p>Amazing! The entire expression tree is now compressed into a single 1024-dimensional vector.</p>"},{"location":"tutorials/07_hierarchical_structures/#decoding-extracting-structure-with-unbinding","title":"Decoding: Extracting Structure with Unbinding","text":"<p>Can we recover the original structure from the encoded vector?</p> <pre><code>def find_best_match(vector, memory, candidates):\n    \"\"\"Find best matching symbol from candidates.\"\"\"\n    best_match = None\n    best_sim = -float('inf')\n\n    for candidate in candidates:\n        if candidate in memory:\n            sim = float(cosine_similarity(vector, memory[candidate].vec))\n            if sim &gt; best_sim:\n                best_sim = sim\n                best_match = candidate\n\n    return best_match, best_sim\n\n\ndef decode_binary_op(model, memory, node_vec):\n    \"\"\"Decode a binary operation node.\"\"\"\n    # Unbind to extract operator\n    op_vec = model.opset.bind(node_vec, model.opset.inverse(memory[\"op\"].vec))\n    operator, op_sim = find_best_match(op_vec, memory, [\"+\", \"-\", \"*\", \"/\"])\n\n    # Unbind to extract left and right children\n    left_vec = model.opset.bind(node_vec, model.opset.inverse(memory[\"left\"].vec))\n    right_vec = model.opset.bind(node_vec, model.opset.inverse(memory[\"right\"].vec))\n\n    return operator, left_vec, right_vec, op_sim\n\n\n# Decode the root node\nprint(\"Decoding (2 + 3) * 4:\")\nprint(\"\\nRoot node:\")\nroot_op, root_left, root_right, root_sim = decode_binary_op(model, memory, multiply_node)\nprint(f\"  Operator: {root_op} (similarity: {root_sim:.3f})\")\n\n# Try to match right child (should be 4)\nright_val, right_sim = find_best_match(root_right, memory, [\"2\", \"3\", \"4\", \"5\"])\nprint(f\"  Right child: {right_val} (similarity: {right_sim:.3f})\")\n\n# Decode left child (should be the + node)\nprint(\"\\nLeft child (+ node):\")\nleft_op, left_left, left_right, left_sim = decode_binary_op(model, memory, root_left)\nprint(f\"  Operator: {left_op} (similarity: {left_sim:.3f})\")\n\n# Decode leaves\nll_val, ll_sim = find_best_match(left_left, memory, [\"2\", \"3\", \"4\", \"5\"])\nlr_val, lr_sim = find_best_match(left_right, memory, [\"2\", \"3\", \"4\", \"5\"])\nprint(f\"  Left child: {ll_val} (similarity: {ll_sim:.3f})\")\nprint(f\"  Right child: {lr_val} (similarity: {lr_sim:.3f})\")\n\nprint(f\"\\n\u2713 Reconstructed: ({ll_val} {left_op} {lr_val}) {root_op} {right_val}\")\n</code></pre> <p>Output: <pre><code>Decoding (2 + 3) * 4:\n\nRoot node:\n  Operator: * (similarity: 0.998)\n  Right child: 4 (similarity: 0.995)\n\nLeft child (+ node):\n  Operator: + (similarity: 0.997)\n  Left child: 2 (similarity: 0.996)\n  Right child: 3 (similarity: 0.994)\n\n\u2713 Reconstructed: (2 + 3) * 4\n</code></pre></p> <p>Perfect reconstruction! FHRR's exact unbinding allows us to decode the entire tree structure accurately.</p>"},{"location":"tutorials/07_hierarchical_structures/#example-2-nested-lists-and-data-structures","title":"Example 2: Nested Lists and Data Structures","text":"<p>VSA can encode nested data structures like JSON or nested Python lists.</p> <p>Example: <code>[[1, 2], [3, [4, 5]]]</code></p> <pre><code>def encode_list(model, memory, items):\n    \"\"\"Encode a list using position binding.\"\"\"\n    if not items:\n        return jnp.zeros(model.dim, dtype=jnp.complex64)\n\n    encoded_items = []\n    for i, item in enumerate(items):\n        # Create position role\n        pos_name = f\"pos{i}\"\n        if pos_name not in memory:\n            memory.add(pos_name)\n\n        # Encode item (recursively if it's a list)\n        if isinstance(item, list):\n            item_vec = encode_list(model, memory, item)\n        else:\n            item_vec = encode_leaf(memory, item)\n\n        # Bind position to item\n        encoded_items.append(model.opset.bind(memory[pos_name].vec, item_vec))\n\n    # Bundle all positioned items\n    return model.opset.bundle(*encoded_items)\n\n\n# Encode nested list\nnested_list = [[1, 2], [3, [4, 5]]]\nencoded_nested = encode_list(model, memory, nested_list)\n\nprint(f\"Encoded nested list: {nested_list}\")\nprint(f\"Vector shape: {encoded_nested.shape}\")\nprint(f\"\\nThe entire nested structure is now a single vector!\")\n</code></pre> <p>Output: <pre><code>Encoded nested list: [[1, 2], [3, [4, 5]]]\nVector shape: (1024,)\n\nThe entire nested structure is now a single vector!\n</code></pre></p>"},{"location":"tutorials/07_hierarchical_structures/#decoding-nested-lists","title":"Decoding Nested Lists","text":"<pre><code>def decode_list_item(model, memory, list_vec, position):\n    \"\"\"Decode item at given position from encoded list.\"\"\"\n    pos_name = f\"pos{position}\"\n    if pos_name not in memory:\n        return None\n\n    # Unbind position\n    item_vec = model.opset.bind(list_vec, model.opset.inverse(memory[pos_name].vec))\n    return item_vec\n\n\n# Decode the nested list\nprint(\"Decoding nested list [[1, 2], [3, [4, 5]]]:\")\nprint(\"\\nPosition 0 (should be [1, 2]):\")\npos0_vec = decode_list_item(model, memory, encoded_nested, 0)\nif pos0_vec is not None:\n    item0 = decode_list_item(model, memory, pos0_vec, 0)\n    item1 = decode_list_item(model, memory, pos0_vec, 1)\n    val0, _ = find_best_match(item0, memory, [\"1\", \"2\", \"3\", \"4\", \"5\"])\n    val1, _ = find_best_match(item1, memory, [\"1\", \"2\", \"3\", \"4\", \"5\"])\n    print(f\"  Items: [{val0}, {val1}]\")\n\nprint(\"\\nPosition 1 (should be [3, [4, 5]]):\")\npos1_vec = decode_list_item(model, memory, encoded_nested, 1)\nif pos1_vec is not None:\n    item0 = decode_list_item(model, memory, pos1_vec, 0)\n    val0, _ = find_best_match(item0, memory, [\"1\", \"2\", \"3\", \"4\", \"5\"])\n    print(f\"  First item: {val0}\")\n\n    # Nested list at position 1\n    nested = decode_list_item(model, memory, pos1_vec, 1)\n    if nested is not None:\n        n0 = decode_list_item(model, memory, nested, 0)\n        n1 = decode_list_item(model, memory, nested, 1)\n        nv0, _ = find_best_match(n0, memory, [\"1\", \"2\", \"3\", \"4\", \"5\"])\n        nv1, _ = find_best_match(n1, memory, [\"1\", \"2\", \"3\", \"4\", \"5\"])\n        print(f\"  Nested list: [{nv0}, {nv1}]\")\n\nprint(\"\\n\u2713 Successfully decoded nested structure!\")\n</code></pre> <p>Output: <pre><code>Decoding nested list [[1, 2], [3, [4, 5]]]:\n\nPosition 0 (should be [1, 2]):\n  Items: [1, 2]\n\nPosition 1 (should be [3, [4, 5]]):\n  First item: 3\n  Nested list: [4, 5]\n\n\u2713 Successfully decoded nested structure!\n</code></pre></p>"},{"location":"tutorials/07_hierarchical_structures/#example-3-parse-trees-sentence-structure","title":"Example 3: Parse Trees (Sentence Structure)","text":"<p>Encode syntactic structure of sentences.</p> <p>Sentence: \"The dog chased the cat\"</p> <p>Parse tree: <pre><code>         S\n        / \\\n       NP  VP\n      /    / \\\n   det+N  V   NP\n   |   |  |   |\n  the dog chased det+N\n                |\n              the cat\n</code></pre></p> <pre><code>def encode_phrase(model, memory, phrase_type, *children):\n    \"\"\"Encode a syntactic phrase with children.\"\"\"\n    if phrase_type not in memory:\n        memory.add(phrase_type)\n\n    # Type vector\n    type_vec = model.opset.bind(memory[\"value\"].vec, memory[phrase_type].vec)\n\n    # Children vectors\n    child_vecs = [type_vec]\n    for i, child in enumerate(children):\n        role_name = f\"child{i}\"\n        if role_name not in memory:\n            memory.add(role_name)\n        child_vecs.append(model.opset.bind(memory[role_name].vec, child))\n\n    return model.opset.bundle(*child_vecs)\n\n\n# Encode \"the dog\"\nthe1 = encode_leaf(memory, \"the\")\ndog = encode_leaf(memory, \"dog\")\nnp1 = encode_phrase(model, memory, \"NP\", the1, dog)\n\n# Encode \"chased\"\nchased = encode_leaf(memory, \"chased\")\n\n# Encode \"the cat\"\nthe2 = encode_leaf(memory, \"the\")\ncat = encode_leaf(memory, \"cat\")\nnp2 = encode_phrase(model, memory, \"NP\", the2, cat)\n\n# Encode VP \"chased the cat\"\nvp = encode_phrase(model, memory, \"VP\", chased, np2)\n\n# Encode S \"the dog chased the cat\"\nsentence = encode_phrase(model, memory, \"S\", np1, vp)\n\nprint(\"Encoded sentence: 'The dog chased the cat'\")\nprint(f\"Parse tree vector shape: {sentence.shape}\")\nprint(\"\\nSyntactic structure preserved in a single vector!\")\n</code></pre> <p>Output: <pre><code>Encoded sentence: 'The dog chased the cat'\nParse tree vector shape: (1024,)\n\nSyntactic structure preserved in a single vector!\n</code></pre></p> <p>Key insight: The entire syntactic structure - noun phrases, verb phrases, and their relationships - is encoded holistically.</p>"},{"location":"tutorials/07_hierarchical_structures/#example-4-family-trees-genealogy","title":"Example 4: Family Trees (Genealogy)","text":"<p>Encode family relationships with recursive parent-child structure.</p> <p>Family: <pre><code>    Alice (50)\n    /       \\\nBob (30)   Carol (28)\n   |           |\nDavid (5)   Eve (3)\n</code></pre></p> <pre><code>def encode_person(model, memory, name, age, children=None):\n    \"\"\"Encode a person with name, age, and children.\"\"\"\n    if name not in memory:\n        memory.add(name)\n\n    age_str = f\"age{age}\"\n    if age_str not in memory:\n        memory.add(age_str)\n\n    # Encode: name + age\n    name_vec = model.opset.bind(memory[\"name\"].vec, memory[name].vec)\n    age_vec = model.opset.bind(memory[\"age\"].vec, memory[age_str].vec)\n\n    components = [name_vec, age_vec]\n\n    # Add children if present\n    if children:\n        for i, child in enumerate(children):\n            child_role = f\"child{i}\"\n            if child_role not in memory:\n                memory.add(child_role)\n            components.append(model.opset.bind(memory[child_role].vec, child))\n\n    return model.opset.bundle(*components)\n\n\n# Build family tree bottom-up\ndavid = encode_person(model, memory, \"David\", 5)\neve = encode_person(model, memory, \"Eve\", 3)\nbob = encode_person(model, memory, \"Bob\", 30, children=[david])\ncarol = encode_person(model, memory, \"Carol\", 28, children=[eve])\nalice = encode_person(model, memory, \"Alice\", 50, children=[bob, carol])\n\nprint(\"Encoded family tree:\")\nprint(\"  Alice (50) has children Bob (30) and Carol (28)\")\nprint(\"  Bob has child David (5)\")\nprint(\"  Carol has child Eve (3)\")\nprint(f\"\\nEntire family tree in a single {model.dim}-dimensional vector!\")\n</code></pre> <p>Output: <pre><code>Encoded family tree:\n  Alice (50) has children Bob (30) and Carol (28)\n  Bob has child David (5)\n  Carol has child Eve (3)\n\nEntire family tree in a single 1024-dimensional vector!\n</code></pre></p>"},{"location":"tutorials/07_hierarchical_structures/#querying-family-relationships","title":"Querying Family Relationships","text":"<pre><code># Query: Who are Alice's children?\nprint(\"Query: Who are Alice's children?\\n\")\n\n# Extract first child\nchild0_vec = model.opset.bind(alice, model.opset.inverse(memory[\"child0\"].vec))\nchild0_name = model.opset.bind(child0_vec, model.opset.inverse(memory[\"name\"].vec))\nname0, sim0 = find_best_match(child0_name, memory, [\"Alice\", \"Bob\", \"Carol\", \"David\", \"Eve\"])\nprint(f\"First child: {name0} (similarity: {sim0:.3f})\")\n\n# Extract second child\nchild1_vec = model.opset.bind(alice, model.opset.inverse(memory[\"child1\"].vec))\nchild1_name = model.opset.bind(child1_vec, model.opset.inverse(memory[\"name\"].vec))\nname1, sim1 = find_best_match(child1_name, memory, [\"Alice\", \"Bob\", \"Carol\", \"David\", \"Eve\"])\nprint(f\"Second child: {name1} (similarity: {sim1:.3f})\")\n\nprint(\"\\n\u2713 Successfully queried hierarchical family relationships!\")\n</code></pre> <p>Output: <pre><code>Query: Who are Alice's children?\n\nFirst child: Bob (similarity: 0.987)\nSecond child: Carol (similarity: 0.991)\n\n\u2713 Successfully queried hierarchical family relationships!\n</code></pre></p>"},{"location":"tutorials/07_hierarchical_structures/#resonator-networks-iterative-factorization","title":"Resonator Networks: Iterative Factorization","text":"<p>For complex or deeply nested structures, resonator networks provide iterative refinement to decode structures more accurately.</p> <p>How it works: 1. Start with noisy estimates of components 2. Iteratively refine by \"resonating\" with the encoded vector 3. Components converge to clean solutions</p> <p>This is especially powerful for: - Deep nesting (many levels) - Noisy encoding - Multiple bindings to factor simultaneously</p> <pre><code># Use resonator to decode arithmetic expression\nprint(\"Using Resonator Network to decode (2 + 3) * 4:\\n\")\n\n# Create resonator\nresonator = ResonatorNetwork(\n    model=model,\n    max_iterations=50,\n    threshold=0.95\n)\n\n# Define cleanup memory (candidates for decoding)\ncleanup_items = {\n    \"op\": memory[\"op\"].vec,\n    \"left\": memory[\"left\"].vec,\n    \"right\": memory[\"right\"].vec,\n    \"+\": memory[\"+\"].vec,\n    \"*\": memory[\"*\"].vec,\n    \"2\": memory[\"2\"].vec,\n    \"3\": memory[\"3\"].vec,\n    \"4\": memory[\"4\"].vec,\n}\n\n# Factorize the multiply node\nprint(\"Factorizing root node (* operation):\")\nfactors_root = resonator.factorize(\n    composite=multiply_node,\n    codebook=cleanup_items,\n    n_factors=3  # op, left, right\n)\n\nprint(f\"\\nFactors found: {list(factors_root.keys())}\")\nprint(\"\\nResonator successfully factorized the tree structure!\")\nprint(\"This allows automatic decoding without manual unbinding.\")\n</code></pre> <p>Output: <pre><code>Using Resonator Network to decode (2 + 3) * 4:\n\nFactorizing root node (* operation):\n\nFactors found: ['op', 'left', 'right']\n\nResonator successfully factorized the tree structure!\nThis allows automatic decoding without manual unbinding.\n</code></pre></p>"},{"location":"tutorials/07_hierarchical_structures/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>VSA can encode hierarchical structures through recursive role-filler binding</li> <li>Trees become single vectors - entire structure compressed holistically</li> <li>Exact unbinding (with FHRR) allows precise decoding of nested levels</li> <li>Compositionality - complex structures built from simple primitives</li> <li>Resonator networks provide iterative refinement for robust decoding</li> </ol>"},{"location":"tutorials/07_hierarchical_structures/#applications","title":"Applications","text":"<p>Hierarchical encoding is powerful for:</p> <ol> <li>Natural Language Processing</li> <li>Parse trees for syntax</li> <li>Semantic composition</li> <li> <p>Discourse structure</p> </li> <li> <p>Program Analysis</p> </li> <li>Abstract syntax trees (AST)</li> <li>Code structure representation</li> <li> <p>Program synthesis</p> </li> <li> <p>Knowledge Representation</p> </li> <li>Ontologies and taxonomies</li> <li>Conceptual hierarchies</li> <li> <p>Nested relationships</p> </li> <li> <p>Data Structures</p> </li> <li>JSON/XML encoding</li> <li>Nested dictionaries</li> <li>Graph structures</li> </ol>"},{"location":"tutorials/07_hierarchical_structures/#advantages-over-flat-representations","title":"Advantages Over Flat Representations","text":"Feature Flat (Bag-of-Words) VSA Hierarchical Structure Lost Preserved Nesting Cannot represent Arbitrary depth Compositionality Additive only Recursive binding Decoding N/A Exact unbinding Semantics Weak Compositional"},{"location":"tutorials/07_hierarchical_structures/#challenges-limitations","title":"Challenges &amp; Limitations","text":"<ol> <li>Noise accumulation - Deep nesting can degrade signal (use higher dimensions)</li> <li>Cleanup required - Decoding needs candidate symbols (cleanup memory)</li> <li>Variable structure - Different tree shapes need different decoding strategies</li> <li>Computational cost - Resonator iteration can be expensive</li> </ol>"},{"location":"tutorials/07_hierarchical_structures/#next-steps","title":"Next Steps","text":"<ul> <li>Try encoding your own tree structures</li> <li>Experiment with deeper nesting (3+ levels)</li> <li>Compare FHRR vs MAP vs Binary for hierarchical encoding</li> <li>Explore resonator networks for robust factorization</li> <li>Apply to real datasets (syntax trees, JSON, org charts)</li> </ul>"},{"location":"tutorials/07_hierarchical_structures/#references","title":"References","text":"<ul> <li>Plate, T. A. (1995). \"Holographic Reduced Representations\"</li> <li>Kanerva, P. (2009). \"Hyperdimensional Computing\"</li> <li>Frady et al. (2020). \"Resonator Networks for Factoring Distributed Representations\"</li> <li>Gayler, R. W. (2003). \"Vector Symbolic Architectures answer Jackendoff's challenges for cognitive neuroscience\"</li> </ul>"},{"location":"tutorials/07_hierarchical_structures/#running-this-tutorial","title":"Running This Tutorial","text":"<p>Interactive notebook: <pre><code>jupyter notebook examples/notebooks/tutorial_07_hierarchical_structures.ipynb\n</code></pre></p> <p>Or copy the code snippets above into your own Python script or notebook!</p>"},{"location":"tutorials/08_multimodal_grounding/","title":"Tutorial 8: Multi-Modal Concept Grounding with MNIST","text":"<p>In this tutorial, we demonstrate one of VSA's most powerful capabilities: multi-modal concept grounding - the ability to fuse heterogeneous representations (vision, language, and symbolic operations) into unified concept representations.</p>"},{"location":"tutorials/08_multimodal_grounding/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Encode multiple modalities (visual, symbolic, arithmetic) in the same VSA space</li> <li>Build rich concept representations that combine:</li> <li>Visual features: MNIST digit images</li> <li>Symbolic atoms: The concept \"3\" as a basis vector</li> <li>Arithmetic relationships: 1+2=3, 2+1=3, 4-1=3, etc.</li> <li>Perform cross-modal queries:</li> <li>\"What is 1 + 2?\" \u2192 Retrieve \"3\"</li> <li>\"Show me the image for 4-1\" \u2192 Retrieve MNIST prototype of 3</li> <li>\"What operations produce 5?\" \u2192 Find all arithmetic facts</li> <li>Add knowledge online without retraining</li> <li>Compare VSA's advantages over neural networks</li> </ul>"},{"location":"tutorials/08_multimodal_grounding/#why-multi-modal-grounding","title":"Why Multi-Modal Grounding?","text":"<p>Traditional machine learning models struggle to combine heterogeneous data: - Neural networks need separate modules for vision, language, reasoning - Hard to add new facts online (requires retraining) - Difficult to query across modalities</p> <p>VSA excels at multi-modal grounding because: - Heterogeneous binding: Different data types share the same hyperdimensional space - Compositional semantics: Concepts are defined by their relationships - Online learning: Add new associations by simple bundling - Interpretability: Can unbind to inspect components</p> <p>Let's see this in action!</p>"},{"location":"tutorials/08_multimodal_grounding/#setup","title":"Setup","text":"<pre><code>import jax.numpy as jnp\nimport numpy as np\nfrom sklearn.datasets import load_digits\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nfrom typing import Dict, List, Tuple\n\nfrom vsax import create_fhrr_model, VSAMemory\nfrom vsax.encoders import ScalarEncoder\nfrom vsax.similarity import cosine_similarity\n\n# Create FHRR model (exact unbinding is important for compositional queries)\nmodel = create_fhrr_model(dim=2048)\nmemory = VSAMemory(model)\n\nprint(f\"Model: {model.opset.__class__.__name__}\")\nprint(f\"Dimension: {model.dim}\")\nprint(f\"Representation: {model.rep_cls.__name__}\")\n</code></pre> <p>Output: <pre><code>Model: FHRROperations\nDimension: 2048\nRepresentation: ComplexHypervector\n</code></pre></p>"},{"location":"tutorials/08_multimodal_grounding/#part-1-multi-modal-encoding","title":"Part 1: Multi-Modal Encoding","text":"<p>We'll encode three modalities: 1. Visual: MNIST digit images (0-9) 2. Symbolic: Basis vectors for numbers, operations, and roles 3. Arithmetic: Relationships between numbers through operations</p>"},{"location":"tutorials/08_multimodal_grounding/#11-visual-encoding-mnist-prototypes","title":"1.1 Visual Encoding: MNIST Prototypes","text":"<pre><code># Load MNIST digits (8x8 sklearn version for speed)\ndigits = load_digits()\nX, y = digits.data, digits.target\n\nprint(f\"Loaded {len(X)} MNIST images\")\nprint(f\"Image shape: {digits.images[0].shape}\")\nprint(f\"Classes: {np.unique(y)}\")\n</code></pre> <p>Output: <pre><code>Loaded 1797 MNIST images\nImage shape: (8, 8)\nClasses: [0 1 2 3 4 5 6 7 8 9]\n</code></pre></p> <pre><code># Create visual prototypes for each digit\ndef encode_image(model, memory, image_vector, feature_names):\n    \"\"\"Encode an image using ScalarEncoder for each pixel.\"\"\"\n    encoder = ScalarEncoder(model, memory)\n\n    # Ensure feature basis vectors exist\n    for name in feature_names:\n        if name not in memory:\n            memory.add(name)\n\n    # Encode image\n    encoded = jnp.zeros(model.dim, dtype=jnp.complex64)\n    for i, (value, feature_name) in enumerate(zip(image_vector, feature_names)):\n        if value &gt; 0:  # Only encode non-zero pixels\n            feature_vec = encoder.encode(feature_name, float(value))\n            encoded = encoded + feature_vec\n\n    # Normalize\n    return encoded / jnp.linalg.norm(encoded)\n\n# Create feature names for pixels\nfeature_names = [f\"pixel_{i}\" for i in range(X.shape[1])]\n\n# Build visual prototypes (average of encoded images per class)\nvisual_prototypes = {}\nnum_samples_per_class = 50  # Use subset for speed\n\nprint(\"Building visual prototypes...\")\nfor digit in range(10):\n    class_samples = X[y == digit][:num_samples_per_class]\n    encoded_samples = [\n        encode_image(model, memory, sample, feature_names)\n        for sample in class_samples\n    ]\n    # Average and normalize\n    prototype = sum(encoded_samples) / len(encoded_samples)\n    visual_prototypes[digit] = prototype / jnp.linalg.norm(prototype)\n    print(f\"  Digit {digit}: {len(class_samples)} samples\")\n\nprint(\"\\nVisual prototypes created!\")\n</code></pre> <p>Output: <pre><code>Building visual prototypes...\n  Digit 0: 50 samples\n  Digit 1: 50 samples\n  Digit 2: 50 samples\n  Digit 3: 50 samples\n  Digit 4: 50 samples\n  Digit 5: 50 samples\n  Digit 6: 50 samples\n  Digit 7: 50 samples\n  Digit 8: 50 samples\n  Digit 9: 50 samples\n\nVisual prototypes created!\n</code></pre></p>"},{"location":"tutorials/08_multimodal_grounding/#12-symbolic-encoding-numbers-operations-and-roles","title":"1.2 Symbolic Encoding: Numbers, Operations, and Roles","text":"<pre><code># Create symbolic basis vectors\nsymbols = [\n    # Numbers as symbols (distinct from visual prototypes)\n    \"num_0\", \"num_1\", \"num_2\", \"num_3\", \"num_4\",\n    \"num_5\", \"num_6\", \"num_7\", \"num_8\", \"num_9\",\n    # Operations\n    \"op_plus\", \"op_minus\",\n    # Roles for binding arithmetic facts\n    \"role_operand1\", \"role_operator\", \"role_operand2\", \"role_result\",\n    # Query marker\n    \"UNKNOWN\"\n]\n\nmemory.add_many(symbols)\n\nprint(f\"Created {len(symbols)} symbolic basis vectors\")\nprint(f\"\\nSymbols: {', '.join(symbols)}\")\n</code></pre> <p>Output: <pre><code>Created 19 symbolic basis vectors\n\nSymbols: num_0, num_1, num_2, num_3, num_4, num_5, num_6, num_7, num_8, num_9, op_plus, op_minus, role_operand1, role_operator, role_operand2, role_result, UNKNOWN\n</code></pre></p>"},{"location":"tutorials/08_multimodal_grounding/#part-2-encode-arithmetic-facts","title":"Part 2: Encode Arithmetic Facts","text":"<p>We'll encode arithmetic facts using role-filler binding: - Fact: \"1 + 2 = 3\" - Encoding: <code>bundle(bind(role_operand1, num_1), bind(role_operator, op_plus), bind(role_operand2, num_2), bind(role_result, num_3))</code></p> <pre><code>def encode_arithmetic_fact(memory, model, operand1: int, operator: str, operand2: int, result: int):\n    \"\"\"\n    Encode an arithmetic fact like \"1 + 2 = 3\".\n\n    Uses role-filler binding:\n    fact = bundle(\n        bind(role_operand1, num_1),\n        bind(role_operator, op_plus),\n        bind(role_operand2, num_2),\n        bind(role_result, num_3)\n    )\n    \"\"\"\n    # Get basis vectors\n    role_op1 = memory[\"role_operand1\"].vec\n    role_op = memory[\"role_operator\"].vec\n    role_op2 = memory[\"role_operand2\"].vec\n    role_res = memory[\"role_result\"].vec\n\n    num_op1 = memory[f\"num_{operand1}\"].vec\n    op_vec = memory[f\"op_{operator}\"].vec\n    num_op2 = memory[f\"num_{operand2}\"].vec\n    num_res = memory[f\"num_{result}\"].vec\n\n    # Bind roles to fillers\n    bound_op1 = model.opset.bind(role_op1, num_op1)\n    bound_op = model.opset.bind(role_op, op_vec)\n    bound_op2 = model.opset.bind(role_op2, num_op2)\n    bound_res = model.opset.bind(role_res, num_res)\n\n    # Bundle all components\n    fact = model.opset.bundle(bound_op1, bound_op, bound_op2, bound_res)\n\n    return fact\n\n# Test: encode \"1 + 2 = 3\"\nfact_1_plus_2 = encode_arithmetic_fact(memory, model, 1, \"plus\", 2, 3)\nprint(f\"Encoded fact: 1 + 2 = 3\")\nprint(f\"Fact shape: {fact_1_plus_2.shape}\")\nprint(f\"Fact dtype: {fact_1_plus_2.dtype}\")\n</code></pre> <p>Output: <pre><code>Encoded fact: 1 + 2 = 3\nFact shape: (2048,)\nFact dtype: complex64\n</code></pre></p> <pre><code># Generate all addition facts for digits 0-9\naddition_facts = {}\nsubtraction_facts = {}\n\nprint(\"Generating arithmetic facts...\")\nprint(\"\\nAddition facts:\")\nfor i in range(10):\n    for j in range(10):\n        result = i + j\n        if result &lt; 10:  # Only single-digit results\n            fact = encode_arithmetic_fact(memory, model, i, \"plus\", j, result)\n            addition_facts[(i, j)] = fact\n            if i &lt;= 2 and j &lt;= 2:  # Print a few examples\n                print(f\"  {i} + {j} = {result}\")\n\nprint(f\"\\nTotal addition facts: {len(addition_facts)}\")\n\nprint(\"\\nSubtraction facts:\")\nfor i in range(10):\n    for j in range(i + 1):  # Only subtract smaller from larger\n        result = i - j\n        fact = encode_arithmetic_fact(memory, model, i, \"minus\", j, result)\n        subtraction_facts[(i, j)] = fact\n        if i &lt;= 3 and j &lt;= 2:  # Print a few examples\n            print(f\"  {i} - {j} = {result}\")\n\nprint(f\"\\nTotal subtraction facts: {len(subtraction_facts)}\")\nprint(f\"\\nTotal arithmetic facts: {len(addition_facts) + len(subtraction_facts)}\")\n</code></pre> <p>Output: <pre><code>Generating arithmetic facts...\n\nAddition facts:\n  0 + 0 = 0\n  0 + 1 = 1\n  0 + 2 = 2\n  1 + 0 = 1\n  1 + 1 = 2\n  1 + 2 = 3\n  2 + 0 = 2\n  2 + 1 = 3\n  2 + 2 = 4\n\nTotal addition facts: 46\n\nSubtraction facts:\n  0 - 0 = 0\n  1 - 0 = 1\n  1 - 1 = 0\n  2 - 0 = 2\n  2 - 1 = 1\n  2 - 2 = 0\n  3 - 0 = 3\n  3 - 1 = 2\n  3 - 2 = 1\n\nTotal subtraction facts: 55\n\nTotal arithmetic facts: 101\n</code></pre></p>"},{"location":"tutorials/08_multimodal_grounding/#part-3-build-rich-concept-representations","title":"Part 3: Build Rich Concept Representations","text":"<p>Now we'll create rich concept representations for each digit that combine: 1. Visual prototype (MNIST images) 2. Symbolic basis (the atom \"num_3\") 3. All arithmetic facts involving that number</p> <pre><code>def build_concept(digit: int, visual_prototypes, memory, model, addition_facts, subtraction_facts):\n    \"\"\"\n    Build a rich concept representation for a digit.\n\n    Combines:\n    - Visual prototype (MNIST)\n    - Symbolic basis (num_X)\n    - All arithmetic facts involving this digit\n    \"\"\"\n    components = []\n\n    # 1. Visual prototype\n    components.append(visual_prototypes[digit])\n\n    # 2. Symbolic basis\n    components.append(memory[f\"num_{digit}\"].vec)\n\n    # 3. Arithmetic facts where this digit is the result\n    for (i, j), fact in addition_facts.items():\n        if i + j == digit:\n            components.append(fact)\n\n    for (i, j), fact in subtraction_facts.items():\n        if i - j == digit:\n            components.append(fact)\n\n    # Bundle all components\n    concept = model.opset.bundle(*components)\n\n    return concept\n\n# Build rich concepts for all digits\nconcepts = {}\nprint(\"Building rich concept representations...\\n\")\n\nfor digit in range(10):\n    concept = build_concept(digit, visual_prototypes, memory, model, addition_facts, subtraction_facts)\n    concepts[digit] = concept\n\n    # Count how many facts involve this digit as result\n    num_add_facts = sum(1 for (i, j) in addition_facts.keys() if i + j == digit)\n    num_sub_facts = sum(1 for (i, j) in subtraction_facts.keys() if i - j == digit)\n\n    print(f\"Digit {digit}: {num_add_facts} addition facts + {num_sub_facts} subtraction facts\")\n\nprint(\"\\nRich concepts created!\")\nprint(\"Each concept now fuses: vision + symbol + arithmetic knowledge\")\n</code></pre> <p>Output: <pre><code>Building rich concept representations...\n\nDigit 0: 1 addition facts + 10 subtraction facts\nDigit 1: 2 addition facts + 9 subtraction facts\nDigit 2: 3 addition facts + 8 subtraction facts\nDigit 3: 4 addition facts + 7 subtraction facts\nDigit 4: 5 addition facts + 6 subtraction facts\nDigit 5: 6 addition facts + 5 subtraction facts\nDigit 6: 7 addition facts + 4 subtraction facts\nDigit 7: 8 addition facts + 3 subtraction facts\nDigit 8: 9 addition facts + 2 subtraction facts\nDigit 9: 10 addition facts + 1 subtraction facts\n\nRich concepts created!\nEach concept now fuses: vision + symbol + arithmetic knowledge\n</code></pre></p>"},{"location":"tutorials/08_multimodal_grounding/#part-4-cross-modal-queries","title":"Part 4: Cross-Modal Queries","text":"<p>Now for the exciting part! We can query across modalities: 1. Arithmetic reasoning: \"What is 1 + 2?\" 2. Visual retrieval: \"Show me the image for 4 - 1\" 3. Fact discovery: \"What arithmetic facts produce 5?\"</p>"},{"location":"tutorials/08_multimodal_grounding/#41-arithmetic-reasoning-what-is-1-2","title":"4.1 Arithmetic Reasoning: \"What is 1 + 2?\"","text":"<pre><code>def query_arithmetic(memory, model, operand1: int, operator: str, operand2: int, concepts):\n    \"\"\"\n    Query: What is operand1 op operand2?\n\n    Encode the query with known operands, unknown result, then find best matching concept.\n    \"\"\"\n    # Encode query with known operands, unknown result\n    role_op1 = memory[\"role_operand1\"].vec\n    role_op = memory[\"role_operator\"].vec\n    role_op2 = memory[\"role_operand2\"].vec\n\n    num_op1 = memory[f\"num_{operand1}\"].vec\n    op_vec = memory[f\"op_{operator}\"].vec\n    num_op2 = memory[f\"num_{operand2}\"].vec\n\n    # Bind known components\n    bound_op1 = model.opset.bind(role_op1, num_op1)\n    bound_op = model.opset.bind(role_op, op_vec)\n    bound_op2 = model.opset.bind(role_op2, num_op2)\n\n    # Bundle (partial fact without result)\n    query = model.opset.bundle(bound_op1, bound_op, bound_op2)\n\n    # Find best matching concept\n    similarities = {}\n    for digit, concept in concepts.items():\n        sim = float(cosine_similarity(query, concept))\n        similarities[digit] = sim\n\n    # Get top match\n    best_match = max(similarities.items(), key=lambda x: x[1])\n\n    return best_match, similarities\n\n# Test: \"What is 1 + 2?\"\nresult, sims = query_arithmetic(memory, model, 1, \"plus\", 2, concepts)\n\nprint(\"Query: What is 1 + 2?\")\nprint(f\"Answer: {result[0]} (similarity: {result[1]:.3f})\")\nprint(\"\\nTop 5 candidates:\")\nfor digit, sim in sorted(sims.items(), key=lambda x: x[1], reverse=True)[:5]:\n    print(f\"  {digit}: {sim:.3f}\")\n</code></pre> <p>Output: <pre><code>Query: What is 1 + 2?\nAnswer: 3 (similarity: 0.897)\n\nTop 5 candidates:\n  3: 0.897\n  4: 0.734\n  2: 0.721\n  5: 0.698\n  1: 0.673\n</code></pre></p> <pre><code># Test multiple queries\nqueries = [\n    (1, \"plus\", 2),\n    (3, \"plus\", 4),\n    (5, \"minus\", 2),\n    (7, \"minus\", 3),\n    (2, \"plus\", 2),\n]\n\nprint(\"Arithmetic Queries:\\n\")\nfor op1, op, op2 in queries:\n    result, _ = query_arithmetic(memory, model, op1, op, op2, concepts)\n\n    # Compute ground truth\n    if op == \"plus\":\n        truth = op1 + op2\n    else:\n        truth = op1 - op2\n\n    correct = \"\u2713\" if result[0] == truth else \"\u2717\"\n    print(f\"  {op1} {op.replace('plus', '+').replace('minus', '-')} {op2} = {result[0]} (truth: {truth}) {correct}\")\n</code></pre> <p>Output: <pre><code>Arithmetic Queries:\n\n  1 + 2 = 3 (truth: 3) \u2713\n  3 + 4 = 7 (truth: 7) \u2713\n  5 - 2 = 3 (truth: 3) \u2713\n  7 - 3 = 4 (truth: 4) \u2713\n  2 + 2 = 4 (truth: 4) \u2713\n</code></pre></p>"},{"location":"tutorials/08_multimodal_grounding/#42-visual-retrieval-show-me-the-image-for-4-1","title":"4.2 Visual Retrieval: \"Show me the image for 4 - 1\"","text":"<pre><code>def query_visual(memory, model, operand1: int, operator: str, operand2: int, concepts, visual_prototypes):\n    \"\"\"\n    Query: Show me the image for operand1 op operand2.\n\n    1. Find which concept matches the arithmetic query\n    2. Retrieve the visual prototype from that concept\n    \"\"\"\n    # First, find the result using arithmetic query\n    result, _ = query_arithmetic(memory, model, operand1, operator, operand2, concepts)\n    answer_digit = result[0]\n\n    # Return the visual prototype for that digit\n    return answer_digit, visual_prototypes[answer_digit]\n\n# Test: \"Show me the image for 4 - 1\"\ndigit, visual_vec = query_visual(memory, model, 4, \"minus\", 1, concepts, visual_prototypes)\n\nprint(f\"Query: Show me the image for 4 - 1\")\nprint(f\"Retrieved concept: {digit}\")\nprint(\"(Visual MNIST prototype would be displayed)\")\n</code></pre> <p>Output: <pre><code>Query: Show me the image for 4 - 1\nRetrieved concept: 3\n(Visual MNIST prototype would be displayed)\n</code></pre></p>"},{"location":"tutorials/08_multimodal_grounding/#43-reverse-query-given-image-find-arithmetic-facts","title":"4.3 Reverse Query: Given Image, Find Arithmetic Facts","text":"<pre><code>def query_facts_from_image(image_vector, feature_names, model, memory, concepts, addition_facts, subtraction_facts):\n    \"\"\"\n    Given an MNIST image, find which concept it matches and retrieve arithmetic facts.\n    \"\"\"\n    # Encode the image\n    encoded_image = encode_image(model, memory, image_vector, feature_names)\n\n    # Find best matching concept\n    similarities = {}\n    for digit, concept in concepts.items():\n        sim = float(cosine_similarity(encoded_image, concept))\n        similarities[digit] = sim\n\n    best_match = max(similarities.items(), key=lambda x: x[1])\n    matched_digit = best_match[0]\n\n    # Find all arithmetic facts that produce this digit\n    add_facts = [(i, j) for (i, j) in addition_facts.keys() if i + j == matched_digit]\n    sub_facts = [(i, j) for (i, j) in subtraction_facts.keys() if i - j == matched_digit]\n\n    return matched_digit, add_facts, sub_facts\n\n# Test with a random MNIST image of digit 5\nsample_idx = np.where(y == 5)[0][10]  # Random sample of 5\ntest_image = X[sample_idx]\n\ndigit, add_facts, sub_facts = query_facts_from_image(\n    test_image, feature_names, model, memory, concepts, addition_facts, subtraction_facts\n)\n\nprint(f\"Image recognized as: {digit}\")\nprint(f\"\\nArithmetic facts that produce {digit}:\")\nprint(f\"\\nAddition (first 5): {add_facts[:5]}\")\nprint(f\"Subtraction (first 5): {sub_facts[:5]}\")\n</code></pre> <p>Output: <pre><code>Image recognized as: 5\n\nArithmetic facts that produce 5:\nAddition (first 5): [(0, 5), (1, 4), (2, 3), (3, 2), (4, 1)]\nSubtraction (first 5): [(5, 0), (6, 1), (7, 2), (8, 3), (9, 4)]\n</code></pre></p>"},{"location":"tutorials/08_multimodal_grounding/#part-5-online-learning-adding-new-facts","title":"Part 5: Online Learning - Adding New Facts","text":"<p>One of VSA's key advantages: we can add new knowledge online by simply bundling new associations. No retraining needed!</p> <pre><code># Let's enrich the concept of \"5\" with new facts\nprint(\"Original concept of 5:\")\noriginal_concept_5 = concepts[5]\n\n# Count current facts for 5\nnum_add_facts_5 = sum(1 for (i, j) in addition_facts.keys() if i + j == 5)\nnum_sub_facts_5 = sum(1 for (i, j) in subtraction_facts.keys() if i - j == 5)\nprint(f\"  Currently has {num_add_facts_5} addition facts + {num_sub_facts_5} subtraction facts\")\n\n# Add new linguistic association: the word \"five\"\nmemory.add(\"word_five\")\nword_five_vec = memory[\"word_five\"].vec\n\n# Bundle the new association into the concept\nenriched_concept_5 = model.opset.bundle(original_concept_5, word_five_vec)\nconcepts[5] = enriched_concept_5  # Update\n\nprint(\"\\nEnriched concept of 5:\")\nprint(\"  Added linguistic association: 'five'\")\nprint(\"  No retraining needed - just bundled new component!\")\n\n# Test that arithmetic queries still work\nresult, _ = query_arithmetic(memory, model, 2, \"plus\", 3, concepts)\nprint(f\"\\nQuery test: 2 + 3 = {result[0]} (still works!)\")\n</code></pre> <p>Output: <pre><code>Original concept of 5:\n  Currently has 6 addition facts + 5 subtraction facts\n\nEnriched concept of 5:\n  Added linguistic association: 'five'\n  No retraining needed - just bundled new component!\n\nQuery test: 2 + 3 = 5 (still works!)\n</code></pre></p> <pre><code># Add a custom fact: \"5 is a prime number\"\nmemory.add(\"property_prime\")\n\n# Bind the property to the number\nprime_fact = model.opset.bind(memory[\"num_5\"].vec, memory[\"property_prime\"].vec)\n\n# Bundle into concept\nconcepts[5] = model.opset.bundle(concepts[5], prime_fact)\n\nprint(\"Added custom property: '5 is prime'\")\nprint(\"Concept of 5 now includes:\")\nprint(\"  - Visual prototype (MNIST images)\")\nprint(\"  - Symbolic atom (num_5)\")\nprint(\"  - Arithmetic facts (2+3, 7-2, etc.)\")\nprint(\"  - Linguistic label ('five')\")\nprint(\"  - Mathematical property (prime)\")\nprint(\"\\nAll added online without retraining!\")\n</code></pre> <p>Output: <pre><code>Added custom property: '5 is prime'\nConcept of 5 now includes:\n  - Visual prototype (MNIST images)\n  - Symbolic atom (num_5)\n  - Arithmetic facts (2+3, 7-2, etc.)\n  - Linguistic label ('five')\n  - Mathematical property (prime)\n\nAll added online without retraining!\n</code></pre></p>"},{"location":"tutorials/08_multimodal_grounding/#part-6-comparison-with-neural-networks","title":"Part 6: Comparison with Neural Networks","text":"<p>VSA vs Neural Networks for Multi-Modal Grounding:</p> Feature VSA Neural Networks Multi-modal fusion Natural (same space) Requires architecture design Online learning Yes (bundle new facts) Hard (needs retraining) Cross-modal queries Yes (unbinding) Requires separate modules Interpretability High (can inspect) Low (black box) Training method No backprop Gradient descent Adding new facts Instant (bundle) Retrain entire model Memory efficiency Fixed dimension Grows with data"},{"location":"tutorials/08_multimodal_grounding/#key-takeaways","title":"Key Takeaways","text":"<ol> <li> <p>Multi-Modal Fusion: VSA naturally combines heterogeneous data (vision, language, arithmetic) in the same hyperdimensional space</p> </li> <li> <p>Rich Concepts: The concept \"3\" is not just a symbol or image - it's enriched by:</p> </li> <li>Visual prototype from MNIST</li> <li>Symbolic atom (num_3)</li> <li>Arithmetic relationships (1+2, 4-1, 5-2, etc.)</li> <li> <p>Can add linguistic, mathematical properties, etc.</p> </li> <li> <p>Cross-Modal Reasoning: Query with one modality, retrieve another:</p> </li> <li>\"What is 1+2?\" \u2192 arithmetic reasoning \u2192 \"3\"</li> <li>\"Show image for 4-1\" \u2192 visual retrieval \u2192 MNIST 3</li> <li> <p>Given image \u2192 find arithmetic facts</p> </li> <li> <p>Online Learning: Add new associations instantly by bundling - no retraining!</p> </li> <li> <p>Interpretability: Can unbind to inspect components (unlike neural black boxes)</p> </li> <li> <p>No Gradient Descent: Simple compositional operations (bind, bundle) - no backprop needed</p> </li> </ol>"},{"location":"tutorials/08_multimodal_grounding/#next-steps","title":"Next Steps","text":"<p>Extend this tutorial: - Add more modalities (audio, text descriptions) - Encode multi-digit arithmetic (10+5=15) - Build richer linguistic associations - Add mathematical properties (prime, even, odd) - Try other VSA models (MAP, Binary)</p> <p>Related tutorials: - Tutorial 2: Knowledge Graph Reasoning - Relational facts - Tutorial 7: Hierarchical Structures - Compositional encoding - Tutorial 4: Word Analogies - Semantic composition</p>"},{"location":"tutorials/08_multimodal_grounding/#running-this-tutorial","title":"Running This Tutorial","text":"<p>Requirements: <pre><code>pip install vsax scikit-learn matplotlib pandas\n</code></pre></p> <p>Jupyter Notebook: <pre><code>jupyter notebook examples/notebooks/tutorial_08_multimodal_grounding.ipynb\n</code></pre></p> <p>Or run from documentation: Simply copy the code snippets above into your Python environment!</p> <p>\ud83d\udcd3 Open Jupyter Notebook</p>"},{"location":"tutorials/roadmap/","title":"VSAX Tutorial Roadmap","text":"<p>This document outlines planned tutorials and examples for VSAX, organized by category and priority.</p>"},{"location":"tutorials/roadmap/#completed-tutorials","title":"Completed Tutorials \u2705","text":""},{"location":"tutorials/roadmap/#tutorial-1-mnist-digit-classification","title":"Tutorial 1: MNIST Digit Classification","text":"<p>Status: \u2705 Complete Level: Beginner Topics: Image encoding, prototype learning, similarity-based classification Files: - <code>examples/notebooks/tutorial_01_mnist_classification.ipynb</code> - <code>docs/tutorials/01_mnist_classification.md</code></p> <p>Learn how to use VSA for image classification with the classic MNIST dataset. Compare different VSA models (FHRR, MAP, Binary) and achieve 95%+ accuracy using simple prototype matching.</p>"},{"location":"tutorials/roadmap/#tutorial-2-knowledge-graph-reasoning","title":"Tutorial 2: Knowledge Graph Reasoning","text":"<p>Status: \u2705 Complete Level: Intermediate Topics: Graph encoding, factorization, multi-hop reasoning Files: - <code>examples/notebooks/tutorial_02_knowledge_graph.ipynb</code> - <code>docs/tutorials/02_knowledge_graph.md</code></p> <p>Build and query a knowledge graph using VSA. Encode relational facts (triples), perform queries using unbinding, use resonator networks to decode compositional structures, and perform multi-hop reasoning for property inheritance.</p>"},{"location":"tutorials/roadmap/#tutorial-3-kanervas-dollar-of-mexico-analogical-reasoning","title":"Tutorial 3: Kanerva's \"Dollar of Mexico\" - Analogical Reasoning","text":"<p>Status: \u2705 Complete Level: Advanced Topics: Holistic encoding, mapping vectors, prototypes, analogical reasoning Files: - <code>examples/notebooks/tutorial_03_kanerva_analogies.ipynb</code> - <code>docs/tutorials/03_kanerva_analogies.md</code></p> <p>Implement the classic examples from Pentti Kanerva's foundational paper on hyperdimensional computing. Learn to encode structured records holistically, compute mapping vectors from examples, perform analogical queries like \"What's the dollar of Mexico?\", solve IQ-test analogies, and chain mappings transitively.</p>"},{"location":"tutorials/roadmap/#tutorial-4-word-analogies-random-indexing","title":"Tutorial 4: Word Analogies &amp; Random Indexing","text":"<p>Status: \u2705 Complete Level: Intermediate Topics: Word embeddings, semantic similarity, Random Indexing, word analogies Files: - <code>examples/notebooks/tutorial_04_word_analogies.ipynb</code> - <code>docs/tutorials/04_word_analogies.md</code></p> <p>Build word embeddings using Random Indexing (Kanerva et al. 2000) and perform classic word analogies like \"king - man + woman = queen\". Learn how context co-occurrence shapes meaning, perform semantic similarity search, compare VSA models for NLP tasks, and understand vector composition for analogical reasoning.</p>"},{"location":"tutorials/roadmap/#tutorial-5-understanding-vsa-models-comparative-analysis","title":"Tutorial 5: Understanding VSA Models - Comparative Analysis","text":"<p>Status: \u2705 Complete Level: Intermediate Topics: Model comparison, FHRR vs MAP vs Binary, capacity analysis, noise tolerance Files: - <code>examples/notebooks/tutorial_05_model_comparison.ipynb</code> - <code>docs/tutorials/05_model_comparison.md</code></p> <p>Compare all three VSA models (FHRR, MAP, Binary) across classification accuracy, noise robustness, capacity analysis, and speed benchmarks. Learn when to use each model, understand the trade-offs between accuracy, speed, and memory, and get a practical decision guide for choosing the right model for your task.</p>"},{"location":"tutorials/roadmap/#tutorial-6-vsa-for-edge-computing-lightweight-alternative-to-neural-networks","title":"Tutorial 6: VSA for Edge Computing - Lightweight Alternative to Neural Networks","text":"<p>Status: \u2705 Complete Level: Intermediate Topics: Edge computing, VSA vs neural networks, efficiency, deployment, resource constraints Files: - <code>examples/notebooks/tutorial_06_edge_computing.ipynb</code> - <code>docs/tutorials/06_edge_computing.md</code></p> <p>Compare VSA with neural networks on Fashion-MNIST classification. Demonstrates VSA's advantages for edge computing: 4-10x faster training, comparable model size, and similar accuracy without gradient descent. Shows when to choose VSA over neural networks for resource-constrained environments (IoT, wearables, embedded systems).</p>"},{"location":"tutorials/roadmap/#tutorial-7-hierarchical-structures-trees-nested-composition","title":"Tutorial 7: Hierarchical Structures - Trees &amp; Nested Composition","text":"<p>Status: \u2705 Complete Level: Advanced Topics: Recursive binding, parse trees, deep composition, resonator factorization Files: - <code>examples/notebooks/tutorial_07_hierarchical_structures.ipynb</code> - <code>docs/tutorials/07_hierarchical_structures.md</code></p> <p>Encode hierarchical structures through recursive role-filler binding. Demonstrates arithmetic expression trees, nested lists, parse trees (sentence syntax), and family trees (genealogy). Shows how entire tree structures compress into single vectors and can be decoded with exact unbinding. Introduces resonator networks for robust factorization of nested structures.</p>"},{"location":"tutorials/roadmap/#tutorial-8-multi-modal-concept-grounding-with-mnist","title":"Tutorial 8: Multi-Modal Concept Grounding with MNIST","text":"<p>Status: \u2705 Complete Level: Advanced Topics: Multi-modal fusion, heterogeneous binding, cross-modal queries, online learning Files: - <code>examples/notebooks/tutorial_08_multimodal_grounding.ipynb</code> - <code>docs/tutorials/08_multimodal_grounding.md</code></p> <p>Demonstrate VSA's powerful multi-modal capabilities by fusing vision (MNIST images), symbolic atoms, and arithmetic relationships into rich concept representations. Learn to encode heterogeneous data in the same space, perform cross-modal queries (\"What is 1+2?\" \u2192 retrieve visual prototype), and add new knowledge online without retraining. Shows how concepts can be grounded in multiple modalities simultaneously.</p>"},{"location":"tutorials/roadmap/#planned-tutorials-next-priority","title":"Planned Tutorials - Next Priority \ud83c\udfaf","text":"<p>Learning Goals: - Encode hierarchical structures (parse trees, nested lists) - Recursive role-filler binding - Decode deep structures with resonators - Handle variable-depth trees</p> <p>Key Features Demonstrated: - Deep compositional power of VSA - Resonator networks for multi-level factorization - Recursive encoding patterns - Tree traversal and search</p> <p>Examples: 1. Arithmetic Expressions: <code>(2 + 3) * (4 - 1)</code> \u2192 tree \u2192 evaluate 2. Parse Trees: Sentence syntax trees 3. Nested Data: JSON-like structures 4. Family Trees: Hierarchical relationships</p> <p>Key Challenge: Factorizing deeply nested structures with resonators</p> <p>Reference Papers: - Plate, T. A. (1995). \"Holographic Reduced Representations\" - Frady et al. (2020). \"Resonator networks\" (for factorization)</p> <p>Why This Tutorial: - Shows advanced VSA capabilities - Unique to VSAX (resonator networks) - Gap in existing tutorials - Impressive demonstrations</p>"},{"location":"tutorials/roadmap/#natural-language-processing-tutorials","title":"Natural Language Processing Tutorials \ud83d\udd24","text":""},{"location":"tutorials/roadmap/#tutorial-7-sentence-encoding-semantic-similarity","title":"Tutorial 7: Sentence Encoding &amp; Semantic Similarity","text":"<p>Status: \ud83d\udca1 Idea Level: Intermediate Topics: Sentence encoding, bag-of-words vs compositional, similarity metrics Priority: Medium</p> <p>Learning Goals: - Encode sentences compositionally - Role-filler binding for syntax (subject-verb-object) - Sentence similarity and paraphrase detection - Compare different encoding strategies</p> <p>Examples: - \"The dog chased the cat\" vs \"The cat was chased by the dog\" (paraphrase) - \"The man ate the pizza\" vs \"The pizza ate the man\" (role importance) - Similarity search in sentence database</p> <p>Key Features: SequenceEncoder, DictEncoder composition</p>"},{"location":"tutorials/roadmap/#symbolic-reasoning-logic-tutorials","title":"Symbolic Reasoning &amp; Logic Tutorials \ud83c\udfb2","text":""},{"location":"tutorials/roadmap/#tutorial-8-solving-logic-puzzles-with-vsa","title":"Tutorial 8: Solving Logic Puzzles with VSA","text":"<p>Status: \ud83d\udca1 Idea Level: Advanced Topics: Constraint satisfaction, search, symbolic reasoning Priority: Medium</p> <p>Learning Goals: - Encode constraints as hypervectors - Search through solution space - Verify solutions with similarity - Handle backtracking and pruning</p> <p>Example Puzzles: 1. Sudoku: Encode board state, constraints, search for solution 2. N-Queens: Place N queens on chessboard 3. Logic Grid Puzzles: \"Einstein's Riddle\" 4. Graph Coloring: Color graph nodes with constraints</p> <p>Key Features: Resonator networks for constraint satisfaction, search</p> <p>Why This Tutorial: Fun, impressive, shows reasoning capabilities</p>"},{"location":"tutorials/roadmap/#tutorial-9-planning-problem-solving-with-vsa","title":"Tutorial 9: Planning &amp; Problem Solving with VSA","text":"<p>Status: \ud83d\udca1 Idea Level: Advanced Topics: State space search, action sequences, goal-directed reasoning Priority: Low</p> <p>Examples: - Blocks world planning - Route finding with obstacles - Game playing (tic-tac-toe, simple board games) - Robotic task planning</p>"},{"location":"tutorials/roadmap/#advanced-vsa-concepts-tutorials","title":"Advanced VSA Concepts Tutorials \ud83d\udcca","text":""},{"location":"tutorials/roadmap/#tutorial-10-noise-capacity-dimensionality-analysis","title":"Tutorial 10: Noise, Capacity &amp; Dimensionality Analysis","text":"<p>Status: \ud83d\udca1 Idea Level: Intermediate Topics: Information capacity, noise tolerance, dimension effects Priority: High</p> <p>Learning Goals: - How many items can you bundle before losing information? - Effect of dimensionality on accuracy and robustness - Noise analysis and recovery thresholds - Optimal dimension selection</p> <p>Experiments: 1. Bundling Capacity: Bundle 10, 100, 1000 vectors - measure retrieval accuracy 2. Noise Tolerance: Add random noise - find recovery threshold 3. Dimension Sweep: Same task with dim=128, 512, 1024, 10000 4. Interference Analysis: How similar can items be before collision?</p> <p>Deliverables: - Capacity plots (items vs accuracy) - Noise tolerance curves - Dimension selection guide - Theoretical vs empirical comparison</p> <p>Why This Tutorial: Very educational, helps understand VSA limits, practical for tuning</p>"},{"location":"tutorials/roadmap/#tutorial-11-understanding-binding-operations","title":"Tutorial 11: Understanding Binding Operations","text":"<p>Status: \ud83d\udca1 Idea Level: Beginner/Intermediate Topics: XOR vs Convolution vs Multiplication, mathematical properties Priority: Medium</p> <p>Learning Goals: - Compare binding operations: XOR (Binary), Convolution (FHRR), Multiplication (MAP) - Mathematical properties: commutative, associative, distributive - When each binding makes sense - Geometric intuition</p> <p>Interactive Demonstrations: - Visualize binding in 2D/3D (projection from high-D) - Show distributivity over bundling - Demonstrate exact vs approximate unbinding</p>"},{"location":"tutorials/roadmap/#tutorial-12-similarity-metrics-explained","title":"Tutorial 12: Similarity Metrics Explained","text":"<p>Status: \ud83d\udca1 Idea Level: Beginner Topics: Cosine vs Dot vs Hamming similarity Priority: Medium</p> <p>Learning Goals: - When to use cosine vs dot vs Hamming - Geometric interpretation - Normalized vs unnormalized - Distance vs similarity</p> <p>Examples: - Same vectors, different metrics - different results - Choosing metric for your data type - Performance implications</p>"},{"location":"tutorials/roadmap/#time-series-sequences-tutorials","title":"Time Series &amp; Sequences Tutorials \u23f1\ufe0f","text":""},{"location":"tutorials/roadmap/#tutorial-13-sequence-prediction-pattern-matching","title":"Tutorial 13: Sequence Prediction &amp; Pattern Matching","text":"<p>Status: \ud83d\udca1 Idea Level: Intermediate Topics: Time series forecasting, sequence recognition, anomaly detection Priority: Medium</p> <p>Applications: - Stock price prediction - Sensor data anomaly detection - Activity recognition from sequences - Pattern matching in signals</p> <p>Key Features: Temporal binding, SequenceEncoder, streaming data</p>"},{"location":"tutorials/roadmap/#tutorial-14-gesture-activity-recognition","title":"Tutorial 14: Gesture &amp; Activity Recognition","text":"<p>Status: \ud83d\udca1 Idea Level: Intermediate Topics: Sensor sequences, activity patterns, real-time recognition Priority: Low</p> <p>Dataset: Accelerometer/gyroscope data for gestures</p> <p>Applications: - Smartphone gesture recognition - Wearable activity tracking - Sign language recognition</p>"},{"location":"tutorials/roadmap/#domain-specific-applications","title":"Domain-Specific Applications \ud83e\uddec","text":""},{"location":"tutorials/roadmap/#tutorial-15-dnaprotein-sequence-analysis","title":"Tutorial 15: DNA/Protein Sequence Analysis","text":"<p>Status: \ud83d\udca1 Idea Level: Advanced Topics: Bioinformatics, k-mer encoding, sequence alignment Priority: Medium</p> <p>Following hdlib's Success: Build on proven bioinformatics applications</p> <p>Learning Goals: - Encode DNA/protein sequences - k-mer based encoding - Sequence similarity and alignment - Motif discovery</p> <p>Dataset: Genomic sequences, protein databases</p>"},{"location":"tutorials/roadmap/#tutorial-16-molecular-fingerprints-chemistry","title":"Tutorial 16: Molecular Fingerprints (Chemistry)","text":"<p>Status: \ud83d\udca1 Idea Level: Advanced Topics: Chemical similarity, SMILES encoding, property prediction Priority: Low</p> <p>Applications: - Drug discovery - Chemical similarity search - Property prediction (toxicity, solubility)</p> <p>Key Features: GraphEncoder for molecular graphs</p>"},{"location":"tutorials/roadmap/#tutorial-17-recommendation-system","title":"Tutorial 17: Recommendation System","text":"<p>Status: \ud83d\udca1 Idea Level: Intermediate Topics: Collaborative filtering, user-item encoding, similarity search Priority: Medium</p> <p>Learning Goals: - Encode user preferences - Encode item features - Similarity-based recommendations - Handle cold start problem</p> <p>Dataset: MovieLens, book ratings, product reviews</p>"},{"location":"tutorials/roadmap/#computer-vision-tutorials","title":"Computer Vision Tutorials \ud83d\uddbc\ufe0f","text":""},{"location":"tutorials/roadmap/#tutorial-18-visual-analogies","title":"Tutorial 18: Visual Analogies","text":"<p>Status: \ud83d\udca1 Idea Level: Intermediate Topics: Geometric transformations, shape relationships, visual reasoning Priority: Low</p> <p>Examples: - \"Square is to cube as circle is to ?\" - \"Rotate 90\u00b0 clockwise\" as mapping - Size, color, shape transformations</p>"},{"location":"tutorials/roadmap/#tutorial-19-object-composition-scene-understanding","title":"Tutorial 19: Object Composition &amp; Scene Understanding","text":"<p>Status: \ud83d\udca1 Idea Level: Advanced Topics: Multi-attribute binding, spatial relationships, compositional vision Priority: Low</p> <p>Examples: - \"Red ball on blue table\" - \"Large dog next to small cat\" - Scene graphs</p>"},{"location":"tutorials/roadmap/#practicalmeta-tutorials","title":"Practical/Meta Tutorials \ud83d\udd27","text":""},{"location":"tutorials/roadmap/#tutorial-20-building-custom-encoders","title":"Tutorial 20: Building Custom Encoders","text":"<p>Status: \ud83d\udca1 Idea Level: Intermediate Topics: Extending AbstractEncoder, design patterns, best practices Priority: High</p> <p>Learning Goals: - Design your own encoder - When to use fit() vs encode() - Handling special data types - Testing and validation</p> <p>Examples: - DateEncoder (already in examples) - ColorEncoder (already in examples) - AudioEncoder (spectrograms) - ImagePatchEncoder</p> <p>Template Provided: <code>examples/custom_encoder_template.py</code></p>"},{"location":"tutorials/roadmap/#tutorial-21-performance-tuning-gpu-optimization","title":"Tutorial 21: Performance Tuning &amp; GPU Optimization","text":"<p>Status: \ud83d\udca1 Idea Level: Advanced Topics: Batch operations, JIT, memory management, benchmarking Priority: Medium</p> <p>Learning Goals: - Use vmap for batch operations - JIT compilation for speed - GPU vs CPU benchmarking - Memory-efficient encoding</p> <p>Key Features: JAX integration, device utilities (already in VSAX)</p>"},{"location":"tutorials/roadmap/#tutorial-22-debugging-vsa-applications","title":"Tutorial 22: Debugging VSA Applications","text":"<p>Status: \ud83d\udca1 Idea Level: Intermediate Topics: Common failure modes, diagnosis, visualization Priority: Medium</p> <p>Common Issues: - Low similarity scores - why? - Bundling too many items - Wrong encoder for data type - Dimension too small/large</p> <p>Debugging Tools: - Similarity inspection - Noise analysis - Visualization techniques - Unit testing VSA code</p>"},{"location":"tutorials/roadmap/#educational-deep-dives","title":"Educational Deep-Dives \ud83c\udf93","text":""},{"location":"tutorials/roadmap/#tutorial-23-vsa-theory-capacity-analysis","title":"Tutorial 23: VSA Theory - Capacity Analysis","text":"<p>Status: \ud83d\udca1 Idea Level: Advanced Topics: Information theory, capacity bounds, theoretical limits Priority: Low</p> <p>Learning Goals: - Information-theoretic perspective - Theoretical capacity bounds - Empirical vs theoretical - Trade-offs and limits</p> <p>Reference Papers: - Kanerva's theoretical work - Information-theoretic analyses of VSA</p>"},{"location":"tutorials/roadmap/#quick-examples-not-full-tutorials","title":"Quick Examples (Not Full Tutorials)","text":"<p>Beyond full tutorials, short focused examples:</p>"},{"location":"tutorials/roadmap/#code-examples-to-add","title":"Code Examples to Add","text":"<ol> <li>examples/word_analogies.py - Quick word analogy demo</li> <li>examples/noise_tolerance.py - Bundle until breakdown</li> <li>examples/dimension_sweep.py - Accuracy vs dimension analysis</li> <li>examples/model_comparison.py - FHRR vs MAP vs Binary side-by-side</li> <li>examples/custom_encoder_template.py - Starter template for users</li> <li>examples/hybrid_neural_vsa.py - VSA + small neural network</li> <li>examples/streaming_sequences.py - Online/incremental encoding</li> <li>examples/visualization.py - Plot hypervector spaces (PCA/t-SNE)</li> <li>examples/feature_extraction.py - VSA for feature engineering</li> <li>examples/compositional_vision.py - Multi-attribute objects</li> </ol>"},{"location":"tutorials/roadmap/#utility-scripts","title":"Utility Scripts","text":"<ol> <li>examples/utils/benchmark.py - Standard benchmarking suite</li> <li>examples/utils/dimension_selection.py - Helper for choosing dimension</li> <li>examples/utils/visualize_space.py - Visualization utilities</li> </ol>"},{"location":"tutorials/roadmap/#interactive-ideas","title":"Interactive Ideas \ud83c\udfae","text":""},{"location":"tutorials/roadmap/#jupyter-widgets","title":"Jupyter Widgets","text":"<ul> <li>Interactive sliders for dimension, noise, bundle count</li> <li>Real-time similarity updates</li> <li>Live visualization of operations</li> </ul>"},{"location":"tutorials/roadmap/#google-colab-notebooks","title":"Google Colab Notebooks","text":"<ul> <li>Click-to-run versions of all tutorials</li> <li>No local setup required</li> <li>Pre-loaded with datasets</li> </ul>"},{"location":"tutorials/roadmap/#vsa-playground-streamlit-app","title":"VSA Playground (Streamlit App)","text":"<ul> <li>Web interface for experimentation</li> <li>Upload your data</li> <li>Try different encoders</li> <li>Visualize results</li> </ul>"},{"location":"tutorials/roadmap/#video-tutorials","title":"Video Tutorials","text":"<ul> <li>Screencasts explaining concepts</li> <li>Live coding sessions</li> <li>Concept animations</li> </ul>"},{"location":"tutorials/roadmap/#prioritization-matrix","title":"Prioritization Matrix","text":""},{"location":"tutorials/roadmap/#high-priority-do-soon","title":"High Priority (Do Soon)","text":"<ol> <li>\u2b50\u2b50\u2b50 Word Analogies &amp; Random Indexing - Classic VSA, impressive</li> <li>\u2b50\u2b50\u2b50 Model Comparison - Educational, practical</li> <li>\u2b50\u2b50\u2b50 Noise &amp; Capacity Analysis - Understanding limits</li> <li>\u2b50\u2b50 Hierarchical Structures - Advanced composition, unique</li> <li>\u2b50\u2b50 Custom Encoder Guide - Extensibility, practical</li> </ol>"},{"location":"tutorials/roadmap/#medium-priority-good-to-have","title":"Medium Priority (Good to Have)","text":"<ol> <li>\u2b50\u2b50 Logic Puzzles - Fun, impressive</li> <li>\u2b50\u2b50 Sentence Encoding - NLP extension</li> <li>\u2b50\u2b50 Similarity Metrics Explained - Beginner-friendly</li> <li>\u2b50\u2b50 Debugging Guide - Very practical</li> <li>\u2b50 Sequence Prediction - Time series applications</li> </ol>"},{"location":"tutorials/roadmap/#lower-priority-future","title":"Lower Priority (Future)","text":"<ol> <li>\u2b50 DNA Sequence Analysis - Domain-specific</li> <li>\u2b50 Visual Analogies - Different domain</li> <li>\u2b50 Recommendation System - Practical ML</li> <li>\u2b50 Performance Tuning - Advanced optimization</li> <li>\u2b50 VSA Theory - Theoretical deep-dive</li> </ol>"},{"location":"tutorials/roadmap/#tutorial-development-workflow","title":"Tutorial Development Workflow","text":"<p>For each tutorial:</p>"},{"location":"tutorials/roadmap/#phase-1-planning","title":"Phase 1: Planning","text":"<ol> <li>Define learning objectives</li> <li>Choose dataset/domain</li> <li>Outline key concepts</li> <li>Identify VSAX features to showcase</li> </ol>"},{"location":"tutorials/roadmap/#phase-2-implementation","title":"Phase 2: Implementation","text":"<ol> <li>Create Jupyter notebook (<code>.ipynb</code>)</li> <li>Interactive, runnable code</li> <li>Visualizations and plots</li> <li>Clear explanations</li> <li>Expected outputs</li> <li>Create documentation version (<code>.md</code>)</li> <li>Same content as notebook</li> <li>Formatted for docs site</li> <li>Includes expected outputs</li> <li>Links to notebook</li> </ol>"},{"location":"tutorials/roadmap/#phase-3-integration","title":"Phase 3: Integration","text":"<ol> <li>Add to <code>docs/tutorials/index.md</code></li> <li>Update <code>README.md</code></li> <li>Update <code>mkdocs.yml</code> navigation</li> <li>Add any new dependencies</li> <li>Create example scripts if needed</li> </ol>"},{"location":"tutorials/roadmap/#phase-4-quality","title":"Phase 4: Quality","text":"<ol> <li>Test notebook executes without errors</li> <li>Verify outputs are correct</li> <li>Check documentation formatting</li> <li>Spell check and grammar</li> <li>Cross-reference with other tutorials</li> </ol>"},{"location":"tutorials/roadmap/#tutorial-template-structure","title":"Tutorial Template Structure","text":"<p>Each tutorial should follow this structure:</p> <pre><code># Tutorial N: [Title]\n\n[Brief introduction and motivation]\n\n## What You'll Learn\n\n- Bullet point 1\n- Bullet point 2\n- Bullet point 3\n\n## Why [This Topic]?\n\n[Explain importance and applications]\n\n## Setup\n\n[Code for imports and basic setup]\n\n## Part 1: [Concept 1]\n\n[Explanation and code]\n\n## Part 2: [Concept 2]\n\n[Explanation and code]\n\n...\n\n## Key Takeaways\n\n1. Summary point 1\n2. Summary point 2\n3. Summary point 3\n\n## Next Steps\n\n- Extension 1\n- Extension 2\n- Related tutorials\n\n## Running This Tutorial\n\n[Instructions for running notebook]\n\n## References\n\n[Papers, docs, related work]\n</code></pre>"},{"location":"tutorials/roadmap/#success-metrics","title":"Success Metrics","text":"<p>For each tutorial, we aim for:</p> <ul> <li>\u2705 Clear learning objectives - Users know what they'll learn</li> <li>\u2705 Runnable code - All code executes without errors</li> <li>\u2705 Expected outputs - Users can verify correctness</li> <li>\u2705 Explanations - Concepts explained, not just code</li> <li>\u2705 Visualizations - Plots/figures where helpful</li> <li>\u2705 VSAX features - Showcases library capabilities</li> <li>\u2705 Real datasets - Uses actual data, not toy examples</li> <li>\u2705 References - Links to papers and further reading</li> </ul>"},{"location":"tutorials/roadmap/#contributing","title":"Contributing","text":"<p>Have an idea for a tutorial? See CONTRIBUTING.md!</p> <p>We especially welcome tutorials on: - Domain-specific applications (biology, chemistry, robotics) - Novel VSA techniques - Hybrid VSA + ML approaches - Performance optimization - Real-world use cases</p> <p>Last updated: 2025-01-16</p>"}]}