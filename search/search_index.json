{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"VSAX: Vector Symbolic Algebra for JAX","text":"<p>VSAX is a GPU-accelerated, JAX-native Python library for Vector Symbolic Architectures (VSAs). It provides composable symbolic representations using hypervectors, algebraic operations for binding and bundling, and encoding strategies for symbolic and structured data.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83d\ude80 Three VSA Models: FHRR, MAP, and Binary implementations \u2705</li> <li>\u26a1 GPU-Accelerated: Built on JAX for high-performance computation</li> <li>\ud83e\udde9 Modular Architecture: Clean separation between representations and operations</li> <li>\ud83e\uddec Complete Representations: Complex, Real, and Binary hypervectors \u2705</li> <li>\u2699\ufe0f Full Operation Sets: FFT-based FHRR, MAP, and XOR/majority Binary ops \u2705</li> <li>\ud83c\udfb2 Random Sampling: Sampling utilities for all representation types \u2705</li> <li>\ud83d\udcaf Type-Safe: Full type annotations with mypy support</li> <li>\u2705 Well-Tested: 339 tests with 96% coverage</li> <li>\ud83d\udd0d Similarity Metrics: Cosine, dot, and Hamming similarity</li> <li>\u26a1 Batch Operations: GPU-accelerated vmap operations</li> <li>\ud83d\udcbe I/O &amp; Persistence: Save/load basis vectors to JSON</li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#from-pypi-recommended","title":"From PyPI (Recommended)","text":"<pre><code>pip install vsax\n</code></pre>"},{"location":"#from-source","title":"From Source","text":"<pre><code>git clone https://github.com/yourusername/vsax.git\ncd vsax\n\n# Using uv (recommended)\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e \".[dev]\"\n\n# Or using pip\npip install -e \".[dev]\"\n</code></pre>"},{"location":"#quick-example","title":"Quick Example","text":""},{"location":"#simple-api-v050","title":"Simple API (v0.5.0)","text":"<pre><code>from vsax import create_fhrr_model, VSAMemory, DictEncoder\nfrom vsax.similarity import cosine_similarity\nfrom vsax.utils import vmap_bind\nimport jax.numpy as jnp\n\n# Create model with factory function\nmodel = create_fhrr_model(dim=512)\n\n# Create memory for symbols\nmemory = VSAMemory(model)\nmemory.add_many([\"dog\", \"cat\", \"animal\", \"run\", \"jump\"])\n\n# Access and manipulate symbols\ndog = memory[\"dog\"]\nanimal = memory[\"animal\"]\n\n# Bind two concepts (circular convolution)\ndog_is_animal = model.opset.bind(dog.vec, animal.vec)\n\n# Bundle multiple concepts (sum and normalize)\npets = model.opset.bundle(memory[\"dog\"].vec, memory[\"cat\"].vec)\n\n# NEW: Similarity search\nsimilarity = cosine_similarity(memory[\"dog\"], memory[\"cat\"])\nprint(f\"Dog-Cat similarity: {similarity:.3f}\")\n\n# NEW: Batch operations (GPU-accelerated)\nnouns = jnp.stack([memory[\"dog\"].vec, memory[\"cat\"].vec])\nverbs = jnp.stack([memory[\"run\"].vec, memory[\"jump\"].vec])\nactions = vmap_bind(model.opset, nouns, verbs)  # Parallel binding!\n\n# NEW: Encoders\nencoder = DictEncoder(model, memory)\nsentence = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})\n</code></pre>"},{"location":"#map-model-real-hypervectors","title":"MAP Model (Real Hypervectors)","text":"<pre><code>from vsax import RealHypervector, MAPOperations, sample_random\n\nmodel = VSAModel(\n    dim=512,\n    rep_cls=RealHypervector,\n    opset=MAPOperations(),\n    sampler=sample_random\n)\n\n# Element-wise multiplication for binding\n# Element-wise mean for bundling\n</code></pre>"},{"location":"#binary-model-bipolar-hypervectors","title":"Binary Model (Bipolar Hypervectors)","text":"<pre><code>from vsax import BinaryHypervector, BinaryOperations, sample_binary_random\n\nmodel = VSAModel(\n    dim=512,\n    rep_cls=BinaryHypervector,\n    opset=BinaryOperations(),\n    sampler=sample_binary_random\n)\n\n# XOR binding (exact unbinding)\n# Majority voting for bundling\n</code></pre>"},{"location":"#development-status","title":"Development Status","text":"<p>Current: Iteration 6 Complete \u2705</p>"},{"location":"#completed","title":"Completed","text":"<p>Iteration 1 (v0.1.0): Foundation &amp; Infrastructure \u2705 - \u2705 Core abstract classes (AbstractHypervector, AbstractOpSet) - \u2705 VSAModel dataclass - \u2705 Package structure - \u2705 Testing infrastructure (pytest, coverage) - \u2705 CI/CD pipeline (GitHub Actions) - \u2705 Documentation site (MkDocs)</p> <p>Iteration 2 (v0.2.0): Core Algebras \u2705 - \u2705 All 3 representations (Complex, Real, Binary) - \u2705 All 3 operation sets (FHRR, MAP, Binary) - \u2705 Sampling utilities - \u2705 175 comprehensive tests with 96% coverage - \u2705 Full integration tests</p> <p>Iteration 3 (v0.3.0): Models &amp; Memory \u2705 - \u2705 VSAMemory for symbol storage - \u2705 Factory functions for easy model creation - \u2705 Integration utilities - \u2705 230 tests with 89% coverage</p> <p>Iteration 4 (v0.4.0): First Usable Release \u2705 - \u2705 5 Core Encoders (Scalar, Sequence, Set, Dict, Graph) - \u2705 AbstractEncoder base class - \u2705 Complete working examples for all 3 models - \u2705 Custom encoder examples - \u2705 280+ tests with 92%+ coverage</p> <p>Iteration 5 (v0.5.0): Similarity Metrics &amp; Utilities \u2705 - \u2705 Cosine, dot, and Hamming similarity functions - \u2705 Batch operations with JAX vmap (vmap_bind, vmap_bundle, vmap_similarity) - \u2705 Visualization utilities (pretty_repr, format_similarity_results) - \u2705 GPU-accelerated similarity search - \u2705 319 tests with 95%+ coverage</p> <p>Iteration 6 (v0.6.0): I/O &amp; Persistence \u2705 - \u2705 save_basis() and load_basis() functions - \u2705 JSON serialization for all 3 models - \u2705 Round-trip vector preservation - \u2705 Dimension and type validation - \u2705 339 tests with 96% coverage</p>"},{"location":"#coming-next","title":"Coming Next","text":"<p>Iteration 7 (v1.0.0): Full Documentation &amp; Production Release - Complete API documentation - Tutorial notebooks - Production-ready v1.0.0 release</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Getting Started - Installation and first steps</li> <li>User Guide - Detailed guides for all components</li> <li>Examples - Working examples for all three models</li> <li>API Reference - Complete API documentation</li> <li>Design Specification - Technical design details</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions! Please see CONTRIBUTING.md for guidelines.</p>"},{"location":"#license","title":"License","text":"<p>VSAX is released under the MIT License. See LICENSE for details.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use VSAX in your research, please cite:</p> <pre><code>@software{vsax2025,\n  title = {VSAX: Vector Symbolic Algebra for JAX},\n  author = {Sarathy, Vasanth},\n  year = {2025},\n  version = {0.7.1},\n  url = {https://github.com/vasanthsarathy/vsax}\n}\n</code></pre>"},{"location":"design-spec/","title":"Technical Specification: VSAX - Vector Symbolic Algebra Library","text":""},{"location":"design-spec/#overview","title":"Overview","text":"<p>VSAX is a GPU-accelerated, JAX-native Python library for vector symbolic architectures (VSAs). It provides composable symbolic representations using hypervectors, algebraic operations for binding and bundling, and encoding strategies for symbolic and structured data. The library is designed to be modular, efficient, and extensible.</p>"},{"location":"design-spec/#core-objectives","title":"Core Objectives","text":"<ul> <li>Enable definition of VSA models combining representations (e.g., complex, real, binary) with algebraic operation sets (e.g., FHRR, MAP).</li> <li>Support encoding of symbolic data (scalars, dictionaries, graphs) using model-defined operations.</li> <li>Maintain a persistent, accessible store of basis hypervectors.</li> <li>Be fully compatible with JAX for high-performance, differentiable, GPU/TPU computation.</li> <li>Provide a clean API and separation of concerns.</li> <li>Be as usable and expressive as NumPy or PyTorch for symbolic computation.</li> </ul>"},{"location":"design-spec/#architecture","title":"Architecture","text":""},{"location":"design-spec/#1-vsamodel","title":"1. VSAModel","text":"<ul> <li><code>dim: int</code> \u2014 dimensionality of all hypervectors</li> <li><code>rep_cls: Type[AbstractHypervector]</code> \u2014 the representation class (e.g. ComplexHypervector)</li> <li><code>opset: AbstractOpSet</code> \u2014 operation strategies (bind, bundle, inverse)</li> <li><code>sampler: Callable[[int, int], jnp.ndarray]</code> \u2014 function for sampling raw vectors</li> </ul> <p>\u27a1\ufe0f Immutable dataclass container for algebra definition. No ops. Used by encoders and memory.</p>"},{"location":"design-spec/#2-vsamemory","title":"2. VSAMemory","text":"<ul> <li>Stores named hypervectors (basis symbols)</li> <li>Uses <code>VSAModel</code> to sample and wrap vectors</li> <li>Supports dictionary-style access:</li> <li><code>memory.add(\"apple\")</code></li> <li><code>memory[\"apple\"]</code></li> <li>Methods:</li> <li><code>add(name: str)</code></li> <li><code>add_many(names: list[str])</code></li> <li><code>get(name: str)</code> \u2192 returns representation-wrapped vector</li> </ul> <p>\u27a1\ufe0f Symbol table + runtime memory for symbolic concepts.</p>"},{"location":"design-spec/#3-abstracthypervector","title":"3. AbstractHypervector","text":"<ul> <li>Base class for representations</li> <li>Wraps a single <code>jnp.ndarray</code> with:</li> <li><code>.vec</code>: the underlying vector</li> <li><code>.normalize()</code></li> <li><code>.to_numpy()</code></li> <li><code>.shape</code>, <code>.dtype</code> proxies</li> <li>Future: implement <code>__jax_array__</code> and <code>__array__</code> for seamless ops</li> </ul> <p>\u27a1\ufe0f Allows clean vector math and JAX compatibility.</p>"},{"location":"design-spec/#4-abstractopset","title":"4. AbstractOpSet","text":"<p>Defines symbolic operations over <code>jnp.ndarray</code>s: - <code>bind(a, b)</code> - <code>bundle(*args)</code> - <code>inverse(a)</code> - <code>permute(a, shift)</code> (optional)</p> <p>\u27a1\ufe0f Stateless, pure functional interface for algebra.</p>"},{"location":"design-spec/#5-encoders","title":"5. Encoders","text":"<p>Classes that convert structured data into hypervectors:</p>"},{"location":"design-spec/#scalarencoder","title":"ScalarEncoder","text":"<ul> <li>Input: <code>name: str</code>, <code>value: float</code></li> <li>Output: powered basis vector (e.g. <code>basis_vec ** value</code>)</li> </ul>"},{"location":"design-spec/#dictencoder","title":"DictEncoder","text":"<ul> <li>Input: <code>{role: filler}</code></li> <li>Output: bundled binding of role-filler pairs</li> </ul> <p>\u27a1\ufe0f Each encoder accepts a model and memory. Add <code>.fit()</code>, <code>.encode()</code> for consistency.</p>"},{"location":"design-spec/#6-similarity-metrics","title":"6. Similarity Metrics","text":"<p>Located in <code>vsax/similarity/</code> - <code>cosine_similarity(a, b)</code> - <code>dot_similarity(a, b)</code> - <code>hamming_similarity(a, b)</code></p> <p>\u27a1\ufe0f Independent of model. Uses <code>.vec</code> or coerces inputs.</p>"},{"location":"design-spec/#7-io","title":"7. I/O","text":""},{"location":"design-spec/#save_basismemory-path","title":"<code>save_basis(memory, path)</code>","text":"<ul> <li>JSON serialization of named basis vectors</li> </ul>"},{"location":"design-spec/#load_basismemory-path","title":"<code>load_basis(memory, path)</code>","text":"<ul> <li>Load into a memory from disk using the model's <code>rep_cls</code></li> </ul> <p>\u27a1\ufe0f Reuse persistent symbolic spaces across sessions.</p>"},{"location":"design-spec/#8-resonator-networks","title":"8. Resonator Networks","text":""},{"location":"design-spec/#cleanupmemory","title":"<code>CleanupMemory</code>","text":"<ul> <li>Codebook projection for nearest vector retrieval</li> <li>Input: query vector</li> <li>Output: closest symbol from codebook or None if below threshold</li> </ul>"},{"location":"design-spec/#resonator","title":"<code>Resonator</code>","text":"<ul> <li>Iterative factorization of VSA composites</li> <li>Decomposes <code>s = a \u2299 b \u2299 c</code> into factors from known codebooks</li> <li>Superposition initialization (Frady et al. 2020)</li> <li>Supports 2-3 factor composites</li> <li>Works with all 3 VSA models</li> </ul> <p>\u27a1\ufe0f Enables decoding of complex VSA data structures.</p>"},{"location":"design-spec/#9-vector-utilities","title":"9. Vector Utilities","text":"<ul> <li><code>vsax.utils.coerce_vec()</code> \u2014 ensure input is <code>jnp.ndarray</code></li> <li><code>vsax.utils.vmap_bind()</code> \u2014 batch version of bind</li> <li><code>vsax.utils.vmap_bundle()</code> \u2014 batch version of bundle</li> <li><code>vsax.utils.pretty_repr()</code> \u2014 printing shape/type of vectors</li> </ul> <p>\u27a1\ufe0f Improves usability and debugging.</p>"},{"location":"design-spec/#representations","title":"Representations","text":"<p>Located in <code>vsax/representations/</code> - <code>ComplexHypervector</code> \u2014 phase-based encoding, useful for FHRR - <code>BinaryHypervector</code> \u2014 elementwise \u00b11 or 0/1 vectors - <code>RealHypervector</code> \u2014 continuous valued vectors</p> <p>Each wraps a <code>jnp.ndarray</code> and conforms to <code>AbstractHypervector</code>.</p>"},{"location":"design-spec/#operation-sets","title":"Operation Sets","text":"<p>Located in <code>vsax/ops/</code> - <code>FHRROperations</code> \u2014 FFT-based circular convolution - <code>MAPOperations</code> \u2014 elementwise multiplication and mean - <code>BinaryOperations</code> \u2014 XOR, majority</p> <p>\u27a1\ufe0f Functional, stateless ops working directly on <code>jnp.ndarray</code>s.</p>"},{"location":"design-spec/#sampling","title":"Sampling","text":"<p>Located in <code>vsax/sampling/</code> - <code>sample_random(dim, n)</code> \u2014 random normal - <code>sample_circular(dim, n)</code> \u2014 structured circular sampling</p> <p>\u27a1\ufe0f Used by <code>VSAModel</code> for basis vector generation.</p>"},{"location":"design-spec/#test-coverage","title":"Test Coverage","text":"<p>Located in <code>tests/</code> - <code>test_model_memory_init()</code> - <code>test_scalar_encoding()</code> - <code>test_dict_encoding()</code> - <code>test_similarity_metrics()</code> - <code>test_save_load()</code> - <code>test_vector_ops()</code> - <code>test_batch_encoding()</code> (planned)</p> <p>\u27a1\ufe0f Validates representation correctness and symbolic consistency.</p>"},{"location":"design-spec/#usage-examples","title":"Usage Examples","text":""},{"location":"design-spec/#example-1-basic-symbolic-binding","title":"Example 1: Basic symbolic binding","text":"<pre><code>a = memory[\"apple\"]\nb = memory[\"fruit\"]\nencoded = model.opset.bind(a.vec, b.vec)\n</code></pre>"},{"location":"design-spec/#example-2-scalar-encoding","title":"Example 2: Scalar Encoding","text":"<pre><code>encoder = ScalarEncoder(model, memory)\nmemory.add(\"temperature\")\nvec = encoder.encode(\"temperature\", 23.5)\n</code></pre>"},{"location":"design-spec/#example-3-dictionary-encoding-role-filler","title":"Example 3: Dictionary Encoding (role-filler)","text":"<pre><code>encoder = DictEncoder(model, memory)\nmemory.add_many([\"subject\", \"predicate\", \"object\", \"dog\", \"is_a\", \"animal\"])\nvec = encoder.encode({\"subject\": \"dog\", \"predicate\": \"is_a\", \"object\": \"animal\"})\n</code></pre>"},{"location":"design-spec/#example-4-similarity","title":"Example 4: Similarity","text":"<pre><code>similarity = cosine_similarity(vec, memory[\"dog\"])\n</code></pre>"},{"location":"design-spec/#example-5-save-and-load-basis","title":"Example 5: Save and Load Basis","text":"<pre><code>save_basis(memory, \"./basis.json\")\nnew_memory = VSAMemory(model)\nload_basis(new_memory, \"./basis.json\")\n</code></pre>"},{"location":"design-spec/#example-6-batch-operations","title":"Example 6: Batch Operations","text":"<pre><code>from vsax.utils.batch import vmap_bind\nX = jnp.stack([a.vec, b.vec, c.vec])\nY = jnp.stack([x.vec, y.vec, z.vec])\nbatch_result = vmap_bind(model.opset, X, Y)\n</code></pre>"},{"location":"design-spec/#example-7-resonator-networks","title":"Example 7: Resonator Networks","text":"<pre><code>from vsax import CleanupMemory, Resonator\n\n# Create codebooks\nletters = CleanupMemory([\"alpha\", \"beta\"], memory)\nnumbers = CleanupMemory([\"one\", \"two\"], memory)\n\n# Create resonator\nresonator = Resonator([letters, numbers], model.opset)\n\n# Factorize composite\ncomposite = model.opset.bind(memory[\"alpha\"].vec, memory[\"one\"].vec)\nfactors = resonator.factorize(composite)  # [\"alpha\", \"one\"]\n</code></pre>"},{"location":"design-spec/#example-8-access-vec-automatically","title":"Example 8: Access .vec automatically","text":"<pre><code># Future sugar\nbind(a, b)  # Automatically unwraps .vec if needed\n</code></pre>"},{"location":"design-spec/#extensibility-plan","title":"Extensibility Plan","text":""},{"location":"design-spec/#completed","title":"Completed \u2705","text":"<ul> <li>\u2705 <code>GraphEncoder</code>, <code>SequenceEncoder</code>, <code>SetEncoder</code>, <code>DictEncoder</code>, <code>ScalarEncoder</code></li> <li>\u2705 Dictionary-style access to <code>VSAMemory</code></li> <li>\u2705 <code>vmap</code>/<code>jit</code>-friendly versions of bind/bundle</li> <li>\u2705 Save/load basis vectors (I/O)</li> <li>\u2705 Resonator networks for factorization</li> <li>\u2705 Similarity metrics (cosine, dot, Hamming)</li> <li>\u2705 Batch operations (vmap_bind, vmap_bundle, vmap_similarity)</li> </ul>"},{"location":"design-spec/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Add <code>TreeEncoder</code> for hierarchical structures</li> <li>Add <code>QuaternionHypervector</code>, <code>FourierHypervector</code></li> <li>Add coercion logic to auto-handle <code>.vec</code></li> <li>Implement <code>__jax_array__</code> on representations for seamless ops</li> <li>Streamlit UI for interactive symbolic exploration</li> <li>CLI tools for inspecting memory</li> <li>Registries for custom representations and opsets</li> <li>Multi-factor resonator support (4+ factors)</li> </ul>"},{"location":"design-spec/#summary","title":"Summary","text":"<p>VSAX (v0.7.1) provides a principled, modular, and efficient system for symbolic reasoning with hypervectors. It is built for researchers and developers interested in neurosymbolic AI, cognitive modeling, and high-performance semantic encoding systems.</p> <p>Key Features: - Three complete VSA models (FHRR, MAP, Binary) - Five core encoders for structured data - Resonator networks for factorization and decoding - Similarity metrics and batch operations - I/O persistence for basis vectors - GPU acceleration via JAX</p> <p>Usability is prioritized with a clean, NumPy-style API, factory functions, batch operations, and JAX-native performance \u2014 enabling symbolic algebra at scale.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<p>VSAX requires Python 3.9 or later.</p>"},{"location":"getting-started/#from-pypi-recommended","title":"From PyPI (Recommended)","text":"<pre><code>pip install vsax\n</code></pre>"},{"location":"getting-started/#from-source","title":"From Source","text":""},{"location":"getting-started/#using-uv-recommended","title":"Using uv (Recommended)","text":"<p>uv is a fast Python package installer and resolver created by Astral (the makers of ruff). It's significantly faster than pip and handles virtual environments seamlessly.</p> <p>Install uv:</p> <pre><code># Unix/macOS\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre> <p>Install VSAX:</p> <pre><code>git clone https://github.com/vasanthsarathy/vsax.git\ncd vsax\n\n# Create virtual environment and install\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e .\n</code></pre>"},{"location":"getting-started/#using-pip","title":"Using pip","text":"<pre><code>git clone https://github.com/vasanthsarathy/vsax.git\ncd vsax\n\n# Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install package\npip install -e .\n</code></pre>"},{"location":"getting-started/#development-installation","title":"Development Installation","text":"<p>To install with development dependencies:</p> <p>Using uv: <pre><code>uv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e \".[dev,docs]\"\n</code></pre></p> <p>Using pip: <pre><code>python -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\npip install -e \".[dev,docs]\"\n</code></pre></p>"},{"location":"getting-started/#verifying-installation","title":"Verifying Installation","text":"<pre><code># Check that vsax is installed\npython -c \"import vsax; print(vsax.__version__)\"\n\n# Run tests\npytest\n</code></pre>"},{"location":"getting-started/#basic-usage","title":"Basic Usage","text":"<p>VSAX supports three VSA models:</p> <ol> <li>FHRR - Fourier Holographic Reduced Representation (complex hypervectors)</li> <li>MAP - Multiply-Add-Permute (real hypervectors)</li> <li>Binary VSA - Binary hypervectors with XOR binding</li> </ol>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":"<pre><code>from vsax import create_fhrr_model, VSAMemory, DictEncoder\nfrom vsax.similarity import cosine_similarity\n\n# Create model with factory function\nmodel = create_fhrr_model(dim=512)\n\n# Create memory for symbols\nmemory = VSAMemory(model)\nmemory.add_many([\"dog\", \"cat\", \"run\", \"jump\"])\n\n# Encode structured data\nencoder = DictEncoder(model, memory)\nsentence = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})\n\n# Similarity search\nsimilarity = cosine_similarity(memory[\"dog\"], memory[\"cat\"])\nprint(f\"Similarity: {similarity:.3f}\")\n</code></pre>"},{"location":"getting-started/#advanced-features","title":"Advanced Features","text":"<p>Resonator Networks (v0.7.0+) - Factorize composite hypervectors:</p> <pre><code>from vsax import CleanupMemory, Resonator\n\n# Create codebooks\nletters = CleanupMemory([\"alpha\", \"beta\"], memory)\nnumbers = CleanupMemory([\"one\", \"two\"], memory)\n\n# Create resonator\nresonator = Resonator([letters, numbers], model.opset)\n\n# Factorize composite\ncomposite = model.opset.bind(memory[\"alpha\"].vec, memory[\"one\"].vec)\nfactors = resonator.factorize(composite)  # [\"alpha\", \"one\"]\n</code></pre> <p>I/O &amp; Persistence (v0.6.0+) - Save and load basis vectors:</p> <pre><code>from vsax import save_basis, load_basis\n\n# Save basis to JSON\nsave_basis(memory, \"my_basis.json\")\n\n# Load basis from JSON\nnew_memory = VSAMemory(model)\nload_basis(new_memory, \"my_basis.json\")\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the API Reference</li> <li>Check out example notebooks</li> <li>Read the design specification</li> <li>See the User Guide for detailed tutorials</li> <li>Learn about Resonator Networks</li> <li>Understand Persistence</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for VSAX v0.7.1.</p>"},{"location":"api/#core-components","title":"Core Components","text":"<ul> <li>Base Classes - Abstract interfaces (AbstractHypervector, AbstractOpSet)</li> <li>VSAModel - Immutable model container</li> </ul>"},{"location":"api/#representations","title":"Representations","text":"<ul> <li>ComplexHypervector - Complex-valued phase-based representation</li> <li>RealHypervector - Real-valued continuous representation</li> <li>BinaryHypervector - Binary/bipolar discrete representation</li> </ul>"},{"location":"api/#operations","title":"Operations","text":"<ul> <li>FHRROperations - FFT-based circular convolution</li> <li>MAPOperations - Element-wise multiply and mean</li> <li>BinaryOperations - XOR and majority voting</li> </ul>"},{"location":"api/#sampling","title":"Sampling","text":"<ul> <li>Sampling Functions - Random vector generation</li> </ul>"},{"location":"api/#memory-utilities","title":"Memory &amp; Utilities","text":"<ul> <li>VSAMemory - Symbol table and basis management</li> <li>Factory Functions - Easy model creation</li> </ul>"},{"location":"api/#encoders","title":"Encoders","text":"<ul> <li>ScalarEncoder - Encode numeric values</li> <li>SequenceEncoder - Encode ordered sequences</li> <li>SetEncoder - Encode unordered collections</li> <li>DictEncoder - Encode key-value pairs</li> <li>GraphEncoder - Encode graph structures</li> <li>AbstractEncoder - Base class for custom encoders</li> </ul>"},{"location":"api/#similarity","title":"Similarity","text":"<ul> <li>Similarity Functions - Cosine, dot, Hamming similarity</li> </ul>"},{"location":"api/#resonator-networks","title":"Resonator Networks","text":"<ul> <li>CleanupMemory &amp; Resonator - Codebook projection and iterative factorization</li> </ul>"},{"location":"api/#io-persistence","title":"I/O &amp; Persistence","text":"<ul> <li>Save/Load Functions - JSON serialization for basis vectors</li> </ul>"},{"location":"api/#utilities","title":"Utilities","text":"<ul> <li>Batch Operations - vmap_bind, vmap_bundle, vmap_similarity</li> <li>Visualization - pretty_repr, format_similarity_results</li> </ul>"},{"location":"api/#quick-links","title":"Quick Links","text":"<ul> <li>Getting Started</li> <li>User Guide</li> <li>Examples</li> </ul>"},{"location":"api/sampling/","title":"Sampling Functions","text":"<p>Functions for generating random basis hypervectors.</p>"},{"location":"api/sampling/#sample_random","title":"sample_random","text":""},{"location":"api/sampling/#vsax.sampling.sample_random","title":"<code>vsax.sampling.sample_random(dim, n, key=None)</code>","text":"<p>Sample n random real-valued vectors from normal distribution.</p> <p>Generates random vectors with elements drawn from a standard normal distribution N(0, 1). These are suitable for use with MAP operations.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimensionality of each vector.</p> required <code>n</code> <code>int</code> <p>Number of vectors to sample.</p> required <code>key</code> <code>Optional[PRNGKey]</code> <p>JAX random key. If None, uses PRNGKey(0).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>JAX array of shape (n, dim) containing sampled vectors.</p> Example <p>import jax key = jax.random.PRNGKey(42) vectors = sample_random(512, 10, key) assert vectors.shape == (10, 512) assert not jnp.iscomplexobj(vectors)</p> Source code in <code>vsax/sampling/random.py</code> <pre><code>def sample_random(\n    dim: int, n: int, key: Optional[jax.random.PRNGKey] = None\n) -&gt; jnp.ndarray:\n    \"\"\"Sample n random real-valued vectors from normal distribution.\n\n    Generates random vectors with elements drawn from a standard normal\n    distribution N(0, 1). These are suitable for use with MAP operations.\n\n    Args:\n        dim: Dimensionality of each vector.\n        n: Number of vectors to sample.\n        key: JAX random key. If None, uses PRNGKey(0).\n\n    Returns:\n        JAX array of shape (n, dim) containing sampled vectors.\n\n    Example:\n        &gt;&gt;&gt; import jax\n        &gt;&gt;&gt; key = jax.random.PRNGKey(42)\n        &gt;&gt;&gt; vectors = sample_random(512, 10, key)\n        &gt;&gt;&gt; assert vectors.shape == (10, 512)\n        &gt;&gt;&gt; assert not jnp.iscomplexobj(vectors)\n    \"\"\"\n    if key is None:\n        key = jax.random.PRNGKey(0)\n\n    return jax.random.normal(key, shape=(n, dim))\n</code></pre>"},{"location":"api/sampling/#sample_complex_random","title":"sample_complex_random","text":""},{"location":"api/sampling/#vsax.sampling.sample_complex_random","title":"<code>vsax.sampling.sample_complex_random(dim, n, key=None)</code>","text":"<p>Sample n random complex-valued vectors with random phases.</p> <p>Generates unit-magnitude complex vectors with uniformly random phases in [0, 2\u03c0). These are suitable for use with FHRR operations.</p> <p>The vectors have the form: exp(i * \u03b8) where \u03b8 ~ Uniform(0, 2\u03c0).</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimensionality of each vector.</p> required <code>n</code> <code>int</code> <p>Number of vectors to sample.</p> required <code>key</code> <code>Optional[PRNGKey]</code> <p>JAX random key. If None, uses PRNGKey(0).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>JAX array of shape (n, dim) containing complex unit-magnitude vectors.</p> Example <p>import jax key = jax.random.PRNGKey(42) vectors = sample_complex_random(512, 10, key) assert vectors.shape == (10, 512) assert jnp.iscomplexobj(vectors)</p> Source code in <code>vsax/sampling/random.py</code> <pre><code>def sample_complex_random(\n    dim: int, n: int, key: Optional[jax.random.PRNGKey] = None\n) -&gt; jnp.ndarray:\n    \"\"\"Sample n random complex-valued vectors with random phases.\n\n    Generates unit-magnitude complex vectors with uniformly random phases\n    in [0, 2\u03c0). These are suitable for use with FHRR operations.\n\n    The vectors have the form: exp(i * \u03b8) where \u03b8 ~ Uniform(0, 2\u03c0).\n\n    Args:\n        dim: Dimensionality of each vector.\n        n: Number of vectors to sample.\n        key: JAX random key. If None, uses PRNGKey(0).\n\n    Returns:\n        JAX array of shape (n, dim) containing complex unit-magnitude vectors.\n\n    Example:\n        &gt;&gt;&gt; import jax\n        &gt;&gt;&gt; key = jax.random.PRNGKey(42)\n        &gt;&gt;&gt; vectors = sample_complex_random(512, 10, key)\n        &gt;&gt;&gt; assert vectors.shape == (10, 512)\n        &gt;&gt;&gt; assert jnp.iscomplexobj(vectors)\n        &gt;&gt;&gt; # All magnitudes should be 1.0\n        &gt;&gt;&gt; assert jnp.allclose(jnp.abs(vectors), 1.0)\n    \"\"\"\n    if key is None:\n        key = jax.random.PRNGKey(0)\n\n    # Sample random phases uniformly in [0, 2\u03c0)\n    phases = jax.random.uniform(key, shape=(n, dim), minval=0, maxval=2 * jnp.pi)\n\n    # Convert to complex unit vectors\n    return jnp.exp(1j * phases)\n</code></pre>"},{"location":"api/sampling/#vsax.sampling.sample_complex_random--all-magnitudes-should-be-10","title":"All magnitudes should be 1.0","text":"<p>assert jnp.allclose(jnp.abs(vectors), 1.0)</p>"},{"location":"api/sampling/#sample_binary_random","title":"sample_binary_random","text":""},{"location":"api/sampling/#vsax.sampling.sample_binary_random","title":"<code>vsax.sampling.sample_binary_random(dim, n, key=None, bipolar=True)</code>","text":"<p>Sample n random binary vectors.</p> <p>Generates random binary vectors with values uniformly sampled from: - Bipolar mode: {-1, +1} - Binary mode: {0, 1}</p> <p>These are suitable for use with Binary VSA operations.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimensionality of each vector.</p> required <code>n</code> <code>int</code> <p>Number of vectors to sample.</p> required <code>key</code> <code>Optional[PRNGKey]</code> <p>JAX random key. If None, uses PRNGKey(0).</p> <code>None</code> <code>bipolar</code> <code>bool</code> <p>If True, sample from {-1, +1}. If False, sample from {0, 1}.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>JAX array of shape (n, dim) containing binary values.</p> Example <p>import jax key = jax.random.PRNGKey(42)</p> Source code in <code>vsax/sampling/random.py</code> <pre><code>def sample_binary_random(\n    dim: int, n: int, key: Optional[jax.random.PRNGKey] = None, bipolar: bool = True\n) -&gt; jnp.ndarray:\n    \"\"\"Sample n random binary vectors.\n\n    Generates random binary vectors with values uniformly sampled from:\n    - Bipolar mode: {-1, +1}\n    - Binary mode: {0, 1}\n\n    These are suitable for use with Binary VSA operations.\n\n    Args:\n        dim: Dimensionality of each vector.\n        n: Number of vectors to sample.\n        key: JAX random key. If None, uses PRNGKey(0).\n        bipolar: If True, sample from {-1, +1}. If False, sample from {0, 1}.\n\n    Returns:\n        JAX array of shape (n, dim) containing binary values.\n\n    Example:\n        &gt;&gt;&gt; import jax\n        &gt;&gt;&gt; key = jax.random.PRNGKey(42)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Bipolar sampling\n        &gt;&gt;&gt; bipolar_vecs = sample_binary_random(512, 10, key, bipolar=True)\n        &gt;&gt;&gt; assert bipolar_vecs.shape == (10, 512)\n        &gt;&gt;&gt; assert jnp.all(jnp.isin(bipolar_vecs, jnp.array([-1, 1])))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Binary sampling\n        &gt;&gt;&gt; binary_vecs = sample_binary_random(512, 10, key, bipolar=False)\n        &gt;&gt;&gt; assert jnp.all(jnp.isin(binary_vecs, jnp.array([0, 1])))\n    \"\"\"\n    if key is None:\n        key = jax.random.PRNGKey(0)\n\n    if bipolar:\n        # Sample from {-1, +1}\n        return jax.random.choice(key, jnp.array([-1, 1]), shape=(n, dim))\n    else:\n        # Sample from {0, 1}\n        return jax.random.choice(key, jnp.array([0, 1]), shape=(n, dim))\n</code></pre>"},{"location":"api/sampling/#vsax.sampling.sample_binary_random--bipolar-sampling","title":"Bipolar sampling","text":"<p>bipolar_vecs = sample_binary_random(512, 10, key, bipolar=True) assert bipolar_vecs.shape == (10, 512) assert jnp.all(jnp.isin(bipolar_vecs, jnp.array([-1, 1])))</p>"},{"location":"api/sampling/#vsax.sampling.sample_binary_random--binary-sampling","title":"Binary sampling","text":"<p>binary_vecs = sample_binary_random(512, 10, key, bipolar=False) assert jnp.all(jnp.isin(binary_vecs, jnp.array([0, 1])))</p>"},{"location":"api/core/base/","title":"Base Classes","text":"<p>Core abstract classes that define the VSA interface.</p>"},{"location":"api/core/base/#abstracthypervector","title":"AbstractHypervector","text":""},{"location":"api/core/base/#vsax.core.base.AbstractHypervector","title":"<code>vsax.core.base.AbstractHypervector</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for all hypervector representations.</p> <p>Wraps a JAX array and provides common operations for hypervectors. All concrete implementations must inherit from this class.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>The underlying JAX array representing the hypervector.</p> required Source code in <code>vsax/core/base.py</code> <pre><code>class AbstractHypervector(ABC):\n    \"\"\"Base class for all hypervector representations.\n\n    Wraps a JAX array and provides common operations for hypervectors.\n    All concrete implementations must inherit from this class.\n\n    Args:\n        vec: The underlying JAX array representing the hypervector.\n    \"\"\"\n\n    def __init__(self, vec: jnp.ndarray) -&gt; None:\n        \"\"\"Initialize hypervector with underlying array.\n\n        Args:\n            vec: JAX array representing the hypervector.\n        \"\"\"\n        self._vec = vec\n\n    @property\n    def vec(self) -&gt; jnp.ndarray:\n        \"\"\"Return the underlying JAX array.\n\n        Returns:\n            The JAX array wrapped by this hypervector.\n        \"\"\"\n        return self._vec\n\n    @property\n    def shape(self) -&gt; tuple[int, ...]:\n        \"\"\"Return the shape of the hypervector.\n\n        Returns:\n            Tuple representing the shape of the underlying array.\n        \"\"\"\n        return cast(tuple[int, ...], self._vec.shape)\n\n    @property\n    def dtype(self) -&gt; jnp.dtype:\n        \"\"\"Return the data type of the hypervector.\n\n        Returns:\n            JAX dtype of the underlying array.\n        \"\"\"\n        return self._vec.dtype\n\n    @abstractmethod\n    def normalize(self) -&gt; \"AbstractHypervector\":\n        \"\"\"Normalize the hypervector.\n\n        The normalization method depends on the representation type.\n        For example, complex vectors normalize to unit magnitude (phase-only),\n        while real vectors use L2 normalization.\n\n        Returns:\n            Normalized hypervector of the same type.\n        \"\"\"\n        pass\n\n    def to_numpy(self) -&gt; np.ndarray:\n        \"\"\"Convert the hypervector to a NumPy array.\n\n        Returns:\n            NumPy array representation of the hypervector.\n        \"\"\"\n        return np.array(self._vec)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return string representation of the hypervector.\n\n        Returns:\n            String showing class name, shape, and dtype.\n        \"\"\"\n        return f\"{self.__class__.__name__}(shape={self.shape}, dtype={self.dtype})\"\n</code></pre>"},{"location":"api/core/base/#vsax.core.base.AbstractHypervector-attributes","title":"Attributes","text":""},{"location":"api/core/base/#vsax.core.base.AbstractHypervector.vec","title":"<code>vec</code>  <code>property</code>","text":"<p>Return the underlying JAX array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The JAX array wrapped by this hypervector.</p>"},{"location":"api/core/base/#vsax.core.base.AbstractHypervector.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Return the shape of the hypervector.</p> <p>Returns:</p> Type Description <code>tuple[int, ...]</code> <p>Tuple representing the shape of the underlying array.</p>"},{"location":"api/core/base/#vsax.core.base.AbstractHypervector.dtype","title":"<code>dtype</code>  <code>property</code>","text":"<p>Return the data type of the hypervector.</p> <p>Returns:</p> Type Description <code>dtype</code> <p>JAX dtype of the underlying array.</p>"},{"location":"api/core/base/#vsax.core.base.AbstractHypervector-functions","title":"Functions","text":""},{"location":"api/core/base/#vsax.core.base.AbstractHypervector.normalize","title":"<code>normalize()</code>  <code>abstractmethod</code>","text":"<p>Normalize the hypervector.</p> <p>The normalization method depends on the representation type. For example, complex vectors normalize to unit magnitude (phase-only), while real vectors use L2 normalization.</p> <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>Normalized hypervector of the same type.</p> Source code in <code>vsax/core/base.py</code> <pre><code>@abstractmethod\ndef normalize(self) -&gt; \"AbstractHypervector\":\n    \"\"\"Normalize the hypervector.\n\n    The normalization method depends on the representation type.\n    For example, complex vectors normalize to unit magnitude (phase-only),\n    while real vectors use L2 normalization.\n\n    Returns:\n        Normalized hypervector of the same type.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base/#vsax.core.base.AbstractHypervector.to_numpy","title":"<code>to_numpy()</code>","text":"<p>Convert the hypervector to a NumPy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>NumPy array representation of the hypervector.</p> Source code in <code>vsax/core/base.py</code> <pre><code>def to_numpy(self) -&gt; np.ndarray:\n    \"\"\"Convert the hypervector to a NumPy array.\n\n    Returns:\n        NumPy array representation of the hypervector.\n    \"\"\"\n    return np.array(self._vec)\n</code></pre>"},{"location":"api/core/base/#abstractopset","title":"AbstractOpSet","text":""},{"location":"api/core/base/#vsax.core.base.AbstractOpSet","title":"<code>vsax.core.base.AbstractOpSet</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for VSA operation sets.</p> <p>Defines the symbolic algebra operations for binding and bundling hypervectors. All operations work directly on JAX arrays, not on AbstractHypervector instances.</p> <p>Concrete implementations (FHRR, MAP, Binary) must implement all abstract methods.</p> Source code in <code>vsax/core/base.py</code> <pre><code>class AbstractOpSet(ABC):\n    \"\"\"Base class for VSA operation sets.\n\n    Defines the symbolic algebra operations for binding and bundling hypervectors.\n    All operations work directly on JAX arrays, not on AbstractHypervector instances.\n\n    Concrete implementations (FHRR, MAP, Binary) must implement all abstract methods.\n    \"\"\"\n\n    @abstractmethod\n    def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bind two hypervectors together.\n\n        Binding creates a composite representation that is dissimilar to both inputs\n        but can be unbound using the inverse operation. The specific binding operation\n        depends on the algebra (e.g., circular convolution for FHRR, elementwise\n        multiplication for MAP).\n\n        Args:\n            a: First hypervector as JAX array.\n            b: Second hypervector as JAX array.\n\n        Returns:\n            Bound hypervector as JAX array.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bundle multiple hypervectors into a single representation.\n\n        Bundling creates a superposition that is similar to all inputs.\n        The bundled vector can be queried to retrieve the constituent vectors.\n\n        Args:\n            *vecs: Variable number of hypervectors as JAX arrays.\n\n        Returns:\n            Bundled hypervector as JAX array.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Compute the inverse of a hypervector.\n\n        The inverse is used to unbind: if c = bind(a, b), then\n        unbind(c, b) = bind(c, inverse(b)) \u2248 a.\n\n        Args:\n            a: Hypervector as JAX array.\n\n        Returns:\n            Inverse hypervector as JAX array.\n        \"\"\"\n        pass\n\n    def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n        \"\"\"Permute a hypervector by circular shift.\n\n        This is an optional operation. The default implementation performs\n        a circular shift, but concrete classes may override with different\n        permutation strategies.\n\n        Args:\n            a: Hypervector as JAX array.\n            shift: Number of positions to shift (positive = right, negative = left).\n\n        Returns:\n            Permuted hypervector as JAX array.\n        \"\"\"\n        return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/core/base/#vsax.core.base.AbstractOpSet-functions","title":"Functions","text":""},{"location":"api/core/base/#vsax.core.base.AbstractOpSet.bind","title":"<code>bind(a, b)</code>  <code>abstractmethod</code>","text":"<p>Bind two hypervectors together.</p> <p>Binding creates a composite representation that is dissimilar to both inputs but can be unbound using the inverse operation. The specific binding operation depends on the algebra (e.g., circular convolution for FHRR, elementwise multiplication for MAP).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>First hypervector as JAX array.</p> required <code>b</code> <code>ndarray</code> <p>Second hypervector as JAX array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Bound hypervector as JAX array.</p> Source code in <code>vsax/core/base.py</code> <pre><code>@abstractmethod\ndef bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bind two hypervectors together.\n\n    Binding creates a composite representation that is dissimilar to both inputs\n    but can be unbound using the inverse operation. The specific binding operation\n    depends on the algebra (e.g., circular convolution for FHRR, elementwise\n    multiplication for MAP).\n\n    Args:\n        a: First hypervector as JAX array.\n        b: Second hypervector as JAX array.\n\n    Returns:\n        Bound hypervector as JAX array.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base/#vsax.core.base.AbstractOpSet.bundle","title":"<code>bundle(*vecs)</code>  <code>abstractmethod</code>","text":"<p>Bundle multiple hypervectors into a single representation.</p> <p>Bundling creates a superposition that is similar to all inputs. The bundled vector can be queried to retrieve the constituent vectors.</p> <p>Parameters:</p> Name Type Description Default <code>*vecs</code> <code>ndarray</code> <p>Variable number of hypervectors as JAX arrays.</p> <code>()</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Bundled hypervector as JAX array.</p> Source code in <code>vsax/core/base.py</code> <pre><code>@abstractmethod\ndef bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bundle multiple hypervectors into a single representation.\n\n    Bundling creates a superposition that is similar to all inputs.\n    The bundled vector can be queried to retrieve the constituent vectors.\n\n    Args:\n        *vecs: Variable number of hypervectors as JAX arrays.\n\n    Returns:\n        Bundled hypervector as JAX array.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base/#vsax.core.base.AbstractOpSet.inverse","title":"<code>inverse(a)</code>  <code>abstractmethod</code>","text":"<p>Compute the inverse of a hypervector.</p> <p>The inverse is used to unbind: if c = bind(a, b), then unbind(c, b) = bind(c, inverse(b)) \u2248 a.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Inverse hypervector as JAX array.</p> Source code in <code>vsax/core/base.py</code> <pre><code>@abstractmethod\ndef inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Compute the inverse of a hypervector.\n\n    The inverse is used to unbind: if c = bind(a, b), then\n    unbind(c, b) = bind(c, inverse(b)) \u2248 a.\n\n    Args:\n        a: Hypervector as JAX array.\n\n    Returns:\n        Inverse hypervector as JAX array.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/core/base/#vsax.core.base.AbstractOpSet.permute","title":"<code>permute(a, shift)</code>","text":"<p>Permute a hypervector by circular shift.</p> <p>This is an optional operation. The default implementation performs a circular shift, but concrete classes may override with different permutation strategies.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array.</p> required <code>shift</code> <code>int</code> <p>Number of positions to shift (positive = right, negative = left).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Permuted hypervector as JAX array.</p> Source code in <code>vsax/core/base.py</code> <pre><code>def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n    \"\"\"Permute a hypervector by circular shift.\n\n    This is an optional operation. The default implementation performs\n    a circular shift, but concrete classes may override with different\n    permutation strategies.\n\n    Args:\n        a: Hypervector as JAX array.\n        shift: Number of positions to shift (positive = right, negative = left).\n\n    Returns:\n        Permuted hypervector as JAX array.\n    \"\"\"\n    return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/core/factory/","title":"Factory Functions","text":"<p>Convenient factory functions for creating VSA models with sensible defaults.</p> <p>These functions provide a simple, one-line way to create fully configured VSA models for each of the three supported algebras: FHRR, MAP, and Binary.</p>"},{"location":"api/core/factory/#create_fhrr_model","title":"create_fhrr_model","text":""},{"location":"api/core/factory/#vsax.core.factory.create_fhrr_model","title":"<code>vsax.core.factory.create_fhrr_model(dim=512, key=None)</code>","text":"<p>Create a FHRR model (Complex hypervectors with FFT-based operations).</p> <p>FHRR (Fourier Holographic Reduced Representation) uses complex-valued hypervectors with circular convolution for binding. It provides exact unbinding via complex conjugation.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimensionality of hypervectors. Default: 512.</p> <code>512</code> <code>key</code> <code>Optional[Array]</code> <p>Optional JAX PRNG key for reproducible sampling. Not used in model creation but can be passed to VSAMemory.</p> <code>None</code> <p>Returns:</p> Type Description <code>VSAModel</code> <p>VSAModel configured for FHRR operations.</p> Example <p>from vsax import create_fhrr_model, VSAMemory model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add(\"symbol\")</p> Source code in <code>vsax/core/factory.py</code> <pre><code>def create_fhrr_model(dim: int = 512, key: Optional[jax.Array] = None) -&gt; VSAModel:\n    \"\"\"Create a FHRR model (Complex hypervectors with FFT-based operations).\n\n    FHRR (Fourier Holographic Reduced Representation) uses complex-valued\n    hypervectors with circular convolution for binding. It provides exact\n    unbinding via complex conjugation.\n\n    Args:\n        dim: Dimensionality of hypervectors. Default: 512.\n        key: Optional JAX PRNG key for reproducible sampling. Not used in\n            model creation but can be passed to VSAMemory.\n\n    Returns:\n        VSAModel configured for FHRR operations.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"symbol\")\n    \"\"\"\n    return VSAModel(\n        dim=dim,\n        rep_cls=ComplexHypervector,\n        opset=FHRROperations(),\n        sampler=sample_complex_random,\n    )\n</code></pre>"},{"location":"api/core/factory/#create_map_model","title":"create_map_model","text":""},{"location":"api/core/factory/#vsax.core.factory.create_map_model","title":"<code>vsax.core.factory.create_map_model(dim=512, key=None)</code>","text":"<p>Create a MAP model (Real hypervectors with element-wise operations).</p> <p>MAP (Multiply-Add-Permute) uses real-valued hypervectors with element-wise multiplication for binding and averaging for bundling. It provides approximate unbinding.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimensionality of hypervectors. Default: 512.</p> <code>512</code> <code>key</code> <code>Optional[Array]</code> <p>Optional JAX PRNG key for reproducible sampling. Not used in model creation but can be passed to VSAMemory.</p> <code>None</code> <p>Returns:</p> Type Description <code>VSAModel</code> <p>VSAModel configured for MAP operations.</p> Example <p>from vsax import create_map_model, VSAMemory model = create_map_model(dim=1024) memory = VSAMemory(model) memory.add_many([\"red\", \"green\", \"blue\"])</p> Source code in <code>vsax/core/factory.py</code> <pre><code>def create_map_model(dim: int = 512, key: Optional[jax.Array] = None) -&gt; VSAModel:\n    \"\"\"Create a MAP model (Real hypervectors with element-wise operations).\n\n    MAP (Multiply-Add-Permute) uses real-valued hypervectors with\n    element-wise multiplication for binding and averaging for bundling.\n    It provides approximate unbinding.\n\n    Args:\n        dim: Dimensionality of hypervectors. Default: 512.\n        key: Optional JAX PRNG key for reproducible sampling. Not used in\n            model creation but can be passed to VSAMemory.\n\n    Returns:\n        VSAModel configured for MAP operations.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_map_model, VSAMemory\n        &gt;&gt;&gt; model = create_map_model(dim=1024)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"red\", \"green\", \"blue\"])\n    \"\"\"\n    return VSAModel(\n        dim=dim,\n        rep_cls=RealHypervector,\n        opset=MAPOperations(),\n        sampler=sample_random,\n    )\n</code></pre>"},{"location":"api/core/factory/#create_binary_model","title":"create_binary_model","text":""},{"location":"api/core/factory/#vsax.core.factory.create_binary_model","title":"<code>vsax.core.factory.create_binary_model(dim=10000, bipolar=True, key=None)</code>","text":"<p>Create a Binary model (Binary hypervectors with XOR/majority operations).</p> <p>Binary VSA uses discrete {-1, +1} (bipolar) or {0, 1} (binary) hypervectors with XOR for binding and majority voting for bundling. It provides exact unbinding (self-inverse property).</p> <p>Note: Binary models typically require higher dimensionality (10000+) for good performance due to discrete representation.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimensionality of hypervectors. Default: 10000 (higher than continuous models due to discrete representation).</p> <code>10000</code> <code>bipolar</code> <code>bool</code> <p>If True, use {-1, +1} representation. If False, use {0, 1}. Default: True (bipolar is more common).</p> <code>True</code> <code>key</code> <code>Optional[Array]</code> <p>Optional JAX PRNG key for reproducible sampling. Not used in model creation but can be passed to VSAMemory.</p> <code>None</code> <p>Returns:</p> Type Description <code>VSAModel</code> <p>VSAModel configured for Binary operations.</p> Example <p>from vsax import create_binary_model, VSAMemory model = create_binary_model(dim=10000, bipolar=True) memory = VSAMemory(model) memory.add(\"concept\")</p> Source code in <code>vsax/core/factory.py</code> <pre><code>def create_binary_model(\n    dim: int = 10000, bipolar: bool = True, key: Optional[jax.Array] = None\n) -&gt; VSAModel:\n    \"\"\"Create a Binary model (Binary hypervectors with XOR/majority operations).\n\n    Binary VSA uses discrete {-1, +1} (bipolar) or {0, 1} (binary) hypervectors\n    with XOR for binding and majority voting for bundling. It provides exact\n    unbinding (self-inverse property).\n\n    Note: Binary models typically require higher dimensionality (10000+) for\n    good performance due to discrete representation.\n\n    Args:\n        dim: Dimensionality of hypervectors. Default: 10000 (higher than\n            continuous models due to discrete representation).\n        bipolar: If True, use {-1, +1} representation. If False, use {0, 1}.\n            Default: True (bipolar is more common).\n        key: Optional JAX PRNG key for reproducible sampling. Not used in\n            model creation but can be passed to VSAMemory.\n\n    Returns:\n        VSAModel configured for Binary operations.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_binary_model, VSAMemory\n        &gt;&gt;&gt; model = create_binary_model(dim=10000, bipolar=True)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"concept\")\n    \"\"\"\n\n    # Create a wrapper sampler that passes bipolar parameter\n    def binary_sampler(dim: int, n: int, key: jax.Array) -&gt; jax.Array:\n        \"\"\"Wrapper sampler that includes bipolar parameter.\"\"\"\n        return sample_binary_random(dim=dim, n=n, key=key, bipolar=bipolar)\n\n    return VSAModel(\n        dim=dim,\n        rep_cls=BinaryHypervector,\n        opset=BinaryOperations(),\n        sampler=binary_sampler,\n    )\n</code></pre>"},{"location":"api/core/memory/","title":"VSAMemory","text":"<p>Dictionary-style symbol table for managing named hypervectors.</p> <p>VSAMemory provides a convenient interface for creating, storing, and accessing hypervectors associated with symbolic names. It automatically handles vector sampling and wrapping using the model's configuration.</p>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory","title":"<code>vsax.core.memory.VSAMemory</code>","text":"<p>Symbol table for storing and managing named basis vectors.</p> <p>VSAMemory provides a dictionary-style interface for creating, storing, and retrieving named hypervectors. Each symbol is associated with a randomly sampled hypervector from the model's sampling distribution.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>VSAModel</code> <p>VSAModel instance defining the representation and operations.</p> required <code>key</code> <code>Optional[Array]</code> <p>Optional JAX PRNG key for reproducible sampling. If None, uses a default key.</p> <code>None</code> Example <p>from vsax import create_fhrr_model, VSAMemory model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add(\"dog\") memory.add_many([\"cat\", \"bird\"]) dog = memory[\"dog\"] assert \"cat\" in memory print(memory.keys()) ['dog', 'cat', 'bird']</p> Source code in <code>vsax/core/memory.py</code> <pre><code>class VSAMemory:\n    \"\"\"Symbol table for storing and managing named basis vectors.\n\n    VSAMemory provides a dictionary-style interface for creating, storing, and\n    retrieving named hypervectors. Each symbol is associated with a randomly\n    sampled hypervector from the model's sampling distribution.\n\n    Args:\n        model: VSAModel instance defining the representation and operations.\n        key: Optional JAX PRNG key for reproducible sampling. If None, uses a\n            default key.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"dog\")\n        &gt;&gt;&gt; memory.add_many([\"cat\", \"bird\"])\n        &gt;&gt;&gt; dog = memory[\"dog\"]\n        &gt;&gt;&gt; assert \"cat\" in memory\n        &gt;&gt;&gt; print(memory.keys())\n        ['dog', 'cat', 'bird']\n    \"\"\"\n\n    def __init__(self, model: VSAModel, key: Optional[jax.Array] = None) -&gt; None:\n        \"\"\"Initialize VSAMemory with a model.\n\n        Args:\n            model: VSAModel instance defining the VSA algebra.\n            key: Optional JAX PRNG key for reproducible sampling.\n        \"\"\"\n        self._model = model\n        self._symbols: dict[str, AbstractHypervector] = {}\n        self._key = key if key is not None else jax.random.PRNGKey(0)\n        self._counter = 0\n\n    @property\n    def model(self) -&gt; VSAModel:\n        \"\"\"Get the underlying VSAModel.\"\"\"\n        return self._model\n\n    def add(self, name: str) -&gt; AbstractHypervector:\n        \"\"\"Add a new symbol to memory with a randomly sampled hypervector.\n\n        If the symbol already exists, returns the existing hypervector without\n        resampling.\n\n        Args:\n            name: Name of the symbol to add.\n\n        Returns:\n            The hypervector associated with the symbol.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; dog = memory.add(\"dog\")\n            &gt;&gt;&gt; assert \"dog\" in memory\n        \"\"\"\n        if name in self._symbols:\n            return self._symbols[name]\n\n        # Split key for this sample\n        self._key, subkey = jax.random.split(self._key)\n\n        # Sample a new vector\n        vec = self._model.sampler(self._model.dim, 1, subkey)[0]\n\n        # Wrap in representation\n        hv = self._model.rep_cls(vec)\n\n        # Store and return\n        self._symbols[name] = hv\n        self._counter += 1\n        return hv\n\n    def add_many(self, names: Iterable[str]) -&gt; list[AbstractHypervector]:\n        \"\"\"Add multiple symbols to memory.\n\n        Args:\n            names: Iterable of symbol names to add.\n\n        Returns:\n            List of hypervectors corresponding to the added symbols.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; colors = memory.add_many([\"red\", \"green\", \"blue\"])\n            &gt;&gt;&gt; assert len(colors) == 3\n        \"\"\"\n        return [self.add(name) for name in names]\n\n    def get(self, name: str) -&gt; AbstractHypervector:\n        \"\"\"Get a hypervector by name.\n\n        Args:\n            name: Name of the symbol to retrieve.\n\n        Returns:\n            The hypervector associated with the symbol.\n\n        Raises:\n            KeyError: If the symbol does not exist in memory.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; memory.add(\"dog\")\n            &gt;&gt;&gt; dog = memory.get(\"dog\")\n        \"\"\"\n        return self._symbols[name]\n\n    def __getitem__(self, name: str) -&gt; AbstractHypervector:\n        \"\"\"Get a hypervector by name using dictionary syntax.\n\n        Args:\n            name: Name of the symbol to retrieve.\n\n        Returns:\n            The hypervector associated with the symbol.\n\n        Raises:\n            KeyError: If the symbol does not exist in memory.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; memory.add(\"dog\")\n            &gt;&gt;&gt; dog = memory[\"dog\"]\n        \"\"\"\n        return self.get(name)\n\n    def __contains__(self, name: str) -&gt; bool:\n        \"\"\"Check if a symbol exists in memory.\n\n        Args:\n            name: Name of the symbol to check.\n\n        Returns:\n            True if the symbol exists, False otherwise.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; memory.add(\"dog\")\n            &gt;&gt;&gt; assert \"dog\" in memory\n            &gt;&gt;&gt; assert \"cat\" not in memory\n        \"\"\"\n        return name in self._symbols\n\n    def keys(self) -&gt; list[str]:\n        \"\"\"Get all symbol names in memory.\n\n        Returns:\n            List of symbol names.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; memory.add_many([\"a\", \"b\", \"c\"])\n            &gt;&gt;&gt; assert memory.keys() == [\"a\", \"b\", \"c\"]\n        \"\"\"\n        return list(self._symbols.keys())\n\n    def __len__(self) -&gt; int:\n        \"\"\"Get the number of symbols in memory.\n\n        Returns:\n            Number of stored symbols.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; memory.add_many([\"a\", \"b\", \"c\"])\n            &gt;&gt;&gt; assert len(memory) == 3\n        \"\"\"\n        return len(self._symbols)\n\n    def clear(self) -&gt; None:\n        \"\"\"Remove all symbols from memory.\n\n        Example:\n            &gt;&gt;&gt; memory = VSAMemory(model)\n            &gt;&gt;&gt; memory.add_many([\"a\", \"b\", \"c\"])\n            &gt;&gt;&gt; memory.clear()\n            &gt;&gt;&gt; assert len(memory) == 0\n        \"\"\"\n        self._symbols.clear()\n        self._counter = 0\n\n    def __repr__(self) -&gt; str:\n        \"\"\"String representation of VSAMemory.\"\"\"\n        return f\"VSAMemory(model={self._model.rep_cls.__name__}, symbols={len(self._symbols)})\"\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory-attributes","title":"Attributes","text":""},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.model","title":"<code>model</code>  <code>property</code>","text":"<p>Get the underlying VSAModel.</p>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory-functions","title":"Functions","text":""},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.__init__","title":"<code>__init__(model, key=None)</code>","text":"<p>Initialize VSAMemory with a model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>VSAModel</code> <p>VSAModel instance defining the VSA algebra.</p> required <code>key</code> <code>Optional[Array]</code> <p>Optional JAX PRNG key for reproducible sampling.</p> <code>None</code> Source code in <code>vsax/core/memory.py</code> <pre><code>def __init__(self, model: VSAModel, key: Optional[jax.Array] = None) -&gt; None:\n    \"\"\"Initialize VSAMemory with a model.\n\n    Args:\n        model: VSAModel instance defining the VSA algebra.\n        key: Optional JAX PRNG key for reproducible sampling.\n    \"\"\"\n    self._model = model\n    self._symbols: dict[str, AbstractHypervector] = {}\n    self._key = key if key is not None else jax.random.PRNGKey(0)\n    self._counter = 0\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.add","title":"<code>add(name)</code>","text":"<p>Add a new symbol to memory with a randomly sampled hypervector.</p> <p>If the symbol already exists, returns the existing hypervector without resampling.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the symbol to add.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The hypervector associated with the symbol.</p> Example <p>memory = VSAMemory(model) dog = memory.add(\"dog\") assert \"dog\" in memory</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def add(self, name: str) -&gt; AbstractHypervector:\n    \"\"\"Add a new symbol to memory with a randomly sampled hypervector.\n\n    If the symbol already exists, returns the existing hypervector without\n    resampling.\n\n    Args:\n        name: Name of the symbol to add.\n\n    Returns:\n        The hypervector associated with the symbol.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; dog = memory.add(\"dog\")\n        &gt;&gt;&gt; assert \"dog\" in memory\n    \"\"\"\n    if name in self._symbols:\n        return self._symbols[name]\n\n    # Split key for this sample\n    self._key, subkey = jax.random.split(self._key)\n\n    # Sample a new vector\n    vec = self._model.sampler(self._model.dim, 1, subkey)[0]\n\n    # Wrap in representation\n    hv = self._model.rep_cls(vec)\n\n    # Store and return\n    self._symbols[name] = hv\n    self._counter += 1\n    return hv\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.add_many","title":"<code>add_many(names)</code>","text":"<p>Add multiple symbols to memory.</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>Iterable[str]</code> <p>Iterable of symbol names to add.</p> required <p>Returns:</p> Type Description <code>list[AbstractHypervector]</code> <p>List of hypervectors corresponding to the added symbols.</p> Example <p>memory = VSAMemory(model) colors = memory.add_many([\"red\", \"green\", \"blue\"]) assert len(colors) == 3</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def add_many(self, names: Iterable[str]) -&gt; list[AbstractHypervector]:\n    \"\"\"Add multiple symbols to memory.\n\n    Args:\n        names: Iterable of symbol names to add.\n\n    Returns:\n        List of hypervectors corresponding to the added symbols.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; colors = memory.add_many([\"red\", \"green\", \"blue\"])\n        &gt;&gt;&gt; assert len(colors) == 3\n    \"\"\"\n    return [self.add(name) for name in names]\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.get","title":"<code>get(name)</code>","text":"<p>Get a hypervector by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the symbol to retrieve.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The hypervector associated with the symbol.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the symbol does not exist in memory.</p> Example <p>memory = VSAMemory(model) memory.add(\"dog\") dog = memory.get(\"dog\")</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def get(self, name: str) -&gt; AbstractHypervector:\n    \"\"\"Get a hypervector by name.\n\n    Args:\n        name: Name of the symbol to retrieve.\n\n    Returns:\n        The hypervector associated with the symbol.\n\n    Raises:\n        KeyError: If the symbol does not exist in memory.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"dog\")\n        &gt;&gt;&gt; dog = memory.get(\"dog\")\n    \"\"\"\n    return self._symbols[name]\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.__getitem__","title":"<code>__getitem__(name)</code>","text":"<p>Get a hypervector by name using dictionary syntax.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the symbol to retrieve.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The hypervector associated with the symbol.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the symbol does not exist in memory.</p> Example <p>memory = VSAMemory(model) memory.add(\"dog\") dog = memory[\"dog\"]</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def __getitem__(self, name: str) -&gt; AbstractHypervector:\n    \"\"\"Get a hypervector by name using dictionary syntax.\n\n    Args:\n        name: Name of the symbol to retrieve.\n\n    Returns:\n        The hypervector associated with the symbol.\n\n    Raises:\n        KeyError: If the symbol does not exist in memory.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"dog\")\n        &gt;&gt;&gt; dog = memory[\"dog\"]\n    \"\"\"\n    return self.get(name)\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.__contains__","title":"<code>__contains__(name)</code>","text":"<p>Check if a symbol exists in memory.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the symbol to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the symbol exists, False otherwise.</p> Example <p>memory = VSAMemory(model) memory.add(\"dog\") assert \"dog\" in memory assert \"cat\" not in memory</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def __contains__(self, name: str) -&gt; bool:\n    \"\"\"Check if a symbol exists in memory.\n\n    Args:\n        name: Name of the symbol to check.\n\n    Returns:\n        True if the symbol exists, False otherwise.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"dog\")\n        &gt;&gt;&gt; assert \"dog\" in memory\n        &gt;&gt;&gt; assert \"cat\" not in memory\n    \"\"\"\n    return name in self._symbols\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.keys","title":"<code>keys()</code>","text":"<p>Get all symbol names in memory.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of symbol names.</p> Example <p>memory = VSAMemory(model) memory.add_many([\"a\", \"b\", \"c\"]) assert memory.keys() == [\"a\", \"b\", \"c\"]</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def keys(self) -&gt; list[str]:\n    \"\"\"Get all symbol names in memory.\n\n    Returns:\n        List of symbol names.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"a\", \"b\", \"c\"])\n        &gt;&gt;&gt; assert memory.keys() == [\"a\", \"b\", \"c\"]\n    \"\"\"\n    return list(self._symbols.keys())\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.__len__","title":"<code>__len__()</code>","text":"<p>Get the number of symbols in memory.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of stored symbols.</p> Example <p>memory = VSAMemory(model) memory.add_many([\"a\", \"b\", \"c\"]) assert len(memory) == 3</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Get the number of symbols in memory.\n\n    Returns:\n        Number of stored symbols.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"a\", \"b\", \"c\"])\n        &gt;&gt;&gt; assert len(memory) == 3\n    \"\"\"\n    return len(self._symbols)\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.clear","title":"<code>clear()</code>","text":"<p>Remove all symbols from memory.</p> Example <p>memory = VSAMemory(model) memory.add_many([\"a\", \"b\", \"c\"]) memory.clear() assert len(memory) == 0</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Remove all symbols from memory.\n\n    Example:\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"a\", \"b\", \"c\"])\n        &gt;&gt;&gt; memory.clear()\n        &gt;&gt;&gt; assert len(memory) == 0\n    \"\"\"\n    self._symbols.clear()\n    self._counter = 0\n</code></pre>"},{"location":"api/core/memory/#vsax.core.memory.VSAMemory.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of VSAMemory.</p> Source code in <code>vsax/core/memory.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"String representation of VSAMemory.\"\"\"\n    return f\"VSAMemory(model={self._model.rep_cls.__name__}, symbols={len(self._symbols)})\"\n</code></pre>"},{"location":"api/core/model/","title":"VSAModel","text":"<p>The immutable container that defines a complete VSA algebra.</p>"},{"location":"api/core/model/#vsax.core.model.VSAModel","title":"<code>vsax.core.model.VSAModel</code>  <code>dataclass</code>","text":"<p>Immutable container defining a complete VSA algebra.</p> <p>VSAModel combines a representation type, operation set, and sampling function to define a complete VSA system. It does not perform operations itself, but serves as a configuration object used by VSAMemory and encoders.</p> <p>Attributes:</p> Name Type Description <code>dim</code> <code>int</code> <p>Dimensionality of all hypervectors in this model.</p> <code>rep_cls</code> <code>type[AbstractHypervector]</code> <p>The hypervector representation class (e.g., ComplexHypervector).</p> <code>opset</code> <code>AbstractOpSet</code> <p>The operation set instance defining bind/bundle/inverse operations.</p> <code>sampler</code> <code>Callable[[int, int, PRNGKey], ndarray]</code> <p>Function to sample random vectors with signature      (dim: int, n: int, key: PRNGKey) -&gt; jnp.ndarray.</p> Example <p>from vsax.representations import ComplexHypervector from vsax.ops import FHRROperations from vsax.sampling import sample_complex_random model = VSAModel( ...     dim=512, ...     rep_cls=ComplexHypervector, ...     opset=FHRROperations(), ...     sampler=sample_complex_random ... )</p> Source code in <code>vsax/core/model.py</code> <pre><code>@dataclass(frozen=True)\nclass VSAModel:\n    \"\"\"Immutable container defining a complete VSA algebra.\n\n    VSAModel combines a representation type, operation set, and sampling function\n    to define a complete VSA system. It does not perform operations itself, but\n    serves as a configuration object used by VSAMemory and encoders.\n\n    Attributes:\n        dim: Dimensionality of all hypervectors in this model.\n        rep_cls: The hypervector representation class (e.g., ComplexHypervector).\n        opset: The operation set instance defining bind/bundle/inverse operations.\n        sampler: Function to sample random vectors with signature\n                 (dim: int, n: int, key: PRNGKey) -&gt; jnp.ndarray.\n\n    Example:\n        &gt;&gt;&gt; from vsax.representations import ComplexHypervector\n        &gt;&gt;&gt; from vsax.ops import FHRROperations\n        &gt;&gt;&gt; from vsax.sampling import sample_complex_random\n        &gt;&gt;&gt; model = VSAModel(\n        ...     dim=512,\n        ...     rep_cls=ComplexHypervector,\n        ...     opset=FHRROperations(),\n        ...     sampler=sample_complex_random\n        ... )\n    \"\"\"\n\n    dim: int\n    rep_cls: type[AbstractHypervector]\n    opset: AbstractOpSet\n    sampler: Callable[[int, int, jax.random.PRNGKey], jnp.ndarray]\n\n    def __post_init__(self) -&gt; None:\n        \"\"\"Validate model parameters.\n\n        Raises:\n            ValueError: If dim is not positive.\n        \"\"\"\n        if self.dim &lt;= 0:\n            raise ValueError(f\"dim must be positive, got {self.dim}\")\n</code></pre>"},{"location":"api/core/model/#vsax.core.model.VSAModel-functions","title":"Functions","text":""},{"location":"api/core/model/#vsax.core.model.VSAModel.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Validate model parameters.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If dim is not positive.</p> Source code in <code>vsax/core/model.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Validate model parameters.\n\n    Raises:\n        ValueError: If dim is not positive.\n    \"\"\"\n    if self.dim &lt;= 0:\n        raise ValueError(f\"dim must be positive, got {self.dim}\")\n</code></pre>"},{"location":"api/encoders/","title":"Encoders API","text":"<p>VSAX encoders convert structured data into hypervector representations.</p>"},{"location":"api/encoders/#base-classes","title":"Base Classes","text":""},{"location":"api/encoders/#vsax.encoders.AbstractEncoder","title":"<code>vsax.encoders.AbstractEncoder</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for encoding structured data into hypervectors.</p> <p>All encoders must implement the <code>encode()</code> method. Encoders can optionally implement <code>fit()</code> for learned encodings and <code>decode()</code> for reconstruction.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The VSAModel instance defining the VSA algebra.</p> <code>memory</code> <p>The VSAMemory instance for accessing basis hypervectors.</p> Example <p>class MyEncoder(AbstractEncoder): ...     def encode(self, data): ...         # Custom encoding logic ...         return self.memory[\"basis\"] encoder = MyEncoder(model, memory) hv = encoder.encode(some_data)</p> Source code in <code>vsax/encoders/base.py</code> <pre><code>class AbstractEncoder(ABC):\n    \"\"\"Abstract base class for encoding structured data into hypervectors.\n\n    All encoders must implement the `encode()` method. Encoders can optionally\n    implement `fit()` for learned encodings and `decode()` for reconstruction.\n\n    Attributes:\n        model: The VSAModel instance defining the VSA algebra.\n        memory: The VSAMemory instance for accessing basis hypervectors.\n\n    Example:\n        &gt;&gt;&gt; class MyEncoder(AbstractEncoder):\n        ...     def encode(self, data):\n        ...         # Custom encoding logic\n        ...         return self.memory[\"basis\"]\n        &gt;&gt;&gt; encoder = MyEncoder(model, memory)\n        &gt;&gt;&gt; hv = encoder.encode(some_data)\n    \"\"\"\n\n    def __init__(self, model: VSAModel, memory: VSAMemory) -&gt; None:\n        \"\"\"Initialize the encoder.\n\n        Args:\n            model: The VSAModel instance.\n            memory: The VSAMemory instance with basis symbols.\n        \"\"\"\n        self.model = model\n        self.memory = memory\n\n    @abstractmethod\n    def encode(self, *args: Any, **kwargs: Any) -&gt; AbstractHypervector:\n        \"\"\"Encode data into a hypervector.\n\n        Args:\n            *args: Positional arguments (encoder-specific).\n            **kwargs: Keyword arguments (encoder-specific).\n\n        Returns:\n            The encoded hypervector.\n\n        Raises:\n            NotImplementedError: This is an abstract method.\n\n        Note:\n            Different encoders may have different signatures. See specific\n            encoder documentation for details.\n        \"\"\"\n        pass\n\n    def fit(self, data: Any) -&gt; None:\n        \"\"\"Optionally fit encoder parameters to data.\n\n        This method is optional and can be used for learned encodings.\n        By default, it does nothing.\n\n        Args:\n            data: The training data.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/encoders/#vsax.encoders.AbstractEncoder-functions","title":"Functions","text":""},{"location":"api/encoders/#vsax.encoders.AbstractEncoder.__init__","title":"<code>__init__(model, memory)</code>","text":"<p>Initialize the encoder.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>VSAModel</code> <p>The VSAModel instance.</p> required <code>memory</code> <code>VSAMemory</code> <p>The VSAMemory instance with basis symbols.</p> required Source code in <code>vsax/encoders/base.py</code> <pre><code>def __init__(self, model: VSAModel, memory: VSAMemory) -&gt; None:\n    \"\"\"Initialize the encoder.\n\n    Args:\n        model: The VSAModel instance.\n        memory: The VSAMemory instance with basis symbols.\n    \"\"\"\n    self.model = model\n    self.memory = memory\n</code></pre>"},{"location":"api/encoders/#vsax.encoders.AbstractEncoder.encode","title":"<code>encode(*args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Encode data into a hypervector.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>Positional arguments (encoder-specific).</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments (encoder-specific).</p> <code>{}</code> <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The encoded hypervector.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This is an abstract method.</p> Note <p>Different encoders may have different signatures. See specific encoder documentation for details.</p> Source code in <code>vsax/encoders/base.py</code> <pre><code>@abstractmethod\ndef encode(self, *args: Any, **kwargs: Any) -&gt; AbstractHypervector:\n    \"\"\"Encode data into a hypervector.\n\n    Args:\n        *args: Positional arguments (encoder-specific).\n        **kwargs: Keyword arguments (encoder-specific).\n\n    Returns:\n        The encoded hypervector.\n\n    Raises:\n        NotImplementedError: This is an abstract method.\n\n    Note:\n        Different encoders may have different signatures. See specific\n        encoder documentation for details.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/encoders/#vsax.encoders.AbstractEncoder.fit","title":"<code>fit(data)</code>","text":"<p>Optionally fit encoder parameters to data.</p> <p>This method is optional and can be used for learned encodings. By default, it does nothing.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The training data.</p> required Source code in <code>vsax/encoders/base.py</code> <pre><code>def fit(self, data: Any) -&gt; None:\n    \"\"\"Optionally fit encoder parameters to data.\n\n    This method is optional and can be used for learned encodings.\n    By default, it does nothing.\n\n    Args:\n        data: The training data.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/encoders/#core-encoders","title":"Core Encoders","text":"<ul> <li>ScalarEncoder - Numeric values</li> <li>SequenceEncoder - Ordered sequences</li> <li>SetEncoder - Unordered collections</li> <li>DictEncoder - Key-value pairs</li> <li>GraphEncoder - Graph structures</li> </ul>"},{"location":"api/encoders/dict/","title":"DictEncoder","text":"<p>Encoder for dictionaries using role-filler binding.</p>"},{"location":"api/encoders/dict/#vsax.encoders.DictEncoder","title":"<code>vsax.encoders.DictEncoder</code>","text":"<p>               Bases: <code>AbstractEncoder</code></p> <p>Encoder for dictionaries using role-filler binding.</p> <p>Encodes dictionaries by binding each key (role) with its value (filler), then bundling all key-value pairs together.</p> <p>Both keys and values must be symbols that exist in memory.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The VSAModel instance defining the VSA algebra.</p> <code>memory</code> <p>The VSAMemory instance for accessing basis hypervectors.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.encoders import DictEncoder model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"subject\", \"action\", \"dog\", \"run\"]) encoder = DictEncoder(model, memory) sentence_hv = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})</p> Source code in <code>vsax/encoders/dict.py</code> <pre><code>class DictEncoder(AbstractEncoder):\n    \"\"\"Encoder for dictionaries using role-filler binding.\n\n    Encodes dictionaries by binding each key (role) with its value (filler),\n    then bundling all key-value pairs together.\n\n    Both keys and values must be symbols that exist in memory.\n\n    Attributes:\n        model: The VSAModel instance defining the VSA algebra.\n        memory: The VSAMemory instance for accessing basis hypervectors.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; from vsax.encoders import DictEncoder\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"subject\", \"action\", \"dog\", \"run\"])\n        &gt;&gt;&gt; encoder = DictEncoder(model, memory)\n        &gt;&gt;&gt; sentence_hv = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})\n    \"\"\"\n\n    def encode(self, mapping: dict[str, str]) -&gt; AbstractHypervector:\n        \"\"\"Encode a dictionary of key-value pairs.\n\n        Args:\n            mapping: A dictionary mapping role names to filler names.\n                     Both keys and values must be symbols in memory.\n\n        Returns:\n            The encoded hypervector representing the dictionary.\n\n        Raises:\n            KeyError: If any key or value is not in memory.\n            ValueError: If the dictionary is empty.\n\n        Example:\n            &gt;&gt;&gt; encoder = DictEncoder(model, memory)\n            &gt;&gt;&gt; dict_hv = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})\n        \"\"\"\n        if len(mapping) == 0:\n            raise ValueError(\"Cannot encode empty dictionary\")\n\n        # Bind each key with its value and collect results\n        bound_pairs = []\n        for key, value in mapping.items():\n            key_hv = self.memory[key]\n            value_hv = self.memory[value]\n\n            # Bind key (role) with value (filler)\n            bound = self.model.opset.bind(key_hv.vec, value_hv.vec)\n            bound_pairs.append(bound)\n\n        # Bundle all key-value pairs\n        result = self.model.opset.bundle(*bound_pairs)\n\n        return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/dict/#vsax.encoders.DictEncoder-functions","title":"Functions","text":""},{"location":"api/encoders/dict/#vsax.encoders.DictEncoder.encode","title":"<code>encode(mapping)</code>","text":"<p>Encode a dictionary of key-value pairs.</p> <p>Parameters:</p> Name Type Description Default <code>mapping</code> <code>dict[str, str]</code> <p>A dictionary mapping role names to filler names.      Both keys and values must be symbols in memory.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The encoded hypervector representing the dictionary.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If any key or value is not in memory.</p> <code>ValueError</code> <p>If the dictionary is empty.</p> Example <p>encoder = DictEncoder(model, memory) dict_hv = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})</p> Source code in <code>vsax/encoders/dict.py</code> <pre><code>def encode(self, mapping: dict[str, str]) -&gt; AbstractHypervector:\n    \"\"\"Encode a dictionary of key-value pairs.\n\n    Args:\n        mapping: A dictionary mapping role names to filler names.\n                 Both keys and values must be symbols in memory.\n\n    Returns:\n        The encoded hypervector representing the dictionary.\n\n    Raises:\n        KeyError: If any key or value is not in memory.\n        ValueError: If the dictionary is empty.\n\n    Example:\n        &gt;&gt;&gt; encoder = DictEncoder(model, memory)\n        &gt;&gt;&gt; dict_hv = encoder.encode({\"subject\": \"dog\", \"action\": \"run\"})\n    \"\"\"\n    if len(mapping) == 0:\n        raise ValueError(\"Cannot encode empty dictionary\")\n\n    # Bind each key with its value and collect results\n    bound_pairs = []\n    for key, value in mapping.items():\n        key_hv = self.memory[key]\n        value_hv = self.memory[value]\n\n        # Bind key (role) with value (filler)\n        bound = self.model.opset.bind(key_hv.vec, value_hv.vec)\n        bound_pairs.append(bound)\n\n    # Bundle all key-value pairs\n    result = self.model.opset.bundle(*bound_pairs)\n\n    return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/graph/","title":"GraphEncoder","text":"<p>Encoder for graph structures using edge binding.</p>"},{"location":"api/encoders/graph/#vsax.encoders.GraphEncoder","title":"<code>vsax.encoders.GraphEncoder</code>","text":"<p>               Bases: <code>AbstractEncoder</code></p> <p>Encoder for graph structures using edge binding.</p> <p>Encodes graphs by representing each edge as a binding of source, relation, and target, then bundling all edges together.</p> <p>Graphs are represented as edge lists: [(source, relation, target), ...]</p> <p>All node and relation names must be symbols that exist in memory.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The VSAModel instance defining the VSA algebra.</p> <code>memory</code> <p>The VSAMemory instance for accessing basis hypervectors.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.encoders import GraphEncoder model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"Alice\", \"Bob\", \"knows\", \"likes\"]) encoder = GraphEncoder(model, memory)</p> Source code in <code>vsax/encoders/graph.py</code> <pre><code>class GraphEncoder(AbstractEncoder):\n    \"\"\"Encoder for graph structures using edge binding.\n\n    Encodes graphs by representing each edge as a binding of source, relation,\n    and target, then bundling all edges together.\n\n    Graphs are represented as edge lists: [(source, relation, target), ...]\n\n    All node and relation names must be symbols that exist in memory.\n\n    Attributes:\n        model: The VSAModel instance defining the VSA algebra.\n        memory: The VSAMemory instance for accessing basis hypervectors.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; from vsax.encoders import GraphEncoder\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"Alice\", \"Bob\", \"knows\", \"likes\"])\n        &gt;&gt;&gt; encoder = GraphEncoder(model, memory)\n        &gt;&gt;&gt; # Alice knows Bob, Alice likes Bob\n        &gt;&gt;&gt; graph_hv = encoder.encode([\n        ...     (\"Alice\", \"knows\", \"Bob\"),\n        ...     (\"Alice\", \"likes\", \"Bob\")\n        ... ])\n    \"\"\"\n\n    def encode(\n        self, edges: list[tuple[str, str, str]]\n    ) -&gt; AbstractHypervector:\n        \"\"\"Encode a graph as a list of edges.\n\n        Args:\n            edges: List of (source, relation, target) tuples.\n                   All names must be symbols in memory.\n\n        Returns:\n            The encoded hypervector representing the graph.\n\n        Raises:\n            KeyError: If any node or relation is not in memory.\n            ValueError: If the edge list is empty.\n\n        Example:\n            &gt;&gt;&gt; encoder = GraphEncoder(model, memory)\n            &gt;&gt;&gt; graph_hv = encoder.encode([\n            ...     (\"Alice\", \"knows\", \"Bob\"),\n            ...     (\"Bob\", \"likes\", \"Alice\")\n            ... ])\n        \"\"\"\n        if len(edges) == 0:\n            raise ValueError(\"Cannot encode empty graph (no edges)\")\n\n        # Encode each edge and collect results\n        edge_encodings = []\n        for source, relation, target in edges:\n            source_hv = self.memory[source]\n            relation_hv = self.memory[relation]\n            target_hv = self.memory[target]\n\n            # Encode edge as bind(source, bind(relation, target))\n            rel_target = self.model.opset.bind(relation_hv.vec, target_hv.vec)\n            edge_encoding = self.model.opset.bind(source_hv.vec, rel_target)\n            edge_encodings.append(edge_encoding)\n\n        # Bundle all edges together\n        result = self.model.opset.bundle(*edge_encodings)\n\n        return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/graph/#vsax.encoders.GraphEncoder--alice-knows-bob-alice-likes-bob","title":"Alice knows Bob, Alice likes Bob","text":"<p>graph_hv = encoder.encode([ ...     (\"Alice\", \"knows\", \"Bob\"), ...     (\"Alice\", \"likes\", \"Bob\") ... ])</p>"},{"location":"api/encoders/graph/#vsax.encoders.GraphEncoder-functions","title":"Functions","text":""},{"location":"api/encoders/graph/#vsax.encoders.GraphEncoder.encode","title":"<code>encode(edges)</code>","text":"<p>Encode a graph as a list of edges.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <code>list[tuple[str, str, str]]</code> <p>List of (source, relation, target) tuples.    All names must be symbols in memory.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The encoded hypervector representing the graph.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If any node or relation is not in memory.</p> <code>ValueError</code> <p>If the edge list is empty.</p> Example <p>encoder = GraphEncoder(model, memory) graph_hv = encoder.encode([ ...     (\"Alice\", \"knows\", \"Bob\"), ...     (\"Bob\", \"likes\", \"Alice\") ... ])</p> Source code in <code>vsax/encoders/graph.py</code> <pre><code>def encode(\n    self, edges: list[tuple[str, str, str]]\n) -&gt; AbstractHypervector:\n    \"\"\"Encode a graph as a list of edges.\n\n    Args:\n        edges: List of (source, relation, target) tuples.\n               All names must be symbols in memory.\n\n    Returns:\n        The encoded hypervector representing the graph.\n\n    Raises:\n        KeyError: If any node or relation is not in memory.\n        ValueError: If the edge list is empty.\n\n    Example:\n        &gt;&gt;&gt; encoder = GraphEncoder(model, memory)\n        &gt;&gt;&gt; graph_hv = encoder.encode([\n        ...     (\"Alice\", \"knows\", \"Bob\"),\n        ...     (\"Bob\", \"likes\", \"Alice\")\n        ... ])\n    \"\"\"\n    if len(edges) == 0:\n        raise ValueError(\"Cannot encode empty graph (no edges)\")\n\n    # Encode each edge and collect results\n    edge_encodings = []\n    for source, relation, target in edges:\n        source_hv = self.memory[source]\n        relation_hv = self.memory[relation]\n        target_hv = self.memory[target]\n\n        # Encode edge as bind(source, bind(relation, target))\n        rel_target = self.model.opset.bind(relation_hv.vec, target_hv.vec)\n        edge_encoding = self.model.opset.bind(source_hv.vec, rel_target)\n        edge_encodings.append(edge_encoding)\n\n    # Bundle all edges together\n    result = self.model.opset.bundle(*edge_encodings)\n\n    return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/scalar/","title":"ScalarEncoder","text":"<p>Encoder for numeric scalar values using power encoding.</p>"},{"location":"api/encoders/scalar/#vsax.encoders.ScalarEncoder","title":"<code>vsax.encoders.ScalarEncoder</code>","text":"<p>               Bases: <code>AbstractEncoder</code></p> <p>Encoder for numeric scalar values using power encoding.</p> <p>For complex hypervectors (FHRR), encodes values by raising the basis hypervector to the power of the value, which rotates the phase.</p> <p>For real and binary hypervectors, encodes by iterated binding of the basis vector with itself.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The VSAModel instance defining the VSA algebra.</p> <code>memory</code> <p>The VSAMemory instance for accessing basis hypervectors.</p> <code>min_val</code> <p>Minimum value for the encoding range (optional).</p> <code>max_val</code> <p>Maximum value for the encoding range (optional).</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.encoders import ScalarEncoder model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add(\"temperature\") encoder = ScalarEncoder(model, memory) temp_hv = encoder.encode(\"temperature\", 23.5)</p> Source code in <code>vsax/encoders/scalar.py</code> <pre><code>class ScalarEncoder(AbstractEncoder):\n    \"\"\"Encoder for numeric scalar values using power encoding.\n\n    For complex hypervectors (FHRR), encodes values by raising the basis\n    hypervector to the power of the value, which rotates the phase.\n\n    For real and binary hypervectors, encodes by iterated binding of the\n    basis vector with itself.\n\n    Attributes:\n        model: The VSAModel instance defining the VSA algebra.\n        memory: The VSAMemory instance for accessing basis hypervectors.\n        min_val: Minimum value for the encoding range (optional).\n        max_val: Maximum value for the encoding range (optional).\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; from vsax.encoders import ScalarEncoder\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add(\"temperature\")\n        &gt;&gt;&gt; encoder = ScalarEncoder(model, memory)\n        &gt;&gt;&gt; temp_hv = encoder.encode(\"temperature\", 23.5)\n    \"\"\"\n\n    def __init__(\n        self,\n        model: VSAModel,\n        memory: VSAMemory,\n        min_val: Optional[float] = None,\n        max_val: Optional[float] = None,\n    ) -&gt; None:\n        \"\"\"Initialize the ScalarEncoder.\n\n        Args:\n            model: The VSAModel instance.\n            memory: The VSAMemory instance with basis symbols.\n            min_val: Minimum value for normalization (optional).\n            max_val: Maximum value for normalization (optional).\n        \"\"\"\n        super().__init__(model, memory)\n        self.min_val = min_val\n        self.max_val = max_val\n\n    def encode(self, symbol_name: str, value: float) -&gt; AbstractHypervector:\n        \"\"\"Encode a scalar value.\n\n        Args:\n            symbol_name: Name of the basis symbol in memory to use.\n            value: The numeric value to encode.\n\n        Returns:\n            The encoded hypervector.\n\n        Raises:\n            KeyError: If symbol_name is not in memory.\n            ValueError: If value is outside the specified range.\n\n        Example:\n            &gt;&gt;&gt; encoder = ScalarEncoder(model, memory)\n            &gt;&gt;&gt; temp_hv = encoder.encode(\"temperature\", 23.5)\n        \"\"\"\n        # Normalize value if range is specified\n        if self.min_val is not None and self.max_val is not None:\n            if not (self.min_val &lt;= value &lt;= self.max_val):\n                raise ValueError(\n                    f\"Value {value} outside range [{self.min_val}, {self.max_val}]\"\n                )\n            # Normalize to 0-1 range\n            value = (value - self.min_val) / (self.max_val - self.min_val)\n\n        # Get basis hypervector\n        basis_hv = self.memory[symbol_name]\n\n        # For complex hypervectors, use power encoding\n        if jnp.iscomplexobj(basis_hv.vec):\n            # Power encoding: v ** value rotates the phase\n            powered_vec = jnp.power(basis_hv.vec, value)\n            return self.model.rep_cls(powered_vec)\n\n        # For real and binary hypervectors, use iterated binding\n        # Bind the vector with itself 'value' times\n        # For fractional values, we approximate with integer binding\n        iterations = int(jnp.round(value * 10))  # Scale for finer granularity\n\n        if iterations == 0:\n            # Return normalized zero-like vector\n            return basis_hv.normalize()\n\n        result = basis_hv.vec\n        for _ in range(iterations - 1):\n            result = self.model.opset.bind(result, basis_hv.vec)\n\n        return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/scalar/#vsax.encoders.ScalarEncoder-functions","title":"Functions","text":""},{"location":"api/encoders/scalar/#vsax.encoders.ScalarEncoder.__init__","title":"<code>__init__(model, memory, min_val=None, max_val=None)</code>","text":"<p>Initialize the ScalarEncoder.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>VSAModel</code> <p>The VSAModel instance.</p> required <code>memory</code> <code>VSAMemory</code> <p>The VSAMemory instance with basis symbols.</p> required <code>min_val</code> <code>Optional[float]</code> <p>Minimum value for normalization (optional).</p> <code>None</code> <code>max_val</code> <code>Optional[float]</code> <p>Maximum value for normalization (optional).</p> <code>None</code> Source code in <code>vsax/encoders/scalar.py</code> <pre><code>def __init__(\n    self,\n    model: VSAModel,\n    memory: VSAMemory,\n    min_val: Optional[float] = None,\n    max_val: Optional[float] = None,\n) -&gt; None:\n    \"\"\"Initialize the ScalarEncoder.\n\n    Args:\n        model: The VSAModel instance.\n        memory: The VSAMemory instance with basis symbols.\n        min_val: Minimum value for normalization (optional).\n        max_val: Maximum value for normalization (optional).\n    \"\"\"\n    super().__init__(model, memory)\n    self.min_val = min_val\n    self.max_val = max_val\n</code></pre>"},{"location":"api/encoders/scalar/#vsax.encoders.ScalarEncoder.encode","title":"<code>encode(symbol_name, value)</code>","text":"<p>Encode a scalar value.</p> <p>Parameters:</p> Name Type Description Default <code>symbol_name</code> <code>str</code> <p>Name of the basis symbol in memory to use.</p> required <code>value</code> <code>float</code> <p>The numeric value to encode.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The encoded hypervector.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If symbol_name is not in memory.</p> <code>ValueError</code> <p>If value is outside the specified range.</p> Example <p>encoder = ScalarEncoder(model, memory) temp_hv = encoder.encode(\"temperature\", 23.5)</p> Source code in <code>vsax/encoders/scalar.py</code> <pre><code>def encode(self, symbol_name: str, value: float) -&gt; AbstractHypervector:\n    \"\"\"Encode a scalar value.\n\n    Args:\n        symbol_name: Name of the basis symbol in memory to use.\n        value: The numeric value to encode.\n\n    Returns:\n        The encoded hypervector.\n\n    Raises:\n        KeyError: If symbol_name is not in memory.\n        ValueError: If value is outside the specified range.\n\n    Example:\n        &gt;&gt;&gt; encoder = ScalarEncoder(model, memory)\n        &gt;&gt;&gt; temp_hv = encoder.encode(\"temperature\", 23.5)\n    \"\"\"\n    # Normalize value if range is specified\n    if self.min_val is not None and self.max_val is not None:\n        if not (self.min_val &lt;= value &lt;= self.max_val):\n            raise ValueError(\n                f\"Value {value} outside range [{self.min_val}, {self.max_val}]\"\n            )\n        # Normalize to 0-1 range\n        value = (value - self.min_val) / (self.max_val - self.min_val)\n\n    # Get basis hypervector\n    basis_hv = self.memory[symbol_name]\n\n    # For complex hypervectors, use power encoding\n    if jnp.iscomplexobj(basis_hv.vec):\n        # Power encoding: v ** value rotates the phase\n        powered_vec = jnp.power(basis_hv.vec, value)\n        return self.model.rep_cls(powered_vec)\n\n    # For real and binary hypervectors, use iterated binding\n    # Bind the vector with itself 'value' times\n    # For fractional values, we approximate with integer binding\n    iterations = int(jnp.round(value * 10))  # Scale for finer granularity\n\n    if iterations == 0:\n        # Return normalized zero-like vector\n        return basis_hv.normalize()\n\n    result = basis_hv.vec\n    for _ in range(iterations - 1):\n        result = self.model.opset.bind(result, basis_hv.vec)\n\n    return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/sequence/","title":"SequenceEncoder","text":"<p>Encoder for ordered sequences using positional binding.</p>"},{"location":"api/encoders/sequence/#vsax.encoders.SequenceEncoder","title":"<code>vsax.encoders.SequenceEncoder</code>","text":"<p>               Bases: <code>AbstractEncoder</code></p> <p>Encoder for ordered sequences using positional binding.</p> <p>Encodes sequences by binding each element with a position hypervector, then bundling all position-element pairs. This preserves order information.</p> <p>Position hypervectors are automatically added to memory with names \"pos_0\", \"pos_1\", etc.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The VSAModel instance defining the VSA algebra.</p> <code>memory</code> <p>The VSAMemory instance for accessing basis hypervectors.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.encoders import SequenceEncoder model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"red\", \"green\", \"blue\"]) encoder = SequenceEncoder(model, memory) color_sequence_hv = encoder.encode([\"red\", \"green\", \"blue\"])</p> Source code in <code>vsax/encoders/sequence.py</code> <pre><code>class SequenceEncoder(AbstractEncoder):\n    \"\"\"Encoder for ordered sequences using positional binding.\n\n    Encodes sequences by binding each element with a position hypervector,\n    then bundling all position-element pairs. This preserves order information.\n\n    Position hypervectors are automatically added to memory with names \"pos_0\",\n    \"pos_1\", etc.\n\n    Attributes:\n        model: The VSAModel instance defining the VSA algebra.\n        memory: The VSAMemory instance for accessing basis hypervectors.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; from vsax.encoders import SequenceEncoder\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"red\", \"green\", \"blue\"])\n        &gt;&gt;&gt; encoder = SequenceEncoder(model, memory)\n        &gt;&gt;&gt; color_sequence_hv = encoder.encode([\"red\", \"green\", \"blue\"])\n    \"\"\"\n\n    def encode(self, sequence: Sequence[str]) -&gt; AbstractHypervector:\n        \"\"\"Encode an ordered sequence of symbols.\n\n        Args:\n            sequence: A list or tuple of symbol names in memory.\n\n        Returns:\n            The encoded hypervector representing the sequence.\n\n        Raises:\n            KeyError: If any symbol in the sequence is not in memory.\n            ValueError: If the sequence is empty.\n\n        Example:\n            &gt;&gt;&gt; encoder = SequenceEncoder(model, memory)\n            &gt;&gt;&gt; seq_hv = encoder.encode([\"red\", \"green\", \"blue\"])\n        \"\"\"\n        if len(sequence) == 0:\n            raise ValueError(\"Cannot encode empty sequence\")\n\n        # Ensure position hypervectors exist in memory\n        for i in range(len(sequence)):\n            pos_name = f\"pos_{i}\"\n            if pos_name not in self.memory:\n                self.memory.add(pos_name)\n\n        # Bind each element with its position and collect results\n        bound_pairs = []\n        for i, symbol in enumerate(sequence):\n            pos_hv = self.memory[f\"pos_{i}\"]\n            elem_hv = self.memory[symbol]\n\n            # Bind position with element\n            bound = self.model.opset.bind(pos_hv.vec, elem_hv.vec)\n            bound_pairs.append(bound)\n\n        # Bundle all position-element pairs\n        result = self.model.opset.bundle(*bound_pairs)\n\n        return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/sequence/#vsax.encoders.SequenceEncoder-functions","title":"Functions","text":""},{"location":"api/encoders/sequence/#vsax.encoders.SequenceEncoder.encode","title":"<code>encode(sequence)</code>","text":"<p>Encode an ordered sequence of symbols.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>Sequence[str]</code> <p>A list or tuple of symbol names in memory.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The encoded hypervector representing the sequence.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If any symbol in the sequence is not in memory.</p> <code>ValueError</code> <p>If the sequence is empty.</p> Example <p>encoder = SequenceEncoder(model, memory) seq_hv = encoder.encode([\"red\", \"green\", \"blue\"])</p> Source code in <code>vsax/encoders/sequence.py</code> <pre><code>def encode(self, sequence: Sequence[str]) -&gt; AbstractHypervector:\n    \"\"\"Encode an ordered sequence of symbols.\n\n    Args:\n        sequence: A list or tuple of symbol names in memory.\n\n    Returns:\n        The encoded hypervector representing the sequence.\n\n    Raises:\n        KeyError: If any symbol in the sequence is not in memory.\n        ValueError: If the sequence is empty.\n\n    Example:\n        &gt;&gt;&gt; encoder = SequenceEncoder(model, memory)\n        &gt;&gt;&gt; seq_hv = encoder.encode([\"red\", \"green\", \"blue\"])\n    \"\"\"\n    if len(sequence) == 0:\n        raise ValueError(\"Cannot encode empty sequence\")\n\n    # Ensure position hypervectors exist in memory\n    for i in range(len(sequence)):\n        pos_name = f\"pos_{i}\"\n        if pos_name not in self.memory:\n            self.memory.add(pos_name)\n\n    # Bind each element with its position and collect results\n    bound_pairs = []\n    for i, symbol in enumerate(sequence):\n        pos_hv = self.memory[f\"pos_{i}\"]\n        elem_hv = self.memory[symbol]\n\n        # Bind position with element\n        bound = self.model.opset.bind(pos_hv.vec, elem_hv.vec)\n        bound_pairs.append(bound)\n\n    # Bundle all position-element pairs\n    result = self.model.opset.bundle(*bound_pairs)\n\n    return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/set/","title":"SetEncoder","text":"<p>Encoder for unordered sets using bundling.</p>"},{"location":"api/encoders/set/#vsax.encoders.SetEncoder","title":"<code>vsax.encoders.SetEncoder</code>","text":"<p>               Bases: <code>AbstractEncoder</code></p> <p>Encoder for unordered sets using bundling.</p> <p>Encodes sets by simply bundling all element hypervectors together. Since bundling is commutative, the result is order-invariant.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The VSAModel instance defining the VSA algebra.</p> <code>memory</code> <p>The VSAMemory instance for accessing basis hypervectors.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.encoders import SetEncoder model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"dog\", \"cat\", \"bird\"]) encoder = SetEncoder(model, memory) animals_set_hv = encoder.encode({\"dog\", \"cat\", \"bird\"})</p> Source code in <code>vsax/encoders/set.py</code> <pre><code>class SetEncoder(AbstractEncoder):\n    \"\"\"Encoder for unordered sets using bundling.\n\n    Encodes sets by simply bundling all element hypervectors together.\n    Since bundling is commutative, the result is order-invariant.\n\n    Attributes:\n        model: The VSAModel instance defining the VSA algebra.\n        memory: The VSAMemory instance for accessing basis hypervectors.\n\n    Example:\n        &gt;&gt;&gt; from vsax import create_fhrr_model, VSAMemory\n        &gt;&gt;&gt; from vsax.encoders import SetEncoder\n        &gt;&gt;&gt; model = create_fhrr_model(dim=512)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"dog\", \"cat\", \"bird\"])\n        &gt;&gt;&gt; encoder = SetEncoder(model, memory)\n        &gt;&gt;&gt; animals_set_hv = encoder.encode({\"dog\", \"cat\", \"bird\"})\n    \"\"\"\n\n    def encode(self, elements: Union[set[str], list[str]]) -&gt; AbstractHypervector:\n        \"\"\"Encode an unordered set of symbols.\n\n        Args:\n            elements: A set or list of symbol names in memory.\n\n        Returns:\n            The encoded hypervector representing the set.\n\n        Raises:\n            KeyError: If any symbol in the set is not in memory.\n            ValueError: If the set is empty.\n\n        Example:\n            &gt;&gt;&gt; encoder = SetEncoder(model, memory)\n            &gt;&gt;&gt; set_hv = encoder.encode({\"dog\", \"cat\", \"bird\"})\n        \"\"\"\n        if len(elements) == 0:\n            raise ValueError(\"Cannot encode empty set\")\n\n        # Get all element hypervectors\n        elem_vecs = [self.memory[symbol].vec for symbol in elements]\n\n        # Bundle all elements together\n        result = self.model.opset.bundle(*elem_vecs)\n\n        return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/encoders/set/#vsax.encoders.SetEncoder-functions","title":"Functions","text":""},{"location":"api/encoders/set/#vsax.encoders.SetEncoder.encode","title":"<code>encode(elements)</code>","text":"<p>Encode an unordered set of symbols.</p> <p>Parameters:</p> Name Type Description Default <code>elements</code> <code>Union[set[str], list[str]]</code> <p>A set or list of symbol names in memory.</p> required <p>Returns:</p> Type Description <code>AbstractHypervector</code> <p>The encoded hypervector representing the set.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If any symbol in the set is not in memory.</p> <code>ValueError</code> <p>If the set is empty.</p> Example <p>encoder = SetEncoder(model, memory) set_hv = encoder.encode({\"dog\", \"cat\", \"bird\"})</p> Source code in <code>vsax/encoders/set.py</code> <pre><code>def encode(self, elements: Union[set[str], list[str]]) -&gt; AbstractHypervector:\n    \"\"\"Encode an unordered set of symbols.\n\n    Args:\n        elements: A set or list of symbol names in memory.\n\n    Returns:\n        The encoded hypervector representing the set.\n\n    Raises:\n        KeyError: If any symbol in the set is not in memory.\n        ValueError: If the set is empty.\n\n    Example:\n        &gt;&gt;&gt; encoder = SetEncoder(model, memory)\n        &gt;&gt;&gt; set_hv = encoder.encode({\"dog\", \"cat\", \"bird\"})\n    \"\"\"\n    if len(elements) == 0:\n        raise ValueError(\"Cannot encode empty set\")\n\n    # Get all element hypervectors\n    elem_vecs = [self.memory[symbol].vec for symbol in elements]\n\n    # Bundle all elements together\n    result = self.model.opset.bundle(*elem_vecs)\n\n    return self.model.rep_cls(result)\n</code></pre>"},{"location":"api/io/","title":"I/O API Reference","text":"<p>JSON-based persistence for VSA basis vectors.</p>"},{"location":"api/io/#overview","title":"Overview","text":"<p>The I/O module provides two functions for saving and loading basis vectors:</p> <ul> <li><code>save_basis()</code> - Save VSAMemory to JSON file</li> <li><code>load_basis()</code> - Load VSAMemory from JSON file</li> </ul> <p>Both functions work with all three VSA models (FHRR, MAP, Binary).</p>"},{"location":"api/io/#functions","title":"Functions","text":""},{"location":"api/io/#save_basis","title":"save_basis","text":"<p>Example:</p> <pre><code>from vsax import create_fhrr_model, VSAMemory, save_basis\n\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\nmemory.add_many([\"dog\", \"cat\", \"animal\"])\n\nsave_basis(memory, \"animals.json\")\n</code></pre>"},{"location":"api/io/#vsax.io.save_basis","title":"<code>vsax.io.save_basis(memory, path)</code>","text":"<p>Save VSAMemory basis vectors to a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>memory</code> <code>VSAMemory</code> <p>VSAMemory instance containing named basis vectors</p> required <code>path</code> <code>Union[str, Path]</code> <p>File path to save JSON (will be created/overwritten)</p> required Example <p>model = create_fhrr_model(dim=128) memory = VSAMemory(model) memory.add_many([\"apple\", \"orange\", \"banana\"]) save_basis(memory, \"fruit_basis.json\")</p> Source code in <code>vsax/io/save.py</code> <pre><code>def save_basis(memory: VSAMemory, path: Union[str, Path]) -&gt; None:\n    \"\"\"Save VSAMemory basis vectors to a JSON file.\n\n    Args:\n        memory: VSAMemory instance containing named basis vectors\n        path: File path to save JSON (will be created/overwritten)\n\n    Example:\n        &gt;&gt;&gt; model = create_fhrr_model(dim=128)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"apple\", \"orange\", \"banana\"])\n        &gt;&gt;&gt; save_basis(memory, \"fruit_basis.json\")\n    \"\"\"\n    path = Path(path)\n\n    # Determine representation type\n    rep_cls = memory.model.rep_cls\n    if rep_cls == ComplexHypervector:\n        rep_type = \"complex\"\n    elif rep_cls == RealHypervector:\n        rep_type = \"real\"\n    elif rep_cls == BinaryHypervector:\n        rep_type = \"binary\"\n    else:\n        raise ValueError(f\"Unknown representation type: {rep_cls}\")\n\n    # Prepare data structure\n    data: dict[str, Any] = {\n        \"metadata\": {\n            \"dim\": memory.model.dim,\n            \"rep_type\": rep_type,\n            \"num_vectors\": len(memory._symbols),\n        },\n        \"vectors\": {},\n    }\n\n    # Serialize each vector\n    for name, hv in memory._symbols.items():\n        vec = hv.vec\n\n        if rep_type == \"complex\":\n            # Split complex into real and imaginary parts\n            data[\"vectors\"][name] = {\n                \"real\": vec.real.tolist(),\n                \"imag\": vec.imag.tolist(),\n            }\n        elif rep_type == \"real\":\n            # Store real vector\n            data[\"vectors\"][name] = vec.tolist()\n        elif rep_type == \"binary\":\n            # Store binary/bipolar vector as integers\n            data[\"vectors\"][name] = vec.astype(int).tolist()\n\n    # Write to file\n    with open(path, \"w\") as f:\n        json.dump(data, f, indent=2)\n</code></pre>"},{"location":"api/io/#load_basis","title":"load_basis","text":"<p>Example:</p> <pre><code>from vsax import create_fhrr_model, VSAMemory, load_basis\n\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\n\nload_basis(memory, \"animals.json\")\nprint(f\"Loaded {len(memory._vectors)} vectors\")\n</code></pre>"},{"location":"api/io/#vsax.io.load_basis","title":"<code>vsax.io.load_basis(memory, path)</code>","text":"<p>Load basis vectors from a JSON file into VSAMemory.</p> <p>Parameters:</p> Name Type Description Default <code>memory</code> <code>VSAMemory</code> <p>VSAMemory instance to populate (must be empty)</p> required <code>path</code> <code>Union[str, Path]</code> <p>File path to load JSON from</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If dimension or representation type doesn't match</p> <code>ValueError</code> <p>If memory is not empty</p> <code>FileNotFoundError</code> <p>If file doesn't exist</p> Example <p>model = create_fhrr_model(dim=128) memory = VSAMemory(model) load_basis(memory, \"fruit_basis.json\") \"apple\" in memory True</p> Source code in <code>vsax/io/load.py</code> <pre><code>def load_basis(memory: VSAMemory, path: Union[str, Path]) -&gt; None:\n    \"\"\"Load basis vectors from a JSON file into VSAMemory.\n\n    Args:\n        memory: VSAMemory instance to populate (must be empty)\n        path: File path to load JSON from\n\n    Raises:\n        ValueError: If dimension or representation type doesn't match\n        ValueError: If memory is not empty\n        FileNotFoundError: If file doesn't exist\n\n    Example:\n        &gt;&gt;&gt; model = create_fhrr_model(dim=128)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; load_basis(memory, \"fruit_basis.json\")\n        &gt;&gt;&gt; \"apple\" in memory\n        True\n    \"\"\"\n    path = Path(path)\n\n    # Check that memory is empty\n    if len(memory._symbols) &gt; 0:\n        raise ValueError(\n            f\"Memory must be empty to load basis. \"\n            f\"Current memory contains {len(memory._symbols)} vectors.\"\n        )\n\n    # Load JSON file\n    with open(path) as f:\n        data = json.load(f)\n\n    # Validate metadata\n    metadata = data[\"metadata\"]\n    saved_dim = metadata[\"dim\"]\n    saved_rep_type = metadata[\"rep_type\"]\n\n    # Check dimension matches\n    if saved_dim != memory.model.dim:\n        raise ValueError(\n            f\"Dimension mismatch: memory has dim={memory.model.dim}, \"\n            f\"but file has dim={saved_dim}\"\n        )\n\n    # Check representation type matches\n    rep_cls = memory.model.rep_cls\n    if rep_cls == ComplexHypervector:\n        expected_type = \"complex\"\n    elif rep_cls == RealHypervector:\n        expected_type = \"real\"\n    elif rep_cls == BinaryHypervector:\n        expected_type = \"binary\"\n    else:\n        raise ValueError(f\"Unknown representation type: {rep_cls}\")\n\n    if saved_rep_type != expected_type:\n        raise ValueError(\n            f\"Representation type mismatch: memory expects {expected_type}, \"\n            f\"but file has {saved_rep_type}\"\n        )\n\n    # Load vectors\n    vectors_data = data[\"vectors\"]\n\n    for name, vec_data in vectors_data.items():\n        if saved_rep_type == \"complex\":\n            # Reconstruct complex vector from real and imaginary parts\n            real_part = jnp.array(vec_data[\"real\"], dtype=jnp.float32)\n            imag_part = jnp.array(vec_data[\"imag\"], dtype=jnp.float32)\n            vec = real_part + 1j * imag_part\n        elif saved_rep_type == \"real\":\n            # Reconstruct real vector\n            vec = jnp.array(vec_data, dtype=jnp.float32)\n        elif saved_rep_type == \"binary\":\n            # Reconstruct binary vector\n            vec = jnp.array(vec_data, dtype=jnp.float32)\n        else:\n            raise ValueError(f\"Unknown rep_type: {saved_rep_type}\")\n\n        # Create hypervector and add to memory\n        hv = rep_cls(vec)\n        memory._symbols[name] = hv\n</code></pre>"},{"location":"api/io/#json-format","title":"JSON Format","text":""},{"location":"api/io/#fhrr-complex-vectors","title":"FHRR (Complex Vectors)","text":"<p>Complex hypervectors are stored with separate real and imaginary parts:</p> <pre><code>{\n  \"metadata\": {\n    \"dim\": 512,\n    \"rep_type\": \"complex\",\n    \"num_vectors\": 2\n  },\n  \"vectors\": {\n    \"dog\": {\n      \"real\": [0.12, -0.34, 0.56, ...],\n      \"imag\": [0.78, -0.23, 0.45, ...]\n    },\n    \"cat\": {\n      \"real\": [-0.67, 0.89, -0.12, ...],\n      \"imag\": [0.34, 0.56, -0.78, ...]\n    }\n  }\n}\n</code></pre>"},{"location":"api/io/#map-real-vectors","title":"MAP (Real Vectors)","text":"<p>Real hypervectors are stored as simple float arrays:</p> <pre><code>{\n  \"metadata\": {\n    \"dim\": 512,\n    \"rep_type\": \"real\",\n    \"num_vectors\": 2\n  },\n  \"vectors\": {\n    \"red\": [0.23, -0.45, 0.67, ...],\n    \"blue\": [-0.12, 0.34, -0.56, ...]\n  }\n}\n</code></pre>"},{"location":"api/io/#binary-bipolar-vectors","title":"Binary (Bipolar Vectors)","text":"<p>Binary hypervectors are stored as integer arrays:</p> <pre><code>{\n  \"metadata\": {\n    \"dim\": 1000,\n    \"rep_type\": \"binary\",\n    \"num_vectors\": 2\n  },\n  \"vectors\": {\n    \"x\": [-1, 1, -1, 1, -1, ...],\n    \"y\": [1, -1, 1, 1, -1, ...]\n  }\n}\n</code></pre>"},{"location":"api/io/#error-handling","title":"Error Handling","text":""},{"location":"api/io/#dimension-mismatch","title":"Dimension Mismatch","text":"<pre><code>from vsax import create_fhrr_model, VSAMemory, save_basis, load_basis\n\n# Save with dim=128\nmodel_128 = create_fhrr_model(dim=128)\nmemory_128 = VSAMemory(model_128)\nmemory_128.add(\"test\")\nsave_basis(memory_128, \"test.json\")\n\n# Try to load with dim=256\nmodel_256 = create_fhrr_model(dim=256)\nmemory_256 = VSAMemory(model_256)\n\ntry:\n    load_basis(memory_256, \"test.json\")\nexcept ValueError as e:\n    print(e)  # Dimension mismatch: memory has dim=256, but file has dim=128\n</code></pre>"},{"location":"api/io/#representation-type-mismatch","title":"Representation Type Mismatch","text":"<pre><code>from vsax import create_fhrr_model, create_map_model\n\n# Save FHRR\nfhrr_memory = VSAMemory(create_fhrr_model(dim=128))\nfhrr_memory.add(\"test\")\nsave_basis(fhrr_memory, \"test.json\")\n\n# Try to load as MAP\nmap_memory = VSAMemory(create_map_model(dim=128))\n\ntry:\n    load_basis(map_memory, \"test.json\")\nexcept ValueError as e:\n    print(e)  # Representation type mismatch: memory expects real, but file has complex\n</code></pre>"},{"location":"api/io/#non-empty-memory","title":"Non-Empty Memory","text":"<pre><code>memory = VSAMemory(create_fhrr_model(dim=128))\nmemory.add(\"existing_vector\")\n\ntry:\n    load_basis(memory, \"test.json\")\nexcept ValueError as e:\n    print(e)  # Memory must be empty to load basis. Current memory contains 1 vectors.\n</code></pre>"},{"location":"api/io/#use-cases","title":"Use Cases","text":""},{"location":"api/io/#persistent-semantic-spaces","title":"Persistent Semantic Spaces","text":"<pre><code># Build once\nmodel = create_fhrr_model(dim=1024)\nmemory = VSAMemory(model)\nmemory.add_many([\"concept1\", \"concept2\", ...])\nsave_basis(memory, \"knowledge_base.json\")\n\n# Reuse across sessions\nmemory_new = VSAMemory(model)\nload_basis(memory_new, \"knowledge_base.json\")\n</code></pre>"},{"location":"api/io/#sharing-vocabularies","title":"Sharing Vocabularies","text":"<pre><code># Project A\nsave_basis(memory_a, \"shared_vocab.json\")\n\n# Project B (same dimension and model type!)\nload_basis(memory_b, \"shared_vocab.json\")\n</code></pre>"},{"location":"api/io/#reproducible-research","title":"Reproducible Research","text":"<pre><code># Version control basis vectors\ngit add experiment_basis.json\ngit commit -m \"Add basis for reproducibility\"\n</code></pre>"},{"location":"api/io/#see-also","title":"See Also","text":"<ul> <li>Persistence User Guide - Detailed usage guide</li> <li>VSAMemory API - Memory management</li> <li>Examples - Complete working examples</li> </ul>"},{"location":"api/ops/binary/","title":"BinaryOperations","text":"<p>XOR and majority voting operations for binary hypervectors.</p>"},{"location":"api/ops/binary/#vsax.ops.BinaryOperations","title":"<code>vsax.ops.BinaryOperations</code>","text":"<p>               Bases: <code>AbstractOpSet</code></p> <p>Binary VSA operations for bipolar {-1, +1} vectors.</p> <p>Binary VSA uses: - Binding: XOR (element-wise multiplication in bipolar representation) - Bundling: Majority vote - Inverse: Self-inverse (XOR is its own inverse)</p> <p>This algebra is particularly efficient for hardware implementation and provides exact unbinding (unlike MAP).</p> <p>Note: Operations assume bipolar {-1, +1} encoding. For {0, 1} encoding, convert to bipolar first.</p> Example <p>import jax import jax.numpy as jnp</p> <p>ops = BinaryOperations() key = jax.random.PRNGKey(0) a = jax.random.choice(key, jnp.array([-1, 1]), shape=(1024,)) b = jax.random.choice(key, jnp.array([-1, 1]), shape=(1024,))</p> <p>bound = ops.bind(a, b) assert jnp.all(jnp.isin(bound, jnp.array([-1, 1])))</p> Source code in <code>vsax/ops/binary.py</code> <pre><code>class BinaryOperations(AbstractOpSet):\n    \"\"\"Binary VSA operations for bipolar {-1, +1} vectors.\n\n    Binary VSA uses:\n    - Binding: XOR (element-wise multiplication in bipolar representation)\n    - Bundling: Majority vote\n    - Inverse: Self-inverse (XOR is its own inverse)\n\n    This algebra is particularly efficient for hardware implementation and\n    provides exact unbinding (unlike MAP).\n\n    Note: Operations assume bipolar {-1, +1} encoding. For {0, 1} encoding,\n    convert to bipolar first.\n\n    Example:\n        &gt;&gt;&gt; import jax\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; ops = BinaryOperations()\n        &gt;&gt;&gt; key = jax.random.PRNGKey(0)\n        &gt;&gt;&gt; a = jax.random.choice(key, jnp.array([-1, 1]), shape=(1024,))\n        &gt;&gt;&gt; b = jax.random.choice(key, jnp.array([-1, 1]), shape=(1024,))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; bound = ops.bind(a, b)\n        &gt;&gt;&gt; assert jnp.all(jnp.isin(bound, jnp.array([-1, 1])))\n    \"\"\"\n\n    def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bind two hypervectors using XOR (element-wise multiplication).\n\n        In bipolar {-1, +1} representation, XOR is implemented as\n        element-wise multiplication:\n        - (+1) XOR (+1) = +1 (same)\n        - (+1) XOR (-1) = -1 (different)\n        - (-1) XOR (+1) = -1 (different)\n        - (-1) XOR (-1) = +1 (same)\n\n        This operation is:\n        - Commutative: bind(a, b) = bind(b, a)\n        - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c)\n        - Self-inverse: bind(bind(a, b), b) = a (exact unbinding)\n\n        Args:\n            a: First hypervector as JAX array (bipolar values).\n            b: Second hypervector as JAX array (bipolar values).\n\n        Returns:\n            Bound hypervector as JAX array (bipolar values).\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = BinaryOperations()\n            &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n            &gt;&gt;&gt; b = jnp.array([1, 1, -1, -1])\n            &gt;&gt;&gt; result = ops.bind(a, b)\n            &gt;&gt;&gt; expected = jnp.array([1, -1, -1, 1])\n            &gt;&gt;&gt; assert jnp.array_equal(result, expected)\n        \"\"\"\n        # XOR in bipolar is multiplication\n        return a * b\n\n    def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bundle multiple hypervectors using majority vote.\n\n        Each element in the bundled vector is determined by the majority\n        value at that position across all input vectors.\n\n        For even counts, ties are broken by the sign of the sum.\n\n        Args:\n            *vecs: Variable number of hypervectors as JAX arrays (bipolar values).\n\n        Returns:\n            Bundled hypervector as JAX array (bipolar values).\n\n        Raises:\n            ValueError: If no vectors are provided.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = BinaryOperations()\n            &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n            &gt;&gt;&gt; b = jnp.array([1, 1, -1, -1])\n            &gt;&gt;&gt; c = jnp.array([1, 1, 1, 1])\n            &gt;&gt;&gt; result = ops.bundle(a, b, c)\n            &gt;&gt;&gt; expected = jnp.array([1, 1, 1, -1])  # Majority at each position\n            &gt;&gt;&gt; assert jnp.array_equal(result, expected)\n        \"\"\"\n        if len(vecs) == 0:\n            raise ValueError(\"bundle() requires at least one vector\")\n\n        # Stack all vectors\n        stacked = jnp.stack(vecs)\n\n        # Sum across vectors (majority has positive/negative sum)\n        summed = jnp.sum(stacked, axis=0)\n\n        # Convert to bipolar: positive sum -&gt; +1, negative sum -&gt; -1\n        # Use sign function (0 maps to 0, but we'll handle that)\n        result = jnp.sign(summed)\n\n        # Handle zeros (ties) by defaulting to +1\n        result = jnp.where(result == 0, 1, result)\n\n        return result.astype(jnp.int32)\n\n    def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Compute the inverse for unbinding.\n\n        For binary XOR, the inverse is the vector itself (self-inverse property).\n        This means: bind(bind(a, b), b) = a (exact unbinding).\n\n        Args:\n            a: Hypervector as JAX array (bipolar values).\n\n        Returns:\n            Inverse hypervector (same as input for XOR).\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = BinaryOperations()\n            &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n            &gt;&gt;&gt; inv_a = ops.inverse(a)\n            &gt;&gt;&gt; assert jnp.array_equal(inv_a, a)\n        \"\"\"\n        # XOR is self-inverse\n        return a\n\n    def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n        \"\"\"Permute a hypervector by circular rotation.\n\n        Args:\n            a: Hypervector as JAX array (bipolar values).\n            shift: Number of positions to rotate (positive = right, negative = left).\n\n        Returns:\n            Permuted hypervector as JAX array.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = BinaryOperations()\n            &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n            &gt;&gt;&gt; rotated = ops.permute(a, 1)\n            &gt;&gt;&gt; expected = jnp.array([-1, 1, -1, 1])\n            &gt;&gt;&gt; assert jnp.array_equal(rotated, expected)\n        \"\"\"\n        return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/ops/binary/#vsax.ops.BinaryOperations-functions","title":"Functions","text":""},{"location":"api/ops/binary/#vsax.ops.BinaryOperations.bind","title":"<code>bind(a, b)</code>","text":"<p>Bind two hypervectors using XOR (element-wise multiplication).</p> <p>In bipolar {-1, +1} representation, XOR is implemented as element-wise multiplication: - (+1) XOR (+1) = +1 (same) - (+1) XOR (-1) = -1 (different) - (-1) XOR (+1) = -1 (different) - (-1) XOR (-1) = +1 (same)</p> <p>This operation is: - Commutative: bind(a, b) = bind(b, a) - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c) - Self-inverse: bind(bind(a, b), b) = a (exact unbinding)</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>First hypervector as JAX array (bipolar values).</p> required <code>b</code> <code>ndarray</code> <p>Second hypervector as JAX array (bipolar values).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Bound hypervector as JAX array (bipolar values).</p> Example <p>import jax.numpy as jnp ops = BinaryOperations() a = jnp.array([1, -1, 1, -1]) b = jnp.array([1, 1, -1, -1]) result = ops.bind(a, b) expected = jnp.array([1, -1, -1, 1]) assert jnp.array_equal(result, expected)</p> Source code in <code>vsax/ops/binary.py</code> <pre><code>def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bind two hypervectors using XOR (element-wise multiplication).\n\n    In bipolar {-1, +1} representation, XOR is implemented as\n    element-wise multiplication:\n    - (+1) XOR (+1) = +1 (same)\n    - (+1) XOR (-1) = -1 (different)\n    - (-1) XOR (+1) = -1 (different)\n    - (-1) XOR (-1) = +1 (same)\n\n    This operation is:\n    - Commutative: bind(a, b) = bind(b, a)\n    - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c)\n    - Self-inverse: bind(bind(a, b), b) = a (exact unbinding)\n\n    Args:\n        a: First hypervector as JAX array (bipolar values).\n        b: Second hypervector as JAX array (bipolar values).\n\n    Returns:\n        Bound hypervector as JAX array (bipolar values).\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = BinaryOperations()\n        &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n        &gt;&gt;&gt; b = jnp.array([1, 1, -1, -1])\n        &gt;&gt;&gt; result = ops.bind(a, b)\n        &gt;&gt;&gt; expected = jnp.array([1, -1, -1, 1])\n        &gt;&gt;&gt; assert jnp.array_equal(result, expected)\n    \"\"\"\n    # XOR in bipolar is multiplication\n    return a * b\n</code></pre>"},{"location":"api/ops/binary/#vsax.ops.BinaryOperations.bundle","title":"<code>bundle(*vecs)</code>","text":"<p>Bundle multiple hypervectors using majority vote.</p> <p>Each element in the bundled vector is determined by the majority value at that position across all input vectors.</p> <p>For even counts, ties are broken by the sign of the sum.</p> <p>Parameters:</p> Name Type Description Default <code>*vecs</code> <code>ndarray</code> <p>Variable number of hypervectors as JAX arrays (bipolar values).</p> <code>()</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Bundled hypervector as JAX array (bipolar values).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no vectors are provided.</p> Example <p>import jax.numpy as jnp ops = BinaryOperations() a = jnp.array([1, -1, 1, -1]) b = jnp.array([1, 1, -1, -1]) c = jnp.array([1, 1, 1, 1]) result = ops.bundle(a, b, c) expected = jnp.array([1, 1, 1, -1])  # Majority at each position assert jnp.array_equal(result, expected)</p> Source code in <code>vsax/ops/binary.py</code> <pre><code>def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bundle multiple hypervectors using majority vote.\n\n    Each element in the bundled vector is determined by the majority\n    value at that position across all input vectors.\n\n    For even counts, ties are broken by the sign of the sum.\n\n    Args:\n        *vecs: Variable number of hypervectors as JAX arrays (bipolar values).\n\n    Returns:\n        Bundled hypervector as JAX array (bipolar values).\n\n    Raises:\n        ValueError: If no vectors are provided.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = BinaryOperations()\n        &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n        &gt;&gt;&gt; b = jnp.array([1, 1, -1, -1])\n        &gt;&gt;&gt; c = jnp.array([1, 1, 1, 1])\n        &gt;&gt;&gt; result = ops.bundle(a, b, c)\n        &gt;&gt;&gt; expected = jnp.array([1, 1, 1, -1])  # Majority at each position\n        &gt;&gt;&gt; assert jnp.array_equal(result, expected)\n    \"\"\"\n    if len(vecs) == 0:\n        raise ValueError(\"bundle() requires at least one vector\")\n\n    # Stack all vectors\n    stacked = jnp.stack(vecs)\n\n    # Sum across vectors (majority has positive/negative sum)\n    summed = jnp.sum(stacked, axis=0)\n\n    # Convert to bipolar: positive sum -&gt; +1, negative sum -&gt; -1\n    # Use sign function (0 maps to 0, but we'll handle that)\n    result = jnp.sign(summed)\n\n    # Handle zeros (ties) by defaulting to +1\n    result = jnp.where(result == 0, 1, result)\n\n    return result.astype(jnp.int32)\n</code></pre>"},{"location":"api/ops/binary/#vsax.ops.BinaryOperations.inverse","title":"<code>inverse(a)</code>","text":"<p>Compute the inverse for unbinding.</p> <p>For binary XOR, the inverse is the vector itself (self-inverse property). This means: bind(bind(a, b), b) = a (exact unbinding).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array (bipolar values).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Inverse hypervector (same as input for XOR).</p> Example <p>import jax.numpy as jnp ops = BinaryOperations() a = jnp.array([1, -1, 1, -1]) inv_a = ops.inverse(a) assert jnp.array_equal(inv_a, a)</p> Source code in <code>vsax/ops/binary.py</code> <pre><code>def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Compute the inverse for unbinding.\n\n    For binary XOR, the inverse is the vector itself (self-inverse property).\n    This means: bind(bind(a, b), b) = a (exact unbinding).\n\n    Args:\n        a: Hypervector as JAX array (bipolar values).\n\n    Returns:\n        Inverse hypervector (same as input for XOR).\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = BinaryOperations()\n        &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n        &gt;&gt;&gt; inv_a = ops.inverse(a)\n        &gt;&gt;&gt; assert jnp.array_equal(inv_a, a)\n    \"\"\"\n    # XOR is self-inverse\n    return a\n</code></pre>"},{"location":"api/ops/binary/#vsax.ops.BinaryOperations.permute","title":"<code>permute(a, shift)</code>","text":"<p>Permute a hypervector by circular rotation.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array (bipolar values).</p> required <code>shift</code> <code>int</code> <p>Number of positions to rotate (positive = right, negative = left).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Permuted hypervector as JAX array.</p> Example <p>import jax.numpy as jnp ops = BinaryOperations() a = jnp.array([1, -1, 1, -1]) rotated = ops.permute(a, 1) expected = jnp.array([-1, 1, -1, 1]) assert jnp.array_equal(rotated, expected)</p> Source code in <code>vsax/ops/binary.py</code> <pre><code>def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n    \"\"\"Permute a hypervector by circular rotation.\n\n    Args:\n        a: Hypervector as JAX array (bipolar values).\n        shift: Number of positions to rotate (positive = right, negative = left).\n\n    Returns:\n        Permuted hypervector as JAX array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = BinaryOperations()\n        &gt;&gt;&gt; a = jnp.array([1, -1, 1, -1])\n        &gt;&gt;&gt; rotated = ops.permute(a, 1)\n        &gt;&gt;&gt; expected = jnp.array([-1, 1, -1, 1])\n        &gt;&gt;&gt; assert jnp.array_equal(rotated, expected)\n    \"\"\"\n    return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/ops/fhrr/","title":"FHRROperations","text":"<p>FFT-based operations for complex hypervectors.</p>"},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations","title":"<code>vsax.ops.FHRROperations</code>","text":"<p>               Bases: <code>AbstractOpSet</code></p> <p>FHRR operations using FFT-based circular convolution.</p> <p>Fourier Holographic Reduced Representation (FHRR) uses circular convolution for binding and complex addition for bundling. These operations work best with complex-valued hypervectors.</p> Binding is implemented via circular convolution in the frequency domain <p>bind(a, b) = IFFT(FFT(a) \u2299 FFT(b))</p> <p>where \u2299 denotes element-wise multiplication.</p> Example <p>import jax import jax.numpy as jnp from vsax.representations import ComplexHypervector</p> <p>ops = FHRROperations() key = jax.random.PRNGKey(0) a = jnp.exp(1j * jax.random.uniform(key, (512,), minval=0, maxval=2jnp.pi)) b = jnp.exp(1j * jax.random.uniform(key, (512,), minval=0, maxval=2jnp.pi))</p> <p>bound = ops.bind(a, b) assert bound.shape == a.shape</p> Source code in <code>vsax/ops/fhrr.py</code> <pre><code>class FHRROperations(AbstractOpSet):\n    \"\"\"FHRR operations using FFT-based circular convolution.\n\n    Fourier Holographic Reduced Representation (FHRR) uses circular convolution\n    for binding and complex addition for bundling. These operations work best\n    with complex-valued hypervectors.\n\n    Binding is implemented via circular convolution in the frequency domain:\n        bind(a, b) = IFFT(FFT(a) \u2299 FFT(b))\n\n    where \u2299 denotes element-wise multiplication.\n\n    Example:\n        &gt;&gt;&gt; import jax\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; from vsax.representations import ComplexHypervector\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; ops = FHRROperations()\n        &gt;&gt;&gt; key = jax.random.PRNGKey(0)\n        &gt;&gt;&gt; a = jnp.exp(1j * jax.random.uniform(key, (512,), minval=0, maxval=2*jnp.pi))\n        &gt;&gt;&gt; b = jnp.exp(1j * jax.random.uniform(key, (512,), minval=0, maxval=2*jnp.pi))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; bound = ops.bind(a, b)\n        &gt;&gt;&gt; assert bound.shape == a.shape\n    \"\"\"\n\n    def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bind two hypervectors using circular convolution.\n\n        Implemented via FFT: IFFT(FFT(a) * FFT(b))\n\n        This operation is:\n        - Commutative: bind(a, b) = bind(b, a)\n        - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c)\n        - Invertible: bind(bind(a, b), inverse(b)) \u2248 a\n\n        Args:\n            a: First hypervector as JAX array.\n            b: Second hypervector as JAX array.\n\n        Returns:\n            Bound hypervector as JAX array.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = FHRROperations()\n            &gt;&gt;&gt; a = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5]))\n            &gt;&gt;&gt; b = jnp.exp(1j * jnp.array([0.3, 0.7, 1.1]))\n            &gt;&gt;&gt; result = ops.bind(a, b)\n            &gt;&gt;&gt; assert jnp.iscomplexobj(result)\n        \"\"\"\n        # Circular convolution via FFT\n        fft_a = jnp.fft.fft(a)\n        fft_b = jnp.fft.fft(b)\n        return jnp.fft.ifft(fft_a * fft_b)\n\n    def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bundle multiple hypervectors using complex addition and normalization.\n\n        The bundled vector is similar to all input vectors and can be queried\n        to retrieve the constituents.\n\n        Args:\n            *vecs: Variable number of hypervectors as JAX arrays.\n\n        Returns:\n            Bundled hypervector as JAX array, normalized to unit magnitude.\n\n        Raises:\n            ValueError: If no vectors are provided.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = FHRROperations()\n            &gt;&gt;&gt; a = jnp.exp(1j * jnp.array([0.0, 0.5, 1.0]))\n            &gt;&gt;&gt; b = jnp.exp(1j * jnp.array([0.3, 0.7, 1.1]))\n            &gt;&gt;&gt; c = jnp.exp(1j * jnp.array([0.6, 0.9, 1.3]))\n            &gt;&gt;&gt; result = ops.bundle(a, b, c)\n            &gt;&gt;&gt; assert jnp.allclose(jnp.abs(result), 1.0, atol=0.1)\n        \"\"\"\n        if len(vecs) == 0:\n            raise ValueError(\"bundle() requires at least one vector\")\n\n        # Sum all vectors\n        result = jnp.sum(jnp.stack(vecs), axis=0)\n\n        # Normalize to unit magnitude (phase-only)\n        return result / jnp.abs(result)\n\n    def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Compute the inverse for unbinding.\n\n        For complex vectors, the inverse is the complex conjugate.\n        For real vectors, the inverse is the reversed vector (circular convolution inverse).\n\n        Args:\n            a: Hypervector as JAX array.\n\n        Returns:\n            Inverse hypervector as JAX array.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = FHRROperations()\n            &gt;&gt;&gt; a = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5]))\n            &gt;&gt;&gt; inv_a = ops.inverse(a)\n            &gt;&gt;&gt; # Binding with inverse should approximate identity\n            &gt;&gt;&gt; result = ops.bind(a, inv_a)\n            &gt;&gt;&gt; # Result should be close to all-ones vector (DC component)\n        \"\"\"\n        if jnp.iscomplexobj(a):\n            # Complex conjugate for complex vectors\n            return jnp.conj(a)\n        else:\n            # Reverse for real vectors (circular convolution inverse)\n            # Note: index 0 stays in place, rest are reversed\n            return jnp.concatenate([a[:1], jnp.flip(a[1:])])\n\n    def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n        \"\"\"Permute a hypervector by circular rotation.\n\n        Args:\n            a: Hypervector as JAX array.\n            shift: Number of positions to rotate (positive = right, negative = left).\n\n        Returns:\n            Permuted hypervector as JAX array.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = FHRROperations()\n            &gt;&gt;&gt; a = jnp.array([1, 2, 3, 4, 5])\n            &gt;&gt;&gt; rotated = ops.permute(a, 2)\n            &gt;&gt;&gt; assert jnp.array_equal(rotated, jnp.array([4, 5, 1, 2, 3]))\n        \"\"\"\n        return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations-functions","title":"Functions","text":""},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations.bind","title":"<code>bind(a, b)</code>","text":"<p>Bind two hypervectors using circular convolution.</p> <p>Implemented via FFT: IFFT(FFT(a) * FFT(b))</p> <p>This operation is: - Commutative: bind(a, b) = bind(b, a) - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c) - Invertible: bind(bind(a, b), inverse(b)) \u2248 a</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>First hypervector as JAX array.</p> required <code>b</code> <code>ndarray</code> <p>Second hypervector as JAX array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Bound hypervector as JAX array.</p> Example <p>import jax.numpy as jnp ops = FHRROperations() a = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5])) b = jnp.exp(1j * jnp.array([0.3, 0.7, 1.1])) result = ops.bind(a, b) assert jnp.iscomplexobj(result)</p> Source code in <code>vsax/ops/fhrr.py</code> <pre><code>def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bind two hypervectors using circular convolution.\n\n    Implemented via FFT: IFFT(FFT(a) * FFT(b))\n\n    This operation is:\n    - Commutative: bind(a, b) = bind(b, a)\n    - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c)\n    - Invertible: bind(bind(a, b), inverse(b)) \u2248 a\n\n    Args:\n        a: First hypervector as JAX array.\n        b: Second hypervector as JAX array.\n\n    Returns:\n        Bound hypervector as JAX array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = FHRROperations()\n        &gt;&gt;&gt; a = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5]))\n        &gt;&gt;&gt; b = jnp.exp(1j * jnp.array([0.3, 0.7, 1.1]))\n        &gt;&gt;&gt; result = ops.bind(a, b)\n        &gt;&gt;&gt; assert jnp.iscomplexobj(result)\n    \"\"\"\n    # Circular convolution via FFT\n    fft_a = jnp.fft.fft(a)\n    fft_b = jnp.fft.fft(b)\n    return jnp.fft.ifft(fft_a * fft_b)\n</code></pre>"},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations.bundle","title":"<code>bundle(*vecs)</code>","text":"<p>Bundle multiple hypervectors using complex addition and normalization.</p> <p>The bundled vector is similar to all input vectors and can be queried to retrieve the constituents.</p> <p>Parameters:</p> Name Type Description Default <code>*vecs</code> <code>ndarray</code> <p>Variable number of hypervectors as JAX arrays.</p> <code>()</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Bundled hypervector as JAX array, normalized to unit magnitude.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no vectors are provided.</p> Example <p>import jax.numpy as jnp ops = FHRROperations() a = jnp.exp(1j * jnp.array([0.0, 0.5, 1.0])) b = jnp.exp(1j * jnp.array([0.3, 0.7, 1.1])) c = jnp.exp(1j * jnp.array([0.6, 0.9, 1.3])) result = ops.bundle(a, b, c) assert jnp.allclose(jnp.abs(result), 1.0, atol=0.1)</p> Source code in <code>vsax/ops/fhrr.py</code> <pre><code>def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bundle multiple hypervectors using complex addition and normalization.\n\n    The bundled vector is similar to all input vectors and can be queried\n    to retrieve the constituents.\n\n    Args:\n        *vecs: Variable number of hypervectors as JAX arrays.\n\n    Returns:\n        Bundled hypervector as JAX array, normalized to unit magnitude.\n\n    Raises:\n        ValueError: If no vectors are provided.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = FHRROperations()\n        &gt;&gt;&gt; a = jnp.exp(1j * jnp.array([0.0, 0.5, 1.0]))\n        &gt;&gt;&gt; b = jnp.exp(1j * jnp.array([0.3, 0.7, 1.1]))\n        &gt;&gt;&gt; c = jnp.exp(1j * jnp.array([0.6, 0.9, 1.3]))\n        &gt;&gt;&gt; result = ops.bundle(a, b, c)\n        &gt;&gt;&gt; assert jnp.allclose(jnp.abs(result), 1.0, atol=0.1)\n    \"\"\"\n    if len(vecs) == 0:\n        raise ValueError(\"bundle() requires at least one vector\")\n\n    # Sum all vectors\n    result = jnp.sum(jnp.stack(vecs), axis=0)\n\n    # Normalize to unit magnitude (phase-only)\n    return result / jnp.abs(result)\n</code></pre>"},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations.inverse","title":"<code>inverse(a)</code>","text":"<p>Compute the inverse for unbinding.</p> <p>For complex vectors, the inverse is the complex conjugate. For real vectors, the inverse is the reversed vector (circular convolution inverse).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Inverse hypervector as JAX array.</p> Example <p>import jax.numpy as jnp ops = FHRROperations() a = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5])) inv_a = ops.inverse(a)</p> Source code in <code>vsax/ops/fhrr.py</code> <pre><code>def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Compute the inverse for unbinding.\n\n    For complex vectors, the inverse is the complex conjugate.\n    For real vectors, the inverse is the reversed vector (circular convolution inverse).\n\n    Args:\n        a: Hypervector as JAX array.\n\n    Returns:\n        Inverse hypervector as JAX array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = FHRROperations()\n        &gt;&gt;&gt; a = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5]))\n        &gt;&gt;&gt; inv_a = ops.inverse(a)\n        &gt;&gt;&gt; # Binding with inverse should approximate identity\n        &gt;&gt;&gt; result = ops.bind(a, inv_a)\n        &gt;&gt;&gt; # Result should be close to all-ones vector (DC component)\n    \"\"\"\n    if jnp.iscomplexobj(a):\n        # Complex conjugate for complex vectors\n        return jnp.conj(a)\n    else:\n        # Reverse for real vectors (circular convolution inverse)\n        # Note: index 0 stays in place, rest are reversed\n        return jnp.concatenate([a[:1], jnp.flip(a[1:])])\n</code></pre>"},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations.inverse--binding-with-inverse-should-approximate-identity","title":"Binding with inverse should approximate identity","text":"<p>result = ops.bind(a, inv_a)</p>"},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations.inverse--result-should-be-close-to-all-ones-vector-dc-component","title":"Result should be close to all-ones vector (DC component)","text":""},{"location":"api/ops/fhrr/#vsax.ops.FHRROperations.permute","title":"<code>permute(a, shift)</code>","text":"<p>Permute a hypervector by circular rotation.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array.</p> required <code>shift</code> <code>int</code> <p>Number of positions to rotate (positive = right, negative = left).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Permuted hypervector as JAX array.</p> Example <p>import jax.numpy as jnp ops = FHRROperations() a = jnp.array([1, 2, 3, 4, 5]) rotated = ops.permute(a, 2) assert jnp.array_equal(rotated, jnp.array([4, 5, 1, 2, 3]))</p> Source code in <code>vsax/ops/fhrr.py</code> <pre><code>def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n    \"\"\"Permute a hypervector by circular rotation.\n\n    Args:\n        a: Hypervector as JAX array.\n        shift: Number of positions to rotate (positive = right, negative = left).\n\n    Returns:\n        Permuted hypervector as JAX array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = FHRROperations()\n        &gt;&gt;&gt; a = jnp.array([1, 2, 3, 4, 5])\n        &gt;&gt;&gt; rotated = ops.permute(a, 2)\n        &gt;&gt;&gt; assert jnp.array_equal(rotated, jnp.array([4, 5, 1, 2, 3]))\n    \"\"\"\n    return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/ops/map/","title":"MAPOperations","text":"<p>Element-wise operations for real hypervectors.</p>"},{"location":"api/ops/map/#vsax.ops.MAPOperations","title":"<code>vsax.ops.MAPOperations</code>","text":"<p>               Bases: <code>AbstractOpSet</code></p> <p>MAP operations using element-wise multiplication and mean.</p> <p>Multiply-Add-Permute (MAP) is a simple VSA algebra that uses: - Binding: element-wise multiplication - Bundling: element-wise mean (averaging) - Inverse: approximate inverse via normalization</p> <p>MAP works best with real-valued hypervectors and is computationally efficient, making it suitable for machine learning applications.</p> Example <p>import jax import jax.numpy as jnp</p> <p>ops = MAPOperations() key = jax.random.PRNGKey(0) a = jax.random.normal(key, (1024,)) b = jax.random.normal(key, (1024,))</p> <p>bound = ops.bind(a, b) assert bound.shape == a.shape</p> Source code in <code>vsax/ops/map.py</code> <pre><code>class MAPOperations(AbstractOpSet):\n    \"\"\"MAP operations using element-wise multiplication and mean.\n\n    Multiply-Add-Permute (MAP) is a simple VSA algebra that uses:\n    - Binding: element-wise multiplication\n    - Bundling: element-wise mean (averaging)\n    - Inverse: approximate inverse via normalization\n\n    MAP works best with real-valued hypervectors and is computationally\n    efficient, making it suitable for machine learning applications.\n\n    Example:\n        &gt;&gt;&gt; import jax\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; ops = MAPOperations()\n        &gt;&gt;&gt; key = jax.random.PRNGKey(0)\n        &gt;&gt;&gt; a = jax.random.normal(key, (1024,))\n        &gt;&gt;&gt; b = jax.random.normal(key, (1024,))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; bound = ops.bind(a, b)\n        &gt;&gt;&gt; assert bound.shape == a.shape\n    \"\"\"\n\n    def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bind two hypervectors using element-wise multiplication.\n\n        This operation is:\n        - Commutative: bind(a, b) = bind(b, a)\n        - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c)\n        - Approximately invertible with the inverse() operation\n\n        Args:\n            a: First hypervector as JAX array.\n            b: Second hypervector as JAX array.\n\n        Returns:\n            Bound hypervector as JAX array (element-wise product).\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = MAPOperations()\n            &gt;&gt;&gt; a = jnp.array([1.0, 2.0, 3.0])\n            &gt;&gt;&gt; b = jnp.array([2.0, 3.0, 4.0])\n            &gt;&gt;&gt; result = ops.bind(a, b)\n            &gt;&gt;&gt; assert jnp.array_equal(result, jnp.array([2.0, 6.0, 12.0]))\n        \"\"\"\n        return a * b\n\n    def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Bundle multiple hypervectors using element-wise mean.\n\n        The bundled vector is the average of all input vectors, providing\n        a representation that is similar to all inputs.\n\n        Args:\n            *vecs: Variable number of hypervectors as JAX arrays.\n\n        Returns:\n            Bundled hypervector as JAX array (element-wise mean).\n\n        Raises:\n            ValueError: If no vectors are provided.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = MAPOperations()\n            &gt;&gt;&gt; a = jnp.array([1.0, 2.0, 3.0])\n            &gt;&gt;&gt; b = jnp.array([3.0, 4.0, 5.0])\n            &gt;&gt;&gt; c = jnp.array([5.0, 6.0, 7.0])\n            &gt;&gt;&gt; result = ops.bundle(a, b, c)\n            &gt;&gt;&gt; expected = jnp.array([3.0, 4.0, 5.0])\n            &gt;&gt;&gt; assert jnp.allclose(result, expected)\n        \"\"\"\n        if len(vecs) == 0:\n            raise ValueError(\"bundle() requires at least one vector\")\n\n        return jnp.mean(jnp.stack(vecs), axis=0)\n\n    def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n        \"\"\"Compute approximate inverse for unbinding.\n\n        For MAP, the inverse is approximated by the normalized vector itself.\n        This works because binding with a normalized vector approximately\n        projects onto the orthogonal complement.\n\n        Note: This is an approximation. Perfect unbinding is not guaranteed.\n\n        Args:\n            a: Hypervector as JAX array.\n\n        Returns:\n            Approximate inverse hypervector as JAX array.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = MAPOperations()\n            &gt;&gt;&gt; a = jnp.array([3.0, 4.0])\n            &gt;&gt;&gt; inv_a = ops.inverse(a)\n            &gt;&gt;&gt; # The inverse should be normalized\n            &gt;&gt;&gt; assert jnp.allclose(jnp.linalg.norm(inv_a), 1.0, atol=1e-6)\n        \"\"\"\n        # Normalize the vector as an approximate inverse\n        # This works because: a * (a / ||a||\u00b2) \u2248 a\u00b2/||a||\u00b2\n        norm_squared = jnp.sum(a**2)\n        return a / (norm_squared + 1e-8)\n\n    def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n        \"\"\"Permute a hypervector by circular rotation.\n\n        Args:\n            a: Hypervector as JAX array.\n            shift: Number of positions to rotate (positive = right, negative = left).\n\n        Returns:\n            Permuted hypervector as JAX array.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; ops = MAPOperations()\n            &gt;&gt;&gt; a = jnp.array([1.0, 2.0, 3.0, 4.0])\n            &gt;&gt;&gt; rotated = ops.permute(a, 1)\n            &gt;&gt;&gt; expected = jnp.array([4.0, 1.0, 2.0, 3.0])\n            &gt;&gt;&gt; assert jnp.array_equal(rotated, expected)\n        \"\"\"\n        return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/ops/map/#vsax.ops.MAPOperations-functions","title":"Functions","text":""},{"location":"api/ops/map/#vsax.ops.MAPOperations.bind","title":"<code>bind(a, b)</code>","text":"<p>Bind two hypervectors using element-wise multiplication.</p> <p>This operation is: - Commutative: bind(a, b) = bind(b, a) - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c) - Approximately invertible with the inverse() operation</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>First hypervector as JAX array.</p> required <code>b</code> <code>ndarray</code> <p>Second hypervector as JAX array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Bound hypervector as JAX array (element-wise product).</p> Example <p>import jax.numpy as jnp ops = MAPOperations() a = jnp.array([1.0, 2.0, 3.0]) b = jnp.array([2.0, 3.0, 4.0]) result = ops.bind(a, b) assert jnp.array_equal(result, jnp.array([2.0, 6.0, 12.0]))</p> Source code in <code>vsax/ops/map.py</code> <pre><code>def bind(self, a: jnp.ndarray, b: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bind two hypervectors using element-wise multiplication.\n\n    This operation is:\n    - Commutative: bind(a, b) = bind(b, a)\n    - Associative: bind(a, bind(b, c)) = bind(bind(a, b), c)\n    - Approximately invertible with the inverse() operation\n\n    Args:\n        a: First hypervector as JAX array.\n        b: Second hypervector as JAX array.\n\n    Returns:\n        Bound hypervector as JAX array (element-wise product).\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = MAPOperations()\n        &gt;&gt;&gt; a = jnp.array([1.0, 2.0, 3.0])\n        &gt;&gt;&gt; b = jnp.array([2.0, 3.0, 4.0])\n        &gt;&gt;&gt; result = ops.bind(a, b)\n        &gt;&gt;&gt; assert jnp.array_equal(result, jnp.array([2.0, 6.0, 12.0]))\n    \"\"\"\n    return a * b\n</code></pre>"},{"location":"api/ops/map/#vsax.ops.MAPOperations.bundle","title":"<code>bundle(*vecs)</code>","text":"<p>Bundle multiple hypervectors using element-wise mean.</p> <p>The bundled vector is the average of all input vectors, providing a representation that is similar to all inputs.</p> <p>Parameters:</p> Name Type Description Default <code>*vecs</code> <code>ndarray</code> <p>Variable number of hypervectors as JAX arrays.</p> <code>()</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Bundled hypervector as JAX array (element-wise mean).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no vectors are provided.</p> Example <p>import jax.numpy as jnp ops = MAPOperations() a = jnp.array([1.0, 2.0, 3.0]) b = jnp.array([3.0, 4.0, 5.0]) c = jnp.array([5.0, 6.0, 7.0]) result = ops.bundle(a, b, c) expected = jnp.array([3.0, 4.0, 5.0]) assert jnp.allclose(result, expected)</p> Source code in <code>vsax/ops/map.py</code> <pre><code>def bundle(self, *vecs: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Bundle multiple hypervectors using element-wise mean.\n\n    The bundled vector is the average of all input vectors, providing\n    a representation that is similar to all inputs.\n\n    Args:\n        *vecs: Variable number of hypervectors as JAX arrays.\n\n    Returns:\n        Bundled hypervector as JAX array (element-wise mean).\n\n    Raises:\n        ValueError: If no vectors are provided.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = MAPOperations()\n        &gt;&gt;&gt; a = jnp.array([1.0, 2.0, 3.0])\n        &gt;&gt;&gt; b = jnp.array([3.0, 4.0, 5.0])\n        &gt;&gt;&gt; c = jnp.array([5.0, 6.0, 7.0])\n        &gt;&gt;&gt; result = ops.bundle(a, b, c)\n        &gt;&gt;&gt; expected = jnp.array([3.0, 4.0, 5.0])\n        &gt;&gt;&gt; assert jnp.allclose(result, expected)\n    \"\"\"\n    if len(vecs) == 0:\n        raise ValueError(\"bundle() requires at least one vector\")\n\n    return jnp.mean(jnp.stack(vecs), axis=0)\n</code></pre>"},{"location":"api/ops/map/#vsax.ops.MAPOperations.inverse","title":"<code>inverse(a)</code>","text":"<p>Compute approximate inverse for unbinding.</p> <p>For MAP, the inverse is approximated by the normalized vector itself. This works because binding with a normalized vector approximately projects onto the orthogonal complement.</p> <p>Note: This is an approximation. Perfect unbinding is not guaranteed.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Approximate inverse hypervector as JAX array.</p> Example <p>import jax.numpy as jnp ops = MAPOperations() a = jnp.array([3.0, 4.0]) inv_a = ops.inverse(a)</p> Source code in <code>vsax/ops/map.py</code> <pre><code>def inverse(self, a: jnp.ndarray) -&gt; jnp.ndarray:\n    \"\"\"Compute approximate inverse for unbinding.\n\n    For MAP, the inverse is approximated by the normalized vector itself.\n    This works because binding with a normalized vector approximately\n    projects onto the orthogonal complement.\n\n    Note: This is an approximation. Perfect unbinding is not guaranteed.\n\n    Args:\n        a: Hypervector as JAX array.\n\n    Returns:\n        Approximate inverse hypervector as JAX array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = MAPOperations()\n        &gt;&gt;&gt; a = jnp.array([3.0, 4.0])\n        &gt;&gt;&gt; inv_a = ops.inverse(a)\n        &gt;&gt;&gt; # The inverse should be normalized\n        &gt;&gt;&gt; assert jnp.allclose(jnp.linalg.norm(inv_a), 1.0, atol=1e-6)\n    \"\"\"\n    # Normalize the vector as an approximate inverse\n    # This works because: a * (a / ||a||\u00b2) \u2248 a\u00b2/||a||\u00b2\n    norm_squared = jnp.sum(a**2)\n    return a / (norm_squared + 1e-8)\n</code></pre>"},{"location":"api/ops/map/#vsax.ops.MAPOperations.inverse--the-inverse-should-be-normalized","title":"The inverse should be normalized","text":"<p>assert jnp.allclose(jnp.linalg.norm(inv_a), 1.0, atol=1e-6)</p>"},{"location":"api/ops/map/#vsax.ops.MAPOperations.permute","title":"<code>permute(a, shift)</code>","text":"<p>Permute a hypervector by circular rotation.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Hypervector as JAX array.</p> required <code>shift</code> <code>int</code> <p>Number of positions to rotate (positive = right, negative = left).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Permuted hypervector as JAX array.</p> Example <p>import jax.numpy as jnp ops = MAPOperations() a = jnp.array([1.0, 2.0, 3.0, 4.0]) rotated = ops.permute(a, 1) expected = jnp.array([4.0, 1.0, 2.0, 3.0]) assert jnp.array_equal(rotated, expected)</p> Source code in <code>vsax/ops/map.py</code> <pre><code>def permute(self, a: jnp.ndarray, shift: int) -&gt; jnp.ndarray:\n    \"\"\"Permute a hypervector by circular rotation.\n\n    Args:\n        a: Hypervector as JAX array.\n        shift: Number of positions to rotate (positive = right, negative = left).\n\n    Returns:\n        Permuted hypervector as JAX array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; ops = MAPOperations()\n        &gt;&gt;&gt; a = jnp.array([1.0, 2.0, 3.0, 4.0])\n        &gt;&gt;&gt; rotated = ops.permute(a, 1)\n        &gt;&gt;&gt; expected = jnp.array([4.0, 1.0, 2.0, 3.0])\n        &gt;&gt;&gt; assert jnp.array_equal(rotated, expected)\n    \"\"\"\n    return jnp.roll(a, shift)\n</code></pre>"},{"location":"api/representations/binary/","title":"BinaryHypervector","text":"<p>Binary hypervector with bipolar or binary encoding.</p>"},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector","title":"<code>vsax.representations.BinaryHypervector</code>","text":"<p>               Bases: <code>AbstractHypervector</code></p> <p>Binary hypervector with bipolar {-1, +1} or binary {0, 1} values.</p> <p>BinaryHypervector represents hypervectors using discrete binary values. It supports two modes: - Bipolar: values in {-1, +1} (default, recommended) - Binary: values in {0, 1}</p> <p>Binary hypervectors are efficient for hardware implementation and provide good performance with XOR binding and majority bundling operations.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>JAX array containing binary values.</p> required <code>bipolar</code> <code>bool</code> <p>If True, expects {-1, +1} values. If False, expects {0, 1} values.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If vec contains values outside the expected binary set.</p> Example <p>import jax.numpy as jnp vec = jnp.array([1, -1, 1, -1]) hv = BinaryHypervector(vec, bipolar=True) normalized = hv.normalize()  # No-op for binary assert jnp.array_equal(normalized.vec, vec)</p> Source code in <code>vsax/representations/binary_hv.py</code> <pre><code>class BinaryHypervector(AbstractHypervector):\n    \"\"\"Binary hypervector with bipolar {-1, +1} or binary {0, 1} values.\n\n    BinaryHypervector represents hypervectors using discrete binary values.\n    It supports two modes:\n    - Bipolar: values in {-1, +1} (default, recommended)\n    - Binary: values in {0, 1}\n\n    Binary hypervectors are efficient for hardware implementation and provide\n    good performance with XOR binding and majority bundling operations.\n\n    Args:\n        vec: JAX array containing binary values.\n        bipolar: If True, expects {-1, +1} values. If False, expects {0, 1} values.\n\n    Raises:\n        ValueError: If vec contains values outside the expected binary set.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([1, -1, 1, -1])\n        &gt;&gt;&gt; hv = BinaryHypervector(vec, bipolar=True)\n        &gt;&gt;&gt; normalized = hv.normalize()  # No-op for binary\n        &gt;&gt;&gt; assert jnp.array_equal(normalized.vec, vec)\n    \"\"\"\n\n    def __init__(self, vec: jnp.ndarray, bipolar: bool = True) -&gt; None:\n        \"\"\"Initialize binary hypervector.\n\n        Args:\n            vec: JAX array with binary values.\n            bipolar: If True, values should be {-1, +1}.\n                    If False, values should be {0, 1}.\n\n        Raises:\n            ValueError: If vec contains invalid values for the chosen mode.\n        \"\"\"\n        self._bipolar = bipolar\n\n        # Validate binary values\n        unique_vals = jnp.unique(vec)\n\n        if bipolar:\n            valid_set = jnp.array([-1, 1])\n            if not jnp.all(jnp.isin(unique_vals, valid_set)):\n                raise ValueError(\n                    f\"Bipolar binary vector must contain only -1 or +1, \"\n                    f\"got unique values: {unique_vals}\"\n                )\n        else:\n            valid_set = jnp.array([0, 1])\n            if not jnp.all(jnp.isin(unique_vals, valid_set)):\n                raise ValueError(\n                    f\"Non-bipolar binary vector must contain only 0 or 1, \"\n                    f\"got unique values: {unique_vals}\"\n                )\n\n        super().__init__(vec)\n\n    def normalize(self) -&gt; \"BinaryHypervector\":\n        \"\"\"No-op normalization for binary hypervectors.\n\n        Binary hypervectors are already in their normalized form.\n\n        Returns:\n            A new BinaryHypervector with the same values.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.array([1, -1, 1])\n            &gt;&gt;&gt; hv = BinaryHypervector(vec)\n            &gt;&gt;&gt; normalized = hv.normalize()\n            &gt;&gt;&gt; assert jnp.array_equal(normalized.vec, vec)\n        \"\"\"\n        return BinaryHypervector(self._vec, bipolar=self._bipolar)\n\n    @property\n    def bipolar(self) -&gt; bool:\n        \"\"\"Check if hypervector uses bipolar {-1, +1} encoding.\n\n        Returns:\n            True if bipolar, False if binary {0, 1}.\n        \"\"\"\n        return self._bipolar\n\n    def to_bipolar(self) -&gt; \"BinaryHypervector\":\n        \"\"\"Convert to bipolar {-1, +1} representation.\n\n        Returns:\n            New BinaryHypervector in bipolar form.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.array([0, 1, 0, 1])\n            &gt;&gt;&gt; hv = BinaryHypervector(vec, bipolar=False)\n            &gt;&gt;&gt; bipolar_hv = hv.to_bipolar()\n            &gt;&gt;&gt; assert jnp.array_equal(bipolar_hv.vec, jnp.array([-1, 1, -1, 1]))\n        \"\"\"\n        if self._bipolar:\n            return self\n        # Convert {0, 1} to {-1, +1}: 2*x - 1\n        bipolar_vec = 2 * self._vec - 1\n        return BinaryHypervector(bipolar_vec, bipolar=True)\n\n    def to_binary(self) -&gt; \"BinaryHypervector\":\n        \"\"\"Convert to binary {0, 1} representation.\n\n        Returns:\n            New BinaryHypervector in binary form.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.array([-1, 1, -1, 1])\n            &gt;&gt;&gt; hv = BinaryHypervector(vec, bipolar=True)\n            &gt;&gt;&gt; binary_hv = hv.to_binary()\n            &gt;&gt;&gt; assert jnp.array_equal(binary_hv.vec, jnp.array([0, 1, 0, 1]))\n        \"\"\"\n        if not self._bipolar:\n            return self\n        # Convert {-1, +1} to {0, 1}: (x + 1) / 2\n        binary_vec = (self._vec + 1) // 2\n        return BinaryHypervector(binary_vec, bipolar=False)\n</code></pre>"},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector-attributes","title":"Attributes","text":""},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector.bipolar","title":"<code>bipolar</code>  <code>property</code>","text":"<p>Check if hypervector uses bipolar {-1, +1} encoding.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if bipolar, False if binary {0, 1}.</p>"},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector-functions","title":"Functions","text":""},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector.__init__","title":"<code>__init__(vec, bipolar=True)</code>","text":"<p>Initialize binary hypervector.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>JAX array with binary values.</p> required <code>bipolar</code> <code>bool</code> <p>If True, values should be {-1, +1}.     If False, values should be {0, 1}.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If vec contains invalid values for the chosen mode.</p> Source code in <code>vsax/representations/binary_hv.py</code> <pre><code>def __init__(self, vec: jnp.ndarray, bipolar: bool = True) -&gt; None:\n    \"\"\"Initialize binary hypervector.\n\n    Args:\n        vec: JAX array with binary values.\n        bipolar: If True, values should be {-1, +1}.\n                If False, values should be {0, 1}.\n\n    Raises:\n        ValueError: If vec contains invalid values for the chosen mode.\n    \"\"\"\n    self._bipolar = bipolar\n\n    # Validate binary values\n    unique_vals = jnp.unique(vec)\n\n    if bipolar:\n        valid_set = jnp.array([-1, 1])\n        if not jnp.all(jnp.isin(unique_vals, valid_set)):\n            raise ValueError(\n                f\"Bipolar binary vector must contain only -1 or +1, \"\n                f\"got unique values: {unique_vals}\"\n            )\n    else:\n        valid_set = jnp.array([0, 1])\n        if not jnp.all(jnp.isin(unique_vals, valid_set)):\n            raise ValueError(\n                f\"Non-bipolar binary vector must contain only 0 or 1, \"\n                f\"got unique values: {unique_vals}\"\n            )\n\n    super().__init__(vec)\n</code></pre>"},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector.normalize","title":"<code>normalize()</code>","text":"<p>No-op normalization for binary hypervectors.</p> <p>Binary hypervectors are already in their normalized form.</p> <p>Returns:</p> Type Description <code>BinaryHypervector</code> <p>A new BinaryHypervector with the same values.</p> Example <p>import jax.numpy as jnp vec = jnp.array([1, -1, 1]) hv = BinaryHypervector(vec) normalized = hv.normalize() assert jnp.array_equal(normalized.vec, vec)</p> Source code in <code>vsax/representations/binary_hv.py</code> <pre><code>def normalize(self) -&gt; \"BinaryHypervector\":\n    \"\"\"No-op normalization for binary hypervectors.\n\n    Binary hypervectors are already in their normalized form.\n\n    Returns:\n        A new BinaryHypervector with the same values.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([1, -1, 1])\n        &gt;&gt;&gt; hv = BinaryHypervector(vec)\n        &gt;&gt;&gt; normalized = hv.normalize()\n        &gt;&gt;&gt; assert jnp.array_equal(normalized.vec, vec)\n    \"\"\"\n    return BinaryHypervector(self._vec, bipolar=self._bipolar)\n</code></pre>"},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector.to_bipolar","title":"<code>to_bipolar()</code>","text":"<p>Convert to bipolar {-1, +1} representation.</p> <p>Returns:</p> Type Description <code>BinaryHypervector</code> <p>New BinaryHypervector in bipolar form.</p> Example <p>import jax.numpy as jnp vec = jnp.array([0, 1, 0, 1]) hv = BinaryHypervector(vec, bipolar=False) bipolar_hv = hv.to_bipolar() assert jnp.array_equal(bipolar_hv.vec, jnp.array([-1, 1, -1, 1]))</p> Source code in <code>vsax/representations/binary_hv.py</code> <pre><code>def to_bipolar(self) -&gt; \"BinaryHypervector\":\n    \"\"\"Convert to bipolar {-1, +1} representation.\n\n    Returns:\n        New BinaryHypervector in bipolar form.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([0, 1, 0, 1])\n        &gt;&gt;&gt; hv = BinaryHypervector(vec, bipolar=False)\n        &gt;&gt;&gt; bipolar_hv = hv.to_bipolar()\n        &gt;&gt;&gt; assert jnp.array_equal(bipolar_hv.vec, jnp.array([-1, 1, -1, 1]))\n    \"\"\"\n    if self._bipolar:\n        return self\n    # Convert {0, 1} to {-1, +1}: 2*x - 1\n    bipolar_vec = 2 * self._vec - 1\n    return BinaryHypervector(bipolar_vec, bipolar=True)\n</code></pre>"},{"location":"api/representations/binary/#vsax.representations.BinaryHypervector.to_binary","title":"<code>to_binary()</code>","text":"<p>Convert to binary {0, 1} representation.</p> <p>Returns:</p> Type Description <code>BinaryHypervector</code> <p>New BinaryHypervector in binary form.</p> Example <p>import jax.numpy as jnp vec = jnp.array([-1, 1, -1, 1]) hv = BinaryHypervector(vec, bipolar=True) binary_hv = hv.to_binary() assert jnp.array_equal(binary_hv.vec, jnp.array([0, 1, 0, 1]))</p> Source code in <code>vsax/representations/binary_hv.py</code> <pre><code>def to_binary(self) -&gt; \"BinaryHypervector\":\n    \"\"\"Convert to binary {0, 1} representation.\n\n    Returns:\n        New BinaryHypervector in binary form.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([-1, 1, -1, 1])\n        &gt;&gt;&gt; hv = BinaryHypervector(vec, bipolar=True)\n        &gt;&gt;&gt; binary_hv = hv.to_binary()\n        &gt;&gt;&gt; assert jnp.array_equal(binary_hv.vec, jnp.array([0, 1, 0, 1]))\n    \"\"\"\n    if not self._bipolar:\n        return self\n    # Convert {-1, +1} to {0, 1}: (x + 1) / 2\n    binary_vec = (self._vec + 1) // 2\n    return BinaryHypervector(binary_vec, bipolar=False)\n</code></pre>"},{"location":"api/representations/complex/","title":"ComplexHypervector","text":"<p>Phase-based complex-valued hypervector for FHRR operations.</p>"},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector","title":"<code>vsax.representations.ComplexHypervector</code>","text":"<p>               Bases: <code>AbstractHypervector</code></p> <p>Phase-based complex-valued hypervector for FHRR.</p> <p>ComplexHypervector uses complex numbers to represent hypervectors, where the phase component encodes information. This is particularly useful for Fourier Holographic Reduced Representation (FHRR) operations.</p> <p>The normalization operation sets all elements to unit magnitude, preserving only the phase information.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>Complex-valued JAX array representing the hypervector.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If vec is not a complex array.</p> Example <p>import jax.numpy as jnp vec = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5])) hv = ComplexHypervector(vec) normalized = hv.normalize() assert jnp.allclose(jnp.abs(normalized.vec), 1.0)</p> Source code in <code>vsax/representations/complex_hv.py</code> <pre><code>class ComplexHypervector(AbstractHypervector):\n    \"\"\"Phase-based complex-valued hypervector for FHRR.\n\n    ComplexHypervector uses complex numbers to represent hypervectors, where\n    the phase component encodes information. This is particularly useful for\n    Fourier Holographic Reduced Representation (FHRR) operations.\n\n    The normalization operation sets all elements to unit magnitude, preserving\n    only the phase information.\n\n    Args:\n        vec: Complex-valued JAX array representing the hypervector.\n\n    Raises:\n        TypeError: If vec is not a complex array.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.exp(1j * jnp.array([0.5, 1.0, 1.5]))\n        &gt;&gt;&gt; hv = ComplexHypervector(vec)\n        &gt;&gt;&gt; normalized = hv.normalize()\n        &gt;&gt;&gt; assert jnp.allclose(jnp.abs(normalized.vec), 1.0)\n    \"\"\"\n\n    def __init__(self, vec: jnp.ndarray) -&gt; None:\n        \"\"\"Initialize complex hypervector.\n\n        Args:\n            vec: Complex-valued JAX array.\n\n        Raises:\n            TypeError: If vec is not complex-valued.\n        \"\"\"\n        if not jnp.iscomplexobj(vec):\n            raise TypeError(\n                f\"ComplexHypervector requires complex array, got {vec.dtype}\"\n            )\n        super().__init__(vec)\n\n    def normalize(self) -&gt; \"ComplexHypervector\":\n        \"\"\"Normalize to unit magnitude (phase-only representation).\n\n        Returns:\n            New ComplexHypervector with all elements having magnitude 1.0,\n            preserving the phase angles.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.array([3+4j, 5+12j])\n            &gt;&gt;&gt; hv = ComplexHypervector(vec)\n            &gt;&gt;&gt; normalized = hv.normalize()\n            &gt;&gt;&gt; magnitudes = jnp.abs(normalized.vec)\n            &gt;&gt;&gt; assert jnp.allclose(magnitudes, 1.0)\n        \"\"\"\n        # Normalize to unit magnitude: z / |z|\n        normalized = self._vec / jnp.abs(self._vec)\n        return ComplexHypervector(normalized)\n\n    @property\n    def phase(self) -&gt; jnp.ndarray:\n        \"\"\"Extract phase component of the complex hypervector.\n\n        Returns:\n            Real-valued array of phase angles in radians, in the range [-\u03c0, \u03c0].\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.exp(1j * jnp.array([0.0, jnp.pi/2, jnp.pi]))\n            &gt;&gt;&gt; hv = ComplexHypervector(vec)\n            &gt;&gt;&gt; phases = hv.phase\n            &gt;&gt;&gt; assert phases.shape == vec.shape\n        \"\"\"\n        return jnp.angle(self._vec)\n\n    @property\n    def magnitude(self) -&gt; jnp.ndarray:\n        \"\"\"Extract magnitude component of the complex hypervector.\n\n        Returns:\n            Real-valued array of magnitudes.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.array([3+4j, 5+12j])\n            &gt;&gt;&gt; hv = ComplexHypervector(vec)\n            &gt;&gt;&gt; mags = hv.magnitude\n            &gt;&gt;&gt; assert jnp.allclose(mags, jnp.array([5.0, 13.0]))\n        \"\"\"\n        return jnp.abs(self._vec)\n</code></pre>"},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector-attributes","title":"Attributes","text":""},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector.phase","title":"<code>phase</code>  <code>property</code>","text":"<p>Extract phase component of the complex hypervector.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Real-valued array of phase angles in radians, in the range [-\u03c0, \u03c0].</p> Example <p>import jax.numpy as jnp vec = jnp.exp(1j * jnp.array([0.0, jnp.pi/2, jnp.pi])) hv = ComplexHypervector(vec) phases = hv.phase assert phases.shape == vec.shape</p>"},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector.magnitude","title":"<code>magnitude</code>  <code>property</code>","text":"<p>Extract magnitude component of the complex hypervector.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Real-valued array of magnitudes.</p> Example <p>import jax.numpy as jnp vec = jnp.array([3+4j, 5+12j]) hv = ComplexHypervector(vec) mags = hv.magnitude assert jnp.allclose(mags, jnp.array([5.0, 13.0]))</p>"},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector-functions","title":"Functions","text":""},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector.__init__","title":"<code>__init__(vec)</code>","text":"<p>Initialize complex hypervector.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>Complex-valued JAX array.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If vec is not complex-valued.</p> Source code in <code>vsax/representations/complex_hv.py</code> <pre><code>def __init__(self, vec: jnp.ndarray) -&gt; None:\n    \"\"\"Initialize complex hypervector.\n\n    Args:\n        vec: Complex-valued JAX array.\n\n    Raises:\n        TypeError: If vec is not complex-valued.\n    \"\"\"\n    if not jnp.iscomplexobj(vec):\n        raise TypeError(\n            f\"ComplexHypervector requires complex array, got {vec.dtype}\"\n        )\n    super().__init__(vec)\n</code></pre>"},{"location":"api/representations/complex/#vsax.representations.ComplexHypervector.normalize","title":"<code>normalize()</code>","text":"<p>Normalize to unit magnitude (phase-only representation).</p> <p>Returns:</p> Type Description <code>ComplexHypervector</code> <p>New ComplexHypervector with all elements having magnitude 1.0,</p> <code>ComplexHypervector</code> <p>preserving the phase angles.</p> Example <p>import jax.numpy as jnp vec = jnp.array([3+4j, 5+12j]) hv = ComplexHypervector(vec) normalized = hv.normalize() magnitudes = jnp.abs(normalized.vec) assert jnp.allclose(magnitudes, 1.0)</p> Source code in <code>vsax/representations/complex_hv.py</code> <pre><code>def normalize(self) -&gt; \"ComplexHypervector\":\n    \"\"\"Normalize to unit magnitude (phase-only representation).\n\n    Returns:\n        New ComplexHypervector with all elements having magnitude 1.0,\n        preserving the phase angles.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([3+4j, 5+12j])\n        &gt;&gt;&gt; hv = ComplexHypervector(vec)\n        &gt;&gt;&gt; normalized = hv.normalize()\n        &gt;&gt;&gt; magnitudes = jnp.abs(normalized.vec)\n        &gt;&gt;&gt; assert jnp.allclose(magnitudes, 1.0)\n    \"\"\"\n    # Normalize to unit magnitude: z / |z|\n    normalized = self._vec / jnp.abs(self._vec)\n    return ComplexHypervector(normalized)\n</code></pre>"},{"location":"api/representations/real/","title":"RealHypervector","text":"<p>Continuous real-valued hypervector for MAP operations.</p>"},{"location":"api/representations/real/#vsax.representations.RealHypervector","title":"<code>vsax.representations.RealHypervector</code>","text":"<p>               Bases: <code>AbstractHypervector</code></p> <p>Continuous real-valued hypervector for MAP operations.</p> <p>RealHypervector uses real numbers to represent hypervectors. This is commonly used with Multiply-Add-Permute (MAP) operations where element-wise multiplication and averaging are the primary operations.</p> <p>The normalization operation performs L2 normalization, scaling the vector to unit length.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>Real-valued JAX array representing the hypervector.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If vec is complex-valued.</p> Example <p>import jax.numpy as jnp vec = jnp.array([1.0, 2.0, 3.0]) hv = RealHypervector(vec) normalized = hv.normalize() assert jnp.allclose(jnp.linalg.norm(normalized.vec), 1.0)</p> Source code in <code>vsax/representations/real_hv.py</code> <pre><code>class RealHypervector(AbstractHypervector):\n    \"\"\"Continuous real-valued hypervector for MAP operations.\n\n    RealHypervector uses real numbers to represent hypervectors. This is\n    commonly used with Multiply-Add-Permute (MAP) operations where element-wise\n    multiplication and averaging are the primary operations.\n\n    The normalization operation performs L2 normalization, scaling the vector\n    to unit length.\n\n    Args:\n        vec: Real-valued JAX array representing the hypervector.\n\n    Raises:\n        TypeError: If vec is complex-valued.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([1.0, 2.0, 3.0])\n        &gt;&gt;&gt; hv = RealHypervector(vec)\n        &gt;&gt;&gt; normalized = hv.normalize()\n        &gt;&gt;&gt; assert jnp.allclose(jnp.linalg.norm(normalized.vec), 1.0)\n    \"\"\"\n\n    def __init__(self, vec: jnp.ndarray) -&gt; None:\n        \"\"\"Initialize real hypervector.\n\n        Args:\n            vec: Real-valued JAX array.\n\n        Raises:\n            TypeError: If vec is complex-valued.\n        \"\"\"\n        if jnp.iscomplexobj(vec):\n            raise TypeError(\n                f\"RealHypervector requires real array, got complex dtype {vec.dtype}\"\n            )\n        super().__init__(vec)\n\n    def normalize(self) -&gt; \"RealHypervector\":\n        \"\"\"L2 normalization to unit length.\n\n        Returns:\n            New RealHypervector with L2 norm equal to 1.0.\n\n        Example:\n            &gt;&gt;&gt; import jax.numpy as jnp\n            &gt;&gt;&gt; vec = jnp.array([3.0, 4.0])\n            &gt;&gt;&gt; hv = RealHypervector(vec)\n            &gt;&gt;&gt; normalized = hv.normalize()\n            &gt;&gt;&gt; assert jnp.allclose(jnp.linalg.norm(normalized.vec), 1.0)\n            &gt;&gt;&gt; assert jnp.allclose(normalized.vec, jnp.array([0.6, 0.8]))\n        \"\"\"\n        norm = jnp.linalg.norm(self._vec)\n        # Add small epsilon to avoid division by zero\n        normalized = self._vec / (norm + 1e-8)\n        return RealHypervector(normalized)\n</code></pre>"},{"location":"api/representations/real/#vsax.representations.RealHypervector-functions","title":"Functions","text":""},{"location":"api/representations/real/#vsax.representations.RealHypervector.__init__","title":"<code>__init__(vec)</code>","text":"<p>Initialize real hypervector.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>ndarray</code> <p>Real-valued JAX array.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If vec is complex-valued.</p> Source code in <code>vsax/representations/real_hv.py</code> <pre><code>def __init__(self, vec: jnp.ndarray) -&gt; None:\n    \"\"\"Initialize real hypervector.\n\n    Args:\n        vec: Real-valued JAX array.\n\n    Raises:\n        TypeError: If vec is complex-valued.\n    \"\"\"\n    if jnp.iscomplexobj(vec):\n        raise TypeError(\n            f\"RealHypervector requires real array, got complex dtype {vec.dtype}\"\n        )\n    super().__init__(vec)\n</code></pre>"},{"location":"api/representations/real/#vsax.representations.RealHypervector.normalize","title":"<code>normalize()</code>","text":"<p>L2 normalization to unit length.</p> <p>Returns:</p> Type Description <code>RealHypervector</code> <p>New RealHypervector with L2 norm equal to 1.0.</p> Example <p>import jax.numpy as jnp vec = jnp.array([3.0, 4.0]) hv = RealHypervector(vec) normalized = hv.normalize() assert jnp.allclose(jnp.linalg.norm(normalized.vec), 1.0) assert jnp.allclose(normalized.vec, jnp.array([0.6, 0.8]))</p> Source code in <code>vsax/representations/real_hv.py</code> <pre><code>def normalize(self) -&gt; \"RealHypervector\":\n    \"\"\"L2 normalization to unit length.\n\n    Returns:\n        New RealHypervector with L2 norm equal to 1.0.\n\n    Example:\n        &gt;&gt;&gt; import jax.numpy as jnp\n        &gt;&gt;&gt; vec = jnp.array([3.0, 4.0])\n        &gt;&gt;&gt; hv = RealHypervector(vec)\n        &gt;&gt;&gt; normalized = hv.normalize()\n        &gt;&gt;&gt; assert jnp.allclose(jnp.linalg.norm(normalized.vec), 1.0)\n        &gt;&gt;&gt; assert jnp.allclose(normalized.vec, jnp.array([0.6, 0.8]))\n    \"\"\"\n    norm = jnp.linalg.norm(self._vec)\n    # Add small epsilon to avoid division by zero\n    normalized = self._vec / (norm + 1e-8)\n    return RealHypervector(normalized)\n</code></pre>"},{"location":"api/resonator/","title":"Resonator Networks API","text":""},{"location":"api/resonator/#overview","title":"Overview","text":"<p>The resonator module implements resonator networks for VSA factorization.</p> <p>Given a composite vector <code>s = a \u2299 b \u2299 c</code>, resonator networks iteratively recover the factors <code>a</code>, <code>b</code>, <code>c</code> from known codebooks.</p>"},{"location":"api/resonator/#cleanupmemory","title":"CleanupMemory","text":""},{"location":"api/resonator/#vsax.resonator.CleanupMemory","title":"<code>vsax.resonator.CleanupMemory</code>","text":"<p>Cleanup memory for projecting vectors onto a codebook.</p> <p>This class implements codebook projection, which finds the nearest vector from a set of known vectors (codebook) to a query vector.</p> <p>Parameters:</p> Name Type Description Default <code>codebook</code> <code>list[str]</code> <p>List of named symbols from VSAMemory to use as codebook.</p> required <code>memory</code> <code>VSAMemory</code> <p>VSAMemory containing the basis vectors.</p> required <code>threshold</code> <code>float</code> <p>Optional similarity threshold for cleanup (default: 0.0).        If best match is below threshold, returns None.</p> <code>0.0</code> Example <p>model = create_binary_model(dim=10000) memory = VSAMemory(model) memory.add_many([\"red\", \"blue\", \"green\"]) cleanup = CleanupMemory([\"red\", \"blue\", \"green\"], memory) noisy = model.opset.bundle(memory[\"red\"].vec, memory[\"blue\"].vec) result = cleanup.query(noisy) print(result)  # Should return \"red\" or \"blue\"</p> Source code in <code>vsax/resonator/cleanup.py</code> <pre><code>class CleanupMemory:\n    \"\"\"Cleanup memory for projecting vectors onto a codebook.\n\n    This class implements codebook projection, which finds the nearest\n    vector from a set of known vectors (codebook) to a query vector.\n\n    Args:\n        codebook: List of named symbols from VSAMemory to use as codebook.\n        memory: VSAMemory containing the basis vectors.\n        threshold: Optional similarity threshold for cleanup (default: 0.0).\n                   If best match is below threshold, returns None.\n\n    Example:\n        &gt;&gt;&gt; model = create_binary_model(dim=10000)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"red\", \"blue\", \"green\"])\n        &gt;&gt;&gt; cleanup = CleanupMemory([\"red\", \"blue\", \"green\"], memory)\n        &gt;&gt;&gt; noisy = model.opset.bundle(memory[\"red\"].vec, memory[\"blue\"].vec)\n        &gt;&gt;&gt; result = cleanup.query(noisy)\n        &gt;&gt;&gt; print(result)  # Should return \"red\" or \"blue\"\n    \"\"\"\n\n    def __init__(\n        self,\n        codebook: list[str],\n        memory: VSAMemory,\n        threshold: float = 0.0,\n    ) -&gt; None:\n        \"\"\"Initialize cleanup memory with codebook.\"\"\"\n        self.codebook = codebook\n        self.memory = memory\n        self.threshold = threshold\n\n        # Validate codebook symbols exist in memory\n        for symbol in codebook:\n            if symbol not in memory:\n                raise ValueError(f\"Symbol '{symbol}' not found in memory\")\n\n        # Pre-compute codebook matrix for efficient lookup\n        self._codebook_vecs = jnp.stack([memory[name].vec for name in codebook])\n\n    def query(\n        self,\n        vec: Union[jnp.ndarray, AbstractHypervector],\n        return_similarity: bool = False,\n    ) -&gt; Union[Optional[str], tuple[Optional[str], float]]:\n        \"\"\"Project vector onto codebook and return nearest symbol.\n\n        Args:\n            vec: Query vector to cleanup (array or hypervector).\n            return_similarity: If True, also return similarity score.\n\n        Returns:\n            If return_similarity=False: Symbol name or None if below threshold.\n            If return_similarity=True: Tuple of (symbol, similarity) or (None, similarity).\n\n        Example:\n            &gt;&gt;&gt; result = cleanup.query(noisy_vec)\n            &gt;&gt;&gt; result_with_score = cleanup.query(noisy_vec, return_similarity=True)\n            &gt;&gt;&gt; print(result_with_score)  # (\"red\", 0.95)\n        \"\"\"\n        # Coerce to array if hypervector\n        if isinstance(vec, AbstractHypervector):\n            vec = vec.vec\n\n        # Compute similarities to all codebook vectors\n        # For complex vectors, use conjugate dot product (inner product)\n        # For real/binary vectors, use direct dot product\n        if jnp.iscomplexobj(self._codebook_vecs):\n            # Complex case: use conjugate dot product, then take abs for similarity\n            similarities = jnp.abs(jnp.dot(self._codebook_vecs.conj(), vec))\n        else:\n            # Real/binary case: direct dot product\n            similarities = jnp.dot(self._codebook_vecs, vec)\n\n        # Find best match\n        best_idx = int(jnp.argmax(similarities))\n        best_sim = float(similarities[best_idx])\n\n        # Check threshold\n        if best_sim &lt; self.threshold:\n            return (None, best_sim) if return_similarity else None\n\n        best_symbol = self.codebook[best_idx]\n        return (best_symbol, best_sim) if return_similarity else best_symbol\n\n    def query_top_k(\n        self,\n        vec: Union[jnp.ndarray, AbstractHypervector],\n        k: int = 3,\n    ) -&gt; list[tuple[str, float]]:\n        \"\"\"Return top-k closest symbols with similarity scores.\n\n        Args:\n            vec: Query vector to cleanup.\n            k: Number of top matches to return.\n\n        Returns:\n            List of (symbol, similarity) tuples sorted by similarity (descending).\n\n        Example:\n            &gt;&gt;&gt; top_matches = cleanup.query_top_k(noisy_vec, k=3)\n            &gt;&gt;&gt; for symbol, sim in top_matches:\n            ...     print(f\"{symbol}: {sim:.3f}\")\n        \"\"\"\n        # Coerce to array if hypervector\n        if isinstance(vec, AbstractHypervector):\n            vec = vec.vec\n\n        # Compute similarities\n        if jnp.iscomplexobj(self._codebook_vecs):\n            similarities = jnp.abs(jnp.dot(self._codebook_vecs.conj(), vec))\n        else:\n            similarities = jnp.dot(self._codebook_vecs, vec)\n\n        # Get top-k indices\n        top_k_indices = jnp.argsort(similarities)[-k:][::-1]\n\n        # Build result list\n        results = [\n            (self.codebook[int(idx)], float(similarities[idx]))\n            for idx in top_k_indices\n        ]\n\n        return results\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return number of vectors in codebook.\"\"\"\n        return len(self.codebook)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return string representation.\"\"\"\n        return f\"CleanupMemory(codebook_size={len(self.codebook)}, threshold={self.threshold})\"\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.CleanupMemory-functions","title":"Functions","text":""},{"location":"api/resonator/#vsax.resonator.CleanupMemory.__init__","title":"<code>__init__(codebook, memory, threshold=0.0)</code>","text":"<p>Initialize cleanup memory with codebook.</p> Source code in <code>vsax/resonator/cleanup.py</code> <pre><code>def __init__(\n    self,\n    codebook: list[str],\n    memory: VSAMemory,\n    threshold: float = 0.0,\n) -&gt; None:\n    \"\"\"Initialize cleanup memory with codebook.\"\"\"\n    self.codebook = codebook\n    self.memory = memory\n    self.threshold = threshold\n\n    # Validate codebook symbols exist in memory\n    for symbol in codebook:\n        if symbol not in memory:\n            raise ValueError(f\"Symbol '{symbol}' not found in memory\")\n\n    # Pre-compute codebook matrix for efficient lookup\n    self._codebook_vecs = jnp.stack([memory[name].vec for name in codebook])\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.CleanupMemory.query","title":"<code>query(vec, return_similarity=False)</code>","text":"<p>Project vector onto codebook and return nearest symbol.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>Union[ndarray, AbstractHypervector]</code> <p>Query vector to cleanup (array or hypervector).</p> required <code>return_similarity</code> <code>bool</code> <p>If True, also return similarity score.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Optional[str], tuple[Optional[str], float]]</code> <p>If return_similarity=False: Symbol name or None if below threshold.</p> <code>Union[Optional[str], tuple[Optional[str], float]]</code> <p>If return_similarity=True: Tuple of (symbol, similarity) or (None, similarity).</p> Example <p>result = cleanup.query(noisy_vec) result_with_score = cleanup.query(noisy_vec, return_similarity=True) print(result_with_score)  # (\"red\", 0.95)</p> Source code in <code>vsax/resonator/cleanup.py</code> <pre><code>def query(\n    self,\n    vec: Union[jnp.ndarray, AbstractHypervector],\n    return_similarity: bool = False,\n) -&gt; Union[Optional[str], tuple[Optional[str], float]]:\n    \"\"\"Project vector onto codebook and return nearest symbol.\n\n    Args:\n        vec: Query vector to cleanup (array or hypervector).\n        return_similarity: If True, also return similarity score.\n\n    Returns:\n        If return_similarity=False: Symbol name or None if below threshold.\n        If return_similarity=True: Tuple of (symbol, similarity) or (None, similarity).\n\n    Example:\n        &gt;&gt;&gt; result = cleanup.query(noisy_vec)\n        &gt;&gt;&gt; result_with_score = cleanup.query(noisy_vec, return_similarity=True)\n        &gt;&gt;&gt; print(result_with_score)  # (\"red\", 0.95)\n    \"\"\"\n    # Coerce to array if hypervector\n    if isinstance(vec, AbstractHypervector):\n        vec = vec.vec\n\n    # Compute similarities to all codebook vectors\n    # For complex vectors, use conjugate dot product (inner product)\n    # For real/binary vectors, use direct dot product\n    if jnp.iscomplexobj(self._codebook_vecs):\n        # Complex case: use conjugate dot product, then take abs for similarity\n        similarities = jnp.abs(jnp.dot(self._codebook_vecs.conj(), vec))\n    else:\n        # Real/binary case: direct dot product\n        similarities = jnp.dot(self._codebook_vecs, vec)\n\n    # Find best match\n    best_idx = int(jnp.argmax(similarities))\n    best_sim = float(similarities[best_idx])\n\n    # Check threshold\n    if best_sim &lt; self.threshold:\n        return (None, best_sim) if return_similarity else None\n\n    best_symbol = self.codebook[best_idx]\n    return (best_symbol, best_sim) if return_similarity else best_symbol\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.CleanupMemory.query_top_k","title":"<code>query_top_k(vec, k=3)</code>","text":"<p>Return top-k closest symbols with similarity scores.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>Union[ndarray, AbstractHypervector]</code> <p>Query vector to cleanup.</p> required <code>k</code> <code>int</code> <p>Number of top matches to return.</p> <code>3</code> <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>List of (symbol, similarity) tuples sorted by similarity (descending).</p> Example <p>top_matches = cleanup.query_top_k(noisy_vec, k=3) for symbol, sim in top_matches: ...     print(f\"{symbol}: {sim:.3f}\")</p> Source code in <code>vsax/resonator/cleanup.py</code> <pre><code>def query_top_k(\n    self,\n    vec: Union[jnp.ndarray, AbstractHypervector],\n    k: int = 3,\n) -&gt; list[tuple[str, float]]:\n    \"\"\"Return top-k closest symbols with similarity scores.\n\n    Args:\n        vec: Query vector to cleanup.\n        k: Number of top matches to return.\n\n    Returns:\n        List of (symbol, similarity) tuples sorted by similarity (descending).\n\n    Example:\n        &gt;&gt;&gt; top_matches = cleanup.query_top_k(noisy_vec, k=3)\n        &gt;&gt;&gt; for symbol, sim in top_matches:\n        ...     print(f\"{symbol}: {sim:.3f}\")\n    \"\"\"\n    # Coerce to array if hypervector\n    if isinstance(vec, AbstractHypervector):\n        vec = vec.vec\n\n    # Compute similarities\n    if jnp.iscomplexobj(self._codebook_vecs):\n        similarities = jnp.abs(jnp.dot(self._codebook_vecs.conj(), vec))\n    else:\n        similarities = jnp.dot(self._codebook_vecs, vec)\n\n    # Get top-k indices\n    top_k_indices = jnp.argsort(similarities)[-k:][::-1]\n\n    # Build result list\n    results = [\n        (self.codebook[int(idx)], float(similarities[idx]))\n        for idx in top_k_indices\n    ]\n\n    return results\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.CleanupMemory.__len__","title":"<code>__len__()</code>","text":"<p>Return number of vectors in codebook.</p> Source code in <code>vsax/resonator/cleanup.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return number of vectors in codebook.\"\"\"\n    return len(self.codebook)\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.CleanupMemory.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation.</p> Source code in <code>vsax/resonator/cleanup.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return string representation.\"\"\"\n    return f\"CleanupMemory(codebook_size={len(self.codebook)}, threshold={self.threshold})\"\n</code></pre>"},{"location":"api/resonator/#example","title":"Example","text":"<pre><code>from vsax import create_binary_model, VSAMemory\nfrom vsax.resonator import CleanupMemory\n\nmodel = create_binary_model(dim=10000, bipolar=True)\nmemory = VSAMemory(model)\nmemory.add_many([\"red\", \"blue\", \"green\"])\n\n# Create cleanup memory\ncleanup = CleanupMemory([\"red\", \"blue\", \"green\"], memory)\n\n# Query with noisy vector\nresult = cleanup.query(noisy_vector)\nprint(result)  # \"red\"\n\n# Get top-k matches\ntop_3 = cleanup.query_top_k(noisy_vector, k=3)\nfor symbol, similarity in top_3:\n    print(f\"{symbol}: {similarity:.3f}\")\n</code></pre>"},{"location":"api/resonator/#resonator","title":"Resonator","text":""},{"location":"api/resonator/#vsax.resonator.Resonator","title":"<code>vsax.resonator.Resonator</code>","text":"<p>Resonator network for factorizing composite VSA vectors.</p> <p>Given a composite vector s = a \u2299 b \u2299 c, this class implements an iterative algorithm to find the factors a, b, c from known codebooks.</p> <p>The algorithm alternates between: 1. Unbinding current estimates of other factors from s 2. Cleaning up the result using codebook projection</p> <p>Parameters:</p> Name Type Description Default <code>codebooks</code> <code>list[CleanupMemory]</code> <p>List of CleanupMemory objects, one per factor position.</p> required <code>opset</code> <code>AbstractOpSet</code> <p>Operation set defining bind/unbind operations.</p> required <code>max_iterations</code> <code>int</code> <p>Maximum number of iterations (default: 100).</p> <code>100</code> <code>convergence_threshold</code> <code>int</code> <p>Stop if estimates don't change (default: 3).</p> <code>3</code> Example <p>model = create_binary_model(dim=10000) memory = VSAMemory(model) memory.add_many([\"red\", \"blue\", \"circle\", \"square\"])</p> Source code in <code>vsax/resonator/resonator.py</code> <pre><code>class Resonator:\n    \"\"\"Resonator network for factorizing composite VSA vectors.\n\n    Given a composite vector s = a \u2299 b \u2299 c, this class implements an\n    iterative algorithm to find the factors a, b, c from known codebooks.\n\n    The algorithm alternates between:\n    1. Unbinding current estimates of other factors from s\n    2. Cleaning up the result using codebook projection\n\n    Args:\n        codebooks: List of CleanupMemory objects, one per factor position.\n        opset: Operation set defining bind/unbind operations.\n        max_iterations: Maximum number of iterations (default: 100).\n        convergence_threshold: Stop if estimates don't change (default: 3).\n\n    Example:\n        &gt;&gt;&gt; model = create_binary_model(dim=10000)\n        &gt;&gt;&gt; memory = VSAMemory(model)\n        &gt;&gt;&gt; memory.add_many([\"red\", \"blue\", \"circle\", \"square\"])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create codebooks for two factor positions\n        &gt;&gt;&gt; colors = CleanupMemory([\"red\", \"blue\"], memory)\n        &gt;&gt;&gt; shapes = CleanupMemory([\"circle\", \"square\"], memory)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create composite: red \u2299 circle\n        &gt;&gt;&gt; composite = model.opset.bind(\n        ...     memory[\"red\"].vec,\n        ...     memory[\"circle\"].vec\n        ... )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Factorize\n        &gt;&gt;&gt; resonator = Resonator([colors, shapes], model.opset)\n        &gt;&gt;&gt; factors = resonator.factorize(composite)\n        &gt;&gt;&gt; print(factors)  # [\"red\", \"circle\"]\n    \"\"\"\n\n    def __init__(\n        self,\n        codebooks: list[CleanupMemory],\n        opset: AbstractOpSet,\n        max_iterations: int = 100,\n        convergence_threshold: int = 3,\n    ) -&gt; None:\n        \"\"\"Initialize resonator network.\"\"\"\n        if len(codebooks) &lt; 2:\n            raise ValueError(\"Need at least 2 codebooks for factorization\")\n\n        self.codebooks = codebooks\n        self.opset = opset\n        self.max_iterations = max_iterations\n        self.convergence_threshold = convergence_threshold\n        self.num_factors = len(codebooks)\n\n    def factorize(\n        self,\n        composite: Union[jnp.ndarray, AbstractHypervector],\n        initial_estimates: Optional[list[str]] = None,\n        return_history: bool = False,\n    ) -&gt; Union[list[Optional[str]], tuple[list[Optional[str]], list[list[Optional[str]]]]]:\n        \"\"\"Factorize a composite vector into its constituent factors.\n\n        Args:\n            composite: Composite vector to factorize.\n            initial_estimates: Optional initial guesses for factors.\n                              If None, uses superposition of all codebook vectors.\n            return_history: If True, return iteration history.\n\n        Returns:\n            If return_history=False: List of factor names (or None if not converged).\n            If return_history=True: Tuple of (factors, history) where history is\n                                    a list of factor estimates at each iteration.\n\n        Example:\n            &gt;&gt;&gt; factors = resonator.factorize(composite)\n            &gt;&gt;&gt; factors, history = resonator.factorize(composite, return_history=True)\n        \"\"\"\n        # Coerce to array if hypervector\n        if isinstance(composite, AbstractHypervector):\n            composite = composite.vec\n\n        # Initialize estimates\n        estimates = self._initialize_estimates(initial_estimates)\n        history: list[list[Optional[str]]] = [estimates.copy()] if return_history else []\n\n        # Track convergence\n        stable_count = 0\n        prev_estimates = estimates.copy()\n\n        # Iterative resonance\n        for iteration in range(self.max_iterations):\n            # Update each factor estimate\n            for i in range(self.num_factors):\n                estimates[i] = self._update_factor(\n                    composite, estimates, i\n                )\n\n            # Track history\n            if return_history:\n                history.append(estimates.copy())\n\n            # Check convergence\n            if estimates == prev_estimates:\n                stable_count += 1\n                if stable_count &gt;= self.convergence_threshold:\n                    break\n            else:\n                stable_count = 0\n                prev_estimates = estimates.copy()\n\n        # Return results\n        if return_history:\n            return estimates, history\n        return estimates\n\n    def _initialize_estimates(\n        self,\n        initial_estimates: Optional[list[str]] = None,\n    ) -&gt; list[Optional[str]]:\n        \"\"\"Initialize factor estimates.\n\n        If initial_estimates provided, validate and use them.\n        Otherwise, use None (superposition initialization happens in update).\n        \"\"\"\n        if initial_estimates is not None:\n            if len(initial_estimates) != self.num_factors:\n                raise ValueError(\n                    f\"Expected {self.num_factors} initial estimates, \"\n                    f\"got {len(initial_estimates)}\"\n                )\n            # Validate estimates exist in codebooks\n            for i, est in enumerate(initial_estimates):\n                if est not in self.codebooks[i].codebook:\n                    raise ValueError(\n                        f\"Initial estimate '{est}' not in codebook {i}\"\n                    )\n            # Cast to list[Optional[str]] for type compatibility\n            return cast(list[Optional[str]], initial_estimates.copy())\n\n        # Start with None (will use superposition in first iteration)\n        return [None] * self.num_factors\n\n    def _update_factor(\n        self,\n        composite: jnp.ndarray,\n        current_estimates: list[Optional[str]],\n        factor_idx: int,\n    ) -&gt; Optional[str]:\n        \"\"\"Update estimate for a single factor.\n\n        Implements: x\u0302(t+1) = g(XX^T(s \u2299 \u0177(t) \u2299 \u1e91(t)))\n\n        Args:\n            composite: The composite vector s.\n            current_estimates: Current estimates for all factors.\n            factor_idx: Which factor to update.\n\n        Returns:\n            Updated factor name or None.\n        \"\"\"\n        # Start with composite vector\n        residual = composite\n\n        # Unbind all OTHER factors from composite\n        # s \u2299 inverse(\u0177) \u2299 inverse(\u1e91) should leave x\u0302\n        for i, estimate_name in enumerate(current_estimates):\n            if i == factor_idx:\n                continue\n\n            if estimate_name is None:\n                # No estimate yet - use superposition of all vectors in codebook\n                # This is the initialization from the paper\n                codebook_vecs = self.codebooks[i]._codebook_vecs\n                superposition = jnp.sum(codebook_vecs, axis=0)\n                residual = self.opset.bind(residual, self.opset.inverse(superposition))\n            else:\n                # Use the current estimate\n                factor_vec = self.codebooks[i].memory[estimate_name].vec\n                residual = self.opset.bind(residual, self.opset.inverse(factor_vec))\n\n        # Cleanup: project residual onto codebook for this factor\n        # This is g(XX^T(...)) from the paper\n        # query with return_similarity=False returns Optional[str]\n        result: Optional[str] = self.codebooks[factor_idx].query(residual)  # type: ignore[assignment]\n\n        return result\n\n    def factorize_batch(\n        self,\n        composites: jnp.ndarray,\n        initial_estimates: Optional[list[list[str]]] = None,\n    ) -&gt; list[list[Optional[str]]]:\n        \"\"\"Factorize multiple composite vectors.\n\n        Args:\n            composites: Array of composite vectors, shape (batch_size, dim).\n            initial_estimates: Optional initial guesses for each composite.\n\n        Returns:\n            List of factor lists, one per composite.\n\n        Example:\n            &gt;&gt;&gt; composites = jnp.stack([comp1, comp2, comp3])\n            &gt;&gt;&gt; all_factors = resonator.factorize_batch(composites)\n        \"\"\"\n        batch_size = composites.shape[0]\n        results: list[list[Optional[str]]] = []\n\n        for i in range(batch_size):\n            init = initial_estimates[i] if initial_estimates else None\n            # factorize returns list[Optional[str]] when return_history=False (default)\n            factors = self.factorize(composites[i], initial_estimates=init, return_history=False)\n            # Type narrowing: we know it's just the list, not the tuple\n            assert isinstance(factors, list), \"Expected list without history\"\n            results.append(factors)\n\n        return results\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return string representation.\"\"\"\n        return (\n            f\"Resonator(num_factors={self.num_factors}, \"\n            f\"max_iterations={self.max_iterations}, \"\n            f\"convergence_threshold={self.convergence_threshold})\"\n        )\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.Resonator--create-codebooks-for-two-factor-positions","title":"Create codebooks for two factor positions","text":"<p>colors = CleanupMemory([\"red\", \"blue\"], memory) shapes = CleanupMemory([\"circle\", \"square\"], memory)</p>"},{"location":"api/resonator/#vsax.resonator.Resonator--create-composite-red-circle","title":"Create composite: red \u2299 circle","text":"<p>composite = model.opset.bind( ...     memory[\"red\"].vec, ...     memory[\"circle\"].vec ... )</p>"},{"location":"api/resonator/#vsax.resonator.Resonator--factorize","title":"Factorize","text":"<p>resonator = Resonator([colors, shapes], model.opset) factors = resonator.factorize(composite) print(factors)  # [\"red\", \"circle\"]</p>"},{"location":"api/resonator/#vsax.resonator.Resonator-functions","title":"Functions","text":""},{"location":"api/resonator/#vsax.resonator.Resonator.__init__","title":"<code>__init__(codebooks, opset, max_iterations=100, convergence_threshold=3)</code>","text":"<p>Initialize resonator network.</p> Source code in <code>vsax/resonator/resonator.py</code> <pre><code>def __init__(\n    self,\n    codebooks: list[CleanupMemory],\n    opset: AbstractOpSet,\n    max_iterations: int = 100,\n    convergence_threshold: int = 3,\n) -&gt; None:\n    \"\"\"Initialize resonator network.\"\"\"\n    if len(codebooks) &lt; 2:\n        raise ValueError(\"Need at least 2 codebooks for factorization\")\n\n    self.codebooks = codebooks\n    self.opset = opset\n    self.max_iterations = max_iterations\n    self.convergence_threshold = convergence_threshold\n    self.num_factors = len(codebooks)\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.Resonator.factorize","title":"<code>factorize(composite, initial_estimates=None, return_history=False)</code>","text":"<p>Factorize a composite vector into its constituent factors.</p> <p>Parameters:</p> Name Type Description Default <code>composite</code> <code>Union[ndarray, AbstractHypervector]</code> <p>Composite vector to factorize.</p> required <code>initial_estimates</code> <code>Optional[list[str]]</code> <p>Optional initial guesses for factors.               If None, uses superposition of all codebook vectors.</p> <code>None</code> <code>return_history</code> <code>bool</code> <p>If True, return iteration history.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[list[Optional[str]], tuple[list[Optional[str]], list[list[Optional[str]]]]]</code> <p>If return_history=False: List of factor names (or None if not converged).</p> <code>Union[list[Optional[str]], tuple[list[Optional[str]], list[list[Optional[str]]]]]</code> <p>If return_history=True: Tuple of (factors, history) where history is                     a list of factor estimates at each iteration.</p> Example <p>factors = resonator.factorize(composite) factors, history = resonator.factorize(composite, return_history=True)</p> Source code in <code>vsax/resonator/resonator.py</code> <pre><code>def factorize(\n    self,\n    composite: Union[jnp.ndarray, AbstractHypervector],\n    initial_estimates: Optional[list[str]] = None,\n    return_history: bool = False,\n) -&gt; Union[list[Optional[str]], tuple[list[Optional[str]], list[list[Optional[str]]]]]:\n    \"\"\"Factorize a composite vector into its constituent factors.\n\n    Args:\n        composite: Composite vector to factorize.\n        initial_estimates: Optional initial guesses for factors.\n                          If None, uses superposition of all codebook vectors.\n        return_history: If True, return iteration history.\n\n    Returns:\n        If return_history=False: List of factor names (or None if not converged).\n        If return_history=True: Tuple of (factors, history) where history is\n                                a list of factor estimates at each iteration.\n\n    Example:\n        &gt;&gt;&gt; factors = resonator.factorize(composite)\n        &gt;&gt;&gt; factors, history = resonator.factorize(composite, return_history=True)\n    \"\"\"\n    # Coerce to array if hypervector\n    if isinstance(composite, AbstractHypervector):\n        composite = composite.vec\n\n    # Initialize estimates\n    estimates = self._initialize_estimates(initial_estimates)\n    history: list[list[Optional[str]]] = [estimates.copy()] if return_history else []\n\n    # Track convergence\n    stable_count = 0\n    prev_estimates = estimates.copy()\n\n    # Iterative resonance\n    for iteration in range(self.max_iterations):\n        # Update each factor estimate\n        for i in range(self.num_factors):\n            estimates[i] = self._update_factor(\n                composite, estimates, i\n            )\n\n        # Track history\n        if return_history:\n            history.append(estimates.copy())\n\n        # Check convergence\n        if estimates == prev_estimates:\n            stable_count += 1\n            if stable_count &gt;= self.convergence_threshold:\n                break\n        else:\n            stable_count = 0\n            prev_estimates = estimates.copy()\n\n    # Return results\n    if return_history:\n        return estimates, history\n    return estimates\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.Resonator.factorize_batch","title":"<code>factorize_batch(composites, initial_estimates=None)</code>","text":"<p>Factorize multiple composite vectors.</p> <p>Parameters:</p> Name Type Description Default <code>composites</code> <code>ndarray</code> <p>Array of composite vectors, shape (batch_size, dim).</p> required <code>initial_estimates</code> <code>Optional[list[list[str]]]</code> <p>Optional initial guesses for each composite.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[list[Optional[str]]]</code> <p>List of factor lists, one per composite.</p> Example <p>composites = jnp.stack([comp1, comp2, comp3]) all_factors = resonator.factorize_batch(composites)</p> Source code in <code>vsax/resonator/resonator.py</code> <pre><code>def factorize_batch(\n    self,\n    composites: jnp.ndarray,\n    initial_estimates: Optional[list[list[str]]] = None,\n) -&gt; list[list[Optional[str]]]:\n    \"\"\"Factorize multiple composite vectors.\n\n    Args:\n        composites: Array of composite vectors, shape (batch_size, dim).\n        initial_estimates: Optional initial guesses for each composite.\n\n    Returns:\n        List of factor lists, one per composite.\n\n    Example:\n        &gt;&gt;&gt; composites = jnp.stack([comp1, comp2, comp3])\n        &gt;&gt;&gt; all_factors = resonator.factorize_batch(composites)\n    \"\"\"\n    batch_size = composites.shape[0]\n    results: list[list[Optional[str]]] = []\n\n    for i in range(batch_size):\n        init = initial_estimates[i] if initial_estimates else None\n        # factorize returns list[Optional[str]] when return_history=False (default)\n        factors = self.factorize(composites[i], initial_estimates=init, return_history=False)\n        # Type narrowing: we know it's just the list, not the tuple\n        assert isinstance(factors, list), \"Expected list without history\"\n        results.append(factors)\n\n    return results\n</code></pre>"},{"location":"api/resonator/#vsax.resonator.Resonator.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation.</p> Source code in <code>vsax/resonator/resonator.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return string representation.\"\"\"\n    return (\n        f\"Resonator(num_factors={self.num_factors}, \"\n        f\"max_iterations={self.max_iterations}, \"\n        f\"convergence_threshold={self.convergence_threshold})\"\n    )\n</code></pre>"},{"location":"api/resonator/#example_1","title":"Example","text":"<pre><code>from vsax import create_binary_model, VSAMemory\nfrom vsax.resonator import CleanupMemory, Resonator\n\n# Setup\nmodel = create_binary_model(dim=10000, bipolar=True)\nmemory = VSAMemory(model)\nmemory.add_many([\"red\", \"blue\", \"circle\", \"square\"])\n\n# Create composite\ncomposite = model.opset.bind(\n    memory[\"red\"].vec,\n    memory[\"circle\"].vec\n)\n\n# Create codebooks\ncolors = CleanupMemory([\"red\", \"blue\"], memory)\nshapes = CleanupMemory([\"circle\", \"square\"], memory)\n\n# Factorize\nresonator = Resonator([colors, shapes], model.opset)\nfactors = resonator.factorize(composite)\n\nprint(factors)  # [\"red\", \"circle\"]\n</code></pre>"},{"location":"api/resonator/#algorithm-details","title":"Algorithm Details","text":""},{"location":"api/resonator/#resonance-equations","title":"Resonance Equations","text":"<p>For a composite <code>s = a \u2299 b \u2299 c</code>, the update equations are:</p> <pre><code>x\u0302(t+1) = g(XX^T(s \u2299 \u0177(t) \u2299 \u1e91(t)))\n\u0177(t+1) = g(YY^T(s \u2299 x\u0302(t) \u2299 \u1e91(t)))\n\u1e91(t+1) = g(ZZ^T(s \u2299 x\u0302(t) \u2299 \u0177(t)))\n</code></pre> <p>Where: - <code>x\u0302, \u0177, \u1e91</code> are factor estimates - <code>X, Y, Z</code> are codebook matrices - <code>g(XX^T\u00b7)</code> is the cleanup operation (codebook projection) - <code>\u2299</code> is the binding operation</p>"},{"location":"api/resonator/#cleanup-operation","title":"Cleanup Operation","text":"<p>The cleanup operation <code>g(XX^T v)</code> projects vector <code>v</code> onto the nearest vector in codebook <code>X</code>.</p> <p>For binary/bipolar vectors: <pre><code>similarities = codebook_matrix @ v\nbest_idx = argmax(similarities)\nresult = codebook[best_idx]\n</code></pre></p> <p>For complex/real vectors: <pre><code>similarities = [cosine_similarity(v, c) for c in codebook]\nbest_idx = argmax(similarities)\nresult = codebook[best_idx]\n</code></pre></p>"},{"location":"api/resonator/#initialization","title":"Initialization","text":"<p>On the first iteration (no prior estimates), the algorithm uses superposition initialization:</p> <pre><code>initial_estimate = sum(all_vectors_in_codebook)\n</code></pre> <p>This provides information about all possible factors simultaneously.</p>"},{"location":"api/resonator/#convergence","title":"Convergence","text":"<p>The algorithm stops when:</p> <ol> <li>Stable convergence: Estimates unchanged for <code>convergence_threshold</code> iterations (default: 3)</li> <li>Max iterations: Reached <code>max_iterations</code> (default: 100)</li> </ol> <p>Binary VSA typically converges in &lt; 10 iterations due to exact unbinding.</p>"},{"location":"api/resonator/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"api/resonator/#time-complexity","title":"Time Complexity","text":"<p>Per iteration for N factors with codebook size M and dimension D: - Unbinding: O(N \u00d7 D) - binding operations - Cleanup: O(M \u00d7 D) - dot products with codebook - Total: O(N \u00d7 M \u00d7 D) per iteration</p> <p>Typical iterations to convergence: 5-20</p>"},{"location":"api/resonator/#space-complexity","title":"Space Complexity","text":"<ul> <li>Codebooks: O(M \u00d7 D) per codebook</li> <li>Estimates: O(N \u00d7 D)</li> <li>Total: O((N + M) \u00d7 D)</li> </ul>"},{"location":"api/resonator/#recommendations","title":"Recommendations","text":"<p>Dimensionality: - Binary VSA: \u226510,000 dimensions - FHRR: \u2265512 dimensions - MAP: \u2265512 dimensions</p> <p>Codebook Size: - Works well with codebooks of 2-100 items - Larger codebooks may require more iterations</p> <p>Number of Factors: - Tested with 2-3 factors - Can handle more but convergence may slow</p>"},{"location":"api/resonator/#common-patterns","title":"Common Patterns","text":""},{"location":"api/resonator/#two-factor-factorization","title":"Two-Factor Factorization","text":"<pre><code># Encode\ncomposite = bind(a, b)\n\n# Setup codebooks\ncodebook_a = CleanupMemory([\"a1\", \"a2\", \"a3\"], memory)\ncodebook_b = CleanupMemory([\"b1\", \"b2\", \"b3\"], memory)\n\n# Factorize\nresonator = Resonator([codebook_a, codebook_b], opset)\nfactors = resonator.factorize(composite)\n</code></pre>"},{"location":"api/resonator/#three-factor-factorization","title":"Three-Factor Factorization","text":"<pre><code># Encode\ncomposite = bind(bind(a, b), c)\n\n# Setup\ncodebook_a = CleanupMemory([...], memory)\ncodebook_b = CleanupMemory([...], memory)\ncodebook_c = CleanupMemory([...], memory)\n\n# Factorize\nresonator = Resonator([codebook_a, codebook_b, codebook_c], opset)\nfactors = resonator.factorize(composite)\n</code></pre>"},{"location":"api/resonator/#batch-processing","title":"Batch Processing","text":"<pre><code>import jax.numpy as jnp\n\n# Create multiple composites\ncomposites = jnp.stack([comp1, comp2, comp3, comp4])\n\n# Batch factorize\nresults = resonator.factorize_batch(composites)\n# results[i] contains factors for composites[i]\n</code></pre>"},{"location":"api/resonator/#monitoring-convergence","title":"Monitoring Convergence","text":"<pre><code>factors, history = resonator.factorize(\n    composite,\n    return_history=True\n)\n\nprint(f\"Converged in {len(history)} iterations\")\nfor i, step in enumerate(history):\n    print(f\"Iteration {i}: {step}\")\n</code></pre>"},{"location":"api/resonator/#error-handling","title":"Error Handling","text":""},{"location":"api/resonator/#invalid-codebook","title":"Invalid Codebook","text":"<pre><code># Raises ValueError if symbol not in memory\ncleanup = CleanupMemory([\"missing_symbol\"], memory)\n# ValueError: Symbol 'missing_symbol' not found in memory\n</code></pre>"},{"location":"api/resonator/#wrong-number-of-estimates","title":"Wrong Number of Estimates","text":"<pre><code># Raises ValueError if initial estimates don't match codebook count\nresonator = Resonator([codebook1, codebook2], opset)\nfactors = resonator.factorize(composite, initial_estimates=[\"a\"])\n# ValueError: Expected 2 initial estimates, got 1\n</code></pre>"},{"location":"api/resonator/#invalid-initial-estimate","title":"Invalid Initial Estimate","text":"<pre><code># Raises ValueError if estimate not in corresponding codebook\nfactors = resonator.factorize(\n    composite,\n    initial_estimates=[\"valid\", \"not_in_codebook\"]\n)\n# ValueError: Initial estimate 'not_in_codebook' not in codebook 1\n</code></pre>"},{"location":"api/resonator/#see-also","title":"See Also","text":"<ul> <li>User Guide: Resonator Networks</li> <li>Example: Tree Search</li> <li>Paper: Frady et al. (2020)</li> </ul>"},{"location":"api/similarity/","title":"Similarity Metrics API","text":"<p>Similarity metrics for comparing hypervectors.</p>"},{"location":"api/similarity/#functions","title":"Functions","text":""},{"location":"api/similarity/#vsax.similarity.cosine_similarity","title":"<code>vsax.similarity.cosine_similarity(a, b)</code>","text":"<p>Compute cosine similarity between two hypervectors.</p> <p>Cosine similarity measures the cosine of the angle between two vectors, ranging from -1 (opposite) to 1 (identical direction). For complex vectors, uses the real part of the complex dot product.</p> <p>Works with all hypervector types: - Complex hypervectors (FHRR): Uses conjugate dot product - Real hypervectors (MAP): Standard cosine similarity - Binary hypervectors: Normalized dot product</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[AbstractHypervector, ndarray]</code> <p>First hypervector (AbstractHypervector or jnp.ndarray).</p> required <code>b</code> <code>Union[AbstractHypervector, ndarray]</code> <p>Second hypervector (AbstractHypervector or jnp.ndarray).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Cosine similarity as a float in range [-1, 1].</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If vectors have different shapes.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.similarity import cosine_similarity model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"dog\", \"cat\", \"animal\"]) similarity = cosine_similarity(memory[\"dog\"], memory[\"cat\"]) print(f\"Similarity: {similarity:.3f}\")</p>"},{"location":"api/similarity/#vsax.similarity.dot_similarity","title":"<code>vsax.similarity.dot_similarity(a, b)</code>","text":"<p>Compute dot product similarity between two hypervectors.</p> <p>The dot product provides an unnormalized similarity measure. Higher values indicate more similarity. For complex vectors, uses the real part of the complex dot product (conjugate dot product).</p> <p>Works with all hypervector types: - Complex hypervectors (FHRR): Real part of a* \u00b7 b - Real hypervectors (MAP): Standard dot product a \u00b7 b - Binary hypervectors: Dot product (count of matching bits)</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[AbstractHypervector, ndarray]</code> <p>First hypervector (AbstractHypervector or jnp.ndarray).</p> required <code>b</code> <code>Union[AbstractHypervector, ndarray]</code> <p>Second hypervector (AbstractHypervector or jnp.ndarray).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Dot product similarity as a float.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If vectors have different shapes.</p> Example <p>from vsax import create_map_model, VSAMemory from vsax.similarity import dot_similarity model = create_map_model(dim=512) memory = VSAMemory(model) memory.add_many([\"apple\", \"orange\", \"fruit\"]) similarity = dot_similarity(memory[\"apple\"], memory[\"orange\"]) print(f\"Dot product: {similarity:.3f}\")</p>"},{"location":"api/similarity/#vsax.similarity.hamming_similarity","title":"<code>vsax.similarity.hamming_similarity(a, b)</code>","text":"<p>Compute Hamming similarity between two binary hypervectors.</p> <p>Hamming similarity measures the proportion of matching bits between two binary vectors. It ranges from 0 (completely different) to 1 (identical).</p> <p>Primarily designed for binary hypervectors but works with any vector type by comparing element equality. For best results, use with bipolar {-1, +1} or binary {0, 1} vectors.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Union[AbstractHypervector, ndarray]</code> <p>First hypervector (AbstractHypervector or jnp.ndarray).</p> required <code>b</code> <code>Union[AbstractHypervector, ndarray]</code> <p>Second hypervector (AbstractHypervector or jnp.ndarray).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Hamming similarity as a float in range [0, 1].</p> <code>float</code> <p>1.0 means all bits match, 0.0 means no bits match.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If vectors have different shapes.</p> Example <p>from vsax import create_binary_model, VSAMemory from vsax.similarity import hamming_similarity model = create_binary_model(dim=10000, bipolar=True) memory = VSAMemory(model) memory.add_many([\"cat\", \"dog\", \"bird\"]) similarity = hamming_similarity(memory[\"cat\"], memory[\"dog\"]) print(f\"Hamming similarity: {similarity:.3f}\")</p>"},{"location":"api/utils/","title":"Utilities API","text":"<p>Utility functions for batch operations and visualization.</p>"},{"location":"api/utils/#batch-operations","title":"Batch Operations","text":""},{"location":"api/utils/#vsax.utils.vmap_bind","title":"<code>vsax.utils.vmap_bind(opset, X, Y)</code>","text":"<p>Vectorized binding of two batches of hypervectors.</p> <p>Applies the bind operation element-wise across two batches of hypervectors using JAX's vmap for efficient parallel execution on GPU/TPU.</p> <p>Parameters:</p> Name Type Description Default <code>opset</code> <code>AbstractOpSet</code> <p>The operation set defining the bind operation.</p> required <code>X</code> <code>Union[ndarray, list[ndarray]]</code> <p>First batch of hypervectors, shape (batch_size, dim).</p> required <code>Y</code> <code>Union[ndarray, list[ndarray]]</code> <p>Second batch of hypervectors, shape (batch_size, dim).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Batch of bound hypervectors, shape (batch_size, dim).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If batch sizes don't match.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.utils import vmap_bind import jax.numpy as jnp model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"a\", \"b\", \"c\", \"x\", \"y\", \"z\"])</p>"},{"location":"api/utils/#vsax.utils.vmap_bind--batch-bind-a-b-c-with-x-y-z","title":"Batch bind: [a, b, c] with [x, y, z]","text":"<p>X = jnp.stack([memory[\"a\"].vec, memory[\"b\"].vec, memory[\"c\"].vec]) Y = jnp.stack([memory[\"x\"].vec, memory[\"y\"].vec, memory[\"z\"].vec]) result = vmap_bind(model.opset, X, Y) print(result.shape)  # (3, 512)</p>"},{"location":"api/utils/#vsax.utils.vmap_bundle","title":"<code>vsax.utils.vmap_bundle(opset, X)</code>","text":"<p>Vectorized bundling across batch dimension.</p> <p>Bundles a batch of hypervectors into a single hypervector using JAX's efficient reduction operations. This is NOT element-wise - it combines all vectors in the batch into one result.</p> <p>Parameters:</p> Name Type Description Default <code>opset</code> <code>AbstractOpSet</code> <p>The operation set defining the bundle operation.</p> required <code>X</code> <code>Union[ndarray, list[ndarray]]</code> <p>Batch of hypervectors, shape (batch_size, dim).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Single bundled hypervector, shape (dim,).</p> Example <p>from vsax import create_map_model, VSAMemory from vsax.utils import vmap_bundle import jax.numpy as jnp model = create_map_model(dim=512) memory = VSAMemory(model) memory.add_many([\"red\", \"green\", \"blue\"])</p>"},{"location":"api/utils/#vsax.utils.vmap_bundle--bundle-colors-together","title":"Bundle colors together","text":"<p>colors = jnp.stack([ ...     memory[\"red\"].vec, ...     memory[\"green\"].vec, ...     memory[\"blue\"].vec ... ]) color_set = vmap_bundle(model.opset, colors) print(color_set.shape)  # (512,)</p>"},{"location":"api/utils/#vsax.utils.vmap_similarity","title":"<code>vsax.utils.vmap_similarity(similarity_fn, query, candidates)</code>","text":"<p>Vectorized similarity computation between query and multiple candidates.</p> <p>Computes similarity between a single query vector and a batch of candidate vectors using JAX's vmap for efficient parallel execution.</p> <p>Note: This function computes raw similarity scores without converting to Python floats, allowing it to work within JAX transformations.</p> <p>Parameters:</p> Name Type Description Default <code>similarity_fn</code> <code>None</code> <p>Similarity function that operates on arrays. Must accept two jnp.ndarray arguments and return a scalar.</p> required <code>query</code> <code>Union[ndarray, list[ndarray]]</code> <p>Single query hypervector, shape (dim,).</p> required <code>candidates</code> <code>Union[ndarray, list[ndarray]]</code> <p>Batch of candidate hypervectors, shape (batch_size, dim).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of similarity scores, shape (batch_size,).</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.utils import vmap_similarity import jax.numpy as jnp model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add_many([\"dog\", \"cat\", \"bird\", \"animal\"])</p>"},{"location":"api/utils/#vsax.utils.vmap_similarity--define-similarity-function-that-works-on-arrays","title":"Define similarity function that works on arrays","text":"<p>def array_cosine(a, b): ...     dot = jnp.vdot(a, b) if jnp.iscomplexobj(a) else jnp.dot(a, b) ...     if jnp.iscomplexobj(a): dot = jnp.real(dot) ...     return dot / (jnp.linalg.norm(a) * jnp.linalg.norm(b) + 1e-10)</p>"},{"location":"api/utils/#vsax.utils.vmap_similarity--find-most-similar-to-animal","title":"Find most similar to \"animal\"","text":"<p>query = memory[\"animal\"].vec candidates = jnp.stack([ ...     memory[\"dog\"].vec, ...     memory[\"cat\"].vec, ...     memory[\"bird\"].vec ... ]) similarities = vmap_similarity(array_cosine, query, candidates) best_match = jnp.argmax(similarities)</p>"},{"location":"api/utils/#visualization","title":"Visualization","text":""},{"location":"api/utils/#vsax.utils.pretty_repr","title":"<code>vsax.utils.pretty_repr(hv, max_elements=5)</code>","text":"<p>Generate a pretty string representation of a hypervector.</p> <p>Creates a human-readable representation showing shape, dtype, and a sample of the vector values. Useful for debugging and interactive exploration.</p> <p>Parameters:</p> Name Type Description Default <code>hv</code> <code>Union[AbstractHypervector, ndarray]</code> <p>Hypervector to represent (AbstractHypervector or jnp.ndarray).</p> required <code>max_elements</code> <code>int</code> <p>Maximum number of elements to display (default: 5).</p> <code>5</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted string representation.</p> Example <p>from vsax import create_fhrr_model, VSAMemory from vsax.utils import pretty_repr model = create_fhrr_model(dim=512) memory = VSAMemory(model) memory.add(\"example\") print(pretty_repr(memory[\"example\"])) ComplexHypervector(dim=512, dtype=complex64) Sample: [0.123+0.456j, -0.789+0.234j, ..., 0.567-0.890j]</p>"},{"location":"api/utils/#vsax.utils.format_similarity_results","title":"<code>vsax.utils.format_similarity_results(query_name, candidate_names, similarities, top_k=5)</code>","text":"<p>Format similarity search results in a readable table.</p> <p>Parameters:</p> Name Type Description Default <code>query_name</code> <code>str</code> <p>Name of the query item.</p> required <code>candidate_names</code> <code>list[str]</code> <p>Names of candidate items.</p> required <code>similarities</code> <code>ndarray</code> <p>Array of similarity scores, shape (n_candidates,).</p> required <code>top_k</code> <code>int</code> <p>Number of top results to display (default: 5).</p> <code>5</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted table string.</p> Example <p>from vsax.utils import format_similarity_results import jax.numpy as jnp results = format_similarity_results( ...     \"dog\", ...     [\"cat\", \"wolf\", \"bird\", \"puppy\"], ...     jnp.array([0.85, 0.92, 0.23, 0.95]), ...     top_k=3 ... ) print(results) Query: dog Top 3 matches:   1. puppy    0.950   2. wolf     0.920   3. cat      0.850</p>"},{"location":"examples/binary/","title":"Binary Model Example","text":"<p>Complete example using Binary VSA with bipolar {-1, +1} hypervectors.</p>"},{"location":"examples/binary/#setup","title":"Setup","text":"<pre><code>import jax\nimport jax.numpy as jnp\nfrom vsax import VSAModel, BinaryHypervector, BinaryOperations, sample_binary_random\n\n# Create Binary model\nmodel = VSAModel(\n    dim=512,\n    rep_cls=BinaryHypervector,\n    opset=BinaryOperations(),\n    sampler=sample_binary_random\n)\n</code></pre>"},{"location":"examples/binary/#basic-operations","title":"Basic Operations","text":"<pre><code># Sample bipolar vectors\nkey = jax.random.PRNGKey(42)\nvectors = model.sampler(dim=model.dim, n=2, key=key, bipolar=True)\n\na = model.rep_cls(vectors[0], bipolar=True)\nb = model.rep_cls(vectors[1], bipolar=True)\n\n# Verify bipolar values\nprint(f\"Unique values: {jnp.unique(a.vec)}\")  # Array([-1, 1])\n\n# Bind (XOR)\nbound = model.opset.bind(a.vec, b.vec)\n\n# Unbind (exact recovery!)\nrecovered = model.opset.bind(bound, b.vec)\nprint(f\"Exact recovery: {jnp.array_equal(recovered, a.vec)}\")  # True!\n\n# Bundle (majority vote)\nbundled = model.opset.bundle(a.vec, b.vec)\n</code></pre>"},{"location":"examples/binary/#symbolic-reasoning-example","title":"Symbolic Reasoning Example","text":"<p>Encode logical facts using binary vectors.</p> <pre><code># Define symbols\nkeys = jax.random.split(key, 4)\nalice = model.sampler(dim=model.dim, n=1, key=keys[0], bipolar=True)[0]\nbob = model.sampler(dim=model.dim, n=1, key=keys[1], bipolar=True)[0]\nlikes = model.sampler(dim=model.dim, n=1, key=keys[2], bipolar=True)[0]\ncharlie = model.sampler(dim=model.dim, n=1, key=keys[3], bipolar=True)[0]\n\n# Encode: \"Alice likes Bob\"\nfact = model.opset.bind(model.opset.bind(alice, likes), bob)\n\n# Query: Who does Alice like?\nquery = model.opset.bind(fact, model.opset.bind(alice, likes))\n# High Hamming similarity to bob\n</code></pre> <p>Advantage: Binary VSA provides exact unbinding and is hardware-friendly!</p>"},{"location":"examples/fhrr/","title":"FHRR Model Example","text":"<p>Complete example using the FHRR (Fourier Holographic Reduced Representation) model with complex-valued hypervectors.</p>"},{"location":"examples/fhrr/#setup","title":"Setup","text":"<pre><code>import jax\nimport jax.numpy as jnp\nfrom vsax import VSAModel, ComplexHypervector, FHRROperations, sample_complex_random\n\n# Create FHRR model\nmodel = VSAModel(\n    dim=512,\n    rep_cls=ComplexHypervector,\n    opset=FHRROperations(),\n    sampler=sample_complex_random\n)\n</code></pre>"},{"location":"examples/fhrr/#basic-operations","title":"Basic Operations","text":""},{"location":"examples/fhrr/#sampling-and-normalization","title":"Sampling and Normalization","text":"<pre><code># Sample basis vectors\nkey = jax.random.PRNGKey(42)\nvectors = model.sampler(dim=model.dim, n=3, key=key)\n\n# Create and normalize hypervectors\na = model.rep_cls(vectors[0]).normalize()\nb = model.rep_cls(vectors[1]).normalize()\nc = model.rep_cls(vectors[2]).normalize()\n\n# Verify unit magnitude\nprint(f\"Magnitude of a: {jnp.allclose(jnp.abs(a.vec), 1.0)}\")  # True\n</code></pre>"},{"location":"examples/fhrr/#binding-circular-convolution","title":"Binding (Circular Convolution)","text":"<pre><code># Bind two vectors\nbound = model.opset.bind(a.vec, b.vec)\nbound_hv = model.rep_cls(bound).normalize()\n\nprint(f\"Bound vector shape: {bound_hv.shape}\")\nprint(f\"Is complex: {jnp.iscomplexobj(bound_hv.vec)}\")\n</code></pre>"},{"location":"examples/fhrr/#unbinding-exact-recovery","title":"Unbinding (Exact Recovery)","text":"<pre><code># Unbind to recover original\ninv_b = model.opset.inverse(b.vec)\nrecovered = model.opset.bind(bound_hv.vec, inv_b)\nrecovered_hv = model.rep_cls(recovered).normalize()\n\n# Check similarity (should be very high)\nsimilarity = jnp.abs(jnp.vdot(a.vec, recovered_hv.vec)) / model.dim\nprint(f\"Recovery similarity: {similarity:.4f}\")  # Close to 1.0\n</code></pre>"},{"location":"examples/fhrr/#bundling-superposition","title":"Bundling (Superposition)","text":"<pre><code># Bundle multiple vectors\nbundled = model.opset.bundle(a.vec, b.vec, c.vec)\nbundled_hv = model.rep_cls(bundled)\n\n# Result has unit magnitude\nprint(f\"Bundled magnitude: {jnp.allclose(jnp.abs(bundled_hv.vec), 1.0)}\")  # True\n</code></pre>"},{"location":"examples/fhrr/#role-filler-binding","title":"Role-Filler Binding","text":"<p>Encode structured data using role-filler binding.</p> <pre><code># Define roles and fillers\nkey = jax.random.PRNGKey(42)\nkeys = jax.random.split(key, 6)\n\n# Roles\nsubject_role = model.sampler(dim=model.dim, n=1, key=keys[0])[0]\nverb_role = model.sampler(dim=model.dim, n=1, key=keys[1])[0]\nobject_role = model.sampler(dim=model.dim, n=1, key=keys[2])[0]\n\n# Fillers (concepts)\ndog = model.sampler(dim=model.dim, n=1, key=keys[3])[0]\nchase = model.sampler(dim=model.dim, n=1, key=keys[4])[0]\ncat = model.sampler(dim=model.dim, n=1, key=keys[5])[0]\n\n# Encode sentence: \"The dog chased the cat\"\nsentence = model.opset.bundle(\n    model.opset.bind(subject_role, dog),\n    model.opset.bind(verb_role, chase),\n    model.opset.bind(object_role, cat)\n)\n\n# Query: What is the subject?\nquery = model.opset.bind(sentence, model.opset.inverse(subject_role))\nquery_hv = model.rep_cls(query).normalize()\ndog_hv = model.rep_cls(dog).normalize()\n\n# Similarity to \"dog\" should be high\nsimilarity = jnp.abs(jnp.vdot(query_hv.vec, dog_hv.vec)) / model.dim\nprint(f\"Subject query similarity to 'dog': {similarity:.4f}\")\n</code></pre>"},{"location":"examples/fhrr/#sequence-encoding","title":"Sequence Encoding","text":"<p>Use permutation for positional information.</p> <pre><code># Encode sequence: [A, B, C]\nsequence_keys = jax.random.split(key, 3)\nA = model.sampler(dim=model.dim, n=1, key=sequence_keys[0])[0]\nB = model.sampler(dim=model.dim, n=1, key=sequence_keys[1])[0]\nC = model.sampler(dim=model.dim, n=1, key=sequence_keys[2])[0]\n\n# Encode with positional information\nsequence = model.opset.bundle(\n    A,                              # Position 0\n    model.opset.permute(B, 1),      # Position 1\n    model.opset.permute(C, 2)       # Position 2\n)\n\n# Decode position 1\npos1_query = model.opset.permute(sequence, -1)\n# High similarity to B\n</code></pre>"},{"location":"examples/fhrr/#next-steps","title":"Next Steps","text":"<ul> <li>See MAP Example for real-valued operations</li> <li>See Binary Example for discrete operations</li> <li>Check API Reference for detailed documentation</li> </ul>"},{"location":"examples/map/","title":"MAP Model Example","text":"<p>Complete example using the MAP (Multiply-Add-Permute) model with real-valued hypervectors.</p>"},{"location":"examples/map/#setup","title":"Setup","text":"<pre><code>import jax\nimport jax.numpy as jnp\nfrom vsax import VSAModel, RealHypervector, MAPOperations, sample_random\n\n# Create MAP model\nmodel = VSAModel(\n    dim=512,\n    rep_cls=RealHypervector,\n    opset=MAPOperations(),\n    sampler=sample_random\n)\n</code></pre>"},{"location":"examples/map/#basic-operations","title":"Basic Operations","text":"<pre><code># Sample and normalize\nkey = jax.random.PRNGKey(42)\nvectors = model.sampler(dim=model.dim, n=2, key=key)\n\na = model.rep_cls(vectors[0]).normalize()\nb = model.rep_cls(vectors[1]).normalize()\n\n# Verify L2 normalization\nprint(f\"L2 norm of a: {jnp.linalg.norm(a.vec):.4f}\")  # 1.0\n\n# Bind (element-wise multiplication)\nbound = model.opset.bind(a.vec, b.vec)\n\n# Bundle (element-wise mean)\nbundled = model.opset.bundle(a.vec, b.vec)\n</code></pre>"},{"location":"examples/map/#feature-binding-example","title":"Feature Binding Example","text":"<p>Encode structured records with real-valued features.</p> <pre><code># Define feature roles\nage_role = model.sampler(dim=model.dim, n=1, key=jax.random.PRNGKey(1))[0]\nincome_role = model.sampler(dim=model.dim, n=1, key=jax.random.PRNGKey(2))[0]\n\n# Encode feature values (simplified - normally you'd use encoders)\nage_25 = model.sampler(dim=model.dim, n=1, key=jax.random.PRNGKey(3))[0]\nincome_50k = model.sampler(dim=model.dim, n=1, key=jax.random.PRNGKey(4))[0]\n\n# Create record\nrecord = model.opset.bundle(\n    model.opset.bind(age_role, age_25),\n    model.opset.bind(income_role, income_50k)\n)\n</code></pre> <p>Note: MAP unbinding is approximate - use for similarity-based retrieval rather than exact recovery.</p>"},{"location":"guide/batch_operations/","title":"Batch Operations","text":"<p>VSAX provides efficient batch operations using JAX's <code>vmap</code> for parallel processing on GPU/TPU. These operations allow you to process multiple hypervectors simultaneously.</p>"},{"location":"guide/batch_operations/#overview","title":"Overview","text":"<p>Batch operations are essential for: - Processing large datasets efficiently - Encoding multiple items at once - Parallel similarity computations - GPU/TPU acceleration</p>"},{"location":"guide/batch_operations/#core-batch-functions","title":"Core Batch Functions","text":""},{"location":"guide/batch_operations/#vmap_bind","title":"vmap_bind","text":"<p>Vectorized binding of two batches of hypervectors.</p> <pre><code>from vsax import create_fhrr_model, VSAMemory\nfrom vsax.utils import vmap_bind\nimport jax.numpy as jnp\n\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\n\n# Create nouns and verbs\nnouns = [\"dog\", \"cat\", \"bird\"]\nverbs = [\"runs\", \"jumps\", \"flies\"]\nmemory.add_many(nouns + verbs)\n\n# Batch bind nouns with verbs\nnoun_vecs = jnp.stack([memory[n].vec for n in nouns])\nverb_vecs = jnp.stack([memory[v].vec for v in verbs])\n\nactions = vmap_bind(model.opset, noun_vecs, verb_vecs)\nprint(f\"Created {actions.shape[0]} action vectors\")\n# Output: Created 3 action vectors\n</code></pre>"},{"location":"guide/batch_operations/#vmap_bundle","title":"vmap_bundle","text":"<p>Vectorized bundling of multiple hypervectors into one.</p> <pre><code>from vsax.utils import vmap_bundle\n\n# Bundle related concepts\ncolors = [\"red\", \"green\", \"blue\"]\nmemory.add_many(colors)\n\ncolor_vecs = jnp.stack([memory[c].vec for c in colors])\ncolor_concept = vmap_bundle(model.opset, color_vecs)\n\nprint(f\"Bundled concept shape: {color_concept.shape}\")\n# Output: Bundled concept shape: (512,)\n</code></pre>"},{"location":"guide/batch_operations/#vmap_similarity","title":"vmap_similarity","text":"<p>Vectorized similarity computation between a query and multiple candidates.</p> <pre><code>from vsax.utils import vmap_similarity\n\n# Find most similar color\nquery = memory[\"red\"].vec\ncandidates = jnp.stack([memory[c].vec for c in [\"green\", \"blue\", \"yellow\"]])\n\nsimilarities = vmap_similarity(None, query, candidates)\nbest_match = jnp.argmax(similarities)\nprint(f\"Most similar: {['green', 'blue', 'yellow'][int(best_match)]}\")\n</code></pre>"},{"location":"guide/batch_operations/#use-cases","title":"Use Cases","text":""},{"location":"guide/batch_operations/#1-sequential-composition","title":"1. Sequential Composition","text":"<p>Combine bind and bundle for structured encoding:</p> <pre><code># Encode multiple role-filler pairs\nroles = [\"subject\", \"verb\", \"object\"]\nfillers = [\"Alice\", \"helps\", \"Bob\"]\nmemory.add_many(roles + fillers)\n\n# Bind roles with fillers\nrole_vecs = jnp.stack([memory[r].vec for r in roles])\nfiller_vecs = jnp.stack([memory[f].vec for f in fillers])\npairs = vmap_bind(model.opset, role_vecs, filler_vecs)\n\n# Bundle into sentence\nsentence = vmap_bundle(model.opset, pairs)\nprint(f\"Sentence encoding: {sentence.shape}\")\n</code></pre>"},{"location":"guide/batch_operations/#2-batch-encoding","title":"2. Batch Encoding","text":"<p>Encode multiple items efficiently:</p> <pre><code># Encode many facts\nsubjects = [\"dog\", \"cat\", \"bird\", \"fish\"]\nactions = [\"runs\", \"sleeps\", \"flies\", \"swims\"]\nmemory.add_many(subjects + actions)\n\n# Batch encode all subject-action pairs\nsubj_vecs = jnp.stack([memory[s].vec for s in subjects])\nact_vecs = jnp.stack([memory[a].vec for a in actions])\n\nfacts = vmap_bind(model.opset, subj_vecs, act_vecs)\nprint(f\"Encoded {facts.shape[0]} facts in parallel\")\n</code></pre>"},{"location":"guide/batch_operations/#3-hierarchical-structures","title":"3. Hierarchical Structures","text":"<p>Build nested representations:</p> <pre><code># Create taxonomy\nmammals = [\"dog\", \"cat\", \"whale\"]\nbirds = [\"eagle\", \"sparrow\", \"penguin\"]\nreptiles = [\"snake\", \"lizard\"]\n\nall_animals = mammals + birds + reptiles\nmemory.add_many(all_animals)\n\n# Bundle each category\nmammal_vecs = jnp.stack([memory[m].vec for m in mammals])\nmammal_concept = vmap_bundle(model.opset, mammal_vecs)\n\nbird_vecs = jnp.stack([memory[b].vec for b in birds])\nbird_concept = vmap_bundle(model.opset, bird_vecs)\n\nreptile_vecs = jnp.stack([memory[r].vec for r in reptiles])\nreptile_concept = vmap_bundle(model.opset, reptile_vecs)\n\n# Bundle categories into higher-level concept\ncategories = jnp.stack([mammal_concept, bird_concept, reptile_concept])\nanimal_concept = vmap_bundle(model.opset, categories)\n\nprint(\"Created hierarchical animal concept\")\n</code></pre>"},{"location":"guide/batch_operations/#4-knowledge-graphs","title":"4. Knowledge Graphs","text":"<p>Encode graph structures with batch operations:</p> <pre><code># Knowledge graph: (subject, predicate, object) triples\nsubjects = [\"Alice\", \"Bob\", \"Charlie\"]\npredicates = [\"knows\", \"likes\", \"helps\"]\nobjects = [\"Bob\", \"Alice\", \"Alice\"]\n\n# Add to memory\nall_concepts = list(set(subjects + predicates + objects))\nmemory.add_many(all_concepts)\n\n# Batch encode triples\nsubj_vecs = jnp.stack([memory[s].vec for s in subjects])\npred_vecs = jnp.stack([memory[p].vec for p in predicates])\nobj_vecs = jnp.stack([memory[o].vec for o in objects])\n\n# Encode as: bind(subject, bind(predicate, object))\npred_obj = vmap_bind(model.opset, pred_vecs, obj_vecs)\ntriples = vmap_bind(model.opset, subj_vecs, pred_obj)\n\n# Bundle all triples into knowledge graph\nknowledge_graph = vmap_bundle(model.opset, triples)\nprint(f\"Knowledge graph: {knowledge_graph.shape}\")\n</code></pre>"},{"location":"guide/batch_operations/#performance-comparison","title":"Performance Comparison","text":"<p>Batch operations provide significant speedups:</p> <pre><code>import time\n\n# Individual operations (slow)\nstart = time.time()\nresults = []\nfor i in range(100):\n    result = model.opset.bind(memory[\"a\"].vec, memory[\"b\"].vec)\n    results.append(result)\nindividual_time = time.time() - start\n\n# Batch operation (fast)\nX = jnp.stack([memory[\"a\"].vec] * 100)\nY = jnp.stack([memory[\"b\"].vec] * 100)\n\nstart = time.time()\nbatch_result = vmap_bind(model.opset, X, Y)\njax.block_until_ready(batch_result)\nbatch_time = time.time() - start\n\nprint(f\"Individual: {individual_time:.4f}s\")\nprint(f\"Batch: {batch_time:.4f}s\")\nprint(f\"Speedup: {individual_time/batch_time:.1f}x\")\n</code></pre>"},{"location":"guide/batch_operations/#best-practices","title":"Best Practices","text":""},{"location":"guide/batch_operations/#1-pre-allocate-arrays","title":"1. Pre-allocate Arrays","text":"<p>Stack vectors once, reuse for multiple operations:</p> <pre><code># Good: Pre-stack\ncandidates = jnp.stack([memory[name].vec for name in names])\nfor query in queries:\n    similarities = vmap_similarity(None, query, candidates)\n\n# Bad: Re-stack every time\nfor query in queries:\n    candidates = jnp.stack([memory[name].vec for name in names])\n    similarities = vmap_similarity(None, query, candidates)\n</code></pre>"},{"location":"guide/batch_operations/#2-use-jit-compilation","title":"2. Use JIT Compilation","text":"<p>For repeated batch operations, use <code>jax.jit</code>:</p> <pre><code>@jax.jit\ndef batch_encode_facts(subjects, actions, opset):\n    pairs = vmap(opset.bind, in_axes=(0, 0))(subjects, actions)\n    return vmap_bundle(opset, pairs)\n\n# First call compiles\nresult = batch_encode_facts(subj_vecs, act_vecs, model.opset)\n\n# Subsequent calls are fast\nresult = batch_encode_facts(subj_vecs2, act_vecs2, model.opset)\n</code></pre>"},{"location":"guide/batch_operations/#3-batch-size-considerations","title":"3. Batch Size Considerations","text":"<p>For very large batches, consider chunking:</p> <pre><code>def chunk_vmap_bind(opset, X, Y, chunk_size=1000):\n    \"\"\"Process large batches in chunks.\"\"\"\n    n = X.shape[0]\n    results = []\n\n    for i in range(0, n, chunk_size):\n        chunk_X = X[i:i+chunk_size]\n        chunk_Y = Y[i:i+chunk_size]\n        chunk_result = vmap_bind(opset, chunk_X, chunk_Y)\n        results.append(chunk_result)\n\n    return jnp.concatenate(results, axis=0)\n\n# Process 10000 bindings in chunks\nlarge_X = jnp.stack([memory[\"a\"].vec] * 10000)\nlarge_Y = jnp.stack([memory[\"b\"].vec] * 10000)\nresult = chunk_vmap_bind(model.opset, large_X, large_Y)\n</code></pre>"},{"location":"guide/batch_operations/#4-gpu-memory-management","title":"4. GPU Memory Management","text":"<p>Monitor GPU memory when processing large batches:</p> <pre><code>import jax\n\n# Check available devices\nprint(f\"Devices: {jax.devices()}\")\n\n# Clear cached compilations if needed\njax.clear_caches()\n\n# Force garbage collection\nimport gc\ngc.collect()\n</code></pre>"},{"location":"guide/batch_operations/#working-with-all-vsa-models","title":"Working with All VSA Models","text":"<p>Batch operations work seamlessly across all VSA models:</p> <pre><code>from vsax import create_map_model, create_binary_model\n\nmodels = {\n    \"FHRR\": create_fhrr_model(dim=512),\n    \"MAP\": create_map_model(dim=512),\n    \"Binary\": create_binary_model(dim=10000, bipolar=True),\n}\n\nfor name, test_model in models.items():\n    mem = VSAMemory(test_model)\n    mem.add_many([\"a\", \"b\", \"c\", \"x\", \"y\", \"z\"])\n\n    X = jnp.stack([mem[\"a\"].vec, mem[\"b\"].vec, mem[\"c\"].vec])\n    Y = jnp.stack([mem[\"x\"].vec, mem[\"y\"].vec, mem[\"z\"].vec])\n\n    result = vmap_bind(test_model.opset, X, Y)\n    print(f\"{name}: {result.shape}\")\n</code></pre>"},{"location":"guide/batch_operations/#complete-example","title":"Complete Example","text":"<p>See <code>examples/batch_operations.py</code> for a comprehensive demonstration of batch processing techniques.</p>"},{"location":"guide/encoders/","title":"Encoders","text":"<p>VSAX provides 5 core encoders for converting structured data into hypervectors, plus an extensible base class for creating custom encoders.</p>"},{"location":"guide/encoders/#overview","title":"Overview","text":"<p>Encoders transform structured data (numbers, sequences, dictionaries, graphs) into hypervector representations that can be manipulated with VSA operations.</p> <p>All encoders: - Work with all 3 VSA models (FHRR, MAP, Binary) - Accept a <code>VSAModel</code> and <code>VSAMemory</code> in their constructor - Implement an <code>encode()</code> method that returns a hypervector</p>"},{"location":"guide/encoders/#core-encoders","title":"Core Encoders","text":""},{"location":"guide/encoders/#scalarencoder","title":"ScalarEncoder","text":"<p>Encodes numeric values using power encoding (for complex hypervectors) or iterated binding (for real/binary).</p> <pre><code>from vsax import create_fhrr_model, VSAMemory, ScalarEncoder\n\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\nmemory.add(\"temperature\")\n\nencoder = ScalarEncoder(model, memory, min_val=0, max_val=100)\ntemp_hv = encoder.encode(\"temperature\", 23.5)\n</code></pre> <p>Use cases: Sensor readings, measurements, ratings, scores</p>"},{"location":"guide/encoders/#sequenceencoder","title":"SequenceEncoder","text":"<p>Encodes ordered sequences (lists, tuples) using positional binding.</p> <pre><code>from vsax import SequenceEncoder\n\nmemory.add_many([\"red\", \"green\", \"blue\"])\nencoder = SequenceEncoder(model, memory)\n\n# Order matters!\nseq1 = encoder.encode([\"red\", \"green\", \"blue\"])\nseq2 = encoder.encode([\"blue\", \"green\", \"red\"])  # Different hypervector\n</code></pre> <p>Use cases: Time series, sentences, ordered lists, paths</p>"},{"location":"guide/encoders/#setencoder","title":"SetEncoder","text":"<p>Encodes unordered collections using bundling (order-invariant).</p> <pre><code>from vsax import SetEncoder\n\nmemory.add_many([\"dog\", \"cat\", \"bird\"])\nencoder = SetEncoder(model, memory)\n\n# Order doesn't matter!\nset1 = encoder.encode({\"dog\", \"cat\", \"bird\"})\nset2 = encoder.encode({\"bird\", \"dog\", \"cat\"})  # Same hypervector\n</code></pre> <p>Use cases: Tags, categories, unordered groups</p>"},{"location":"guide/encoders/#dictencoder","title":"DictEncoder","text":"<p>Encodes key-value pairs using role-filler binding.</p> <pre><code>from vsax import DictEncoder\n\nmemory.add_many([\"subject\", \"action\", \"dog\", \"run\"])\nencoder = DictEncoder(model, memory)\n\nsentence = encoder.encode({\n    \"subject\": \"dog\",\n    \"action\": \"run\"\n})\n</code></pre> <p>Use cases: Structured records, semantic frames, property-value pairs</p>"},{"location":"guide/encoders/#graphencoder","title":"GraphEncoder","text":"<p>Encodes graph structures as edge lists.</p> <pre><code>from vsax import GraphEncoder\n\nmemory.add_many([\"Alice\", \"Bob\", \"knows\", \"likes\"])\nencoder = GraphEncoder(model, memory)\n\nsocial_graph = encoder.encode([\n    (\"Alice\", \"knows\", \"Bob\"),\n    (\"Alice\", \"likes\", \"Bob\")\n])\n</code></pre> <p>Use cases: Knowledge graphs, social networks, dependency graphs</p>"},{"location":"guide/encoders/#custom-encoders","title":"Custom Encoders","text":"<p>Create custom encoders by subclassing <code>AbstractEncoder</code>:</p> <pre><code>from vsax import AbstractEncoder\n\nclass DateEncoder(AbstractEncoder):\n    def encode(self, date_obj):\n        # Your custom encoding logic\n        year_hv = self.encode_component(date_obj.year)\n        month_hv = self.encode_component(date_obj.month)\n        day_hv = self.encode_component(date_obj.day)\n\n        result = self.model.opset.bundle(year_hv, month_hv, day_hv)\n        return self.model.rep_cls(result)\n</code></pre> <p>See examples/custom_encoder.py for complete examples.</p>"},{"location":"guide/encoders/#best-practices","title":"Best Practices","text":"<ol> <li>Add symbols first: Ensure all required symbols are in memory before encoding</li> <li>Consistent dimensions: Use the same model for all related encodings</li> <li>Combine encoders: Use multiple encoders together for complex data structures</li> <li>Test with similarity: Verify encodings make sense by checking similarity between related items</li> </ol>"},{"location":"guide/encoders/#see-also","title":"See Also","text":"<ul> <li>API Reference - Encoders</li> <li>Examples - FHRR</li> <li>Examples - Custom Encoders</li> </ul>"},{"location":"guide/factory/","title":"Factory Functions: Easy Model Creation","text":"<p>Factory functions provide a simple, one-line way to create VSA models with sensible defaults. Instead of manually configuring representations, operation sets, and samplers, use factory functions for quick setup.</p>"},{"location":"guide/factory/#available-factory-functions","title":"Available Factory Functions","text":"<p>VSAX provides three factory functions, one for each VSA model type:</p> <ul> <li><code>create_fhrr_model()</code> - Complex hypervectors with FFT-based operations</li> <li><code>create_map_model()</code> - Real hypervectors with element-wise operations</li> <li><code>create_binary_model()</code> - Binary hypervectors with XOR/majority operations</li> </ul>"},{"location":"guide/factory/#create_fhrr_model","title":"create_fhrr_model","text":"<p>Create a FHRR (Fourier Holographic Reduced Representation) model.</p> <pre><code>from vsax import create_fhrr_model\n\n# Default dimension (512)\nmodel = create_fhrr_model()\n\n# Custom dimension\nmodel = create_fhrr_model(dim=1024)\n</code></pre> <p>Properties: - Uses <code>ComplexHypervector</code> (complex-valued) - Uses <code>FHRROperations</code> (FFT-based circular convolution) - Uses <code>sample_complex_random</code> (unit magnitude, random phase) - Default dimension: 512 - Unbinding: Exact (via complex conjugate)</p> <p>When to use: - Need exact unbinding - Working with sequential/temporal data - Frequency-domain representations</p>"},{"location":"guide/factory/#create_map_model","title":"create_map_model","text":"<p>Create a MAP (Multiply-Add-Permute) model.</p> <pre><code>from vsax import create_map_model\n\n# Default dimension (512)\nmodel = create_map_model()\n\n# Custom dimension\nmodel = create_map_model(dim=2048)\n</code></pre> <p>Properties: - Uses <code>RealHypervector</code> (real-valued) - Uses <code>MAPOperations</code> (element-wise multiplication/mean) - Uses <code>sample_random</code> (Gaussian distribution) - Default dimension: 512 - Unbinding: Approximate</p> <p>When to use: - Continuous feature representations - Approximate pattern matching - Lower memory footprint than complex</p>"},{"location":"guide/factory/#create_binary_model","title":"create_binary_model","text":"<p>Create a Binary VSA model.</p> <pre><code>from vsax import create_binary_model\n\n# Default dimension (10000), bipolar mode\nmodel = create_binary_model()\n\n# Custom dimension\nmodel = create_binary_model(dim=5000)\n\n# Binary mode {0, 1} instead of bipolar {-1, +1}\nmodel = create_binary_model(dim=10000, bipolar=False)\n</code></pre> <p>Properties: - Uses <code>BinaryHypervector</code> (discrete binary/bipolar) - Uses <code>BinaryOperations</code> (XOR for bind, majority for bundle) - Uses <code>sample_binary_random</code> (random bipolar or binary) - Default dimension: 10000 (higher than continuous models) - Unbinding: Exact (self-inverse property) - Default mode: Bipolar (<code>{-1, +1}</code>)</p> <p>When to use: - Need exact unbinding with minimal computation - Boolean/logical operations - Hardware-friendly representations - Very large symbol spaces (use higher dimensions)</p>"},{"location":"guide/factory/#comparison","title":"Comparison","text":"Model Type Dimension Unbinding Memory Speed FHRR Complex 512 (default) Exact Medium Medium (FFT) MAP Real 512 (default) Approximate Low Fast Binary Discrete 10000 (default) Exact Very Low Very Fast"},{"location":"guide/factory/#complete-example","title":"Complete Example","text":"<pre><code>from vsax import create_fhrr_model, create_map_model, create_binary_model, VSAMemory\nimport jax\n\n# Create all three models\nfhrr = create_fhrr_model(dim=512)\nmap_model = create_map_model(dim=512)\nbinary = create_binary_model(dim=10000, bipolar=True)\n\n# All models work with VSAMemory\nfor model in [fhrr, map_model, binary]:\n    memory = VSAMemory(model, key=jax.random.PRNGKey(42))\n    memory.add_many([\"concept1\", \"concept2\"])\n\n    # Same interface across all models\n    c1 = memory[\"concept1\"]\n    c2 = memory[\"concept2\"]\n\n    # Bind and bundle\n    bound = model.opset.bind(c1.vec, c2.vec)\n    bundled = model.opset.bundle(c1.vec, c2.vec)\n</code></pre>"},{"location":"guide/factory/#versus-manual-creation","title":"Versus Manual Creation","text":"<p>Before (v0.2.0): <pre><code>from vsax import VSAModel, ComplexHypervector, FHRROperations, sample_complex_random\n\nmodel = VSAModel(\n    dim=512,\n    rep_cls=ComplexHypervector,\n    opset=FHRROperations(),\n    sampler=sample_complex_random\n)\n</code></pre></p> <p>After (v0.3.0): <pre><code>from vsax import create_fhrr_model\n\nmodel = create_fhrr_model(dim=512)\n</code></pre></p> <p>Much simpler! Factory functions reduce boilerplate while maintaining full flexibility.</p>"},{"location":"guide/factory/#advanced-custom-models","title":"Advanced: Custom Models","text":"<p>If you need custom configurations, you can still use <code>VSAModel</code> directly:</p> <pre><code>from vsax import VSAModel, RealHypervector, MAPOperations\n\n# Custom sampler\ndef my_sampler(dim, n, key):\n    return jax.random.uniform(key, shape=(n, dim)) * 2 - 1\n\nmodel = VSAModel(\n    dim=256,\n    rep_cls=RealHypervector,\n    opset=MAPOperations(),\n    sampler=my_sampler\n)\n</code></pre> <p>But for 95% of use cases, factory functions are sufficient.</p>"},{"location":"guide/factory/#api-reference","title":"API Reference","text":"<pre><code>def create_fhrr_model(dim: int = 512, key: Optional[jax.Array] = None) -&gt; VSAModel:\n    \"\"\"Create FHRR model with complex hypervectors.\"\"\"\n\ndef create_map_model(dim: int = 512, key: Optional[jax.Array] = None) -&gt; VSAModel:\n    \"\"\"Create MAP model with real hypervectors.\"\"\"\n\ndef create_binary_model(\n    dim: int = 10000,\n    bipolar: bool = True,\n    key: Optional[jax.Array] = None\n) -&gt; VSAModel:\n    \"\"\"Create Binary model with discrete hypervectors.\"\"\"\n</code></pre>"},{"location":"guide/factory/#next-steps","title":"Next Steps","text":"<ul> <li>VSAMemory Guide - Symbol table management</li> <li>Operations Guide - Binding and bundling</li> <li>Examples - Complete working examples</li> </ul>"},{"location":"guide/memory/","title":"VSAMemory: Symbol Table Management","text":"<p>VSAMemory provides a dictionary-style interface for creating and managing named hypervectors (basis symbols). It acts as a symbol table that automatically samples and stores hypervectors for symbolic concepts.</p>"},{"location":"guide/memory/#overview","title":"Overview","text":"<p>VSAMemory simplifies working with VSA models by:</p> <ul> <li>Automatic sampling: Creates hypervectors on-demand when you add symbols</li> <li>Dictionary-style access: Use familiar <code>memory[\"symbol\"]</code> syntax</li> <li>Reproducibility: Optional PRNG key for deterministic sampling</li> <li>Model-agnostic: Works with FHRR, MAP, and Binary models</li> </ul>"},{"location":"guide/memory/#basic-usage","title":"Basic Usage","text":""},{"location":"guide/memory/#creating-memory","title":"Creating Memory","text":"<pre><code>from vsax import create_fhrr_model, VSAMemory\n\n# Create a model\nmodel = create_fhrr_model(dim=512)\n\n# Create memory (with optional key for reproducibility)\nmemory = VSAMemory(model, key=jax.random.PRNGKey(42))\n</code></pre>"},{"location":"guide/memory/#adding-symbols","title":"Adding Symbols","text":"<pre><code># Add a single symbol\ndog = memory.add(\"dog\")\n\n# Add multiple symbols\nmemory.add_many([\"cat\", \"bird\", \"fish\"])\n\n# Adding duplicate returns the same hypervector\ndog2 = memory.add(\"dog\")  # Same as dog\nassert jnp.array_equal(dog.vec, dog2.vec)\n</code></pre>"},{"location":"guide/memory/#accessing-symbols","title":"Accessing Symbols","text":"<pre><code># Dictionary-style access\ndog = memory[\"dog\"]\ncat = memory[\"cat\"]\n\n# Check if symbol exists\nif \"dog\" in memory:\n    print(\"Dog is in memory\")\n\n# Get all symbol names\nsymbols = memory.keys()  # ['dog', 'cat', 'bird', 'fish']\n\n# Number of symbols\ncount = len(memory)  # 4\n</code></pre>"},{"location":"guide/memory/#using-symbols","title":"Using Symbols","text":"<pre><code># Get the underlying vector\ndog_vec = memory[\"dog\"].vec\n\n# Bind two concepts\ndog_is_animal = model.opset.bind(memory[\"dog\"].vec, memory[\"animal\"].vec)\n\n# Bundle multiple concepts\npets = model.opset.bundle(\n    memory[\"dog\"].vec,\n    memory[\"cat\"].vec,\n    memory[\"bird\"].vec\n)\n</code></pre>"},{"location":"guide/memory/#clearing-memory","title":"Clearing Memory","text":"<pre><code># Remove all symbols\nmemory.clear()\nassert len(memory) == 0\n</code></pre>"},{"location":"guide/memory/#complete-example-role-filler-binding","title":"Complete Example: Role-Filler Binding","text":"<pre><code>import jax\nfrom vsax import create_fhrr_model, VSAMemory\n\n# Create FHRR model and memory\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model, key=jax.random.PRNGKey(42))\n\n# Add roles and fillers\nmemory.add_many([\"subject\", \"predicate\", \"object\"])\nmemory.add_many([\"dog\", \"chases\", \"cat\"])\n\n# Create sentence: \"dog chases cat\"\nsubject_dog = model.opset.bind(\n    memory[\"subject\"].vec,\n    memory[\"dog\"].vec\n)\n\npredicate_chases = model.opset.bind(\n    memory[\"predicate\"].vec,\n    memory[\"chases\"].vec\n)\n\nobject_cat = model.opset.bind(\n    memory[\"object\"].vec,\n    memory[\"cat\"].vec\n)\n\n# Bundle into sentence representation\nsentence = model.opset.bundle(subject_dog, predicate_chases, object_cat)\n</code></pre>"},{"location":"guide/memory/#reproducibility","title":"Reproducibility","text":"<p>Use a PRNG key for deterministic symbol generation:</p> <pre><code>import jax\n\nkey = jax.random.PRNGKey(42)\n\n# Two memories with same key produce identical symbols\nmemory1 = VSAMemory(create_fhrr_model(dim=512), key=key)\nmemory2 = VSAMemory(create_fhrr_model(dim=512), key=key)\n\ndog1 = memory1.add(\"dog\")\ndog2 = memory2.add(\"dog\")\n\nassert jnp.array_equal(dog1.vec, dog2.vec)  # Identical\n</code></pre>"},{"location":"guide/memory/#working-with-different-models","title":"Working with Different Models","text":"<p>VSAMemory works identically across all model types:</p>"},{"location":"guide/memory/#fhrr-model","title":"FHRR Model","text":"<pre><code>fhrr = create_fhrr_model(dim=512)\nmemory = VSAMemory(fhrr)\ndog = memory.add(\"dog\")\n# dog.vec is complex-valued\n</code></pre>"},{"location":"guide/memory/#map-model","title":"MAP Model","text":"<pre><code>map_model = create_map_model(dim=512)\nmemory = VSAMemory(map_model)\nfeature = memory.add(\"feature\")\n# feature.vec is real-valued\n</code></pre>"},{"location":"guide/memory/#binary-model","title":"Binary Model","text":"<pre><code>binary = create_binary_model(dim=10000, bipolar=True)\nmemory = VSAMemory(binary)\nconcept = memory.add(\"concept\")\n# concept.vec is bipolar {-1, +1}\n</code></pre>"},{"location":"guide/memory/#api-reference","title":"API Reference","text":""},{"location":"guide/memory/#vsamemory-class","title":"VSAMemory Class","text":"<pre><code>class VSAMemory:\n    def __init__(self, model: VSAModel, key: Optional[jax.Array] = None):\n        \"\"\"Initialize VSAMemory with a model.\"\"\"\n\n    def add(self, name: str) -&gt; AbstractHypervector:\n        \"\"\"Add a symbol and return its hypervector.\"\"\"\n\n    def add_many(self, names: Iterable[str]) -&gt; List[AbstractHypervector]:\n        \"\"\"Add multiple symbols at once.\"\"\"\n\n    def get(self, name: str) -&gt; AbstractHypervector:\n        \"\"\"Get a hypervector by name (raises KeyError if missing).\"\"\"\n\n    def __getitem__(self, name: str) -&gt; AbstractHypervector:\n        \"\"\"Dictionary-style access: memory[\"dog\"]\"\"\"\n\n    def __contains__(self, name: str) -&gt; bool:\n        \"\"\"Check if symbol exists: \"dog\" in memory\"\"\"\n\n    def keys(self) -&gt; List[str]:\n        \"\"\"Get all symbol names.\"\"\"\n\n    def clear(self) -&gt; None:\n        \"\"\"Remove all symbols.\"\"\"\n\n    def __len__(self) -&gt; int:\n        \"\"\"Number of stored symbols.\"\"\"\n</code></pre>"},{"location":"guide/memory/#best-practices","title":"Best Practices","text":"<ol> <li>Use factory functions: Create models with <code>create_fhrr_model()</code>, <code>create_map_model()</code>, or <code>create_binary_model()</code></li> <li>Add symbols upfront: Add all symbols at once with <code>add_many()</code> for consistency</li> <li>Use keys for reproducibility: Pass a PRNG key when reproducibility matters</li> <li>Access vectors explicitly: Use <code>.vec</code> to get the underlying array for operations</li> </ol>"},{"location":"guide/memory/#next-steps","title":"Next Steps","text":"<ul> <li>Factory Functions - Easy model creation</li> <li>Operations Guide - Binding and bundling operations</li> <li>Examples - Complete working examples</li> </ul>"},{"location":"guide/models/","title":"VSA Models","text":"<p>The <code>VSAModel</code> is an immutable container that defines a complete VSA algebra by combining a representation type, operation set, and sampler.</p>"},{"location":"guide/models/#vsamodel-structure","title":"VSAModel Structure","text":"<pre><code>@dataclass(frozen=True)\nclass VSAModel:\n    dim: int                          # Dimensionality\n    rep_cls: type[AbstractHypervector]  # Representation class\n    opset: AbstractOpSet              # Operation set\n    sampler: Callable                 # Sampling function\n</code></pre>"},{"location":"guide/models/#creating-models","title":"Creating Models","text":""},{"location":"guide/models/#fhrr-model","title":"FHRR Model","text":"<pre><code>from vsax import VSAModel, ComplexHypervector, FHRROperations, sample_complex_random\n\nfhrr_model = VSAModel(\n    dim=512,\n    rep_cls=ComplexHypervector,\n    opset=FHRROperations(),\n    sampler=sample_complex_random\n)\n</code></pre>"},{"location":"guide/models/#map-model","title":"MAP Model","text":"<pre><code>from vsax import RealHypervector, MAPOperations, sample_random\n\nmap_model = VSAModel(\n    dim=512,\n    rep_cls=RealHypervector,\n    opset=MAPOperations(),\n    sampler=sample_random\n)\n</code></pre>"},{"location":"guide/models/#binary-model","title":"Binary Model","text":"<pre><code>from vsax import BinaryHypervector, BinaryOperations, sample_binary_random\n\nbinary_model = VSAModel(\n    dim=512,\n    rep_cls=BinaryHypervector,\n    opset=BinaryOperations(),\n    sampler=sample_binary_random\n)\n</code></pre>"},{"location":"guide/models/#using-models","title":"Using Models","text":"<pre><code>import jax\n\n# Sample basis vectors\nkey = jax.random.PRNGKey(42)\nvectors = fhrr_model.sampler(dim=fhrr_model.dim, n=2, key=key)\n\n# Create hypervectors using model's representation\na = fhrr_model.rep_cls(vectors[0]).normalize()\nb = fhrr_model.rep_cls(vectors[1]).normalize()\n\n# Perform operations using model's opset\nbound = fhrr_model.opset.bind(a.vec, b.vec)\nbundled = fhrr_model.opset.bundle(a.vec, b.vec)\n</code></pre>"},{"location":"guide/models/#model-properties","title":"Model Properties","text":"<p>Immutability: Models are frozen dataclasses - cannot be modified after creation.</p> <pre><code>model = VSAModel(dim=512, ...)\n\n# This will raise an error\nmodel.dim = 1024  # FrozenInstanceError!\n</code></pre> <p>Type Safety: The model ensures all components work together correctly.</p>"},{"location":"guide/models/#next-vsamemory","title":"Next: VSAMemory","text":"<p>Use <code>VSAMemory</code> to manage named basis vectors:</p> <pre><code>from vsax import VSAMemory\n\nmemory = VSAMemory(model)\nmemory.add(\"dog\")\nmemory.add(\"cat\")\n\ndog = memory[\"dog\"]  # Access by name\n</code></pre> <p>See the VSAMemory guide for more details.</p>"},{"location":"guide/models/#next-steps","title":"Next Steps","text":"<ul> <li>See Examples for complete model usage</li> <li>Check API Reference for detailed documentation</li> </ul>"},{"location":"guide/operations/","title":"VSA Operations","text":"<p>VSA operations define how hypervectors are combined and manipulated. VSAX provides three operation sets, each corresponding to a representation type.</p>"},{"location":"guide/operations/#overview","title":"Overview","text":"<p>All operation sets implement the <code>AbstractOpSet</code> interface with four core operations:</p> Operation Purpose Example <code>bind(a, b)</code> Combine/associate two vectors Role-filler binding <code>bundle(*vecs)</code> Superposition of multiple vectors Create composite representations <code>inverse(a)</code> Compute inverse for unbinding Retrieve bound information <code>permute(a, shift)</code> Circular shift/rotation Sequential encoding"},{"location":"guide/operations/#fhrroperations","title":"FHRROperations","text":"<p>Operations for complex-valued hypervectors using FFT-based circular convolution.</p>"},{"location":"guide/operations/#binding-circular-convolution","title":"Binding (Circular Convolution)","text":"<p>Binds two complex vectors using circular convolution implemented via FFT.</p> <pre><code>from vsax import FHRROperations\nimport jax.numpy as jnp\n\nops = FHRROperations()\n\n# Create unit-magnitude complex vectors\na = jnp.exp(1j * jnp.array([0.1, 0.5, 1.0, 1.5]))\nb = jnp.exp(1j * jnp.array([0.2, 0.6, 1.1, 1.6]))\n\n# Bind via circular convolution\nbound = ops.bind(a, b)\n\n# Result is also complex\nassert jnp.iscomplexobj(bound)\n</code></pre> <p>Properties: - Commutative: <code>bind(a, b) = bind(b, a)</code> - Associative: <code>bind(a, bind(b, c)) = bind(bind(a, b), c)</code> - Invertible: Can recover <code>a</code> from <code>bind(a, b)</code> using <code>inverse(b)</code></p>"},{"location":"guide/operations/#bundling-sum-and-normalize","title":"Bundling (Sum and Normalize)","text":"<p>Bundles multiple vectors by summing and normalizing to unit magnitude.</p> <pre><code># Bundle three vectors\nbundled = ops.bundle(a, b, c)\n\n# All elements have unit magnitude\nassert jnp.allclose(jnp.abs(bundled), 1.0)\n</code></pre> <p>Properties: - Similarity preserving: Bundled vector is similar to constituents - Approximate: Some information loss occurs - Commutative: Order doesn't matter</p>"},{"location":"guide/operations/#inverse-complex-conjugate","title":"Inverse (Complex Conjugate)","text":"<p>For complex vectors, the inverse is the complex conjugate.</p> <pre><code># Unbind to recover original\ninv_b = ops.inverse(b)\nrecovered = ops.bind(bound, inv_b)\n\n# recovered \u2248 a (with high similarity)\n</code></pre>"},{"location":"guide/operations/#example-role-filler-binding","title":"Example: Role-Filler Binding","text":"<pre><code># Represent \"The dog chased the cat\"\nsubject = jnp.exp(1j * jax.random.uniform(key1, (512,)))\nverb = jnp.exp(1j * jax.random.uniform(key2, (512,)))\nobject_ = jnp.exp(1j * jax.random.uniform(key3, (512,)))\n\ndog = jnp.exp(1j * jax.random.uniform(key4, (512,)))\nchase = jnp.exp(1j * jax.random.uniform(key5, (512,)))\ncat = jnp.exp(1j * jax.random.uniform(key6, (512,)))\n\n# Create sentence representation\nsentence = ops.bundle(\n    ops.bind(subject, dog),\n    ops.bind(verb, chase),\n    ops.bind(object_, cat)\n)\n\n# Query: What was the subject?\nquery = ops.bind(sentence, ops.inverse(subject))\n# query \u2248 dog (high similarity)\n</code></pre>"},{"location":"guide/operations/#mapoperations","title":"MAPOperations","text":"<p>Operations for real-valued hypervectors using element-wise operations.</p>"},{"location":"guide/operations/#binding-element-wise-multiplication","title":"Binding (Element-wise Multiplication)","text":"<p>Simplest binding operation - just multiply element-wise.</p> <pre><code>from vsax import MAPOperations\n\nops = MAPOperations()\n\n# Real vectors\na = jax.random.normal(key1, (512,))\nb = jax.random.normal(key2, (512,))\n\n# Bind via multiplication\nbound = ops.bind(a, b)\nassert bound.shape == a.shape\nassert jnp.array_equal(bound, a * b)\n</code></pre> <p>Properties: - Commutative: <code>bind(a, b) = bind(b, a)</code> - Associative: <code>bind(a, bind(b, c)) = bind(bind(a, b), c)</code> - Approximate unbinding: Cannot perfectly recover original</p>"},{"location":"guide/operations/#bundling-element-wise-mean","title":"Bundling (Element-wise Mean)","text":"<p>Average of all input vectors.</p> <pre><code># Bundle three vectors\nbundled = ops.bundle(a, b, c)\n\n# Result is the mean\nassert jnp.allclose(bundled, (a + b + c) / 3)\n</code></pre> <p>Properties: - Order-independent - Lossy: Individual vectors cannot be perfectly recovered - Preserves similarity: Bundled vector similar to constituents</p>"},{"location":"guide/operations/#inverse-approximate","title":"Inverse (Approximate)","text":"<p>MAP uses an approximate inverse based on normalization.</p> <pre><code># Approximate inverse\ninv_b = ops.inverse(b)\n\n# Unbinding is approximate\nrecovered = ops.bind(bound, inv_b)\n# recovered \u2248 a (but not exact)\n</code></pre> <p>Note: MAP unbinding is approximate - use for applications where exact recovery isn't critical.</p>"},{"location":"guide/operations/#example-feature-binding","title":"Example: Feature Binding","text":"<pre><code># Represent a data point: {age: 25, income: 50000, city: \"SF\"}\nage_role = jax.random.normal(key1, (512,))\nincome_role = jax.random.normal(key2, (512,))\ncity_role = jax.random.normal(key3, (512,))\n\nage_25 = jax.random.normal(key4, (512,))\nincome_50k = jax.random.normal(key5, (512,))\nsf = jax.random.normal(key6, (512,))\n\n# Create record\nrecord = ops.bundle(\n    ops.bind(age_role, age_25),\n    ops.bind(income_role, income_50k),\n    ops.bind(city_role, sf)\n)\n</code></pre>"},{"location":"guide/operations/#binaryoperations","title":"BinaryOperations","text":"<p>Operations for binary hypervectors using XOR and majority voting.</p>"},{"location":"guide/operations/#binding-xor","title":"Binding (XOR)","text":"<p>In bipolar {-1, +1} representation, XOR is implemented as multiplication.</p> <pre><code>from vsax import BinaryOperations\n\nops = BinaryOperations()\n\n# Bipolar vectors\na = jnp.array([1, -1, 1, -1, 1, 1, -1, -1])\nb = jnp.array([1, 1, -1, -1, 1, -1, 1, -1])\n\n# Bind via XOR (multiplication in bipolar)\nbound = ops.bind(a, b)\n\n# Result: element-wise multiplication\n# Same values \u2192 +1, different values \u2192 -1\n</code></pre> <p>Properties: - Commutative: <code>bind(a, b) = bind(b, a)</code> - Associative: <code>bind(a, bind(b, c)) = bind(bind(a, b), c)</code> - Self-inverse: <code>bind(bind(a, b), b) = a</code> (exact unbinding!)</p>"},{"location":"guide/operations/#bundling-majority-vote","title":"Bundling (Majority Vote)","text":"<p>Each position in the bundled vector is determined by majority vote.</p> <pre><code>a = jnp.array([1, -1, 1, -1])\nb = jnp.array([1, 1, -1, -1])\nc = jnp.array([1, 1, 1, 1])\n\nbundled = ops.bundle(a, b, c)\n\n# Position 0: [1, 1, 1] \u2192 majority 1\n# Position 1: [-1, 1, 1] \u2192 majority 1\n# Position 2: [1, -1, 1] \u2192 majority 1\n# Position 3: [-1, -1, 1] \u2192 majority -1\n# Result: [1, 1, 1, -1]\n</code></pre> <p>Tie Breaking: For even numbers of vectors, ties default to +1.</p>"},{"location":"guide/operations/#inverse-self-inverse","title":"Inverse (Self-Inverse)","text":"<p>XOR is its own inverse, so <code>inverse(a) = a</code>.</p> <pre><code># Exact unbinding\ninv_b = ops.inverse(b)  # inv_b == b\nrecovered = ops.bind(bound, inv_b)\nassert jnp.array_equal(recovered, a)  # Exact recovery!\n</code></pre>"},{"location":"guide/operations/#example-symbolic-reasoning","title":"Example: Symbolic Reasoning","text":"<pre><code># Encode facts: \"Alice likes Bob\", \"Bob likes Charlie\"\nalice = jax.random.choice(key1, jnp.array([-1, 1]), (512,))\nbob = jax.random.choice(key2, jnp.array([-1, 1]), (512,))\ncharlie = jax.random.choice(key3, jnp.array([-1, 1]), (512,))\nlikes = jax.random.choice(key4, jnp.array([-1, 1]), (512,))\n\n# Create knowledge base\nfact1 = ops.bind(ops.bind(alice, likes), bob)\nfact2 = ops.bind(ops.bind(bob, likes), charlie)\nkb = ops.bundle(fact1, fact2)\n\n# Query: Who does Alice like?\nquery = ops.bind(ops.bind(kb, alice), likes)\n# High similarity to bob\n</code></pre>"},{"location":"guide/operations/#permutation","title":"Permutation","text":"<p>All operation sets support circular permutation (rotation).</p> <pre><code>vec = jnp.array([1, 2, 3, 4, 5])\n\n# Rotate right by 2\nshifted = ops.permute(vec, 2)\n# Result: [4, 5, 1, 2, 3]\n\n# Rotate left by 2\nshifted = ops.permute(vec, -2)\n# Result: [3, 4, 5, 1, 2]\n</code></pre> <p>Use cases: - Sequence encoding - Temporal ordering - Positional information</p>"},{"location":"guide/operations/#comparison","title":"Comparison","text":"Feature FHRR MAP Binary Binding FFT convolution Element-wise \u00d7 XOR Unbinding Exact (conjugate) Approximate Exact (self-inverse) Bundling Sum + normalize Mean Majority vote Complexity O(n log n) O(n) O(n) Memory 2x (complex) 1x 1/32x"},{"location":"guide/operations/#best-practices","title":"Best Practices","text":"<ol> <li>Normalize inputs: Ensure vectors are properly normalized before operations</li> <li>Consistent types: Don't mix operation sets with wrong representations</li> <li>Batch operations: Use JAX's <code>vmap</code> for processing multiple vectors</li> <li>Numerical stability: Be aware of numerical precision, especially with FHRR</li> </ol>"},{"location":"guide/operations/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Sampling to create basis vectors</li> <li>See Models to combine representations and operations</li> <li>Check Examples for complete workflows</li> </ul>"},{"location":"guide/persistence/","title":"Persistence: Saving and Loading Basis Vectors","text":"<p>VSAX provides simple JSON-based persistence for saving and loading basis vectors. This enables you to:</p> <ul> <li>Preserve semantic spaces across sessions</li> <li>Share vocabularies between projects</li> <li>Version control your basis vectors</li> <li>Reproduce experiments with exact same vectors</li> </ul>"},{"location":"guide/persistence/#quick-start","title":"Quick Start","text":"<pre><code>from vsax import create_fhrr_model, VSAMemory, save_basis, load_basis\n\n# Create and populate memory\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\nmemory.add_many([\"dog\", \"cat\", \"animal\", \"pet\"])\n\n# Save to JSON\nsave_basis(memory, \"animals.json\")\n\n# Later: Load into new memory\nnew_memory = VSAMemory(model)\nload_basis(new_memory, \"animals.json\")\n\n# Vectors are preserved exactly\nassert \"dog\" in new_memory\n</code></pre>"},{"location":"guide/persistence/#saving-basis-vectors","title":"Saving Basis Vectors","text":""},{"location":"guide/persistence/#basic-usage","title":"Basic Usage","text":"<pre><code>from pathlib import Path\nfrom vsax import save_basis\n\n# Save with Path object\nsave_basis(memory, Path(\"my_basis.json\"))\n\n# Or with string path\nsave_basis(memory, \"my_basis.json\")\n</code></pre>"},{"location":"guide/persistence/#what-gets-saved","title":"What Gets Saved?","text":"<p>The JSON file contains:</p> <ol> <li>Metadata: Dimension, representation type, vector count</li> <li>Vectors: All named vectors in the memory</li> </ol> <p>Example JSON structure for FHRR (complex) vectors:</p> <pre><code>{\n  \"metadata\": {\n    \"dim\": 512,\n    \"rep_type\": \"complex\",\n    \"num_vectors\": 3\n  },\n  \"vectors\": {\n    \"dog\": {\n      \"real\": [0.12, -0.34, ...],\n      \"imag\": [0.56, 0.78, ...]\n    },\n    \"cat\": {\n      \"real\": [-0.45, 0.23, ...],\n      \"imag\": [0.11, -0.67, ...]\n    }\n  }\n}\n</code></pre>"},{"location":"guide/persistence/#all-three-models-supported","title":"All Three Models Supported","text":"<p>FHRR (Complex Vectors): - Stored as separate real and imaginary parts - JSON keys: <code>\"real\"</code> and <code>\"imag\"</code></p> <p>MAP (Real Vectors): - Stored as simple float arrays - Direct list representation</p> <p>Binary (Bipolar Vectors): - Stored as integer arrays (-1, +1 or 0, 1) - Compact representation</p> <pre><code># Each model saves differently\nfhrr_model = create_fhrr_model(dim=512)\nmap_model = create_map_model(dim=512)\nbinary_model = create_binary_model(dim=10000, bipolar=True)\n\nmemory_fhrr = VSAMemory(fhrr_model)\nmemory_map = VSAMemory(map_model)\nmemory_binary = VSAMemory(binary_model)\n\n# All use same API\nsave_basis(memory_fhrr, \"fhrr.json\")\nsave_basis(memory_map, \"map.json\")\nsave_basis(memory_binary, \"binary.json\")\n</code></pre>"},{"location":"guide/persistence/#loading-basis-vectors","title":"Loading Basis Vectors","text":""},{"location":"guide/persistence/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from vsax import load_basis\n\n# Create empty memory with correct model\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\n\n# Load from file\nload_basis(memory, \"my_basis.json\")\n\n# Memory is now populated\nprint(f\"Loaded {len(memory._vectors)} vectors\")\n</code></pre>"},{"location":"guide/persistence/#requirements","title":"Requirements","text":"<ol> <li>Empty Memory: Memory must be empty before loading</li> <li>Matching Dimension: File dimension must match memory's model dimension</li> <li>Matching Type: File rep_type must match memory's model type</li> </ol>"},{"location":"guide/persistence/#error-handling","title":"Error Handling","text":"<pre><code># Dimension mismatch\nmodel_128 = create_fhrr_model(dim=128)\nmodel_256 = create_fhrr_model(dim=256)\n\nmemory_128 = VSAMemory(model_128)\nmemory_128.add(\"test\")\nsave_basis(memory_128, \"test.json\")\n\nmemory_256 = VSAMemory(model_256)\ntry:\n    load_basis(memory_256, \"test.json\")  # \u274c Dimension mismatch!\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n\n# Representation type mismatch\nfhrr_memory = VSAMemory(create_fhrr_model(dim=128))\nfhrr_memory.add(\"test\")\nsave_basis(fhrr_memory, \"test.json\")\n\nmap_memory = VSAMemory(create_map_model(dim=128))\ntry:\n    load_basis(map_memory, \"test.json\")  # \u274c Type mismatch!\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n\n# Non-empty memory\nmemory = VSAMemory(create_fhrr_model(dim=128))\nmemory.add(\"existing\")\ntry:\n    load_basis(memory, \"test.json\")  # \u274c Memory not empty!\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n</code></pre>"},{"location":"guide/persistence/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guide/persistence/#1-persistent-semantic-spaces","title":"1. Persistent Semantic Spaces","text":"<p>Build a knowledge base once, reuse it across sessions:</p> <pre><code># Session 1: Build semantic space\nmodel = create_fhrr_model(dim=1024)\nmemory = VSAMemory(model)\n\n# Add domain vocabulary\nmemory.add_many([\n    \"entity1\", \"entity2\", \"relation1\", \"relation2\",\n    \"attribute1\", \"attribute2\", ...\n])\n\n# Create complex structures\nentity_with_attr = model.opset.bind(\n    memory[\"entity1\"].vec,\n    memory[\"attribute1\"].vec\n)\n\n# Save for later\nsave_basis(memory, \"knowledge_base.json\")\n\n# Session 2: Load and use\nmemory_new = VSAMemory(model)\nload_basis(memory_new, \"knowledge_base.json\")\n\n# All symbols available immediately\nentity = memory_new[\"entity1\"]\n</code></pre>"},{"location":"guide/persistence/#2-sharing-vocabularies","title":"2. Sharing Vocabularies","text":"<p>Share exact basis vectors between projects or team members:</p> <pre><code># Project A: Create shared vocabulary\nmodel = create_map_model(dim=512)\nmemory = VSAMemory(model)\nmemory.add_many([\"term1\", \"term2\", \"term3\", ...])\nsave_basis(memory, \"shared_vocab.json\")\n\n# Project B: Use same vocabulary\nmodel_b = create_map_model(dim=512)  # Same dim!\nmemory_b = VSAMemory(model_b)\nload_basis(memory_b, \"shared_vocab.json\")\n\n# Projects now use identical basis\n</code></pre>"},{"location":"guide/persistence/#3-reproducible-research","title":"3. Reproducible Research","text":"<p>Version control your basis vectors for reproducible experiments:</p> <pre><code># Save basis with experiment\ngit add experiment_basis.json\ngit commit -m \"Add basis for experiment 1\"\n\n# Others can reproduce exact results\ngit clone repo\npython experiment.py  # Loads experiment_basis.json\n</code></pre>"},{"location":"guide/persistence/#4-incremental-development","title":"4. Incremental Development","text":"<p>Save progress and resume later:</p> <pre><code># Day 1: Initial setup\nmemory = VSAMemory(create_fhrr_model(dim=512))\nmemory.add_many([\"concept1\", \"concept2\", ...])\nsave_basis(memory, \"progress.json\")\n\n# Day 2: Resume and extend\nmemory = VSAMemory(create_fhrr_model(dim=512))\nload_basis(memory, \"progress.json\")\nmemory.add_many([\"concept3\", \"concept4\", ...])  # Add more\nsave_basis(memory, \"progress.json\")  # Overwrite\n</code></pre>"},{"location":"guide/persistence/#best-practices","title":"Best Practices","text":""},{"location":"guide/persistence/#file-organization","title":"File Organization","text":"<pre><code>project/\n\u251c\u2500\u2500 basis/\n\u2502   \u251c\u2500\u2500 entities.json      # Entity vectors\n\u2502   \u251c\u2500\u2500 relations.json     # Relation vectors\n\u2502   \u2514\u2500\u2500 attributes.json    # Attribute vectors\n\u251c\u2500\u2500 experiments/\n\u2502   \u251c\u2500\u2500 exp1_basis.json\n\u2502   \u2514\u2500\u2500 exp2_basis.json\n\u2514\u2500\u2500 shared/\n    \u2514\u2500\u2500 common_vocab.json\n</code></pre>"},{"location":"guide/persistence/#naming-conventions","title":"Naming Conventions","text":"<pre><code># Descriptive filenames\nsave_basis(memory, \"medical_terms_512d_fhrr.json\")\nsave_basis(memory, \"colors_256d_map.json\")\nsave_basis(memory, \"code_symbols_10k_binary.json\")\n</code></pre>"},{"location":"guide/persistence/#version-control","title":"Version Control","text":"<pre><code># Include dimension and date in filename\nfrom datetime import datetime\n\ndate_str = datetime.now().strftime(\"%Y%m%d\")\nfilename = f\"basis_{model.dim}d_{date_str}.json\"\nsave_basis(memory, filename)\n</code></pre>"},{"location":"guide/persistence/#testing","title":"Testing","text":"<pre><code>import jax.numpy as jnp\n\n# Always verify round-trip\nsave_basis(memory_original, \"test.json\")\nload_basis(memory_loaded, \"test.json\")\n\nfor name in memory_original._vectors:\n    vec1 = memory_original[name].vec\n    vec2 = memory_loaded[name].vec\n    assert jnp.allclose(vec1, vec2, atol=1e-6)\n</code></pre>"},{"location":"guide/persistence/#performance-considerations","title":"Performance Considerations","text":""},{"location":"guide/persistence/#file-size","title":"File Size","text":"<ul> <li>FHRR: 2\u00d7 vector dimension (real + imag parts)</li> <li>MAP: 1\u00d7 vector dimension (real values)</li> <li>Binary: 1\u00d7 vector dimension (integers)</li> </ul> <p>Approximate sizes for 100 vectors:</p> Model Dim File Size FHRR 512 ~500 KB MAP 512 ~250 KB Binary 10,000 ~2 MB"},{"location":"guide/persistence/#load-time","title":"Load Time","text":"<p>Loading is fast (typically &lt; 100ms for typical sizes):</p> <pre><code>import time\n\nstart = time.time()\nload_basis(memory, \"large_basis.json\")\nelapsed = time.time() - start\nprint(f\"Loaded in {elapsed*1000:.1f}ms\")\n</code></pre>"},{"location":"guide/persistence/#large-vocabularies","title":"Large Vocabularies","text":"<p>For very large vocabularies (1000s of vectors):</p> <pre><code># Consider splitting into multiple files\nsave_basis(entities_memory, \"entities.json\")\nsave_basis(relations_memory, \"relations.json\")\nsave_basis(attributes_memory, \"attributes.json\")\n\n# Load only what you need\nmemory = VSAMemory(model)\nload_basis(memory, \"entities.json\")  # Load just entities\n</code></pre>"},{"location":"guide/persistence/#troubleshooting","title":"Troubleshooting","text":"<p>File not found? <pre><code>from pathlib import Path\n\npath = Path(\"my_basis.json\")\nif not path.exists():\n    print(f\"File not found: {path.absolute()}\")\n</code></pre></p> <p>Wrong dimension? <pre><code># Check file metadata first\nimport json\nwith open(\"basis.json\") as f:\n    data = json.load(f)\n    print(f\"File dimension: {data['metadata']['dim']}\")\n    print(f\"File type: {data['metadata']['rep_type']}\")\n</code></pre></p> <p>Corrupted JSON? <pre><code>try:\n    load_basis(memory, \"basis.json\")\nexcept json.JSONDecodeError:\n    print(\"JSON file is corrupted\")\n</code></pre></p>"},{"location":"guide/persistence/#see-also","title":"See Also","text":"<ul> <li>API Reference: I/O - Complete API documentation</li> <li>Examples: persistence.py - Full working example</li> <li>VSAMemory Guide - Memory management</li> </ul>"},{"location":"guide/representations/","title":"Hypervector Representations","text":"<p>VSAX provides three hypervector representations, each designed for a specific VSA algebra. All representations inherit from <code>AbstractHypervector</code> and provide a consistent interface.</p>"},{"location":"guide/representations/#overview","title":"Overview","text":"Representation Values Use Case Operations <code>ComplexHypervector</code> Complex unit-magnitude FHRR (Fourier) Circular convolution <code>RealHypervector</code> Real continuous MAP Element-wise multiply <code>BinaryHypervector</code> Bipolar {-1,+1} or Binary {0,1} Binary VSA XOR, majority vote"},{"location":"guide/representations/#complexhypervector","title":"ComplexHypervector","text":"<p>Phase-based representation using complex numbers for FHRR (Fourier Holographic Reduced Representation).</p>"},{"location":"guide/representations/#features","title":"Features","text":"<ul> <li>Unit magnitude: All elements have magnitude 1.0</li> <li>Phase encoding: Information stored in phase (angle)</li> <li>Exact unbinding: Circular convolution is invertible via conjugate</li> <li>GPU-friendly: Leverages JAX's complex number support</li> </ul>"},{"location":"guide/representations/#example","title":"Example","text":"<pre><code>import jax\nimport jax.numpy as jnp\nfrom vsax import ComplexHypervector, sample_complex_random\n\n# Sample a complex vector\nkey = jax.random.PRNGKey(42)\nvec = sample_complex_random(dim=512, n=1, key=key)[0]\n\n# Create hypervector\nhv = ComplexHypervector(vec)\n\n# Normalize to unit magnitude (phase-only)\nnormalized = hv.normalize()\n\n# Access properties\nprint(f\"Phase: {hv.phase}\")           # Angles in [-\u03c0, \u03c0]\nprint(f\"Magnitude: {hv.magnitude}\")    # All should be ~1.0\nprint(f\"Shape: {hv.shape}\")            # (512,)\n</code></pre>"},{"location":"guide/representations/#properties","title":"Properties","text":"<ul> <li><code>phase</code>: Extract phase component (angles)</li> <li><code>magnitude</code>: Extract magnitude component</li> <li><code>vec</code>: Underlying JAX array</li> <li><code>shape</code>: Vector shape</li> <li><code>dtype</code>: Data type (complex64 or complex128)</li> </ul>"},{"location":"guide/representations/#methods","title":"Methods","text":"<ul> <li><code>normalize()</code>: Normalize to unit magnitude (phase-only representation)</li> <li><code>to_numpy()</code>: Convert to NumPy array</li> </ul>"},{"location":"guide/representations/#realhypervector","title":"RealHypervector","text":"<p>Continuous real-valued representation for MAP (Multiply-Add-Permute) operations.</p>"},{"location":"guide/representations/#features_1","title":"Features","text":"<ul> <li>L2 normalization: Vectors normalized to unit length</li> <li>Continuous values: Real-valued elements</li> <li>Approximate unbinding: MAP unbinding is approximate, not exact</li> <li>Simple operations: Element-wise multiplication and mean</li> </ul>"},{"location":"guide/representations/#example_1","title":"Example","text":"<pre><code>from vsax import RealHypervector, sample_random\n\n# Sample a real vector\nkey = jax.random.PRNGKey(42)\nvec = sample_random(dim=512, n=1, key=key)[0]\n\n# Create hypervector\nhv = RealHypervector(vec)\n\n# L2 normalize\nnormalized = hv.normalize()\n\n# Properties\nprint(f\"L2 norm: {jnp.linalg.norm(normalized.vec)}\")  # Should be 1.0\nprint(f\"Is complex: {jnp.iscomplexobj(hv.vec)}\")      # False\n</code></pre>"},{"location":"guide/representations/#methods_1","title":"Methods","text":"<ul> <li><code>normalize()</code>: L2 normalization to unit length</li> <li><code>to_numpy()</code>: Convert to NumPy array</li> </ul>"},{"location":"guide/representations/#binaryhypervector","title":"BinaryHypervector","text":"<p>Discrete binary representation for Binary VSA with XOR binding.</p>"},{"location":"guide/representations/#features_2","title":"Features","text":"<ul> <li>Exact unbinding: XOR is self-inverse</li> <li>Two modes: Bipolar {-1, +1} or Binary {0, 1}</li> <li>Hardware-friendly: Efficient for digital hardware</li> <li>Majority voting: Robust bundling via majority vote</li> </ul>"},{"location":"guide/representations/#example_2","title":"Example","text":"<pre><code>from vsax import BinaryHypervector, sample_binary_random\n\n# Sample bipolar vectors\nkey = jax.random.PRNGKey(42)\nvec = sample_binary_random(dim=512, n=1, key=key, bipolar=True)[0]\n\n# Create bipolar hypervector\nhv = BinaryHypervector(vec, bipolar=True)\n\n# Check mode\nprint(f\"Is bipolar: {hv.bipolar}\")  # True\n\n# Convert between representations\nbinary_hv = hv.to_binary()      # Convert to {0, 1}\nbipolar_hv = binary_hv.to_bipolar()  # Convert back to {-1, +1}\n\n# Verify values\nprint(f\"Values: {jnp.unique(hv.vec)}\")  # Array([-1, 1])\n</code></pre>"},{"location":"guide/representations/#conversion","title":"Conversion","text":"<pre><code># Bipolar {-1, +1} to Binary {0, 1}\n# Formula: (x + 1) / 2\n# Example: -1 \u2192 0, +1 \u2192 1\n\n# Binary {0, 1} to Bipolar {-1, +1}\n# Formula: 2*x - 1\n# Example: 0 \u2192 -1, 1 \u2192 +1\n</code></pre>"},{"location":"guide/representations/#properties_1","title":"Properties","text":"<ul> <li><code>bipolar</code>: Check if using bipolar encoding</li> <li><code>vec</code>: Underlying JAX array</li> <li><code>shape</code>: Vector shape</li> <li><code>dtype</code>: Data type (typically int32)</li> </ul>"},{"location":"guide/representations/#methods_2","title":"Methods","text":"<ul> <li><code>normalize()</code>: No-op for binary (already normalized)</li> <li><code>to_bipolar()</code>: Convert to {-1, +1} representation</li> <li><code>to_binary()</code>: Convert to {0, 1} representation</li> <li><code>to_numpy()</code>: Convert to NumPy array</li> </ul>"},{"location":"guide/representations/#common-interface","title":"Common Interface","text":"<p>All representations share a common interface via <code>AbstractHypervector</code>:</p> <pre><code>class AbstractHypervector:\n    @property\n    def vec(self) -&gt; jnp.ndarray:\n        \"\"\"Access underlying JAX array\"\"\"\n\n    @property\n    def shape(self) -&gt; tuple[int, ...]:\n        \"\"\"Vector shape\"\"\"\n\n    @property\n    def dtype(self):\n        \"\"\"Data type\"\"\"\n\n    def normalize(self) -&gt; \"AbstractHypervector\":\n        \"\"\"Normalize the hypervector\"\"\"\n\n    def to_numpy(self) -&gt; np.ndarray:\n        \"\"\"Convert to NumPy array\"\"\"\n</code></pre>"},{"location":"guide/representations/#choosing-a-representation","title":"Choosing a Representation","text":"<p>Use ComplexHypervector when: - You need exact unbinding - Working with sequences or structured data - GPU acceleration is available - Circular convolution is suitable for your task</p> <p>Use RealHypervector when: - You have continuous-valued data - Approximate unbinding is acceptable - Simple operations are preferred - Working with embeddings or features</p> <p>Use BinaryHypervector when: - Deploying to hardware (FPGA, ASIC) - Memory constraints are tight - You need exact unbinding - Working with symbolic/discrete data</p>"},{"location":"guide/representations/#performance-considerations","title":"Performance Considerations","text":"Representation Memory Computation Unbinding Complex 2x (real+imag) FFT overhead Exact Real 1x Fast multiply/add Approximate Binary 1/32x (int vs float) Fastest Exact"},{"location":"guide/representations/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Operations for each representation</li> <li>See Examples for complete workflows</li> <li>Check API Reference for detailed docs</li> </ul>"},{"location":"guide/resonator/","title":"Resonator Networks","text":"<p>Resonator networks solve the factorization problem in Vector Symbolic Architectures: given a composite vector formed by binding multiple factors, recover the original factors.</p> <p>This implementation is based on:</p> <p>Frady, E. P., Kleyko, D., &amp; Sommer, F. T. (2020). A Theory of Sequence Indexing and Working Memory in Recurrent Neural Networks. Neural Computation.</p>"},{"location":"guide/resonator/#the-factorization-problem","title":"The Factorization Problem","text":""},{"location":"guide/resonator/#problem-statement","title":"Problem Statement","text":"<p>Given a composite vector: <pre><code>s = a \u2299 b \u2299 c\n</code></pre></p> <p>Where <code>a</code>, <code>b</code>, <code>c</code> are vectors from known codebooks <code>A</code>, <code>B</code>, <code>C</code>, find the specific vectors that were bound together.</p>"},{"location":"guide/resonator/#why-its-hard","title":"Why It's Hard","text":"<ul> <li>Superposition: After binding, the composite is a new vector that doesn't obviously contain the factors</li> <li>Search space: With codebooks of size N, there are N\u00b3 possible combinations for 3 factors</li> <li>Noise: Binding isn't always perfectly reversible (especially for MAP model)</li> </ul>"},{"location":"guide/resonator/#the-solution-resonator-networks","title":"The Solution: Resonator Networks","text":"<p>Resonator networks use an iterative algorithm that alternates between: 1. Unbinding: Remove current estimates of other factors 2. Cleanup: Project result onto codebook (find nearest clean vector)</p> <p>The algorithm converges to the correct factors through resonance - mutual reinforcement of consistent estimates.</p>"},{"location":"guide/resonator/#quick-start","title":"Quick Start","text":""},{"location":"guide/resonator/#basic-two-factor-factorization","title":"Basic Two-Factor Factorization","text":"<pre><code>from vsax import create_binary_model, VSAMemory\nfrom vsax.resonator import CleanupMemory, Resonator\n\n# Create model and memory\nmodel = create_binary_model(dim=10000, bipolar=True)\nmemory = VSAMemory(model)\nmemory.add_many([\"red\", \"blue\", \"circle\", \"square\"])\n\n# Create composite: red \u2299 circle\ncomposite = model.opset.bind(\n    memory[\"red\"].vec,\n    memory[\"circle\"].vec\n)\n\n# Create codebooks for each factor position\ncolors = CleanupMemory([\"red\", \"blue\"], memory)\nshapes = CleanupMemory([\"circle\", \"square\"], memory)\n\n# Factorize!\nresonator = Resonator([colors, shapes], model.opset)\nfactors = resonator.factorize(composite)\n\nprint(factors)  # [\"red\", \"circle\"]\n</code></pre>"},{"location":"guide/resonator/#three-factor-factorization","title":"Three-Factor Factorization","text":"<pre><code># Add size attribute\nmemory.add_many([\"large\", \"small\"])\n\n# Create composite: red \u2299 circle \u2299 large\ncomposite = model.opset.bind(\n    model.opset.bind(memory[\"red\"].vec, memory[\"circle\"].vec),\n    memory[\"large\"].vec\n)\n\n# Create codebooks\ncolors = CleanupMemory([\"red\", \"blue\"], memory)\nshapes = CleanupMemory([\"circle\", \"square\"], memory)\nsizes = CleanupMemory([\"large\", \"small\"], memory)\n\n# Factorize with three factors\nresonator = Resonator([colors, shapes, sizes], model.opset)\nfactors = resonator.factorize(composite)\n\nprint(factors)  # [\"red\", \"circle\", \"large\"]\n</code></pre>"},{"location":"guide/resonator/#core-components","title":"Core Components","text":""},{"location":"guide/resonator/#cleanupmemory","title":"CleanupMemory","text":"<p><code>CleanupMemory</code> implements codebook projection - finding the nearest vector from a set of known vectors.</p>"},{"location":"guide/resonator/#creating-a-cleanup-memory","title":"Creating a Cleanup Memory","text":"<pre><code>from vsax.resonator import CleanupMemory\n\n# Define codebook symbols\ncolors = CleanupMemory([\"red\", \"blue\", \"green\"], memory)\n\n# With similarity threshold\ncolors = CleanupMemory(\n    [\"red\", \"blue\", \"green\"],\n    memory,\n    threshold=0.5  # Return None if similarity &lt; 0.5\n)\n</code></pre>"},{"location":"guide/resonator/#querying","title":"Querying","text":"<pre><code># Simple query\nresult = colors.query(noisy_vector)\nprint(result)  # \"red\"\n\n# With similarity score\nresult, similarity = colors.query(noisy_vector, return_similarity=True)\nprint(f\"{result}: {similarity:.3f}\")\n\n# Top-k matches\ntop_3 = colors.query_top_k(noisy_vector, k=3)\nfor symbol, sim in top_3:\n    print(f\"{symbol}: {sim:.3f}\")\n</code></pre>"},{"location":"guide/resonator/#how-it-works","title":"How It Works","text":"<p>For binary/bipolar vectors, cleanup uses dot product similarity: <pre><code>similarities = codebook_matrix @ query_vector\nbest_idx = argmax(similarities)\n</code></pre></p> <p>This is equivalent to the projection operation from the paper: <code>g(XX^T v)</code></p>"},{"location":"guide/resonator/#resonator","title":"Resonator","text":"<p><code>Resonator</code> implements the iterative factorization algorithm.</p>"},{"location":"guide/resonator/#creating-a-resonator","title":"Creating a Resonator","text":"<pre><code>from vsax.resonator import Resonator\n\nresonator = Resonator(\n    codebooks=[colors, shapes, sizes],  # One per factor\n    opset=model.opset,                  # Defines bind/unbind\n    max_iterations=100,                 # Stop after N iterations\n    convergence_threshold=3             # Stop if stable for N iterations\n)\n</code></pre>"},{"location":"guide/resonator/#factorization","title":"Factorization","text":"<pre><code># Basic factorization\nfactors = resonator.factorize(composite)\n\n# With initial estimates (optional)\nfactors = resonator.factorize(\n    composite,\n    initial_estimates=[\"red\", \"circle\", \"large\"]\n)\n\n# Get convergence history\nfactors, history = resonator.factorize(composite, return_history=True)\nprint(f\"Converged in {len(history)} iterations\")\nfor i, step in enumerate(history):\n    print(f\"  Iteration {i}: {step}\")\n\n# Batch factorization\nimport jax.numpy as jnp\ncomposites = jnp.stack([comp1, comp2, comp3])\nall_factors = resonator.factorize_batch(composites)\n</code></pre>"},{"location":"guide/resonator/#the-algorithm","title":"The Algorithm","text":""},{"location":"guide/resonator/#resonance-equations","title":"Resonance Equations","text":"<p>For a 3-factor composite <code>s = a \u2299 b \u2299 c</code>, the resonator updates are:</p> <pre><code>\u00e2(t+1) = cleanup_A(s \u2299 inv(b\u0302(t)) \u2299 inv(\u0109(t)))\nb\u0302(t+1) = cleanup_B(s \u2299 inv(\u00e2(t)) \u2299 inv(\u0109(t)))\n\u0109(t+1) = cleanup_C(s \u2299 inv(\u00e2(t)) \u2299 inv(b\u0302(t)))\n</code></pre> <p>Where: - <code>\u00e2, b\u0302, \u0109</code> are current estimates - <code>cleanup_X</code> projects onto codebook X - <code>inv(\u00b7)</code> is the unbinding operation</p>"},{"location":"guide/resonator/#initialization","title":"Initialization","text":"<p>On the first iteration (when estimates are None), the algorithm uses superposition initialization: <pre><code>superposition = sum(all_vectors_in_codebook)\n</code></pre></p> <p>This gives the algorithm information about all possible factors simultaneously.</p>"},{"location":"guide/resonator/#convergence","title":"Convergence","text":"<p>The algorithm stops when: 1. Estimates don't change for <code>convergence_threshold</code> iterations (default: 3), OR 2. <code>max_iterations</code> is reached (default: 100)</p> <p>For binary VSA with exact unbinding, convergence is typically very fast (&lt; 10 iterations).</p>"},{"location":"guide/resonator/#best-practices","title":"Best Practices","text":""},{"location":"guide/resonator/#model-selection","title":"Model Selection","text":"<p>Binary VSA (Recommended for Resonator) - \u2705 Exact unbinding (self-inverse property) - \u2705 Fast convergence - \u2705 High accuracy - \u26a0\ufe0f Requires high dimensionality (\u226510,000)</p> <pre><code>model = create_binary_model(dim=10000, bipolar=True)\n</code></pre> <p>FHRR (Complex) - \u2705 Exact unbinding (complex conjugate) - \u2705 Lower dimensionality needed (\u2265512) - \u26a0\ufe0f More complex operations</p> <pre><code>model = create_fhrr_model(dim=512)\n</code></pre> <p>MAP (Real) - \u26a0\ufe0f Approximate unbinding - \u26a0\ufe0f May require more iterations - \u2705 Simple operations</p> <pre><code>model = create_map_model(dim=512)\n</code></pre>"},{"location":"guide/resonator/#codebook-design","title":"Codebook Design","text":"<p>Separate Semantic Spaces <pre><code># Good: Codebooks represent different semantic categories\ncolors = CleanupMemory([\"red\", \"blue\", \"green\"], memory)\nshapes = CleanupMemory([\"circle\", \"square\"], memory)\nsizes = CleanupMemory([\"large\", \"small\"], memory)\n</code></pre></p> <p>Avoid Overlap <pre><code># Bad: Same symbols in multiple codebooks creates ambiguity\ncodebook1 = CleanupMemory([\"red\", \"blue\"], memory)\ncodebook2 = CleanupMemory([\"red\", \"green\"], memory)  # \"red\" appears twice!\n</code></pre></p> <p>Balanced Sizes <pre><code># Codebooks don't need to be the same size\ncolors = CleanupMemory([\"red\", \"blue\", \"green\", \"yellow\"], memory)  # 4 items\nshapes = CleanupMemory([\"circle\", \"square\"], memory)                # 2 items\n</code></pre></p>"},{"location":"guide/resonator/#performance-tips","title":"Performance Tips","text":"<p>Use Binary Model for Best Performance <pre><code># Binary VSA is fastest and most accurate for resonator\nmodel = create_binary_model(dim=10000, bipolar=True)\n</code></pre></p> <p>Batch Processing <pre><code># Process multiple composites efficiently\ncomposites = jnp.stack([c1, c2, c3, c4])\nresults = resonator.factorize_batch(composites)\n</code></pre></p> <p>Monitor Convergence <pre><code># Check if convergence is too slow\nfactors, history = resonator.factorize(composite, return_history=True)\nif len(history) &gt; 50:\n    print(\"Warning: Slow convergence, may need higher dimensionality\")\n</code></pre></p>"},{"location":"guide/resonator/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guide/resonator/#structured-data-decoding","title":"Structured Data Decoding","text":"<p>Decode attribute-value structures: <pre><code># Encode: object \u2299 color \u2299 shape \u2299 size\nobjects = [\"obj1\", \"obj2\", \"obj3\"]\ncolors = [\"red\", \"blue\", \"green\"]\nshapes = [\"circle\", \"square\", \"triangle\"]\nsizes = [\"large\", \"small\"]\n\n# ... factorize to recover attributes\n</code></pre></p>"},{"location":"guide/resonator/#sequence-indexing","title":"Sequence Indexing","text":"<p>Recover elements from indexed sequences: <pre><code># Encode: item \u2299 position\n# Example: \"apple\" \u2299 position_1 \u2299 \"banana\" \u2299 position_2\n</code></pre></p>"},{"location":"guide/resonator/#tree-decoding","title":"Tree Decoding","text":"<p>Decode hierarchical tree structures: <pre><code># Encode: parent \u2299 left_child \u2299 right_child\n# See examples/resonator_tree_search.py for details\n</code></pre></p>"},{"location":"guide/resonator/#graph-structure-recovery","title":"Graph Structure Recovery","text":"<p>Decode graph edges: <pre><code># Encode: edge \u2299 source_node \u2299 target_node\n</code></pre></p>"},{"location":"guide/resonator/#advanced-topics","title":"Advanced Topics","text":""},{"location":"guide/resonator/#custom-convergence-criteria","title":"Custom Convergence Criteria","text":"<pre><code>class CustomResonator(Resonator):\n    def factorize(self, composite, **kwargs):\n        # Custom convergence logic\n        # Check similarity scores, add early stopping, etc.\n        ...\n</code></pre>"},{"location":"guide/resonator/#hierarchical-factorization","title":"Hierarchical Factorization","text":"<p>For nested structures, factorize recursively: <pre><code># First level: Get high-level factors\nfactors_L1 = resonator_L1.factorize(composite)\n\n# Second level: Factorize one of the factors\nfactors_L2 = resonator_L2.factorize(factors_L1[0])\n</code></pre></p>"},{"location":"guide/resonator/#error-analysis","title":"Error Analysis","text":"<pre><code># Check which factors are uncertain\nfactors, history = resonator.factorize(composite, return_history=True)\n\n# Look for oscillation (indicates ambiguity)\nfor i in range(len(history) - 5):\n    if history[i] == history[i + 4]:\n        print(f\"Factor {i} may be ambiguous\")\n</code></pre>"},{"location":"guide/resonator/#examples","title":"Examples","text":"<p>See <code>examples/resonator_tree_search.py</code> for complete working examples:</p> <ol> <li>Simple tree decoding - Basic two-factor case</li> <li>Multiple trees - Decoding different structures</li> <li>Convergence history - Monitoring the iterative process</li> <li>Nested trees - Hierarchical structures</li> <li>Batch processing - Multiple composites at once</li> <li>Error correction - Robustness to noise</li> </ol>"},{"location":"guide/resonator/#references","title":"References","text":"<ul> <li>Frady, E. P., Kleyko, D., &amp; Sommer, F. T. (2020). A Theory of Sequence Indexing and Working Memory in Recurrent Neural Networks. Neural Computation.</li> <li>Plate, T. A. (1995). Holographic reduced representations. IEEE Transactions on Neural Networks.</li> <li>Kanerva, P. (2009). Hyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. Cognitive Computation.</li> </ul>"},{"location":"guide/sampling/","title":"Sampling Hypervectors","text":"<p>VSAX provides sampling functions to generate random basis hypervectors for each representation type.</p>"},{"location":"guide/sampling/#overview","title":"Overview","text":"Function Output Distribution Use With <code>sample_random</code> Real vectors Normal N(0,1) RealHypervector, MAP <code>sample_complex_random</code> Complex vectors Uniform phase ComplexHypervector, FHRR <code>sample_binary_random</code> Binary vectors Uniform {-1,+1} or {0,1} BinaryHypervector, Binary"},{"location":"guide/sampling/#sample_random","title":"sample_random","text":"<p>Samples real-valued vectors from standard normal distribution.</p> <pre><code>from vsax.sampling import sample_random\nimport jax\n\nkey = jax.random.PRNGKey(42)\nvectors = sample_random(dim=512, n=10, key=key)\n\n# Shape: (10, 512)\n# Elements: drawn from N(0, 1)\n</code></pre> <p>Parameters: - <code>dim</code>: Vector dimensionality - <code>n</code>: Number of vectors to sample - <code>key</code>: JAX random key (optional, defaults to PRNGKey(0))</p>"},{"location":"guide/sampling/#sample_complex_random","title":"sample_complex_random","text":"<p>Samples unit-magnitude complex vectors with uniformly random phases.</p> <pre><code>from vsax.sampling import sample_complex_random\n\nkey = jax.random.PRNGKey(42)\nvectors = sample_complex_random(dim=512, n=10, key=key)\n\n# All magnitudes are 1.0\nassert jnp.allclose(jnp.abs(vectors), 1.0)\n\n# Phases uniformly distributed in [0, 2\u03c0)\nphases = jnp.angle(vectors)\n</code></pre> <p>Properties: - All elements have magnitude 1.0 - Phases uniformly distributed in [0, 2\u03c0) - Suitable for FHRR operations</p>"},{"location":"guide/sampling/#sample_binary_random","title":"sample_binary_random","text":"<p>Samples binary vectors with values from {-1, +1} (bipolar) or {0, 1} (binary).</p> <pre><code>from vsax.sampling import sample_binary_random\n\nkey = jax.random.PRNGKey(42)\n\n# Bipolar sampling (default)\nbipolar_vecs = sample_binary_random(dim=512, n=10, key=key, bipolar=True)\nassert jnp.all(jnp.isin(bipolar_vecs, jnp.array([-1, 1])))\n\n# Binary sampling\nbinary_vecs = sample_binary_random(dim=512, n=10, key=key, bipolar=False)\nassert jnp.all(jnp.isin(binary_vecs, jnp.array([0, 1])))\n</code></pre> <p>Parameters: - <code>dim</code>: Vector dimensionality - <code>n</code>: Number of vectors to sample - <code>key</code>: JAX random key (optional) - <code>bipolar</code>: If True, sample from {-1, +1}; if False, sample from {0, 1}</p>"},{"location":"guide/sampling/#reproducibility","title":"Reproducibility","text":"<p>Use JAX's PRNG system for reproducible sampling:</p> <pre><code># Same key = same samples\nkey = jax.random.PRNGKey(42)\nsamples1 = sample_random(dim=100, n=5, key=key)\nsamples2 = sample_random(dim=100, n=5, key=key)\nassert jnp.array_equal(samples1, samples2)\n\n# Different keys = different samples\nkey2 = jax.random.PRNGKey(43)\nsamples3 = sample_random(dim=100, n=5, key=key2)\nassert not jnp.array_equal(samples1, samples3)\n</code></pre>"},{"location":"guide/sampling/#complete-example","title":"Complete Example","text":"<pre><code>import jax\nfrom vsax import VSAModel, ComplexHypervector, FHRROperations, sample_complex_random\n\n# Create model with sampler\nmodel = VSAModel(\n    dim=512,\n    rep_cls=ComplexHypervector,\n    opset=FHRROperations(),\n    sampler=sample_complex_random\n)\n\n# Use model's sampler\nkey = jax.random.PRNGKey(42)\nbasis_vectors = model.sampler(dim=model.dim, n=100, key=key)\n\n# Create hypervectors\nhvs = [model.rep_cls(vec).normalize() for vec in basis_vectors]\n</code></pre>"},{"location":"guide/sampling/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Models to combine samplers with representations</li> <li>See Examples for complete workflows</li> </ul>"},{"location":"guide/similarity/","title":"Similarity Metrics","text":"<p>Similarity metrics allow you to compare hypervectors and find related concepts. VSAX provides three main similarity functions that work across all VSA models (FHRR, MAP, Binary).</p>"},{"location":"guide/similarity/#available-metrics","title":"Available Metrics","text":""},{"location":"guide/similarity/#cosine-similarity","title":"Cosine Similarity","text":"<p>Cosine similarity measures the cosine of the angle between two vectors, ranging from -1 (opposite) to 1 (identical direction).</p> <pre><code>from vsax import create_fhrr_model, VSAMemory\nfrom vsax.similarity import cosine_similarity\n\nmodel = create_fhrr_model(dim=512)\nmemory = VSAMemory(model)\nmemory.add_many([\"dog\", \"cat\", \"wolf\"])\n\n# Compare similarity\nsim_dog_cat = cosine_similarity(memory[\"dog\"], memory[\"cat\"])\nsim_dog_wolf = cosine_similarity(memory[\"dog\"], memory[\"wolf\"])\n\nprint(f\"Dog-Cat similarity: {sim_dog_cat:.3f}\")\nprint(f\"Dog-Wolf similarity: {sim_dog_wolf:.3f}\")\n</code></pre> <p>When to use: Best for general-purpose similarity comparisons. Normalized to [-1, 1] range.</p>"},{"location":"guide/similarity/#dot-product-similarity","title":"Dot Product Similarity","text":"<p>Dot product provides an unnormalized similarity measure. Higher values indicate more similarity.</p> <pre><code>from vsax.similarity import dot_similarity\n\n# Works with all hypervector types\nsimilarity = dot_similarity(memory[\"dog\"], memory[\"cat\"])\nprint(f\"Dot product: {similarity:.3f}\")\n</code></pre> <p>When to use: When you need raw similarity scores or when vectors are already normalized.</p>"},{"location":"guide/similarity/#hamming-similarity","title":"Hamming Similarity","text":"<p>Hamming similarity measures the proportion of matching elements, ranging from 0 (completely different) to 1 (identical).</p> <pre><code>from vsax import create_binary_model\nfrom vsax.similarity import hamming_similarity\n\nmodel = create_binary_model(dim=10000, bipolar=True)\nmemory = VSAMemory(model)\nmemory.add_many([\"dog\", \"cat\"])\n\nsimilarity = hamming_similarity(memory[\"dog\"], memory[\"cat\"])\nprint(f\"Hamming similarity: {similarity:.3f}\")\n</code></pre> <p>When to use: Best for binary hypervectors. Counts matching bits.</p>"},{"location":"guide/similarity/#batch-similarity-search","title":"Batch Similarity Search","text":"<p>For efficient similarity search across multiple candidates, use <code>vmap_similarity</code>:</p> <pre><code>import jax.numpy as jnp\nfrom vsax.utils import vmap_similarity, format_similarity_results\n\n# Create query and candidates\nquery = memory[\"dog\"].vec\ncandidates = jnp.stack([\n    memory[\"cat\"].vec,\n    memory[\"wolf\"].vec,\n    memory[\"lion\"].vec,\n])\n\n# Compute all similarities at once\nsimilarities = vmap_similarity(None, query, candidates)\n\n# Find best match\nbest_match_idx = jnp.argmax(similarities)\nprint(f\"Best match: {['cat', 'wolf', 'lion'][int(best_match_idx)]}\")\n\n# Format results nicely\nresults = format_similarity_results(\n    \"dog\",\n    [\"cat\", \"wolf\", \"lion\"],\n    similarities,\n    top_k=3\n)\nprint(results)\n</code></pre>"},{"location":"guide/similarity/#use-cases","title":"Use Cases","text":""},{"location":"guide/similarity/#1-finding-similar-concepts","title":"1. Finding Similar Concepts","text":"<pre><code># Build knowledge base\nanimals = [\"dog\", \"cat\", \"wolf\", \"lion\", \"eagle\", \"snake\"]\nmemory.add_many(animals)\n\n# Query for similar animals\nquery = memory[\"wolf\"]\ncandidates = jnp.stack([memory[a].vec for a in animals if a != \"wolf\"])\nsimilarities = vmap_similarity(None, query.vec, candidates)\n\n# Top 3 most similar\ntop_indices = jnp.argsort(similarities)[-3:][::-1]\nfor idx in top_indices:\n    animal = [a for a in animals if a != \"wolf\"][int(idx)]\n    sim = float(similarities[int(idx)])\n    print(f\"  {animal}: {sim:.3f}\")\n</code></pre>"},{"location":"guide/similarity/#2-concept-retrieval","title":"2. Concept Retrieval","text":"<pre><code># Encode structured data\nfrom vsax.encoders import DictEncoder\n\nencoder = DictEncoder(model, memory)\n\n# Add concepts to memory\nmemory.add_many([\"subject\", \"action\", \"object\"])\nmemory.add_many([\"dog\", \"cat\", \"runs\", \"sleeps\", \"bone\", \"mouse\"])\n\n# Encode facts\nfact1 = encoder.encode({\"subject\": \"dog\", \"action\": \"runs\"})\nfact2 = encoder.encode({\"subject\": \"cat\", \"action\": \"sleeps\"})\nfact3 = encoder.encode({\"subject\": \"dog\", \"object\": \"bone\"})\n\n# Query: What does the dog do?\nquery_concepts = model.opset.bind(memory[\"subject\"].vec, memory[\"dog\"].vec)\n\n# Find most similar fact\nfacts = jnp.stack([fact1.vec, fact2.vec, fact3.vec])\nsimilarities = vmap_similarity(None, query_concepts, facts)\n\nbest_fact = int(jnp.argmax(similarities))\nprint(f\"Most similar fact: {['dog runs', 'cat sleeps', 'dog-bone'][best_fact]}\")\n</code></pre>"},{"location":"guide/similarity/#3-similarity-matrix","title":"3. Similarity Matrix","text":"<pre><code># Compute all pairwise similarities\nconcepts = [\"dog\", \"cat\", \"wolf\", \"eagle\"]\nn = len(concepts)\n\nprint(\"\\nSimilarity Matrix:\")\nprint(\"       \" + \"\".join(f\"{c:&gt;8s}\" for c in concepts))\n\nfor i, concept1 in enumerate(concepts):\n    print(f\"{concept1:&gt;8s}\", end=\"\")\n    for j, concept2 in enumerate(concepts):\n        sim = cosine_similarity(memory[concept1], memory[concept2])\n        print(f\"{sim:8.3f}\", end=\"\")\n    print()\n</code></pre>"},{"location":"guide/similarity/#comparison-of-metrics","title":"Comparison of Metrics","text":"Metric Range Best For Complexity Cosine [-1, 1] General similarity O(n) Dot Product Unbounded Normalized vectors O(n) Hamming [0, 1] Binary vectors O(n)"},{"location":"guide/similarity/#performance-tips","title":"Performance Tips","text":"<ol> <li> <p>Use vmap_similarity for batch queries: Much faster than loop ing with individual similarity calls</p> </li> <li> <p>Pre-stack candidates: Stack candidate vectors once, reuse for multiple queries</p> </li> <li> <p>JIT compilation: For repeated similarity computations, wrap in <code>jax.jit</code></p> </li> </ol> <pre><code>import jax\n\n@jax.jit\ndef fast_similarity_search(query, candidates):\n    return vmap_similarity(None, query, candidates)\n\n# First call compiles, subsequent calls are fast\nsimilarities = fast_similarity_search(query_vec, candidate_vecs)\n</code></pre> <ol> <li>GPU acceleration: VSAX automatically uses GPU when available through JAX</li> </ol>"},{"location":"guide/similarity/#complete-example","title":"Complete Example","text":"<p>See <code>examples/similarity_search.py</code> for a comprehensive demonstration of similarity search techniques.</p>"}]}