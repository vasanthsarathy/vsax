{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 15: Program Synthesis with VSA\n",
    "\n",
    "This tutorial demonstrates how to use Vector Symbolic Architectures for program synthesis — representing, searching, composing, and decomposing programs as hypervectors.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- How to encode programs as structured role-filler hypervectors\n",
    "- How to build a searchable program library\n",
    "- How to query programs by partial specification (e.g., \"which program uses addition?\")\n",
    "- How to compose programs into multi-step pipelines\n",
    "- How to decompose pipelines back into individual steps via unbinding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why VSA for Program Synthesis?\n",
    "\n",
    "Program synthesis — automatically constructing programs from specifications — is a core challenge in AI. VSAs offer a natural fit:\n",
    "\n",
    "1. **Structured Representation**: Programs have structure (operation, arguments, constants) that maps directly to role-filler binding\n",
    "2. **Compositional**: Programs can be composed into pipelines using bundling and binding\n",
    "3. **Searchable**: A library of programs can be searched by partial specification using similarity\n",
    "4. **Decomposable**: Composed programs can be taken apart via unbinding to recover sub-programs\n",
    "5. **Fixed-Size**: Every program, regardless of complexity, is a single fixed-dimensional vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from vsax import create_fhrr_model, VSAMemory\n",
    "from vsax.similarity import cosine_similarity\n",
    "\n",
    "# FHRR gives exact unbinding — critical for decomposition\n",
    "model = create_fhrr_model(dim=1024)\n",
    "memory = VSAMemory(model)\n",
    "\n",
    "# Define vocabulary\n",
    "operations = [\"add\", \"sub\", \"mul\", \"inc\", \"double\", \"negate\"]\n",
    "roles = [\"op\", \"arg\", \"const\", \"step1\", \"step2\"]\n",
    "variables = [\"x\"]\n",
    "constants = [\"one\", \"two\", \"three\", \"five\"]\n",
    "\n",
    "memory.add_many(operations + roles + variables + constants)\n",
    "\n",
    "print(f\"Model: {model.rep_cls.__name__}, dim={model.dim}\")\n",
    "print(f\"Vocabulary: {len(memory)} symbols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Encoding Programs as Hypervectors\n",
    "\n",
    "Each program in our DSL has three components:\n",
    "- **Operation**: what to do (`add`, `sub`, `mul`, etc.)\n",
    "- **Argument**: the input variable (`x`)\n",
    "- **Constant**: an optional numeric operand (`one`, `two`, etc.)\n",
    "\n",
    "We encode a program as a role-filler structure:\n",
    "```\n",
    "program = bundle(bind(op_role, operation), bind(arg_role, variable), bind(const_role, constant))\n",
    "```\n",
    "\n",
    "Bundling creates a superposition of the three role-filler pairs. Each pair is recoverable via unbinding, though the other pairs contribute some noise. Higher dimensions reduce this noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opset = model.opset\n",
    "\n",
    "def encode_program(op_name, arg_name, const_name=None):\n",
    "    \"\"\"Encode a program as a role-filler hypervector.\"\"\"\n",
    "    parts = [\n",
    "        opset.bind(memory[\"op\"].vec, memory[op_name].vec),\n",
    "        opset.bind(memory[\"arg\"].vec, memory[arg_name].vec),\n",
    "    ]\n",
    "    if const_name is not None:\n",
    "        parts.append(opset.bind(memory[\"const\"].vec, memory[const_name].vec))\n",
    "    return opset.bundle(*parts)\n",
    "\n",
    "# Encode six programs\n",
    "programs = {\n",
    "    \"add(x,3)\":    encode_program(\"add\", \"x\", \"three\"),\n",
    "    \"sub(x,2)\":    encode_program(\"sub\", \"x\", \"two\"),\n",
    "    \"mul(x,5)\":    encode_program(\"mul\", \"x\", \"five\"),\n",
    "    \"inc(x)\":      encode_program(\"inc\", \"x\", \"one\"),\n",
    "    \"double(x)\":   encode_program(\"double\", \"x\", \"two\"),\n",
    "    \"negate(x)\":   encode_program(\"negate\", \"x\"),\n",
    "}\n",
    "\n",
    "print(\"Encoded programs:\")\n",
    "for name in programs:\n",
    "    print(f\"  {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Building a Program Library\n",
    "\n",
    "The program library is simply a dictionary mapping names to hypervectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = programs.copy()\n",
    "print(f\"Program library: {len(library)} programs\")\n",
    "for name in library:\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Querying Programs — Extracting Attributes\n",
    "\n",
    "Given a program hypervector, we can extract any attribute by unbinding the corresponding role:\n",
    "\n",
    "```\n",
    "recovered_op = unbind(program, op_role)\n",
    "```\n",
    "\n",
    "Since each program is a bundle of multiple role-filler pairs, unbinding one role recovers the correct filler plus noise from the other pairs. The correct answer always has the highest similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attribute(program_vec, role_name, candidates):\n",
    "    \"\"\"Extract an attribute from a program by unbinding the role.\"\"\"\n",
    "    role_vec = memory[role_name].vec\n",
    "    recovered = opset.unbind(program_vec, role_vec)\n",
    "\n",
    "    best_name, best_sim = None, -1.0\n",
    "    for name in candidates:\n",
    "        sim = float(cosine_similarity(recovered, memory[name].vec))\n",
    "        if sim > best_sim:\n",
    "            best_sim = sim\n",
    "            best_name = name\n",
    "    return best_name, best_sim\n",
    "\n",
    "# Extract the operation from each program\n",
    "print(\"Extracting operations from programs:\")\n",
    "for prog_name, prog_vec in library.items():\n",
    "    op, sim = extract_attribute(prog_vec, \"op\", operations)\n",
    "    print(f\"  {prog_name:15s} -> op={op:8s} (similarity={sim:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the constant from programs that have one\n",
    "print(\"Extracting constants from programs:\")\n",
    "for prog_name, prog_vec in library.items():\n",
    "    const, sim = extract_attribute(prog_vec, \"const\", constants)\n",
    "    has_const = \"<-- match\" if sim > 0.05 else \"(no constant)\"\n",
    "    print(f\"  {prog_name:15s} -> const={const:5s} (similarity={sim:.3f}) {has_const}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how `negate(x)` — which has no constant bound — produces a much lower similarity than programs that do have a constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Searching by Specification\n",
    "\n",
    "We can search the library for programs matching a partial specification. For example, \"find all programs that use addition\":\n",
    "\n",
    "```\n",
    "query = bind(op_role, add)\n",
    "```\n",
    "\n",
    "This query is compared against every library entry using cosine similarity. Because the query is one of the role-filler pairs bundled into the program, the matching program will have the highest similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_library(query_vec, library, top_k=3):\n",
    "    \"\"\"Search library for programs similar to a query.\"\"\"\n",
    "    results = []\n",
    "    for name, prog_vec in library.items():\n",
    "        sim = float(cosine_similarity(query_vec, prog_vec))\n",
    "        results.append((name, sim))\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results[:top_k]\n",
    "\n",
    "# Query: \"which programs use addition?\"\n",
    "query_add = opset.bind(memory[\"op\"].vec, memory[\"add\"].vec)\n",
    "print(\"Query: programs that use 'add'\")\n",
    "for name, sim in search_library(query_add, library):\n",
    "    print(f\"  {name:15s}  similarity={sim:.3f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Query: \"which programs use constant 'two'?\"\n",
    "query_two = opset.bind(memory[\"const\"].vec, memory[\"two\"].vec)\n",
    "print(\"Query: programs that use constant 'two'\")\n",
    "for name, sim in search_library(query_two, library):\n",
    "    print(f\"  {name:15s}  similarity={sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct programs clearly dominate. Both `sub(x,2)` and `double(x)` use constant `two`, so they score equally high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Composing Programs into Pipelines\n",
    "\n",
    "We can compose multiple programs into a pipeline by binding each program to a step role:\n",
    "\n",
    "```\n",
    "pipeline = bundle(bind(step1, program_A), bind(step2, program_B))\n",
    "```\n",
    "\n",
    "This represents: \"first apply program A, then apply program B.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline: first double(x), then add(x, 3)\n",
    "# Semantically: add(double(x), 3) = 2x + 3\n",
    "prog_double = library[\"double(x)\"]\n",
    "prog_add3 = library[\"add(x,3)\"]\n",
    "\n",
    "pipeline = opset.bundle(\n",
    "    opset.bind(memory[\"step1\"].vec, prog_double),\n",
    "    opset.bind(memory[\"step2\"].vec, prog_add3),\n",
    ")\n",
    "\n",
    "print(\"Pipeline: step1=double(x), step2=add(x,3)\")\n",
    "print(f\"Pipeline vector shape: {pipeline.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Decomposing Pipelines\n",
    "\n",
    "Given a pipeline, we can recover each step by unbinding the step role, then searching the library:\n",
    "\n",
    "```\n",
    "recovered_step1 = unbind(pipeline, step1_role)\n",
    "```\n",
    "\n",
    "The recovered vector is compared against all library programs to identify the best match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_pipeline(pipeline_vec, library):\n",
    "    \"\"\"Decompose a pipeline into its constituent steps.\"\"\"\n",
    "    steps = {}\n",
    "    for step_name in [\"step1\", \"step2\"]:\n",
    "        step_role = memory[step_name].vec\n",
    "        recovered = opset.unbind(pipeline_vec, step_role)\n",
    "\n",
    "        # Search library for the best match\n",
    "        best_name, best_sim = None, -1.0\n",
    "        for prog_name, prog_vec in library.items():\n",
    "            sim = float(cosine_similarity(recovered, prog_vec))\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                best_name = prog_name\n",
    "        steps[step_name] = (best_name, best_sim)\n",
    "    return steps\n",
    "\n",
    "steps = decompose_pipeline(pipeline, library)\n",
    "print(\"Decomposed pipeline:\")\n",
    "for step, (name, sim) in steps.items():\n",
    "    print(f\"  {step}: {name} (similarity={sim:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another pipeline: first negate(x), then mul(x, 5)\n",
    "# Semantically: mul(negate(x), 5) = -5x\n",
    "pipeline2 = opset.bundle(\n",
    "    opset.bind(memory[\"step1\"].vec, library[\"negate(x)\"]),\n",
    "    opset.bind(memory[\"step2\"].vec, library[\"mul(x,5)\"]),\n",
    ")\n",
    "\n",
    "steps2 = decompose_pipeline(pipeline2, library)\n",
    "print(\"Pipeline 2 decomposed:\")\n",
    "for step, (name, sim) in steps2.items():\n",
    "    print(f\"  {step}: {name} (similarity={sim:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Role-Filler Encoding**: Programs are naturally represented as `bundle(bind(role, filler), ...)` structures\n",
    "2. **Attribute Extraction**: Unbinding a role from a program recovers the filler — the correct answer always has the highest similarity\n",
    "3. **Library Search**: Partial specifications (e.g., \"uses addition\") find matching programs via similarity\n",
    "4. **Composition**: Multi-step pipelines are built by binding programs to step roles and bundling\n",
    "5. **Decomposition**: Unbinding step roles from a pipeline recovers the original sub-programs as best matches\n",
    "6. **Fixed-Size Vectors**: Every program — simple or composed — is a single 1024-dimensional vector\n",
    "7. **Noise vs. Signal**: Bundling introduces noise, but the correct answer always dominates — higher dimensions improve signal-to-noise ratio\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Scale the DSL with more operations, control flow, and data types\n",
    "- Explore program search over larger libraries (100+ programs)\n",
    "- Use resonator networks for factorizing programs with unknown structure\n",
    "- Combine with neural models for learning program representations from examples\n",
    "- See Tutorial 7 (Hierarchical Structures) for recursive composition patterns\n",
    "- See Tutorial 2 (Knowledge Graph Reasoning) for more role-filler binding examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
