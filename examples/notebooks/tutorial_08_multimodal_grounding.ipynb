{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 8: Multi-Modal Concept Grounding with MNIST\n",
    "\n",
    "In this tutorial, we demonstrate one of VSA's most powerful capabilities: **multi-modal concept grounding** - the ability to fuse heterogeneous representations (vision, language, and symbolic operations) into unified concept representations.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Encode multiple modalities (visual, symbolic, arithmetic) in the same VSA space\n",
    "- Build rich concept representations that combine:\n",
    "  - **Visual features**: MNIST digit images\n",
    "  - **Symbolic atoms**: The concept \"3\" as a basis vector\n",
    "  - **Arithmetic relationships**: 1+2=3, 2+1=3, 4-1=3, etc.\n",
    "- Perform cross-modal queries:\n",
    "  - \"What is 1 + 2?\" → Retrieve \"3\"\n",
    "  - \"Show me the image for 4-1\" → Retrieve MNIST prototype of 3\n",
    "  - \"What operations produce 5?\" → Find all arithmetic facts\n",
    "- Add knowledge online without retraining\n",
    "- Compare VSA's advantages over neural networks\n",
    "\n",
    "## Why Multi-Modal Grounding?\n",
    "\n",
    "Traditional machine learning models struggle to combine heterogeneous data:\n",
    "- Neural networks need separate modules for vision, language, reasoning\n",
    "- Hard to add new facts online (requires retraining)\n",
    "- Difficult to query across modalities\n",
    "\n",
    "VSA excels at multi-modal grounding because:\n",
    "- **Heterogeneous binding**: Different data types share the same hyperdimensional space\n",
    "- **Compositional semantics**: Concepts are defined by their relationships\n",
    "- **Online learning**: Add new associations by simple bundling\n",
    "- **Interpretability**: Can unbind to inspect components\n",
    "\n",
    "Let's see this in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from vsax import create_fhrr_model, VSAMemory\n",
    "from vsax.encoders import ScalarEncoder\n",
    "from vsax.similarity import cosine_similarity\n",
    "\n",
    "# Create FHRR model (exact unbinding is important for compositional queries)\n",
    "model = create_fhrr_model(dim=2048)\n",
    "memory = VSAMemory(model)\n",
    "\n",
    "print(f\"Model: {model.opset.__class__.__name__}\")\n",
    "print(f\"Dimension: {model.dim}\")\n",
    "print(f\"Representation: {model.rep_cls.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Multi-Modal Encoding\n",
    "\n",
    "We'll encode three modalities:\n",
    "1. **Visual**: MNIST digit images (0-9)\n",
    "2. **Symbolic**: Basis vectors for numbers, operations, and roles\n",
    "3. **Arithmetic**: Relationships between numbers through operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Visual Encoding: MNIST Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST digits (8x8 sklearn version for speed)\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "print(f\"Loaded {len(X)} MNIST images\")\n",
    "print(f\"Image shape: {digits.images[0].shape}\")\n",
    "print(f\"Classes: {np.unique(y)}\")\n",
    "\n",
    "# Visualize sample digits\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='gray')\n",
    "    ax.set_title(f\"Label: {y[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visual prototypes for each digit\n",
    "def encode_image(model, memory, image_vector, feature_names):\n",
    "    \"\"\"Encode an image using ScalarEncoder for each pixel.\"\"\"\n",
    "    encoder = ScalarEncoder(model, memory)\n",
    "    \n",
    "    # Ensure feature basis vectors exist\n",
    "    for name in feature_names:\n",
    "        if name not in memory:\n",
    "            memory.add(name)\n",
    "    \n",
    "    # Encode image\n",
    "    encoded = jnp.zeros(model.dim, dtype=jnp.complex64)\n",
    "    for i, (value, feature_name) in enumerate(zip(image_vector, feature_names)):\n",
    "        if value > 0:  # Only encode non-zero pixels\n",
    "            feature_vec = encoder.encode(feature_name, float(value))\n",
    "            encoded = encoded + feature_vec\n",
    "    \n",
    "    # Normalize\n",
    "    return encoded / jnp.linalg.norm(encoded)\n",
    "\n",
    "# Create feature names for pixels\n",
    "feature_names = [f\"pixel_{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "# Build visual prototypes (average of encoded images per class)\n",
    "visual_prototypes = {}\n",
    "num_samples_per_class = 50  # Use subset for speed\n",
    "\n",
    "print(\"Building visual prototypes...\")\n",
    "for digit in range(10):\n",
    "    class_samples = X[y == digit][:num_samples_per_class]\n",
    "    encoded_samples = [\n",
    "        encode_image(model, memory, sample, feature_names)\n",
    "        for sample in class_samples\n",
    "    ]\n",
    "    # Average and normalize\n",
    "    prototype = sum(encoded_samples) / len(encoded_samples)\n",
    "    visual_prototypes[digit] = prototype / jnp.linalg.norm(prototype)\n",
    "    print(f\"  Digit {digit}: {len(class_samples)} samples\")\n",
    "\n",
    "print(\"\\nVisual prototypes created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Symbolic Encoding: Numbers, Operations, and Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create symbolic basis vectors\n",
    "symbols = [\n",
    "    # Numbers as symbols (distinct from visual prototypes)\n",
    "    \"num_0\", \"num_1\", \"num_2\", \"num_3\", \"num_4\",\n",
    "    \"num_5\", \"num_6\", \"num_7\", \"num_8\", \"num_9\",\n",
    "    # Operations\n",
    "    \"op_plus\", \"op_minus\",\n",
    "    # Roles for binding arithmetic facts\n",
    "    \"role_operand1\", \"role_operator\", \"role_operand2\", \"role_result\",\n",
    "    # Query marker\n",
    "    \"UNKNOWN\"\n",
    "]\n",
    "\n",
    "memory.add_many(symbols)\n",
    "\n",
    "print(f\"Created {len(symbols)} symbolic basis vectors\")\n",
    "print(f\"\\nSymbols: {', '.join(symbols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Encode Arithmetic Facts\n",
    "\n",
    "We'll encode arithmetic facts using role-filler binding:\n",
    "- Fact: \"1 + 2 = 3\"\n",
    "- Encoding: `bundle(bind(role_operand1, num_1), bind(role_operator, op_plus), bind(role_operand2, num_2), bind(role_result, num_3))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_arithmetic_fact(memory, model, operand1: int, operator: str, operand2: int, result: int):\n",
    "    \"\"\"\n",
    "    Encode an arithmetic fact like \"1 + 2 = 3\".\n",
    "    \n",
    "    Uses role-filler binding:\n",
    "    fact = bundle(\n",
    "        bind(role_operand1, num_1),\n",
    "        bind(role_operator, op_plus),\n",
    "        bind(role_operand2, num_2),\n",
    "        bind(role_result, num_3)\n",
    "    )\n",
    "    \"\"\"\n",
    "    # Get basis vectors\n",
    "    role_op1 = memory[\"role_operand1\"].vec\n",
    "    role_op = memory[\"role_operator\"].vec\n",
    "    role_op2 = memory[\"role_operand2\"].vec\n",
    "    role_res = memory[\"role_result\"].vec\n",
    "    \n",
    "    num_op1 = memory[f\"num_{operand1}\"].vec\n",
    "    op_vec = memory[f\"op_{operator}\"].vec\n",
    "    num_op2 = memory[f\"num_{operand2}\"].vec\n",
    "    num_res = memory[f\"num_{result}\"].vec\n",
    "    \n",
    "    # Bind roles to fillers\n",
    "    bound_op1 = model.opset.bind(role_op1, num_op1)\n",
    "    bound_op = model.opset.bind(role_op, op_vec)\n",
    "    bound_op2 = model.opset.bind(role_op2, num_op2)\n",
    "    bound_res = model.opset.bind(role_res, num_res)\n",
    "    \n",
    "    # Bundle all components\n",
    "    fact = model.opset.bundle(bound_op1, bound_op, bound_op2, bound_res)\n",
    "    \n",
    "    return fact\n",
    "\n",
    "# Test: encode \"1 + 2 = 3\"\n",
    "fact_1_plus_2 = encode_arithmetic_fact(memory, model, 1, \"plus\", 2, 3)\n",
    "print(f\"Encoded fact: 1 + 2 = 3\")\n",
    "print(f\"Fact shape: {fact_1_plus_2.shape}\")\n",
    "print(f\"Fact dtype: {fact_1_plus_2.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all addition facts for digits 0-9\n",
    "addition_facts = {}\n",
    "subtraction_facts = {}\n",
    "\n",
    "print(\"Generating arithmetic facts...\")\n",
    "print(\"\\nAddition facts:\")\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        result = i + j\n",
    "        if result < 10:  # Only single-digit results\n",
    "            fact = encode_arithmetic_fact(memory, model, i, \"plus\", j, result)\n",
    "            addition_facts[(i, j)] = fact\n",
    "            if i <= 2 and j <= 2:  # Print a few examples\n",
    "                print(f\"  {i} + {j} = {result}\")\n",
    "\n",
    "print(f\"\\nTotal addition facts: {len(addition_facts)}\")\n",
    "\n",
    "print(\"\\nSubtraction facts:\")\n",
    "for i in range(10):\n",
    "    for j in range(i + 1):  # Only subtract smaller from larger\n",
    "        result = i - j\n",
    "        fact = encode_arithmetic_fact(memory, model, i, \"minus\", j, result)\n",
    "        subtraction_facts[(i, j)] = fact\n",
    "        if i <= 3 and j <= 2:  # Print a few examples\n",
    "            print(f\"  {i} - {j} = {result}\")\n",
    "\n",
    "print(f\"\\nTotal subtraction facts: {len(subtraction_facts)}\")\n",
    "print(f\"\\nTotal arithmetic facts: {len(addition_facts) + len(subtraction_facts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Build Rich Concept Representations\n",
    "\n",
    "Now we'll create **rich concept representations** for each digit that combine:\n",
    "1. Visual prototype (MNIST images)\n",
    "2. Symbolic basis (the atom \"num_3\")\n",
    "3. All arithmetic facts involving that number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_concept(digit: int, visual_prototypes, memory, model, addition_facts, subtraction_facts):\n",
    "    \"\"\"\n",
    "    Build a rich concept representation for a digit.\n",
    "    \n",
    "    Combines:\n",
    "    - Visual prototype (MNIST)\n",
    "    - Symbolic basis (num_X)\n",
    "    - All arithmetic facts involving this digit\n",
    "    \"\"\"\n",
    "    components = []\n",
    "    \n",
    "    # 1. Visual prototype\n",
    "    components.append(visual_prototypes[digit])\n",
    "    \n",
    "    # 2. Symbolic basis\n",
    "    components.append(memory[f\"num_{digit}\"].vec)\n",
    "    \n",
    "    # 3. Arithmetic facts where this digit is the result\n",
    "    for (i, j), fact in addition_facts.items():\n",
    "        if i + j == digit:\n",
    "            components.append(fact)\n",
    "    \n",
    "    for (i, j), fact in subtraction_facts.items():\n",
    "        if i - j == digit:\n",
    "            components.append(fact)\n",
    "    \n",
    "    # Bundle all components\n",
    "    concept = model.opset.bundle(*components)\n",
    "    \n",
    "    return concept\n",
    "\n",
    "# Build rich concepts for all digits\n",
    "concepts = {}\n",
    "print(\"Building rich concept representations...\\n\")\n",
    "\n",
    "for digit in range(10):\n",
    "    concept = build_concept(digit, visual_prototypes, memory, model, addition_facts, subtraction_facts)\n",
    "    concepts[digit] = concept\n",
    "    \n",
    "    # Count how many facts involve this digit as result\n",
    "    num_add_facts = sum(1 for (i, j) in addition_facts.keys() if i + j == digit)\n",
    "    num_sub_facts = sum(1 for (i, j) in subtraction_facts.keys() if i - j == digit)\n",
    "    \n",
    "    print(f\"Digit {digit}: {num_add_facts} addition facts + {num_sub_facts} subtraction facts\")\n",
    "\n",
    "print(\"\\nRich concepts created!\")\n",
    "print(\"Each concept now fuses: vision + symbol + arithmetic knowledge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Cross-Modal Queries\n",
    "\n",
    "Now for the exciting part! We can query across modalities:\n",
    "1. **Arithmetic reasoning**: \"What is 1 + 2?\"\n",
    "2. **Visual retrieval**: \"Show me the image for 4 - 1\"\n",
    "3. **Fact discovery**: \"What arithmetic facts produce 5?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Arithmetic Reasoning: \"What is 1 + 2?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_arithmetic(memory, model, operand1: int, operator: str, operand2: int, concepts):\n",
    "    \"\"\"\n",
    "    Query: What is operand1 op operand2?\n",
    "    \n",
    "    Encode the query with UNKNOWN as result, then find best matching concept.\n",
    "    \"\"\"\n",
    "    # Encode query with known operands, unknown result\n",
    "    role_op1 = memory[\"role_operand1\"].vec\n",
    "    role_op = memory[\"role_operator\"].vec\n",
    "    role_op2 = memory[\"role_operand2\"].vec\n",
    "    \n",
    "    num_op1 = memory[f\"num_{operand1}\"].vec\n",
    "    op_vec = memory[f\"op_{operator}\"].vec\n",
    "    num_op2 = memory[f\"num_{operand2}\"].vec\n",
    "    \n",
    "    # Bind known components\n",
    "    bound_op1 = model.opset.bind(role_op1, num_op1)\n",
    "    bound_op = model.opset.bind(role_op, op_vec)\n",
    "    bound_op2 = model.opset.bind(role_op2, num_op2)\n",
    "    \n",
    "    # Bundle (partial fact without result)\n",
    "    query = model.opset.bundle(bound_op1, bound_op, bound_op2)\n",
    "    \n",
    "    # Find best matching concept\n",
    "    similarities = {}\n",
    "    for digit, concept in concepts.items():\n",
    "        sim = float(cosine_similarity(query, concept))\n",
    "        similarities[digit] = sim\n",
    "    \n",
    "    # Get top match\n",
    "    best_match = max(similarities.items(), key=lambda x: x[1])\n",
    "    \n",
    "    return best_match, similarities\n",
    "\n",
    "# Test: \"What is 1 + 2?\"\n",
    "result, sims = query_arithmetic(memory, model, 1, \"plus\", 2, concepts)\n",
    "\n",
    "print(\"Query: What is 1 + 2?\")\n",
    "print(f\"Answer: {result[0]} (similarity: {result[1]:.3f})\")\n",
    "print(\"\\nTop 5 candidates:\")\n",
    "for digit, sim in sorted(sims.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"  {digit}: {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple queries\n",
    "queries = [\n",
    "    (1, \"plus\", 2),\n",
    "    (3, \"plus\", 4),\n",
    "    (5, \"minus\", 2),\n",
    "    (7, \"minus\", 3),\n",
    "    (2, \"plus\", 2),\n",
    "]\n",
    "\n",
    "print(\"Arithmetic Queries:\\n\")\n",
    "for op1, op, op2 in queries:\n",
    "    result, _ = query_arithmetic(memory, model, op1, op, op2, concepts)\n",
    "    \n",
    "    # Compute ground truth\n",
    "    if op == \"plus\":\n",
    "        truth = op1 + op2\n",
    "    else:\n",
    "        truth = op1 - op2\n",
    "    \n",
    "    correct = \"✓\" if result[0] == truth else \"✗\"\n",
    "    print(f\"  {op1} {op.replace('plus', '+').replace('minus', '-')} {op2} = {result[0]} (truth: {truth}) {correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visual Retrieval: \"Show me the image for 4 - 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_visual(memory, model, operand1: int, operator: str, operand2: int, concepts, visual_prototypes):\n",
    "    \"\"\"\n",
    "    Query: Show me the image for operand1 op operand2.\n",
    "    \n",
    "    1. Find which concept matches the arithmetic query\n",
    "    2. Retrieve the visual prototype from that concept\n",
    "    \"\"\"\n",
    "    # First, find the result using arithmetic query\n",
    "    result, _ = query_arithmetic(memory, model, operand1, operator, operand2, concepts)\n",
    "    answer_digit = result[0]\n",
    "    \n",
    "    # Return the visual prototype for that digit\n",
    "    return answer_digit, visual_prototypes[answer_digit]\n",
    "\n",
    "# Test: \"Show me the image for 4 - 1\"\n",
    "digit, visual_vec = query_visual(memory, model, 4, \"minus\", 1, concepts, visual_prototypes)\n",
    "\n",
    "print(f\"Query: Show me the image for 4 - 1\")\n",
    "print(f\"Retrieved concept: {digit}\")\n",
    "\n",
    "# Find a sample MNIST image of this digit to display\n",
    "sample_idx = np.where(y == digit)[0][0]\n",
    "sample_image = digits.images[sample_idx]\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "plt.title(f\"Visual prototype for 4 - 1 = {digit}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Reverse Query: Given Image, Find Arithmetic Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_facts_from_image(image_vector, feature_names, model, memory, concepts, addition_facts, subtraction_facts):\n",
    "    \"\"\"\n",
    "    Given an MNIST image, find which concept it matches and retrieve arithmetic facts.\n",
    "    \"\"\"\n",
    "    # Encode the image\n",
    "    encoded_image = encode_image(model, memory, image_vector, feature_names)\n",
    "    \n",
    "    # Find best matching concept\n",
    "    similarities = {}\n",
    "    for digit, concept in concepts.items():\n",
    "        sim = float(cosine_similarity(encoded_image, concept))\n",
    "        similarities[digit] = sim\n",
    "    \n",
    "    best_match = max(similarities.items(), key=lambda x: x[1])\n",
    "    matched_digit = best_match[0]\n",
    "    \n",
    "    # Find all arithmetic facts that produce this digit\n",
    "    add_facts = [(i, j) for (i, j) in addition_facts.keys() if i + j == matched_digit]\n",
    "    sub_facts = [(i, j) for (i, j) in subtraction_facts.keys() if i - j == matched_digit]\n",
    "    \n",
    "    return matched_digit, add_facts, sub_facts\n",
    "\n",
    "# Test with a random MNIST image of digit 5\n",
    "sample_idx = np.where(y == 5)[0][10]  # Random sample of 5\n",
    "test_image = X[sample_idx]\n",
    "test_image_2d = digits.images[sample_idx]\n",
    "\n",
    "digit, add_facts, sub_facts = query_facts_from_image(\n",
    "    test_image, feature_names, model, memory, concepts, addition_facts, subtraction_facts\n",
    ")\n",
    "\n",
    "print(f\"Image recognized as: {digit}\")\n",
    "print(f\"\\nArithmetic facts that produce {digit}:\")\n",
    "print(f\"\\nAddition (first 5): {add_facts[:5]}\")\n",
    "print(f\"Subtraction (first 5): {sub_facts[:5]}\")\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(test_image_2d, cmap='gray')\n",
    "plt.title(f\"Query image (recognized as {digit})\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Online Learning - Adding New Facts\n",
    "\n",
    "One of VSA's key advantages: we can add new knowledge online by simply bundling new associations. No retraining needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's enrich the concept of \"5\" with new facts\n",
    "print(\"Original concept of 5:\")\n",
    "original_concept_5 = concepts[5]\n",
    "\n",
    "# Count current facts for 5\n",
    "num_add_facts_5 = sum(1 for (i, j) in addition_facts.keys() if i + j == 5)\n",
    "num_sub_facts_5 = sum(1 for (i, j) in subtraction_facts.keys() if i - j == 5)\n",
    "print(f\"  Currently has {num_add_facts_5} addition facts + {num_sub_facts_5} subtraction facts\")\n",
    "\n",
    "# Add new linguistic association: the word \"five\"\n",
    "memory.add(\"word_five\")\n",
    "word_five_vec = memory[\"word_five\"].vec\n",
    "\n",
    "# Bundle the new association into the concept\n",
    "enriched_concept_5 = model.opset.bundle(original_concept_5, word_five_vec)\n",
    "concepts[5] = enriched_concept_5  # Update\n",
    "\n",
    "print(\"\\nEnriched concept of 5:\")\n",
    "print(\"  Added linguistic association: 'five'\")\n",
    "print(\"  No retraining needed - just bundled new component!\")\n",
    "\n",
    "# Test that arithmetic queries still work\n",
    "result, _ = query_arithmetic(memory, model, 2, \"plus\", 3, concepts)\n",
    "print(f\"\\nQuery test: 2 + 3 = {result[0]} (still works!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a custom fact: \"5 is a prime number\"\n",
    "memory.add(\"property_prime\")\n",
    "\n",
    "# Bind the property to the number\n",
    "prime_fact = model.opset.bind(memory[\"num_5\"].vec, memory[\"property_prime\"].vec)\n",
    "\n",
    "# Bundle into concept\n",
    "concepts[5] = model.opset.bundle(concepts[5], prime_fact)\n",
    "\n",
    "print(\"Added custom property: '5 is prime'\")\n",
    "print(\"Concept of 5 now includes:\")\n",
    "print(\"  - Visual prototype (MNIST images)\")\n",
    "print(\"  - Symbolic atom (num_5)\")\n",
    "print(\"  - Arithmetic facts (2+3, 7-2, etc.)\")\n",
    "print(\"  - Linguistic label ('five')\")\n",
    "print(\"  - Mathematical property (prime)\")\n",
    "print(\"\\nAll added online without retraining!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Comparison with Neural Networks\n",
    "\n",
    "Let's compare VSA's multi-modal capabilities with traditional neural networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = {\n",
    "    \"Feature\": [\n",
    "        \"Multi-modal fusion\",\n",
    "        \"Online learning\",\n",
    "        \"Cross-modal queries\",\n",
    "        \"Interpretability\",\n",
    "        \"Training method\",\n",
    "        \"Adding new facts\",\n",
    "        \"Memory efficiency\",\n",
    "    ],\n",
    "    \"VSA\": [\n",
    "        \"Natural (same space)\",\n",
    "        \"Yes (bundle new facts)\",\n",
    "        \"Yes (unbinding)\",\n",
    "        \"High (can inspect)\",\n",
    "        \"No backprop\",\n",
    "        \"Instant (bundle)\",\n",
    "        \"Fixed dimension\",\n",
    "    ],\n",
    "    \"Neural Networks\": [\n",
    "        \"Requires architecture design\",\n",
    "        \"Hard (needs retraining)\",\n",
    "        \"Requires separate modules\",\n",
    "        \"Low (black box)\",\n",
    "        \"Gradient descent\",\n",
    "        \"Retrain entire model\",\n",
    "        \"Grows with data\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(comparison)\n",
    "print(\"\\nVSA vs Neural Networks for Multi-Modal Grounding:\\n\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Multi-Modal Fusion**: VSA naturally combines heterogeneous data (vision, language, arithmetic) in the same hyperdimensional space\n",
    "\n",
    "2. **Rich Concepts**: The concept \"3\" is not just a symbol or image - it's enriched by:\n",
    "   - Visual prototype from MNIST\n",
    "   - Symbolic atom (num_3)\n",
    "   - Arithmetic relationships (1+2, 4-1, 5-2, etc.)\n",
    "   - Can add linguistic, mathematical properties, etc.\n",
    "\n",
    "3. **Cross-Modal Reasoning**: Query with one modality, retrieve another:\n",
    "   - \"What is 1+2?\" → arithmetic reasoning → \"3\"\n",
    "   - \"Show image for 4-1\" → visual retrieval → MNIST 3\n",
    "   - Given image → find arithmetic facts\n",
    "\n",
    "4. **Online Learning**: Add new associations instantly by bundling - no retraining!\n",
    "\n",
    "5. **Interpretability**: Can unbind to inspect components (unlike neural black boxes)\n",
    "\n",
    "6. **No Gradient Descent**: Simple compositional operations (bind, bundle) - no backprop needed\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "**Extend this tutorial**:\n",
    "- Add more modalities (audio, text descriptions)\n",
    "- Encode multi-digit arithmetic (10+5=15)\n",
    "- Build richer linguistic associations\n",
    "- Add mathematical properties (prime, even, odd)\n",
    "- Try other VSA models (MAP, Binary)\n",
    "\n",
    "**Related tutorials**:\n",
    "- [Tutorial 2: Knowledge Graph Reasoning](02_knowledge_graph.md) - Relational facts\n",
    "- [Tutorial 7: Hierarchical Structures](07_hierarchical_structures.md) - Compositional encoding\n",
    "- [Tutorial 4: Word Analogies](04_word_analogies.md) - Semantic composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running This Tutorial\n",
    "\n",
    "**Requirements**:\n",
    "```bash\n",
    "pip install vsax scikit-learn matplotlib pandas\n",
    "```\n",
    "\n",
    "**Run notebook**:\n",
    "```bash\n",
    "jupyter notebook examples/notebooks/tutorial_08_multimodal_grounding.ipynb\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
