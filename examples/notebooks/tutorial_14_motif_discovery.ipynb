{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 14: Motif Discovery and Sequence Alignment\n",
    "\n",
    "This tutorial demonstrates advanced VSA techniques for bioinformatics, including k-mer fingerprinting, approximate sequence alignment, motif detection, and multi-sequence comparison.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- How to create k-mer fingerprints for sequence signatures\n",
    "- How to perform approximate sequence alignment using similarity\n",
    "- How to detect motifs using sliding window and permutation\n",
    "- How to build multi-sequence comparison matrices\n",
    "- How to discover conserved motifs across sequence families\n",
    "- How to leverage GPU acceleration for batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "from vsax import (\n",
    "    create_fhrr_model,\n",
    "    create_map_model,\n",
    "    create_binary_model,\n",
    "    create_quaternion_model,\n",
    "    VSAMemory,\n",
    ")\n",
    "from vsax.encoders import SequenceEncoder, SetEncoder\n",
    "from vsax.similarity import cosine_similarity\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Part 1: K-mer Fingerprinting for Sequence Signatures\n",
    "\n",
    "K-mers are subsequences of length k that capture local sequence patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "K = 4  # k-mer length\n",
    "DIM = 1024\n",
    "\n",
    "# Initialize model\n",
    "model = create_fhrr_model(dim=DIM)\n",
    "memory = VSAMemory(model)\n",
    "\n",
    "# For DNA sequences\n",
    "nucleotides = [\"A\", \"T\", \"G\", \"C\"]\n",
    "memory.add_many(nucleotides)\n",
    "\n",
    "# Generate all possible k-mers\n",
    "def generate_all_kmers(alphabet, k):\n",
    "    \"\"\"Generate all possible k-mers from an alphabet.\"\"\"\n",
    "    if k == 0:\n",
    "        return [\"\"]\n",
    "    smaller = generate_all_kmers(alphabet, k - 1)\n",
    "    return [char + kmer for char in alphabet for kmer in smaller]\n",
    "\n",
    "all_kmers = generate_all_kmers(nucleotides, K)\n",
    "memory.add_many(all_kmers)\n",
    "\n",
    "print(f\"Generated {len(all_kmers)} unique {K}-mers\")\n",
    "print(f\"Examples: {all_kmers[:8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kmer_spectrum(sequence, k=4):\n",
    "    \"\"\"Extract k-mer spectrum (frequency distribution).\"\"\"\n",
    "    kmers = []\n",
    "    seq_str = ''.join(sequence) if isinstance(sequence, list) else sequence\n",
    "    for i in range(len(seq_str) - k + 1):\n",
    "        kmers.append(seq_str[i:i+k])\n",
    "    return Counter(kmers)\n",
    "\n",
    "def encode_kmer_spectrum(sequence, k, model, memory):\n",
    "    \"\"\"Encode sequence as weighted k-mer spectrum.\"\"\"\n",
    "    spectrum = extract_kmer_spectrum(sequence, k)\n",
    "\n",
    "    # Weight each k-mer by its frequency\n",
    "    weighted_vecs = []\n",
    "    for kmer, count in spectrum.items():\n",
    "        kmer_hv = memory[kmer]\n",
    "        weighted_vecs.append(kmer_hv.vec * count)\n",
    "\n",
    "    # Bundle all weighted k-mers\n",
    "    result = model.opset.bundle(*weighted_vecs)\n",
    "    return model.rep_cls(result)\n",
    "\n",
    "def compute_similarity(hv_a, hv_b):\n",
    "    return float(cosine_similarity(hv_a.vec, hv_b.vec))\n",
    "\n",
    "# Test sequences\n",
    "seq1 = \"ATGCGATCGATCGATCGATCGATCGATCG\"\n",
    "seq2 = \"ATGCGATCGATCGATCGATCGATCGATCG\"  # Identical\n",
    "seq3 = \"ATGCGATCGATCGATCGATCGATCGTTTT\"  # Similar\n",
    "seq4 = \"CCCCGGGGAAAATTTTCCCCGGGGAAAAT\"  # Different composition\n",
    "\n",
    "# Encode spectra\n",
    "hv1 = encode_kmer_spectrum(seq1, K, model, memory)\n",
    "hv2 = encode_kmer_spectrum(seq2, K, model, memory)\n",
    "hv3 = encode_kmer_spectrum(seq3, K, model, memory)\n",
    "hv4 = encode_kmer_spectrum(seq4, K, model, memory)\n",
    "\n",
    "print(\"K-mer Spectrum Similarity:\")\n",
    "print(f\"  Seq1 vs Seq2 (identical): {compute_similarity(hv1, hv2):.4f}\")\n",
    "print(f\"  Seq1 vs Seq3 (similar):   {compute_similarity(hv1, hv3):.4f}\")\n",
    "print(f\"  Seq1 vs Seq4 (different): {compute_similarity(hv1, hv4):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Part 2: Approximate Sequence Alignment\n",
    "\n",
    "VSA enables fast approximate alignment using similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_encode(sequence, window_size, model, memory):\n",
    "    \"\"\"Encode all windows of a sequence.\"\"\"\n",
    "    seq_encoder = SequenceEncoder(model, memory)\n",
    "    seq_str = ''.join(sequence) if isinstance(sequence, list) else sequence\n",
    "\n",
    "    windows = []\n",
    "    for i in range(len(seq_str) - window_size + 1):\n",
    "        window = list(seq_str[i:i+window_size])\n",
    "        windows.append({\n",
    "            'position': i,\n",
    "            'sequence': seq_str[i:i+window_size],\n",
    "            'hv': seq_encoder.encode(window)\n",
    "        })\n",
    "    return windows\n",
    "\n",
    "def find_best_alignment(query, target, window_size, model, memory):\n",
    "    \"\"\"Find best alignment position of query in target.\"\"\"\n",
    "    seq_encoder = SequenceEncoder(model, memory)\n",
    "    query_hv = seq_encoder.encode(list(query))\n",
    "\n",
    "    target_windows = sliding_window_encode(target, len(query), model, memory)\n",
    "\n",
    "    best_pos = -1\n",
    "    best_sim = -1\n",
    "    all_sims = []\n",
    "\n",
    "    for window in target_windows:\n",
    "        sim = compute_similarity(query_hv, window['hv'])\n",
    "        all_sims.append((window['position'], sim))\n",
    "        if sim > best_sim:\n",
    "            best_sim = sim\n",
    "            best_pos = window['position']\n",
    "\n",
    "    return best_pos, best_sim, all_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Find a motif in a longer sequence\n",
    "target_seq = \"AAATTTGGGCCCATGCATCGATCGATCGAAATTTGGGCCC\"\n",
    "query_motif = \"ATCGATCG\"\n",
    "\n",
    "align_model = create_fhrr_model(dim=512)\n",
    "align_memory = VSAMemory(align_model)\n",
    "align_memory.add_many(nucleotides)\n",
    "\n",
    "best_pos, best_sim, all_sims = find_best_alignment(\n",
    "    query_motif, target_seq, len(query_motif), align_model, align_memory\n",
    ")\n",
    "\n",
    "print(f\"Query motif: {query_motif}\")\n",
    "print(f\"Target: {target_seq}\")\n",
    "print(f\"\\nBest alignment position: {best_pos}\")\n",
    "print(f\"Best similarity: {best_sim:.4f}\")\n",
    "print(f\"Aligned region: {target_seq[best_pos:best_pos+len(query_motif)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize alignment scores\n",
    "positions, sims = zip(*all_sims)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(positions, sims, color='steelblue')\n",
    "plt.axhline(y=0.9, color='red', linestyle='--', label='High similarity threshold')\n",
    "plt.xlabel('Position in Target')\n",
    "plt.ylabel('Similarity')\n",
    "plt.title('Approximate Alignment Scores')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Part 3: Sliding Window Motif Detection with Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_position_encoder(model, memory, max_pos=100):\n",
    "    \"\"\"Create position-aware encoder using permutation.\"\"\"\n",
    "    position_hvs = {}\n",
    "    for i in range(max_pos):\n",
    "        pos_name = f\"pos_{i}\"\n",
    "        if pos_name not in memory:\n",
    "            memory.add(pos_name)\n",
    "        position_hvs[i] = memory[pos_name]\n",
    "    return position_hvs\n",
    "\n",
    "def encode_with_positions(sequence, model, memory, position_hvs):\n",
    "    \"\"\"Encode sequence with explicit position information.\"\"\"\n",
    "    bound_pairs = []\n",
    "    for i, char in enumerate(sequence):\n",
    "        if char in memory:\n",
    "            char_hv = memory[char]\n",
    "            pos_hv = position_hvs[i % len(position_hvs)]\n",
    "            bound = model.opset.bind(char_hv.vec, pos_hv.vec)\n",
    "            bound_pairs.append(bound)\n",
    "\n",
    "    result = model.opset.bundle(*bound_pairs)\n",
    "    return model.rep_cls(result)\n",
    "\n",
    "# Create position-aware encoding\n",
    "pos_model = create_fhrr_model(dim=512)\n",
    "pos_memory = VSAMemory(pos_model)\n",
    "pos_memory.add_many(nucleotides)\n",
    "position_hvs = create_position_encoder(pos_model, pos_memory, max_pos=50)\n",
    "\n",
    "# Test: Same motif at different positions should have lower similarity\n",
    "motif = \"ATGC\"\n",
    "context1 = \"AAAA\" + motif + \"AAAA\"  # Motif at position 4\n",
    "context2 = \"AAAAAAA\" + motif + \"A\"  # Motif at position 7\n",
    "\n",
    "hv1 = encode_with_positions(list(context1), pos_model, pos_memory, position_hvs)\n",
    "hv2 = encode_with_positions(list(context2), pos_model, pos_memory, position_hvs)\n",
    "\n",
    "print(f\"Context 1: {context1} (motif at pos 4)\")\n",
    "print(f\"Context 2: {context2} (motif at pos 7)\")\n",
    "print(f\"Similarity: {compute_similarity(hv1, hv2):.4f}\")\n",
    "print(\"(Lower than 1.0 because positions differ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Part 4: Multi-Sequence Comparison Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(sequences, model, memory, encoding_fn):\n",
    "    \"\"\"Build pairwise similarity matrix for sequences.\"\"\"\n",
    "    hvs = [encoding_fn(seq, model, memory) for seq in sequences]\n",
    "\n",
    "    n = len(sequences)\n",
    "    matrix = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            matrix[i, j] = compute_similarity(hvs[i], hvs[j])\n",
    "\n",
    "    return matrix, hvs\n",
    "\n",
    "# Example: Compare a set of related sequences\n",
    "sequences = [\n",
    "    \"ATGCGATCGATCGATCGATCG\",  # Base sequence\n",
    "    \"ATGCGATCGATCGATCGATCG\",  # Identical\n",
    "    \"ATGCGATCGATCGATCGATTT\",  # 2 mutations\n",
    "    \"ATGCGATCGATCGATTTTTTT\",  # 6 mutations\n",
    "    \"TTTTTTTTTTTTTTTTTTTTG\",  # Very different\n",
    "    \"ATGCGATCGATCGATCGATCC\",  # 1 mutation\n",
    "]\n",
    "\n",
    "labels = [\"Base\", \"Identical\", \"2 mut\", \"6 mut\", \"Different\", \"1 mut\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple sequence encoder\n",
    "def simple_encode(seq, model, memory):\n",
    "    seq_encoder = SequenceEncoder(model, memory)\n",
    "    return seq_encoder.encode(list(seq))\n",
    "\n",
    "matrix_model = create_fhrr_model(dim=1024)\n",
    "matrix_memory = VSAMemory(matrix_model)\n",
    "matrix_memory.add_many(nucleotides)\n",
    "\n",
    "sim_matrix, _ = build_similarity_matrix(sequences, matrix_model, matrix_memory, simple_encode)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(sim_matrix, annot=True, fmt='.3f', cmap='viridis',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Multi-Sequence Similarity Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nSimilarity Statistics:\")\n",
    "print(f\"  Identical pairs: {sim_matrix[0, 1]:.4f}\")\n",
    "print(f\"  Low mutation (1-2): {np.mean([sim_matrix[0, 2], sim_matrix[0, 5]]):.4f}\")\n",
    "print(f\"  High mutation (6): {sim_matrix[0, 3]:.4f}\")\n",
    "print(f\"  Different sequence: {sim_matrix[0, 4]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Part 5: Conserved Motif Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_conserved_motifs(sequences, window_size, model, memory, threshold=0.7):\n",
    "    \"\"\"Discover conserved motifs across a sequence family.\"\"\"\n",
    "    seq_encoder = SequenceEncoder(model, memory)\n",
    "\n",
    "    # Extract all windows from all sequences\n",
    "    all_windows = []\n",
    "    for seq_idx, seq in enumerate(sequences):\n",
    "        seq_str = ''.join(seq) if isinstance(seq, list) else seq\n",
    "        for pos in range(len(seq_str) - window_size + 1):\n",
    "            window = seq_str[pos:pos+window_size]\n",
    "            hv = seq_encoder.encode(list(window))\n",
    "            all_windows.append({\n",
    "                'seq_idx': seq_idx,\n",
    "                'position': pos,\n",
    "                'sequence': window,\n",
    "                'hv': hv\n",
    "            })\n",
    "\n",
    "    # Find windows that are similar across multiple sequences\n",
    "    motif_candidates = {}\n",
    "\n",
    "    for i, w1 in enumerate(all_windows):\n",
    "        matches = []\n",
    "        for j, w2 in enumerate(all_windows):\n",
    "            if w1['seq_idx'] != w2['seq_idx']:  # Different sequences\n",
    "                sim = compute_similarity(w1['hv'], w2['hv'])\n",
    "                if sim > threshold:\n",
    "                    matches.append((w2['seq_idx'], w2['position'], sim))\n",
    "\n",
    "        # Count how many different sequences match\n",
    "        matched_seqs = set(m[0] for m in matches)\n",
    "        if len(matched_seqs) >= len(sequences) // 2:  # Found in at least half\n",
    "            motif_candidates[w1['sequence']] = {\n",
    "                'count': len(matched_seqs) + 1,\n",
    "                'avg_sim': np.mean([m[2] for m in matches]) if matches else 1.0,\n",
    "                'positions': [(w1['seq_idx'], w1['position'])] + [(m[0], m[1]) for m in matches]\n",
    "            }\n",
    "\n",
    "    return motif_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence family with conserved \"GATC\" motif\n",
    "sequence_family = [\n",
    "    \"AAAAAGATCGAAAAA\",\n",
    "    \"TTTTTGATCGTTTTT\",\n",
    "    \"CCCCCGATCGCCCCC\",\n",
    "    \"GGGGGGATCGGGGGG\",\n",
    "    \"ATATAGATCGATATA\",\n",
    "]\n",
    "\n",
    "motif_model = create_fhrr_model(dim=512)\n",
    "motif_memory = VSAMemory(motif_model)\n",
    "motif_memory.add_many(nucleotides)\n",
    "\n",
    "conserved = discover_conserved_motifs(\n",
    "    sequence_family, window_size=4, model=motif_model,\n",
    "    memory=motif_memory, threshold=0.8\n",
    ")\n",
    "\n",
    "print(\"Discovered Conserved Motifs:\")\n",
    "print(\"-\" * 50)\n",
    "for motif, info in sorted(conserved.items(), key=lambda x: -x[1]['count']):\n",
    "    print(f\"  {motif}: found in {info['count']} sequences, avg_sim={info['avg_sim']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Part 6: GPU-Accelerated Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_encode_sequences(sequences, model, memory):\n",
    "    \"\"\"Batch encode sequences efficiently.\"\"\"\n",
    "    seq_encoder = SequenceEncoder(model, memory)\n",
    "    hvs = []\n",
    "    for seq in sequences:\n",
    "        hv = seq_encoder.encode(list(seq))\n",
    "        hvs.append(hv.vec)\n",
    "    return jnp.stack(hvs)\n",
    "\n",
    "def batch_similarity_matrix(hvs):\n",
    "    \"\"\"Compute pairwise similarity matrix using GPU-friendly operations.\"\"\"\n",
    "    norms = jnp.linalg.norm(hvs, axis=1, keepdims=True)\n",
    "    normalized = hvs / (norms + 1e-10)\n",
    "\n",
    "    if jnp.iscomplexobj(hvs):\n",
    "        sim_matrix = jnp.abs(jnp.dot(normalized, jnp.conj(normalized.T)))\n",
    "    else:\n",
    "        sim_matrix = jnp.dot(normalized, normalized.T)\n",
    "\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset\n",
    "np.random.seed(42)\n",
    "num_sequences = 100\n",
    "seq_length = 50\n",
    "\n",
    "def random_sequence(length):\n",
    "    return ''.join(np.random.choice(list(\"ATGC\"), length))\n",
    "\n",
    "large_dataset = [random_sequence(seq_length) for _ in range(num_sequences)]\n",
    "\n",
    "# Batch encode\n",
    "batch_model = create_fhrr_model(dim=512)\n",
    "batch_memory = VSAMemory(batch_model)\n",
    "batch_memory.add_many(nucleotides)\n",
    "\n",
    "print(f\"Encoding {num_sequences} sequences of length {seq_length}...\")\n",
    "start = time.time()\n",
    "\n",
    "hvs = batch_encode_sequences(large_dataset, batch_model, batch_memory)\n",
    "sim_matrix = batch_similarity_matrix(hvs)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Completed in {elapsed:.3f} seconds\")\n",
    "print(f\"Matrix shape: {sim_matrix.shape}\")\n",
    "print(f\"Average similarity: {float(jnp.mean(sim_matrix)):.4f}\")\n",
    "print(f\"Max off-diagonal: {float(jnp.max(sim_matrix - jnp.eye(num_sequences))):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Part 7: Model Comparison for Motif Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": "from vsax.similarity import quaternion_similarity\n\ndef evaluate_motif_detection(model_name, model_fn, dim, use_quaternion=False):\n    \"\"\"Evaluate model on motif detection task.\"\"\"\n    model = model_fn(dim=dim)\n    memory = VSAMemory(model)\n    memory.add_many(nucleotides)\n    encoder = SequenceEncoder(model, memory)\n\n    # Create sequences with embedded motif\n    motif = \"TATA\"  # TATA box motif\n    base = \"A\" * 20\n\n    pos1 = base[:5] + motif + base[9:]   # Position 5\n    pos2 = base[:10] + motif + base[14:] # Position 10\n    no_motif = base                       # No motif\n\n    hv_motif = encoder.encode(list(motif))\n    hv_pos1 = encoder.encode(list(pos1))\n    hv_pos2 = encoder.encode(list(pos2))\n    hv_no_motif = encoder.encode(list(no_motif))\n\n    # Use appropriate similarity function for model type\n    if use_quaternion:\n        sim_fn = lambda a, b: float(quaternion_similarity(a.vec, b.vec))\n    else:\n        sim_fn = compute_similarity\n\n    return {\n        'model': model_name,\n        'motif_at_5': sim_fn(hv_motif, encoder.encode(list(pos1[5:9]))),\n        'motif_at_10': sim_fn(hv_motif, encoder.encode(list(pos2[10:14]))),\n        'full_seq_sim': sim_fn(hv_pos1, hv_pos2),\n        'with_vs_without': sim_fn(hv_pos1, hv_no_motif),\n    }\n\nmodels = {\n    'FHRR': (create_fhrr_model, 1024, False),\n    'MAP': (create_map_model, 1024, False),\n    'Binary': (create_binary_model, 4096, False),\n    'Quaternion': (create_quaternion_model, 1024, True),\n}\n\nprint(\"Model Comparison for Motif Detection:\")\nprint(\"=\" * 70)\n\nresults = []\nfor name, (fn, dim, use_quat) in models.items():\n    result = evaluate_motif_detection(name, fn, dim, use_quaternion=use_quat)\n    results.append(result)\n    print(f\"\\n{name} (dim={dim}):\")\n    print(f\"  Motif match at pos 5:  {result['motif_at_5']:.4f}\")\n    print(f\"  Motif match at pos 10: {result['motif_at_10']:.4f}\")\n    print(f\"  Same motif, diff pos:  {result['full_seq_sim']:.4f}\")\n    print(f\"  With vs without motif: {result['with_vs_without']:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": "# Demonstrate Quaternion palindrome handling\nq_model = create_quaternion_model(dim=512)\nq_memory = VSAMemory(q_model)\nq_memory.add_many(nucleotides)\nq_encoder = SequenceEncoder(q_model, q_memory)\n\n# Palindromic restriction site: GAATTC (EcoRI)\nforward = \"GAATTC\"\nreverse = \"CTTAAG\"  # Reverse complement\n\nhv_fwd = q_encoder.encode(list(forward))\nhv_rev = q_encoder.encode(list(reverse))\n\nsim = float(quaternion_similarity(hv_fwd.vec, hv_rev.vec))\nprint(f\"EcoRI forward (GAATTC) vs reverse complement (CTTAAG): {sim:.4f}\")\nprint(\"Quaternion distinguishes strand orientation!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **K-mer fingerprints**: Fast sequence signatures without alignment\n",
    "2. **Approximate alignment**: VSA enables O(n) alignment vs O(nÂ²) traditional methods\n",
    "3. **Sliding window detection**: Motifs can be found at any position\n",
    "4. **Multi-sequence comparison**: Efficient pairwise matrices with batch GPU operations\n",
    "5. **Conserved motif discovery**: Find shared patterns across sequence families\n",
    "6. **Model recommendations**:\n",
    "   - **FHRR**: Best for unbinding queries and exact motif matching\n",
    "   - **MAP**: Fastest for large-scale comparisons\n",
    "   - **Binary**: Most memory-efficient for huge databases\n",
    "   - **Quaternion**: Best for strand-aware and order-sensitive analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}