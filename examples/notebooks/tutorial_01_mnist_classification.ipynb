{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: MNIST Digit Classification with VSA\n",
    "\n",
    "This tutorial demonstrates how to use VSAX for image classification using the MNIST digits dataset.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- How to encode images as hypervectors\n",
    "- How to create class prototypes using VSA\n",
    "- How to perform similarity-based classification\n",
    "- How to compare different VSA models (FHRR, MAP, Binary)\n",
    "\n",
    "## Why VSA for Classification?\n",
    "\n",
    "Vector Symbolic Architectures offer a unique approach to classification:\n",
    "- **Interpretable**: Class representations are explicit hypervectors\n",
    "- **Few-shot learning**: Can learn from few examples per class\n",
    "- **Compositional**: Can combine features naturally\n",
    "- **Efficient**: GPU-accelerated with JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from vsax import VSAMemory, create_binary_model, create_fhrr_model, create_map_model\n",
    "\n",
    "# Import our dataset helpers\n",
    "sys.path.insert(0, '../utils')\n",
    "from dataset_helpers import load_mnist_digits, normalize_images\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore MNIST Data\n",
    "\n",
    "We'll use scikit-learn's digits dataset (8x8 images of handwritten digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST digits\n",
    "X_train, X_test, y_train, y_test = load_mnist_digits()\n",
    "\n",
    "# Normalize to [0, 1]\n",
    "X_train = normalize_images(X_train)\n",
    "X_test = normalize_images(X_test)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Image dimensions: {X_train.shape[1]} pixels (8x8 flattened)\")\n",
    "print(f\"Classes: {np.unique(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i].reshape(8, 8), cmap='gray')\n",
    "    ax.set_title(f\"Digit: {y_train[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VSA-Based Classification\n",
    "\n",
    "### Step 1: Create VSA Model\n",
    "\n",
    "Let's start with the FHRR model (complex hypervectors with exact unbinding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FHRR model with 1024 dimensions\n",
    "model = create_fhrr_model(dim=1024)\n",
    "memory = VSAMemory(model)\n",
    "\n",
    "print(f\"Model: {model.rep_cls.__name__}\")\n",
    "print(f\"Operations: {model.opset.__class__.__name__}\")\n",
    "print(f\"Dimension: {model.dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Encode Images as Hypervectors\n",
    "\n",
    "Each image is encoded by:\n",
    "1. Creating a random basis hypervector for each pixel position\n",
    "2. Scaling each basis vector by the pixel intensity\n",
    "3. Bundling all scaled pixel vectors together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basis vectors for each of the 64 pixel positions\n",
    "pixel_names = [f\"pixel_{i}\" for i in range(64)]\n",
    "memory.add_many(pixel_names)\n",
    "\n",
    "print(f\"Created {len(pixel_names)} pixel basis vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image, model, memory):\n",
    "    \"\"\"Encode an image as a hypervector.\n",
    "    \n",
    "    Args:\n",
    "        image: Flattened image array (64,)\n",
    "        model: VSAModel instance\n",
    "        memory: VSAMemory with pixel basis vectors\n",
    "    \n",
    "    Returns:\n",
    "        Encoded hypervector\n",
    "    \"\"\"\n",
    "    # Get all pixel basis vectors\n",
    "    pixel_vecs = [memory[f\"pixel_{i}\"].vec for i in range(64)]\n",
    "\n",
    "    # Scale each pixel vector by intensity and bundle\n",
    "    scaled_vecs = []\n",
    "    for i, intensity in enumerate(image):\n",
    "        if intensity > 0:  # Only include active pixels\n",
    "            # For complex vectors, scale by multiplying\n",
    "            scaled = pixel_vecs[i] * intensity\n",
    "            scaled_vecs.append(scaled)\n",
    "\n",
    "    if len(scaled_vecs) == 0:\n",
    "        # Return zero vector for blank images\n",
    "        return jnp.zeros(model.dim, dtype=pixel_vecs[0].dtype)\n",
    "\n",
    "    # Bundle all scaled pixel vectors\n",
    "    return model.opset.bundle(*scaled_vecs)\n",
    "\n",
    "# Test encoding\n",
    "test_encoding = encode_image(X_train[0], model, memory)\n",
    "print(f\"Encoded shape: {test_encoding.shape}\")\n",
    "print(f\"Encoded dtype: {test_encoding.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Class Prototypes\n",
    "\n",
    "For each digit class (0-9), we create a prototype by averaging the encodings of all training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all training images\n",
    "print(\"Encoding training images...\")\n",
    "train_encodings = []\n",
    "for img in X_train:\n",
    "    train_encodings.append(encode_image(img, model, memory))\n",
    "train_encodings = jnp.stack(train_encodings)\n",
    "\n",
    "print(f\"Encoded {len(train_encodings)} training images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prototype for each digit class\n",
    "prototypes = {}\n",
    "for digit in range(10):\n",
    "    # Get all encodings for this digit\n",
    "    digit_mask = y_train == digit\n",
    "    digit_encodings = train_encodings[digit_mask]\n",
    "\n",
    "    # Average to create prototype\n",
    "    prototype = model.opset.bundle(*digit_encodings)\n",
    "    prototypes[digit] = prototype\n",
    "\n",
    "    print(f\"Digit {digit}: {digit_mask.sum()} training examples\")\n",
    "\n",
    "print(f\"\\nCreated {len(prototypes)} class prototypes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Classify Test Images\n",
    "\n",
    "Classification is done by finding the most similar prototype using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image, model, memory, prototypes):\n",
    "    \"\"\"Classify an image using prototype matching.\n",
    "    \n",
    "    Args:\n",
    "        image: Flattened image array\n",
    "        model: VSAModel instance\n",
    "        memory: VSAMemory with pixel basis vectors\n",
    "        prototypes: Dict mapping digit -> prototype vector\n",
    "    \n",
    "    Returns:\n",
    "        Predicted digit (0-9)\n",
    "    \"\"\"\n",
    "    # Encode the test image\n",
    "    encoding = encode_image(image, model, memory)\n",
    "\n",
    "    # Compute similarity to each prototype\n",
    "    similarities = {}\n",
    "    for digit, prototype in prototypes.items():\n",
    "        # For complex vectors, use absolute value of dot product\n",
    "        sim = jnp.abs(jnp.vdot(encoding, prototype))\n",
    "        similarities[digit] = float(sim)\n",
    "\n",
    "    # Return digit with highest similarity\n",
    "    return max(similarities, key=similarities.get)\n",
    "\n",
    "# Test on a few examples\n",
    "print(\"Testing classification on first 5 test images:\")\n",
    "for i in range(5):\n",
    "    pred = classify_image(X_test[i], model, memory, prototypes)\n",
    "    print(f\"  Image {i}: True={y_test[i]}, Predicted={pred}, {'✓' if pred == y_test[i] else '✗'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify all test images\n",
    "print(\"Classifying all test images...\")\n",
    "predictions = []\n",
    "for img in X_test:\n",
    "    pred = classify_image(img, model, memory, prototypes)\n",
    "    predictions.append(pred)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"\\nTest Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'FHRR Model - Confusion Matrix (Accuracy: {accuracy:.2%})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Different VSA Models\n",
    "\n",
    "Let's compare FHRR, MAP, and Binary models on the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, model_fn, dim):\n",
    "    \"\"\"Evaluate a VSA model on MNIST classification.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model\n",
    "        model_fn: Factory function to create model\n",
    "        dim: Dimension for the model\n",
    "    \n",
    "    Returns:\n",
    "        Test accuracy\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {model_name} Model (dim={dim})\")\n",
    "    print('='*60)\n",
    "\n",
    "    # Create model and memory\n",
    "    model = model_fn(dim=dim)\n",
    "    memory = VSAMemory(model)\n",
    "    memory.add_many([f\"pixel_{i}\" for i in range(64)])\n",
    "\n",
    "    # Encode training images and create prototypes\n",
    "    print(\"Encoding training images...\")\n",
    "    train_encodings = [encode_image(img, model, memory) for img in X_train]\n",
    "    train_encodings = jnp.stack(train_encodings)\n",
    "\n",
    "    prototypes = {}\n",
    "    for digit in range(10):\n",
    "        digit_mask = y_train == digit\n",
    "        digit_encodings = train_encodings[digit_mask]\n",
    "        prototypes[digit] = model.opset.bundle(*digit_encodings)\n",
    "\n",
    "    # Classify test images\n",
    "    print(\"Classifying test images...\")\n",
    "    predictions = [classify_image(img, model, memory, prototypes) for img in X_test]\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Test Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "results = {}\n",
    "\n",
    "results['FHRR'] = evaluate_model('FHRR', create_fhrr_model, dim=1024)\n",
    "results['MAP'] = evaluate_model('MAP', create_map_model, dim=1024)\n",
    "results['Binary'] = evaluate_model('Binary', create_binary_model, dim=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "models = list(results.keys())\n",
    "accuracies = [results[m] for m in models]\n",
    "\n",
    "bars = plt.bar(models, accuracies, color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "plt.ylabel('Test Accuracy', fontsize=12)\n",
    "plt.title('VSA Model Comparison on MNIST Digits', fontsize=14, fontweight='bold')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Add accuracy labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{acc:.2%}', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "for model, acc in results.items():\n",
    "    print(f\"  {model}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **VSA for Classification**: We successfully classified MNIST digits using prototype-based VSA classification\n",
    "2. **Simple Approach**: The method is straightforward - encode images, create prototypes, match by similarity\n",
    "3. **Model Comparison**: Different VSA models (FHRR, MAP, Binary) show competitive performance\n",
    "4. **Interpretable**: Each class has an explicit prototype hypervector that represents it\n",
    "5. **Scalable**: JAX makes this GPU-accelerated and efficient for larger datasets\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try different encoding strategies (e.g., using ScalarEncoder)\n",
    "- Experiment with different dimensions\n",
    "- Use fewer training examples (few-shot learning)\n",
    "- Try on full MNIST (28x28 images)\n",
    "- Explore Tutorial 2: Knowledge Graph Reasoning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
