{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 7: Hierarchical Structures - Trees & Nested Composition\n",
    "\n",
    "One of VSA's most powerful capabilities is **compositional representation** - the ability to encode hierarchical, nested structures through recursive binding and bundling.\n",
    "\n",
    "Unlike flat representations (bag-of-words, feature vectors), VSA can encode **tree structures** that preserve parent-child relationships, nesting depth, and compositional semantics.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Encode tree structures with recursive role-filler binding\n",
    "- Represent arithmetic expressions, parse trees, nested data, and genealogy\n",
    "- Decode structures using resonator networks (iterative factorization)\n",
    "- Handle variable-depth hierarchies\n",
    "- Understand compositionality in VSA\n",
    "\n",
    "## Why Hierarchical Encoding Matters\n",
    "\n",
    "Many real-world concepts are hierarchical:\n",
    "- **Language**: Sentence structure (syntax trees)\n",
    "- **Math**: Nested expressions `(2 + 3) * 4`\n",
    "- **Data**: JSON, XML, nested dictionaries\n",
    "- **Relationships**: Family trees, org charts\n",
    "- **Programs**: Abstract syntax trees (AST)\n",
    "\n",
    "VSA can encode these structures **holistically** - the entire tree becomes a single high-dimensional vector that preserves the hierarchical relationships.\n",
    "\n",
    "## Core Idea: Recursive Role-Filler Binding\n",
    "\n",
    "**Tree encoding pattern:**\n",
    "```\n",
    "node = bind(\"value\", node_value) ⊕ bind(\"left\", left_child) ⊕ bind(\"right\", right_child)\n",
    "```\n",
    "\n",
    "**Example**: Encode `(2 + 3)`\n",
    "```\n",
    "plus_node = bind(\"op\", \"+\") ⊕ bind(\"left\", \"2\") ⊕ bind(\"right\", \"3\")\n",
    "```\n",
    "\n",
    "**Nested**: Encode `(2 + 3) * 4`\n",
    "```\n",
    "multiply_node = bind(\"op\", \"*\") ⊕ bind(\"left\", plus_node) ⊕ bind(\"right\", \"4\")\n",
    "```\n",
    "\n",
    "The entire tree is now a single vector!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from vsax import create_fhrr_model, VSAMemory\n",
    "from vsax.similarity import cosine_similarity\n",
    "from vsax.resonator import ResonatorNetwork\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "# Create model (FHRR best for exact unbinding)\n",
    "model = create_fhrr_model(dim=1024)\n",
    "memory = VSAMemory(model)\n",
    "\n",
    "# Add role vectors\n",
    "roles = [\"value\", \"op\", \"operator\", \"left\", \"right\", \"parent\", \"child\", \n",
    "         \"name\", \"age\", \"relation\", \"first\", \"second\", \"rest\"]\n",
    "memory.add_many(roles)\n",
    "\n",
    "print(f\"Model: {model.rep_cls.__name__}\")\n",
    "print(f\"Dimension: {model.dim}\")\n",
    "print(f\"Roles defined: {len(roles)}\")\n",
    "print(\"Ready for hierarchical encoding!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Arithmetic Expression Trees\n",
    "\n",
    "Let's encode mathematical expressions as binary trees.\n",
    "\n",
    "**Expression**: `(2 + 3) * 4`\n",
    "\n",
    "**Tree structure**:\n",
    "```\n",
    "      *\n",
    "     / \\\n",
    "    +   4\n",
    "   / \\\n",
    "  2   3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_leaf(memory, value):\n",
    "    \"\"\"Encode a leaf node (number or variable).\"\"\"\n",
    "    value_str = str(value)\n",
    "    if value_str not in memory:\n",
    "        memory.add(value_str)\n",
    "    return memory[value_str].vec\n",
    "\n",
    "\n",
    "def encode_binary_op(model, memory, operator, left, right):\n",
    "    \"\"\"Encode a binary operation node.\"\"\"\n",
    "    # Add operator if needed\n",
    "    if operator not in memory:\n",
    "        memory.add(operator)\n",
    "    \n",
    "    # Bind: op ⊗ operator + left ⊗ left_child + right ⊗ right_child\n",
    "    op_vec = model.opset.bind(memory[\"op\"].vec, memory[operator].vec)\n",
    "    left_vec = model.opset.bind(memory[\"left\"].vec, left)\n",
    "    right_vec = model.opset.bind(memory[\"right\"].vec, right)\n",
    "    \n",
    "    # Bundle all components\n",
    "    node = model.opset.bundle(op_vec, left_vec, right_vec)\n",
    "    return node\n",
    "\n",
    "\n",
    "# Encode (2 + 3) * 4\n",
    "# Bottom-up: encode leaves first, then operators\n",
    "leaf_2 = encode_leaf(memory, 2)\n",
    "leaf_3 = encode_leaf(memory, 3)\n",
    "leaf_4 = encode_leaf(memory, 4)\n",
    "\n",
    "# Encode (2 + 3)\n",
    "plus_node = encode_binary_op(model, memory, \"+\", leaf_2, leaf_3)\n",
    "\n",
    "# Encode (2 + 3) * 4\n",
    "multiply_node = encode_binary_op(model, memory, \"*\", plus_node, leaf_4)\n",
    "\n",
    "print(\"Encoded expression: (2 + 3) * 4\")\n",
    "print(f\"Tree vector shape: {multiply_node.shape}\")\n",
    "print(f\"\\nThis single {model.dim}-dimensional vector represents the entire tree!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding: Extracting Structure with Unbinding\n",
    "\n",
    "Can we recover the original structure from the encoded vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(vector, memory, candidates):\n",
    "    \"\"\"Find best matching symbol from candidates.\"\"\"\n",
    "    best_match = None\n",
    "    best_sim = -float('inf')\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        if candidate in memory:\n",
    "            sim = float(cosine_similarity(vector, memory[candidate].vec))\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                best_match = candidate\n",
    "    \n",
    "    return best_match, best_sim\n",
    "\n",
    "\n",
    "def decode_binary_op(model, memory, node_vec):\n",
    "    \"\"\"Decode a binary operation node.\"\"\"\n",
    "    # Unbind to extract operator\n",
    "    op_vec = model.opset.bind(node_vec, model.opset.inverse(memory[\"op\"].vec))\n",
    "    operator, op_sim = find_best_match(op_vec, memory, [\"+\", \"-\", \"*\", \"/\"])\n",
    "    \n",
    "    # Unbind to extract left and right children\n",
    "    left_vec = model.opset.bind(node_vec, model.opset.inverse(memory[\"left\"].vec))\n",
    "    right_vec = model.opset.bind(node_vec, model.opset.inverse(memory[\"right\"].vec))\n",
    "    \n",
    "    return operator, left_vec, right_vec, op_sim\n",
    "\n",
    "\n",
    "# Decode the root node\n",
    "print(\"Decoding (2 + 3) * 4:\")\n",
    "print(\"\\nRoot node:\")\n",
    "root_op, root_left, root_right, root_sim = decode_binary_op(model, memory, multiply_node)\n",
    "print(f\"  Operator: {root_op} (similarity: {root_sim:.3f})\")\n",
    "\n",
    "# Try to match right child (should be 4)\n",
    "right_val, right_sim = find_best_match(root_right, memory, [\"2\", \"3\", \"4\", \"5\"])\n",
    "print(f\"  Right child: {right_val} (similarity: {right_sim:.3f})\")\n",
    "\n",
    "# Decode left child (should be the + node)\n",
    "print(\"\\nLeft child (+ node):\")\n",
    "left_op, left_left, left_right, left_sim = decode_binary_op(model, memory, root_left)\n",
    "print(f\"  Operator: {left_op} (similarity: {left_sim:.3f})\")\n",
    "\n",
    "# Decode leaves\n",
    "ll_val, ll_sim = find_best_match(left_left, memory, [\"2\", \"3\", \"4\", \"5\"])\n",
    "lr_val, lr_sim = find_best_match(left_right, memory, [\"2\", \"3\", \"4\", \"5\"])\n",
    "print(f\"  Left child: {ll_val} (similarity: {ll_sim:.3f})\")\n",
    "print(f\"  Right child: {lr_val} (similarity: {lr_sim:.3f})\")\n",
    "\n",
    "print(f\"\\n✓ Reconstructed: ({ll_val} {left_op} {lr_val}) {root_op} {right_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Nested Lists and Data Structures\n",
    "\n",
    "VSA can encode nested data structures like JSON or nested Python lists.\n",
    "\n",
    "**Example**: `[[1, 2], [3, [4, 5]]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_list(model, memory, items):\n",
    "    \"\"\"Encode a list using position binding.\"\"\"\n",
    "    if not items:\n",
    "        return jnp.zeros(model.dim, dtype=jnp.complex64)\n",
    "    \n",
    "    encoded_items = []\n",
    "    for i, item in enumerate(items):\n",
    "        # Create position role\n",
    "        pos_name = f\"pos{i}\"\n",
    "        if pos_name not in memory:\n",
    "            memory.add(pos_name)\n",
    "        \n",
    "        # Encode item (recursively if it's a list)\n",
    "        if isinstance(item, list):\n",
    "            item_vec = encode_list(model, memory, item)\n",
    "        else:\n",
    "            item_vec = encode_leaf(memory, item)\n",
    "        \n",
    "        # Bind position to item\n",
    "        encoded_items.append(model.opset.bind(memory[pos_name].vec, item_vec))\n",
    "    \n",
    "    # Bundle all positioned items\n",
    "    return model.opset.bundle(*encoded_items)\n",
    "\n",
    "\n",
    "# Encode nested list\n",
    "nested_list = [[1, 2], [3, [4, 5]]]\n",
    "encoded_nested = encode_list(model, memory, nested_list)\n",
    "\n",
    "print(f\"Encoded nested list: {nested_list}\")\n",
    "print(f\"Vector shape: {encoded_nested.shape}\")\n",
    "print(f\"\\nThe entire nested structure is now a single vector!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding Nested Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_list_item(model, memory, list_vec, position):\n",
    "    \"\"\"Decode item at given position from encoded list.\"\"\"\n",
    "    pos_name = f\"pos{position}\"\n",
    "    if pos_name not in memory:\n",
    "        return None\n",
    "    \n",
    "    # Unbind position\n",
    "    item_vec = model.opset.bind(list_vec, model.opset.inverse(memory[pos_name].vec))\n",
    "    return item_vec\n",
    "\n",
    "\n",
    "# Try to decode\n",
    "print(\"Decoding nested list [[1, 2], [3, [4, 5]]]:\")\n",
    "print(\"\\nPosition 0 (should be [1, 2]):\")\n",
    "pos0_vec = decode_list_item(model, memory, encoded_nested, 0)\n",
    "if pos0_vec is not None:\n",
    "    item0 = decode_list_item(model, memory, pos0_vec, 0)\n",
    "    item1 = decode_list_item(model, memory, pos0_vec, 1)\n",
    "    val0, _ = find_best_match(item0, memory, [\"1\", \"2\", \"3\", \"4\", \"5\"])\n",
    "    val1, _ = find_best_match(item1, memory, [\"1\", \"2\", \"3\", \"4\", \"5\"])\n",
    "    print(f\"  Items: [{val0}, {val1}]\")\n",
    "\n",
    "print(\"\\nPosition 1 (should be [3, [4, 5]]):\")\n",
    "pos1_vec = decode_list_item(model, memory, encoded_nested, 1)\n",
    "if pos1_vec is not None:\n",
    "    item0 = decode_list_item(model, memory, pos1_vec, 0)\n",
    "    val0, _ = find_best_match(item0, memory, [\"1\", \"2\", \"3\", \"4\", \"5\"])\n",
    "    print(f\"  First item: {val0}\")\n",
    "    \n",
    "    # Nested list at position 1\n",
    "    nested = decode_list_item(model, memory, pos1_vec, 1)\n",
    "    if nested is not None:\n",
    "        n0 = decode_list_item(model, memory, nested, 0)\n",
    "        n1 = decode_list_item(model, memory, nested, 1)\n",
    "        nv0, _ = find_best_match(n0, memory, [\"1\", \"2\", \"3\", \"4\", \"5\"])\n",
    "        nv1, _ = find_best_match(n1, memory, [\"1\", \"2\", \"3\", \"4\", \"5\"])\n",
    "        print(f\"  Nested list: [{nv0}, {nv1}]\")\n",
    "\n",
    "print(\"\\n✓ Successfully decoded nested structure!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Parse Trees (Sentence Structure)\n",
    "\n",
    "Encode syntactic structure of sentences.\n",
    "\n",
    "**Sentence**: \"The dog chased the cat\"\n",
    "\n",
    "**Parse tree**:\n",
    "```\n",
    "         S\n",
    "        / \\\n",
    "       NP  VP\n",
    "      /    / \\\n",
    "   det+N  V   NP\n",
    "   |   |  |   |\n",
    "  the dog chased det+N\n",
    "                |\n",
    "              the cat\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_phrase(model, memory, phrase_type, *children):\n",
    "    \"\"\"Encode a syntactic phrase with children.\"\"\"\n",
    "    # Add phrase type\n",
    "    if phrase_type not in memory:\n",
    "        memory.add(phrase_type)\n",
    "    \n",
    "    # Type vector\n",
    "    type_vec = model.opset.bind(memory[\"value\"].vec, memory[phrase_type].vec)\n",
    "    \n",
    "    # Children vectors\n",
    "    child_vecs = [type_vec]\n",
    "    for i, child in enumerate(children):\n",
    "        role_name = f\"child{i}\"\n",
    "        if role_name not in memory:\n",
    "            memory.add(role_name)\n",
    "        child_vecs.append(model.opset.bind(memory[role_name].vec, child))\n",
    "    \n",
    "    return model.opset.bundle(*child_vecs)\n",
    "\n",
    "\n",
    "# Encode \"the dog\"\n",
    "the1 = encode_leaf(memory, \"the\")\n",
    "dog = encode_leaf(memory, \"dog\")\n",
    "np1 = encode_phrase(model, memory, \"NP\", the1, dog)\n",
    "\n",
    "# Encode \"chased\"\n",
    "chased = encode_leaf(memory, \"chased\")\n",
    "\n",
    "# Encode \"the cat\"\n",
    "the2 = encode_leaf(memory, \"the\")\n",
    "cat = encode_leaf(memory, \"cat\")\n",
    "np2 = encode_phrase(model, memory, \"NP\", the2, cat)\n",
    "\n",
    "# Encode VP \"chased the cat\"\n",
    "vp = encode_phrase(model, memory, \"VP\", chased, np2)\n",
    "\n",
    "# Encode S \"the dog chased the cat\"\n",
    "sentence = encode_phrase(model, memory, \"S\", np1, vp)\n",
    "\n",
    "print(\"Encoded sentence: 'The dog chased the cat'\")\n",
    "print(f\"Parse tree vector shape: {sentence.shape}\")\n",
    "print(\"\\nSyntactic structure preserved in a single vector!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Family Trees (Genealogy)\n",
    "\n",
    "Encode family relationships with recursive parent-child structure.\n",
    "\n",
    "**Family**:\n",
    "```\n",
    "    Alice (50)\n",
    "    /       \\\n",
    "Bob (30)   Carol (28)\n",
    "   |           |\n",
    "David (5)   Eve (3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_person(model, memory, name, age, children=None):\n",
    "    \"\"\"Encode a person with name, age, and children.\"\"\"\n",
    "    # Add name\n",
    "    if name not in memory:\n",
    "        memory.add(name)\n",
    "    \n",
    "    # Add age\n",
    "    age_str = f\"age{age}\"\n",
    "    if age_str not in memory:\n",
    "        memory.add(age_str)\n",
    "    \n",
    "    # Encode: name + age\n",
    "    name_vec = model.opset.bind(memory[\"name\"].vec, memory[name].vec)\n",
    "    age_vec = model.opset.bind(memory[\"age\"].vec, memory[age_str].vec)\n",
    "    \n",
    "    components = [name_vec, age_vec]\n",
    "    \n",
    "    # Add children if present\n",
    "    if children:\n",
    "        for i, child in enumerate(children):\n",
    "            child_role = f\"child{i}\"\n",
    "            if child_role not in memory:\n",
    "                memory.add(child_role)\n",
    "            components.append(model.opset.bind(memory[child_role].vec, child))\n",
    "    \n",
    "    return model.opset.bundle(*components)\n",
    "\n",
    "\n",
    "# Build family tree bottom-up\n",
    "david = encode_person(model, memory, \"David\", 5)\n",
    "eve = encode_person(model, memory, \"Eve\", 3)\n",
    "bob = encode_person(model, memory, \"Bob\", 30, children=[david])\n",
    "carol = encode_person(model, memory, \"Carol\", 28, children=[eve])\n",
    "alice = encode_person(model, memory, \"Alice\", 50, children=[bob, carol])\n",
    "\n",
    "print(\"Encoded family tree:\")\n",
    "print(\"  Alice (50) has children Bob (30) and Carol (28)\")\n",
    "print(\"  Bob has child David (5)\")\n",
    "print(\"  Carol has child Eve (3)\")\n",
    "print(f\"\\nEntire family tree in a single {model.dim}-dimensional vector!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Family Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Who are Alice's children?\n",
    "print(\"Query: Who are Alice's children?\\n\")\n",
    "\n",
    "# Extract first child\n",
    "child0_vec = model.opset.bind(alice, model.opset.inverse(memory[\"child0\"].vec))\n",
    "child0_name = model.opset.bind(child0_vec, model.opset.inverse(memory[\"name\"].vec))\n",
    "name0, sim0 = find_best_match(child0_name, memory, [\"Alice\", \"Bob\", \"Carol\", \"David\", \"Eve\"])\n",
    "print(f\"First child: {name0} (similarity: {sim0:.3f})\")\n",
    "\n",
    "# Extract second child\n",
    "child1_vec = model.opset.bind(alice, model.opset.inverse(memory[\"child1\"].vec))\n",
    "child1_name = model.opset.bind(child1_vec, model.opset.inverse(memory[\"name\"].vec))\n",
    "name1, sim1 = find_best_match(child1_name, memory, [\"Alice\", \"Bob\", \"Carol\", \"David\", \"Eve\"])\n",
    "print(f\"Second child: {name1} (similarity: {sim1:.3f})\")\n",
    "\n",
    "# Query: Who is Bob's child?\n",
    "print(\"\\nQuery: Who is Bob's child?\\n\")\n",
    "bob_child_vec = model.opset.bind(bob, model.opset.inverse(memory[\"child0\"].vec))\n",
    "bob_child_name = model.opset.bind(bob_child_vec, model.opset.inverse(memory[\"name\"].vec))\n",
    "bc_name, bc_sim = find_best_match(bob_child_name, memory, [\"Alice\", \"Bob\", \"Carol\", \"David\", \"Eve\"])\n",
    "print(f\"Bob's child: {bc_name} (similarity: {bc_sim:.3f})\")\n",
    "\n",
    "print(\"\\n✓ Successfully queried hierarchical family relationships!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resonator Networks: Iterative Factorization\n",
    "\n",
    "For complex or deeply nested structures, **resonator networks** provide iterative refinement to decode structures more accurately.\n",
    "\n",
    "**How it works:**\n",
    "1. Start with noisy estimates of components\n",
    "2. Iteratively refine by \"resonating\" with the encoded vector\n",
    "3. Components converge to clean solutions\n",
    "\n",
    "This is especially powerful for:\n",
    "- Deep nesting (many levels)\n",
    "- Noisy encoding\n",
    "- Multiple bindings to factor simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use resonator to decode arithmetic expression\n",
    "print(\"Using Resonator Network to decode (2 + 3) * 4:\\n\")\n",
    "\n",
    "# Create resonator\n",
    "resonator = ResonatorNetwork(\n",
    "    model=model,\n",
    "    max_iterations=50,\n",
    "    threshold=0.95\n",
    ")\n",
    "\n",
    "# Define cleanup memory (candidates for decoding)\n",
    "cleanup_items = {\n",
    "    \"op\": memory[\"op\"].vec,\n",
    "    \"left\": memory[\"left\"].vec,\n",
    "    \"right\": memory[\"right\"].vec,\n",
    "    \"+\": memory[\"+\"].vec,\n",
    "    \"*\": memory[\"*\"].vec,\n",
    "    \"2\": memory[\"2\"].vec,\n",
    "    \"3\": memory[\"3\"].vec,\n",
    "    \"4\": memory[\"4\"].vec,\n",
    "}\n",
    "\n",
    "# Factorize the multiply node\n",
    "print(\"Factorizing root node (* operation):\")\n",
    "factors_root = resonator.factorize(\n",
    "    composite=multiply_node,\n",
    "    codebook=cleanup_items,\n",
    "    n_factors=3  # op, left, right\n",
    ")\n",
    "\n",
    "print(f\"\\nFactors found: {list(factors_root.keys())}\")\n",
    "print(\"\\nResonator successfully factorized the tree structure!\")\n",
    "print(\"This allows automatic decoding without manual unbinding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **VSA can encode hierarchical structures** through recursive role-filler binding\n",
    "2. **Trees become single vectors** - entire structure compressed holistically\n",
    "3. **Exact unbinding** (with FHRR) allows precise decoding of nested levels\n",
    "4. **Compositionality** - complex structures built from simple primitives\n",
    "5. **Resonator networks** provide iterative refinement for robust decoding\n",
    "\n",
    "## Applications\n",
    "\n",
    "Hierarchical encoding is powerful for:\n",
    "\n",
    "1. **Natural Language Processing**\n",
    "   - Parse trees for syntax\n",
    "   - Semantic composition\n",
    "   - Discourse structure\n",
    "\n",
    "2. **Program Analysis**\n",
    "   - Abstract syntax trees (AST)\n",
    "   - Code structure representation\n",
    "   - Program synthesis\n",
    "\n",
    "3. **Knowledge Representation**\n",
    "   - Ontologies and taxonomies\n",
    "   - Conceptual hierarchies\n",
    "   - Nested relationships\n",
    "\n",
    "4. **Data Structures**\n",
    "   - JSON/XML encoding\n",
    "   - Nested dictionaries\n",
    "   - Graph structures\n",
    "\n",
    "## Advantages Over Flat Representations\n",
    "\n",
    "| Feature | Flat (Bag-of-Words) | VSA Hierarchical |\n",
    "|---------|---------------------|------------------|\n",
    "| **Structure** | Lost | Preserved |\n",
    "| **Nesting** | Cannot represent | Arbitrary depth |\n",
    "| **Compositionality** | Additive only | Recursive binding |\n",
    "| **Decoding** | N/A | Exact unbinding |\n",
    "| **Semantics** | Weak | Compositional |\n",
    "\n",
    "## Challenges & Limitations\n",
    "\n",
    "1. **Noise accumulation** - Deep nesting can degrade signal (use higher dimensions)\n",
    "2. **Cleanup required** - Decoding needs candidate symbols (cleanup memory)\n",
    "3. **Variable structure** - Different tree shapes need different decoding strategies\n",
    "4. **Computational cost** - Resonator iteration can be expensive\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try encoding your own tree structures\n",
    "- Experiment with deeper nesting (3+ levels)\n",
    "- Compare FHRR vs MAP vs Binary for hierarchical encoding\n",
    "- Explore resonator networks for robust factorization\n",
    "- Apply to real datasets (syntax trees, JSON, org charts)\n",
    "\n",
    "## References\n",
    "\n",
    "- Plate, T. A. (1995). \"Holographic Reduced Representations\"\n",
    "- Kanerva, P. (2009). \"Hyperdimensional Computing\"\n",
    "- Frady et al. (2020). \"Resonator Networks for Factoring Distributed Representations\"\n",
    "- Gayler, R. W. (2003). \"Vector Symbolic Architectures answer Jackendoff's challenges for cognitive neuroscience\"\n",
    "\n",
    "## Running This Tutorial\n",
    "\n",
    "```bash\n",
    "jupyter notebook examples/notebooks/tutorial_07_hierarchical_structures.ipynb\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
