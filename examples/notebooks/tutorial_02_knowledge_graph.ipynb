{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Knowledge Graph Reasoning with VSAX\n",
    "\n",
    "This tutorial demonstrates how to use Vector Symbolic Architectures (VSAs) for knowledge graph representation and reasoning.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Encode knowledge as relational triples (subject-relation-object)\n",
    "- Build and query a knowledge base using VSA\n",
    "- Use resonator networks to factorize compositional structures\n",
    "- Perform multi-hop reasoning to infer new knowledge\n",
    "- Compare different VSA models for knowledge representation\n",
    "\n",
    "## Why VSA for Knowledge Graphs?\n",
    "\n",
    "VSAs offer several advantages for knowledge representation:\n",
    "\n",
    "1. **Compositional**: Facts can be composed using binding operations\n",
    "2. **Distributed**: Knowledge is spread across high-dimensional vectors\n",
    "3. **Robust**: Tolerant to noise and partial information\n",
    "4. **Efficient**: Constant-time operations regardless of knowledge base size\n",
    "5. **Analogical**: Similar facts have similar representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from vsax import create_fhrr_model, create_map_model, create_binary_model\n",
    "from vsax import VSAMemory\n",
    "from vsax.encoders import GraphEncoder\n",
    "from vsax.resonator import CleanupMemory, Resonator\n",
    "from vsax.similarity import cosine_similarity\n",
    "from vsax.utils import format_similarity_results\n",
    "\n",
    "# Create FHRR model (best for exact unbinding)\n",
    "model = create_fhrr_model(dim=512)\n",
    "memory = VSAMemory(model)\n",
    "\n",
    "print(f\"Model: {model.rep_cls.__name__}\")\n",
    "print(f\"Dimension: {model.dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Knowledge Base\n",
    "\n",
    "We'll create a simple animal taxonomy with:\n",
    "- **Taxonomy relations**: X isA Y (dog isA mammal)\n",
    "- **Property relations**: X hasProperty Y (dog hasProperty fur)\n",
    "- **Action relations**: X can Y (dog can bark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all concepts we'll need\n",
    "concepts = [\n",
    "    # Animals\n",
    "    \"dog\", \"cat\", \"bird\", \"fish\", \"snake\",\n",
    "    # Categories\n",
    "    \"mammal\", \"reptile\", \"animal\",\n",
    "    # Relations\n",
    "    \"isA\", \"hasProperty\", \"can\",\n",
    "    # Properties\n",
    "    \"fur\", \"feathers\", \"scales\", \"warm_blooded\", \"cold_blooded\",\n",
    "    # Actions\n",
    "    \"bark\", \"meow\", \"fly\", \"swim\", \"slither\"\n",
    "]\n",
    "\n",
    "# Add all concepts to memory\n",
    "memory.add_many(concepts)\n",
    "print(f\"Knowledge base contains {len(memory)} concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define knowledge as triples: (subject, relation, object)\n",
    "facts = [\n",
    "    # Taxonomy\n",
    "    (\"dog\", \"isA\", \"mammal\"),\n",
    "    (\"cat\", \"isA\", \"mammal\"),\n",
    "    (\"bird\", \"isA\", \"animal\"),\n",
    "    (\"fish\", \"isA\", \"animal\"),\n",
    "    (\"snake\", \"isA\", \"reptile\"),\n",
    "    (\"mammal\", \"isA\", \"animal\"),\n",
    "    (\"reptile\", \"isA\", \"animal\"),\n",
    "    \n",
    "    # Properties\n",
    "    (\"dog\", \"hasProperty\", \"fur\"),\n",
    "    (\"cat\", \"hasProperty\", \"fur\"),\n",
    "    (\"bird\", \"hasProperty\", \"feathers\"),\n",
    "    (\"fish\", \"hasProperty\", \"scales\"),\n",
    "    (\"snake\", \"hasProperty\", \"scales\"),\n",
    "    (\"mammal\", \"hasProperty\", \"warm_blooded\"),\n",
    "    (\"reptile\", \"hasProperty\", \"cold_blooded\"),\n",
    "    \n",
    "    # Actions\n",
    "    (\"dog\", \"can\", \"bark\"),\n",
    "    (\"cat\", \"can\", \"meow\"),\n",
    "    (\"bird\", \"can\", \"fly\"),\n",
    "    (\"fish\", \"can\", \"swim\"),\n",
    "    (\"snake\", \"can\", \"slither\"),\n",
    "]\n",
    "\n",
    "print(f\"Knowledge base contains {len(facts)} facts\")\n",
    "print(\"\\nSample facts:\")\n",
    "for fact in facts[:5]:\n",
    "    print(f\"  {fact[0]} {fact[1]} {fact[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Facts as Hypervectors\n",
    "\n",
    "Each fact (subject, relation, object) is encoded as:\n",
    "```\n",
    "fact = bind(subject, bind(relation, object))\n",
    "```\n",
    "\n",
    "This allows us to:\n",
    "- Query for objects given subject and relation\n",
    "- Query for relations given subject and object\n",
    "- Factorize facts using resonator networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store individual facts\n",
    "fact_hvs = {}\n",
    "\n",
    "for subject, relation, obj in facts:\n",
    "    s_hv = memory[subject]\n",
    "    r_hv = memory[relation]\n",
    "    o_hv = memory[obj]\n",
    "    \n",
    "    # Encode: bind(subject, bind(relation, object))\n",
    "    ro = model.opset.bind(r_hv.vec, o_hv.vec)\n",
    "    fact_hv = model.opset.bind(s_hv.vec, ro)\n",
    "    \n",
    "    fact_hvs[(subject, relation, obj)] = model.rep_cls(fact_hv)\n",
    "\n",
    "print(f\"Encoded {len(fact_hvs)} facts as hypervectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the Knowledge Base\n",
    "\n",
    "We can query facts by unbinding (using inverse operation):\n",
    "\n",
    "**Query: \"What is a dog?\"** (dog isA ?)\n",
    "```\n",
    "query = unbind(fact, bind(dog, isA))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_fact(subject: str, relation: str) -> str:\n",
    "    \"\"\"Query: subject + relation -> object\"\"\"\n",
    "    # Find the matching fact\n",
    "    for (s, r, o), fact_hv in fact_hvs.items():\n",
    "        if s == subject and r == relation:\n",
    "            # Unbind to get the object\n",
    "            s_hv = memory[subject]\n",
    "            r_hv = memory[relation]\n",
    "            \n",
    "            # query = unbind(fact, bind(subject, relation))\n",
    "            sr = model.opset.bind(s_hv.vec, r_hv.vec)\n",
    "            query_result = model.opset.bind(fact_hv.vec, model.opset.inverse(sr))\n",
    "            \n",
    "            # Find most similar concept\n",
    "            similarities = {}\n",
    "            for concept in concepts:\n",
    "                sim = cosine_similarity(query_result, memory[concept].vec)\n",
    "                similarities[concept] = sim\n",
    "            \n",
    "            best_match = max(similarities, key=similarities.get)\n",
    "            confidence = similarities[best_match]\n",
    "            \n",
    "            return f\"{best_match} (confidence: {confidence:.3f})\"\n",
    "    \n",
    "    return \"No fact found\"\n",
    "\n",
    "# Test queries\n",
    "print(\"Querying the knowledge base:\")\n",
    "print(f\"dog isA? -> {query_fact('dog', 'isA')}\")\n",
    "print(f\"cat isA? -> {query_fact('cat', 'isA')}\")\n",
    "print(f\"dog hasProperty? -> {query_fact('dog', 'hasProperty')}\")\n",
    "print(f\"dog can? -> {query_fact('dog', 'can')}\")\n",
    "print(f\"bird can? -> {query_fact('bird', 'can')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization with Resonator Networks\n",
    "\n",
    "Given a composite fact, we can use resonators to decode its components:\n",
    "- Input: A fact hypervector\n",
    "- Output: The (subject, relation, object) triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cleanup memories for each category\n",
    "animals = [\"dog\", \"cat\", \"bird\", \"fish\", \"snake\"]\n",
    "relations = [\"isA\", \"hasProperty\", \"can\"]\n",
    "all_objects = [\"mammal\", \"reptile\", \"animal\", \"fur\", \"feathers\", \"scales\", \n",
    "               \"warm_blooded\", \"cold_blooded\", \"bark\", \"meow\", \"fly\", \"swim\", \"slither\"]\n",
    "\n",
    "subject_cleanup = CleanupMemory(model, memory, animals)\n",
    "relation_cleanup = CleanupMemory(model, memory, relations)\n",
    "object_cleanup = CleanupMemory(model, memory, all_objects)\n",
    "\n",
    "# Create resonator\n",
    "resonator = Resonator(\n",
    "    model=model,\n",
    "    codebooks=[subject_cleanup, relation_cleanup, object_cleanup],\n",
    "    max_iterations=20,\n",
    "    convergence_threshold=0.95\n",
    ")\n",
    "\n",
    "print(f\"Created resonator with {len(resonator.codebooks)} codebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test factorization\n",
    "test_facts = [\n",
    "    (\"dog\", \"isA\", \"mammal\"),\n",
    "    (\"bird\", \"can\", \"fly\"),\n",
    "    (\"snake\", \"hasProperty\", \"scales\"),\n",
    "]\n",
    "\n",
    "print(\"Factorizing facts with resonator:\\n\")\n",
    "for subject, relation, obj in test_facts:\n",
    "    fact_hv = fact_hvs[(subject, relation, obj)]\n",
    "    \n",
    "    # Factorize\n",
    "    factors = resonator.factorize(fact_hv.vec, return_history=False)\n",
    "    \n",
    "    print(f\"Original: ({subject}, {relation}, {obj})\")\n",
    "    print(f\"Decoded:  ({factors[0]}, {factors[1]}, {factors[2]})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-hop Reasoning\n",
    "\n",
    "VSAs enable multi-hop reasoning through composition:\n",
    "\n",
    "**Example**: If \"dog isA mammal\" and \"mammal isA animal\", then \"dog isA animal\"\n",
    "\n",
    "We can compose facts by:\n",
    "1. Unbinding to get intermediate results\n",
    "2. Binding with new relations\n",
    "3. Querying the composed structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_hop_query(start: str, relation1: str, relation2: str) -> str:\n",
    "    \"\"\"Two-hop query: start -relation1-> X -relation2-> ?\"\"\"\n",
    "    \n",
    "    # First hop: start -relation1-> intermediate\n",
    "    intermediate = None\n",
    "    for (s, r, o), fact_hv in fact_hvs.items():\n",
    "        if s == start and r == relation1:\n",
    "            intermediate = o\n",
    "            break\n",
    "    \n",
    "    if intermediate is None:\n",
    "        return \"No path found\"\n",
    "    \n",
    "    # Second hop: intermediate -relation2-> result\n",
    "    result = None\n",
    "    for (s, r, o), fact_hv in fact_hvs.items():\n",
    "        if s == intermediate and r == relation2:\n",
    "            result = o\n",
    "            break\n",
    "    \n",
    "    if result is None:\n",
    "        return f\"Reached {intermediate}, but no further\"\n",
    "    \n",
    "    return f\"{start} -{relation1}-> {intermediate} -{relation2}-> {result}\"\n",
    "\n",
    "print(\"Multi-hop reasoning:\\n\")\n",
    "print(multi_hop_query(\"dog\", \"isA\", \"isA\"))  # dog -> mammal -> animal\n",
    "print(multi_hop_query(\"cat\", \"isA\", \"isA\"))  # cat -> mammal -> animal\n",
    "print(multi_hop_query(\"snake\", \"isA\", \"isA\"))  # snake -> reptile -> animal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property Inheritance\n",
    "\n",
    "We can infer inherited properties through the taxonomy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_properties(animal: str) -> list[str]:\n",
    "    \"\"\"Get direct and inherited properties of an animal.\"\"\"\n",
    "    properties = []\n",
    "    \n",
    "    # Direct properties\n",
    "    for (s, r, o), _ in fact_hvs.items():\n",
    "        if s == animal and r == \"hasProperty\":\n",
    "            properties.append(f\"{o} (direct)\")\n",
    "    \n",
    "    # Find category\n",
    "    category = None\n",
    "    for (s, r, o), _ in fact_hvs.items():\n",
    "        if s == animal and r == \"isA\":\n",
    "            category = o\n",
    "            break\n",
    "    \n",
    "    # Inherited properties from category\n",
    "    if category:\n",
    "        for (s, r, o), _ in fact_hvs.items():\n",
    "            if s == category and r == \"hasProperty\":\n",
    "                properties.append(f\"{o} (inherited from {category})\")\n",
    "    \n",
    "    return properties\n",
    "\n",
    "print(\"Property inheritance:\\n\")\n",
    "for animal in [\"dog\", \"cat\", \"snake\"]:\n",
    "    props = get_all_properties(animal)\n",
    "    print(f\"{animal}:\")\n",
    "    for prop in props:\n",
    "        print(f\"  - {prop}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Complete Knowledge Graph\n",
    "\n",
    "Let's bundle all facts into a single knowledge graph hypervector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle all facts\n",
    "all_fact_vecs = [fact_hv.vec for fact_hv in fact_hvs.values()]\n",
    "knowledge_graph = model.opset.bundle(*all_fact_vecs)\n",
    "knowledge_graph_hv = model.rep_cls(knowledge_graph)\n",
    "\n",
    "print(f\"Created knowledge graph with {len(facts)} facts\")\n",
    "print(f\"Shape: {knowledge_graph_hv.shape}\")\n",
    "print(f\"Type: {type(knowledge_graph_hv).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the bundled knowledge graph\n",
    "def query_kg(subject: str, relation: str) -> list[tuple[str, float]]:\n",
    "    \"\"\"Query the bundled knowledge graph for similar objects.\"\"\"\n",
    "    s_hv = memory[subject]\n",
    "    r_hv = memory[relation]\n",
    "    \n",
    "    # Unbind subject and relation from the knowledge graph\n",
    "    sr = model.opset.bind(s_hv.vec, r_hv.vec)\n",
    "    query_result = model.opset.bind(knowledge_graph, model.opset.inverse(sr))\n",
    "    \n",
    "    # Find similar concepts\n",
    "    results = []\n",
    "    for concept in all_objects:\n",
    "        sim = cosine_similarity(query_result, memory[concept].vec)\n",
    "        results.append((concept, float(sim)))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results[:5]\n",
    "\n",
    "print(\"Querying bundled knowledge graph:\\n\")\n",
    "print(\"dog isA ...\")\n",
    "for obj, sim in query_kg(\"dog\", \"isA\"):\n",
    "    print(f\"  {obj}: {sim:.3f}\")\n",
    "\n",
    "print(\"\\nbird hasProperty ...\")\n",
    "for obj, sim in query_kg(\"bird\", \"hasProperty\"):\n",
    "    print(f\"  {obj}: {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing VSA Models\n",
    "\n",
    "Let's compare FHRR, MAP, and Binary models for knowledge graph tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_name: str, model, dim: int = 512):\n",
    "    \"\"\"Test a VSA model on knowledge graph encoding/decoding.\"\"\"\n",
    "    memory = VSAMemory(model)\n",
    "    memory.add_many(concepts)\n",
    "    \n",
    "    # Encode a test fact\n",
    "    subject, relation, obj = \"dog\", \"isA\", \"mammal\"\n",
    "    s_hv = memory[subject]\n",
    "    r_hv = memory[relation]\n",
    "    o_hv = memory[obj]\n",
    "    \n",
    "    ro = model.opset.bind(r_hv.vec, o_hv.vec)\n",
    "    fact_hv = model.opset.bind(s_hv.vec, ro)\n",
    "    \n",
    "    # Unbind and query\n",
    "    sr = model.opset.bind(s_hv.vec, r_hv.vec)\n",
    "    query_result = model.opset.bind(fact_hv, model.opset.inverse(sr))\n",
    "    \n",
    "    # Find similarity to correct answer\n",
    "    similarity = cosine_similarity(query_result, o_hv.vec)\n",
    "    \n",
    "    return float(similarity)\n",
    "\n",
    "models_to_test = [\n",
    "    (\"FHRR\", create_fhrr_model(dim=512)),\n",
    "    (\"MAP\", create_map_model(dim=512)),\n",
    "    (\"Binary\", create_binary_model(dim=10000)),  # Binary needs higher dim\n",
    "]\n",
    "\n",
    "print(\"Model comparison (unbinding accuracy):\\n\")\n",
    "for name, model in models_to_test:\n",
    "    accuracy = test_model(name, model)\n",
    "    print(f\"{name:10s}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Compositional Encoding**: Facts are encoded as `bind(subject, bind(relation, object))`\n",
    "2. **Efficient Querying**: Unbinding allows constant-time queries\n",
    "3. **Factorization**: Resonators can decode compositional structures\n",
    "4. **Multi-hop Reasoning**: Chaining facts enables inference\n",
    "5. **Property Inheritance**: Taxonomic relationships support reasoning\n",
    "6. **Model Choice**: FHRR provides exact unbinding, best for knowledge graphs\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try larger knowledge bases\n",
    "- Implement more complex reasoning patterns\n",
    "- Experiment with analogical reasoning\n",
    "- Combine with neural networks for hybrid approaches\n",
    "- Explore temporal reasoning (adding time as a dimension)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
