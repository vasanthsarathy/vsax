# VSAX: Vector Symbolic Algebra for JAX

VSAX is a GPU-accelerated, JAX-native Python library for Vector Symbolic Architectures (VSAs). It provides composable symbolic representations using hypervectors, algebraic operations for binding and bundling, and encoding strategies for symbolic and structured data.

## Features

- üöÄ **Three VSA Models**: FHRR, MAP, and Binary implementations ‚úÖ
- ‚ö° **GPU-Accelerated**: Built on JAX for high-performance computation
- üß© **Modular Architecture**: Clean separation between representations and operations
- üß¨ **Complete Representations**: Complex, Real, and Binary hypervectors ‚úÖ
- ‚öôÔ∏è **Full Operation Sets**: FFT-based FHRR, MAP, and XOR/majority Binary ops ‚úÖ
- üé≤ **Random Sampling**: Sampling utilities for all representation types ‚úÖ
- üíØ **Type-Safe**: Full type annotations with mypy support
- ‚úÖ **Well-Tested**: 339 tests with 96% coverage
- üîç **Similarity Metrics**: Cosine, dot, and Hamming similarity
- ‚ö° **Batch Operations**: GPU-accelerated vmap operations
- üíæ **I/O & Persistence**: Save/load basis vectors to JSON

## Installation

### From PyPI (Recommended)

```bash
pip install vsax
```

### From Source

```bash
git clone https://github.com/yourusername/vsax.git
cd vsax

# Using uv (recommended)
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -e ".[dev]"

# Or using pip
pip install -e ".[dev]"
```

## Quick Example

### Simple API (v0.5.0)

```python
from vsax import create_fhrr_model, VSAMemory, DictEncoder
from vsax.similarity import cosine_similarity
from vsax.utils import vmap_bind
import jax.numpy as jnp

# Create model with factory function
model = create_fhrr_model(dim=512)

# Create memory for symbols
memory = VSAMemory(model)
memory.add_many(["dog", "cat", "animal", "run", "jump"])

# Access and manipulate symbols
dog = memory["dog"]
animal = memory["animal"]

# Bind two concepts (circular convolution)
dog_is_animal = model.opset.bind(dog.vec, animal.vec)

# Bundle multiple concepts (sum and normalize)
pets = model.opset.bundle(memory["dog"].vec, memory["cat"].vec)

# NEW: Similarity search
similarity = cosine_similarity(memory["dog"], memory["cat"])
print(f"Dog-Cat similarity: {similarity:.3f}")

# NEW: Batch operations (GPU-accelerated)
nouns = jnp.stack([memory["dog"].vec, memory["cat"].vec])
verbs = jnp.stack([memory["run"].vec, memory["jump"].vec])
actions = vmap_bind(model.opset, nouns, verbs)  # Parallel binding!

# NEW: Encoders
encoder = DictEncoder(model, memory)
sentence = encoder.encode({"subject": "dog", "action": "run"})
```

### MAP Model (Real Hypervectors)

```python
from vsax import RealHypervector, MAPOperations, sample_random

model = VSAModel(
    dim=512,
    rep_cls=RealHypervector,
    opset=MAPOperations(),
    sampler=sample_random
)

# Element-wise multiplication for binding
# Element-wise mean for bundling
```

### Binary Model (Bipolar Hypervectors)

```python
from vsax import BinaryHypervector, BinaryOperations, sample_binary_random

model = VSAModel(
    dim=512,
    rep_cls=BinaryHypervector,
    opset=BinaryOperations(),
    sampler=sample_binary_random
)

# XOR binding (exact unbinding)
# Majority voting for bundling
```

## Development Status

**Current**: Iteration 6 Complete ‚úÖ

### Completed

**Iteration 1** (v0.1.0): Foundation & Infrastructure ‚úÖ
- ‚úÖ Core abstract classes (AbstractHypervector, AbstractOpSet)
- ‚úÖ VSAModel dataclass
- ‚úÖ Package structure
- ‚úÖ Testing infrastructure (pytest, coverage)
- ‚úÖ CI/CD pipeline (GitHub Actions)
- ‚úÖ Documentation site (MkDocs)

**Iteration 2** (v0.2.0): Core Algebras ‚úÖ
- ‚úÖ All 3 representations (Complex, Real, Binary)
- ‚úÖ All 3 operation sets (FHRR, MAP, Binary)
- ‚úÖ Sampling utilities
- ‚úÖ 175 comprehensive tests with 96% coverage
- ‚úÖ Full integration tests

**Iteration 3** (v0.3.0): Models & Memory ‚úÖ
- ‚úÖ VSAMemory for symbol storage
- ‚úÖ Factory functions for easy model creation
- ‚úÖ Integration utilities
- ‚úÖ 230 tests with 89% coverage

**Iteration 4** (v0.4.0): First Usable Release ‚úÖ
- ‚úÖ 5 Core Encoders (Scalar, Sequence, Set, Dict, Graph)
- ‚úÖ AbstractEncoder base class
- ‚úÖ Complete working examples for all 3 models
- ‚úÖ Custom encoder examples
- ‚úÖ 280+ tests with 92%+ coverage

**Iteration 5** (v0.5.0): Similarity Metrics & Utilities ‚úÖ
- ‚úÖ Cosine, dot, and Hamming similarity functions
- ‚úÖ Batch operations with JAX vmap (vmap_bind, vmap_bundle, vmap_similarity)
- ‚úÖ Visualization utilities (pretty_repr, format_similarity_results)
- ‚úÖ GPU-accelerated similarity search
- ‚úÖ 319 tests with 95%+ coverage

**Iteration 6** (v0.6.0): I/O & Persistence ‚úÖ
- ‚úÖ save_basis() and load_basis() functions
- ‚úÖ JSON serialization for all 3 models
- ‚úÖ Round-trip vector preservation
- ‚úÖ Dimension and type validation
- ‚úÖ 339 tests with 96% coverage

### Coming Next

**Iteration 7** (v1.0.0): Full Documentation & Production Release
- Complete API documentation
- Tutorial notebooks
- Production-ready v1.0.0 release

## Documentation

- [Getting Started](getting-started.md) - Installation and first steps
- [User Guide](guide/representations.md) - Detailed guides for all components
- [Examples](examples/fhrr.md) - Working examples for all three models
- [API Reference](api/index.md) - Complete API documentation
- [Design Specification](design-spec.md) - Technical design details

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](https://github.com/yourusername/vsax/blob/main/CONTRIBUTING.md) for guidelines.

## License

VSAX is released under the MIT License. See [LICENSE](https://github.com/yourusername/vsax/blob/main/LICENSE) for details.

## Citation

If you use VSAX in your research, please cite:

```bibtex
@software{vsax2025,
  title = {VSAX: Vector Symbolic Algebra for JAX},
  author = {Sarathy, Vasanth},
  year = {2025},
  version = {0.7.1},
  url = {https://github.com/vasanthsarathy/vsax}
}
```
